{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"tension_strenght\": \"tensile_strength\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_height</th>\n",
       "      <th>wall_thickness</th>\n",
       "      <th>infill_density</th>\n",
       "      <th>infill_pattern</th>\n",
       "      <th>nozzle_temperature</th>\n",
       "      <th>bed_temperature</th>\n",
       "      <th>print_speed</th>\n",
       "      <th>material</th>\n",
       "      <th>fan_speed</th>\n",
       "      <th>roughness</th>\n",
       "      <th>tensile_strength</th>\n",
       "      <th>elongation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "      <td>grid</td>\n",
       "      <td>220</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>abs</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>225</td>\n",
       "      <td>65</td>\n",
       "      <td>40</td>\n",
       "      <td>abs</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>grid</td>\n",
       "      <td>230</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>abs</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>240</td>\n",
       "      <td>75</td>\n",
       "      <td>40</td>\n",
       "      <td>abs</td>\n",
       "      <td>75</td>\n",
       "      <td>68</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>grid</td>\n",
       "      <td>250</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>abs</td>\n",
       "      <td>100</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>pla</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>24</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.02</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>grid</td>\n",
       "      <td>205</td>\n",
       "      <td>65</td>\n",
       "      <td>40</td>\n",
       "      <td>pla</td>\n",
       "      <td>25</td>\n",
       "      <td>55</td>\n",
       "      <td>12</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.02</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>pla</td>\n",
       "      <td>50</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.02</td>\n",
       "      <td>9</td>\n",
       "      <td>70</td>\n",
       "      <td>grid</td>\n",
       "      <td>215</td>\n",
       "      <td>75</td>\n",
       "      <td>40</td>\n",
       "      <td>pla</td>\n",
       "      <td>75</td>\n",
       "      <td>24</td>\n",
       "      <td>27</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.02</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>220</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>pla</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.06</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>grid</td>\n",
       "      <td>220</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>abs</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>37</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.06</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>225</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>abs</td>\n",
       "      <td>25</td>\n",
       "      <td>92</td>\n",
       "      <td>12</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.06</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>grid</td>\n",
       "      <td>230</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>abs</td>\n",
       "      <td>50</td>\n",
       "      <td>118</td>\n",
       "      <td>16</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.06</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>240</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>abs</td>\n",
       "      <td>75</td>\n",
       "      <td>200</td>\n",
       "      <td>9</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.06</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>grid</td>\n",
       "      <td>250</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>abs</td>\n",
       "      <td>100</td>\n",
       "      <td>220</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.06</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>pla</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>27</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.06</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>grid</td>\n",
       "      <td>205</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>pla</td>\n",
       "      <td>25</td>\n",
       "      <td>145</td>\n",
       "      <td>23</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.06</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>pla</td>\n",
       "      <td>50</td>\n",
       "      <td>88</td>\n",
       "      <td>26</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.06</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>grid</td>\n",
       "      <td>215</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>pla</td>\n",
       "      <td>75</td>\n",
       "      <td>92</td>\n",
       "      <td>33</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.06</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>220</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>pla</td>\n",
       "      <td>100</td>\n",
       "      <td>74</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>grid</td>\n",
       "      <td>220</td>\n",
       "      <td>60</td>\n",
       "      <td>120</td>\n",
       "      <td>abs</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>16</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>225</td>\n",
       "      <td>65</td>\n",
       "      <td>120</td>\n",
       "      <td>abs</td>\n",
       "      <td>25</td>\n",
       "      <td>144</td>\n",
       "      <td>12</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>grid</td>\n",
       "      <td>230</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>abs</td>\n",
       "      <td>50</td>\n",
       "      <td>265</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.10</td>\n",
       "      <td>9</td>\n",
       "      <td>80</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>240</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>abs</td>\n",
       "      <td>75</td>\n",
       "      <td>312</td>\n",
       "      <td>19</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.10</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>grid</td>\n",
       "      <td>250</td>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>abs</td>\n",
       "      <td>100</td>\n",
       "      <td>368</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>120</td>\n",
       "      <td>pla</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>11</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>grid</td>\n",
       "      <td>205</td>\n",
       "      <td>65</td>\n",
       "      <td>120</td>\n",
       "      <td>pla</td>\n",
       "      <td>25</td>\n",
       "      <td>176</td>\n",
       "      <td>12</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>pla</td>\n",
       "      <td>50</td>\n",
       "      <td>128</td>\n",
       "      <td>18</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>grid</td>\n",
       "      <td>215</td>\n",
       "      <td>75</td>\n",
       "      <td>120</td>\n",
       "      <td>pla</td>\n",
       "      <td>75</td>\n",
       "      <td>138</td>\n",
       "      <td>34</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>220</td>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>pla</td>\n",
       "      <td>100</td>\n",
       "      <td>121</td>\n",
       "      <td>14</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>grid</td>\n",
       "      <td>220</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>abs</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>27</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.15</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>225</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>abs</td>\n",
       "      <td>25</td>\n",
       "      <td>154</td>\n",
       "      <td>19</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.15</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>grid</td>\n",
       "      <td>230</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>abs</td>\n",
       "      <td>50</td>\n",
       "      <td>225</td>\n",
       "      <td>18</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>240</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>abs</td>\n",
       "      <td>75</td>\n",
       "      <td>289</td>\n",
       "      <td>9</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.15</td>\n",
       "      <td>7</td>\n",
       "      <td>80</td>\n",
       "      <td>grid</td>\n",
       "      <td>250</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>abs</td>\n",
       "      <td>100</td>\n",
       "      <td>326</td>\n",
       "      <td>13</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.15</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>pla</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>33</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>grid</td>\n",
       "      <td>205</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>pla</td>\n",
       "      <td>25</td>\n",
       "      <td>212</td>\n",
       "      <td>24</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "      <td>pla</td>\n",
       "      <td>50</td>\n",
       "      <td>168</td>\n",
       "      <td>26</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.15</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>grid</td>\n",
       "      <td>215</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>pla</td>\n",
       "      <td>75</td>\n",
       "      <td>172</td>\n",
       "      <td>22</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.15</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>220</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>pla</td>\n",
       "      <td>100</td>\n",
       "      <td>163</td>\n",
       "      <td>4</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>grid</td>\n",
       "      <td>220</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>abs</td>\n",
       "      <td>0</td>\n",
       "      <td>212</td>\n",
       "      <td>35</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.20</td>\n",
       "      <td>9</td>\n",
       "      <td>90</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>225</td>\n",
       "      <td>65</td>\n",
       "      <td>40</td>\n",
       "      <td>abs</td>\n",
       "      <td>25</td>\n",
       "      <td>276</td>\n",
       "      <td>34</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.20</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>grid</td>\n",
       "      <td>230</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>abs</td>\n",
       "      <td>50</td>\n",
       "      <td>298</td>\n",
       "      <td>28</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.20</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>240</td>\n",
       "      <td>75</td>\n",
       "      <td>40</td>\n",
       "      <td>abs</td>\n",
       "      <td>75</td>\n",
       "      <td>360</td>\n",
       "      <td>28</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.20</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>grid</td>\n",
       "      <td>250</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>abs</td>\n",
       "      <td>100</td>\n",
       "      <td>357</td>\n",
       "      <td>21</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>200</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>pla</td>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>28</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>grid</td>\n",
       "      <td>205</td>\n",
       "      <td>65</td>\n",
       "      <td>40</td>\n",
       "      <td>pla</td>\n",
       "      <td>25</td>\n",
       "      <td>265</td>\n",
       "      <td>14</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>210</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>pla</td>\n",
       "      <td>50</td>\n",
       "      <td>278</td>\n",
       "      <td>30</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.20</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>grid</td>\n",
       "      <td>215</td>\n",
       "      <td>75</td>\n",
       "      <td>40</td>\n",
       "      <td>pla</td>\n",
       "      <td>75</td>\n",
       "      <td>244</td>\n",
       "      <td>29</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.20</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>honeycomb</td>\n",
       "      <td>220</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>pla</td>\n",
       "      <td>100</td>\n",
       "      <td>220</td>\n",
       "      <td>27</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    layer_height  wall_thickness  infill_density infill_pattern  \\\n",
       "0           0.02               8              90           grid   \n",
       "1           0.02               7              90      honeycomb   \n",
       "2           0.02               1              80           grid   \n",
       "3           0.02               4              70      honeycomb   \n",
       "4           0.02               6              90           grid   \n",
       "5           0.02              10              40      honeycomb   \n",
       "6           0.02               5              10           grid   \n",
       "7           0.02              10              10      honeycomb   \n",
       "8           0.02               9              70           grid   \n",
       "9           0.02               8              40      honeycomb   \n",
       "10          0.06               6              80           grid   \n",
       "11          0.06               2              20      honeycomb   \n",
       "12          0.06              10              50           grid   \n",
       "13          0.06               6              10      honeycomb   \n",
       "14          0.06               3              50           grid   \n",
       "15          0.06              10              90      honeycomb   \n",
       "16          0.06               3              40           grid   \n",
       "17          0.06               8              30      honeycomb   \n",
       "18          0.06               5              80           grid   \n",
       "19          0.06              10              50      honeycomb   \n",
       "20          0.10               1              40           grid   \n",
       "21          0.10               2              30      honeycomb   \n",
       "22          0.10               1              50           grid   \n",
       "23          0.10               9              80      honeycomb   \n",
       "24          0.10               2              60           grid   \n",
       "25          0.10               1              50      honeycomb   \n",
       "26          0.10               4              40           grid   \n",
       "27          0.10               3              50      honeycomb   \n",
       "28          0.10               4              90           grid   \n",
       "29          0.10               1              30      honeycomb   \n",
       "30          0.15               4              50           grid   \n",
       "31          0.15               7              10      honeycomb   \n",
       "32          0.15               6              50           grid   \n",
       "33          0.15               1              50      honeycomb   \n",
       "34          0.15               7              80           grid   \n",
       "35          0.15               3              80      honeycomb   \n",
       "36          0.15               4              50           grid   \n",
       "37          0.15              10              30      honeycomb   \n",
       "38          0.15               6              40           grid   \n",
       "39          0.15               1              10      honeycomb   \n",
       "40          0.20               4              80           grid   \n",
       "41          0.20               9              90      honeycomb   \n",
       "42          0.20               7              30           grid   \n",
       "43          0.20               6              90      honeycomb   \n",
       "44          0.20               3              80           grid   \n",
       "45          0.20               5              60      honeycomb   \n",
       "46          0.20               4              20           grid   \n",
       "47          0.20               5              60      honeycomb   \n",
       "48          0.20               7              40           grid   \n",
       "49          0.20               3              60      honeycomb   \n",
       "\n",
       "    nozzle_temperature  bed_temperature  print_speed material  fan_speed  \\\n",
       "0                  220               60           40      abs          0   \n",
       "1                  225               65           40      abs         25   \n",
       "2                  230               70           40      abs         50   \n",
       "3                  240               75           40      abs         75   \n",
       "4                  250               80           40      abs        100   \n",
       "5                  200               60           40      pla          0   \n",
       "6                  205               65           40      pla         25   \n",
       "7                  210               70           40      pla         50   \n",
       "8                  215               75           40      pla         75   \n",
       "9                  220               80           40      pla        100   \n",
       "10                 220               60           60      abs          0   \n",
       "11                 225               65           60      abs         25   \n",
       "12                 230               70           60      abs         50   \n",
       "13                 240               75           60      abs         75   \n",
       "14                 250               80           60      abs        100   \n",
       "15                 200               60           60      pla          0   \n",
       "16                 205               65           60      pla         25   \n",
       "17                 210               70           60      pla         50   \n",
       "18                 215               75           60      pla         75   \n",
       "19                 220               80           60      pla        100   \n",
       "20                 220               60          120      abs          0   \n",
       "21                 225               65          120      abs         25   \n",
       "22                 230               70          120      abs         50   \n",
       "23                 240               75          120      abs         75   \n",
       "24                 250               80          120      abs        100   \n",
       "25                 200               60          120      pla          0   \n",
       "26                 205               65          120      pla         25   \n",
       "27                 210               70          120      pla         50   \n",
       "28                 215               75          120      pla         75   \n",
       "29                 220               80          120      pla        100   \n",
       "30                 220               60           60      abs          0   \n",
       "31                 225               65           60      abs         25   \n",
       "32                 230               70           60      abs         50   \n",
       "33                 240               75           60      abs         75   \n",
       "34                 250               80           60      abs        100   \n",
       "35                 200               60           60      pla          0   \n",
       "36                 205               65           60      pla         25   \n",
       "37                 210               70           60      pla         50   \n",
       "38                 215               75           60      pla         75   \n",
       "39                 220               80           60      pla        100   \n",
       "40                 220               60           40      abs          0   \n",
       "41                 225               65           40      abs         25   \n",
       "42                 230               70           40      abs         50   \n",
       "43                 240               75           40      abs         75   \n",
       "44                 250               80           40      abs        100   \n",
       "45                 200               60           40      pla          0   \n",
       "46                 205               65           40      pla         25   \n",
       "47                 210               70           40      pla         50   \n",
       "48                 215               75           40      pla         75   \n",
       "49                 220               80           40      pla        100   \n",
       "\n",
       "    roughness  tensile_strength  elongation  \n",
       "0          25                18         1.2  \n",
       "1          32                16         1.4  \n",
       "2          40                 8         0.8  \n",
       "3          68                10         0.5  \n",
       "4          92                 5         0.7  \n",
       "5          60                24         1.1  \n",
       "6          55                12         1.3  \n",
       "7          21                14         1.5  \n",
       "8          24                27         1.4  \n",
       "9          30                25         1.7  \n",
       "10         75                37         2.4  \n",
       "11         92                12         1.4  \n",
       "12        118                16         1.3  \n",
       "13        200                 9         0.8  \n",
       "14        220                10         1.0  \n",
       "15        126                27         2.2  \n",
       "16        145                23         1.9  \n",
       "17         88                26         1.6  \n",
       "18         92                33         2.1  \n",
       "19         74                29         2.0  \n",
       "20        120                16         1.2  \n",
       "21        144                12         1.1  \n",
       "22        265                10         0.9  \n",
       "23        312                19         0.8  \n",
       "24        368                 8         0.4  \n",
       "25        180                11         1.6  \n",
       "26        176                12         1.2  \n",
       "27        128                18         1.8  \n",
       "28        138                34         2.9  \n",
       "29        121                14         1.5  \n",
       "30        168                27         2.4  \n",
       "31        154                19         1.8  \n",
       "32        225                18         1.4  \n",
       "33        289                 9         0.6  \n",
       "34        326                13         0.7  \n",
       "35        192                33         2.8  \n",
       "36        212                24         1.8  \n",
       "37        168                26         2.1  \n",
       "38        172                22         2.3  \n",
       "39        163                 4         0.7  \n",
       "40        212                35         3.3  \n",
       "41        276                34         3.1  \n",
       "42        298                28         2.2  \n",
       "43        360                28         1.6  \n",
       "44        357                21         1.1  \n",
       "45        321                28         2.7  \n",
       "46        265                14         1.8  \n",
       "47        278                30         3.2  \n",
       "48        244                29         3.2  \n",
       "49        220                27         3.1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   layer_height        50 non-null     float64\n",
      " 1   wall_thickness      50 non-null     int64  \n",
      " 2   infill_density      50 non-null     int64  \n",
      " 3   infill_pattern      50 non-null     object \n",
      " 4   nozzle_temperature  50 non-null     int64  \n",
      " 5   bed_temperature     50 non-null     int64  \n",
      " 6   print_speed         50 non-null     int64  \n",
      " 7   material            50 non-null     object \n",
      " 8   fan_speed           50 non-null     int64  \n",
      " 9   roughness           50 non-null     int64  \n",
      " 10  tensile_strength    50 non-null     int64  \n",
      " 11  elongation          50 non-null     float64\n",
      "dtypes: float64(2), int64(8), object(2)\n",
      "memory usage: 4.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "infill_pattern\n",
       "grid         25\n",
       "honeycomb    25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.infill_pattern.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "material\n",
       "abs    25\n",
       "pla    25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.material.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_height: [0.02 0.06 0.1  0.15 0.2 ]\n",
      "\n",
      "wall_thickness: [ 8  7  1  4  6 10  5  9  2  3]\n",
      "\n",
      "infill_density: [90 80 70 40 10 20 50 30 60]\n",
      "\n",
      "infill_pattern: ['grid' 'honeycomb']\n",
      "\n",
      "nozzle_temperature: [220 225 230 240 250 200 205 210 215]\n",
      "\n",
      "bed_temperature: [60 65 70 75 80]\n",
      "\n",
      "print_speed: [ 40  60 120]\n",
      "\n",
      "material: ['abs' 'pla']\n",
      "\n",
      "fan_speed: [  0  25  50  75 100]\n",
      "\n",
      "roughness: [ 25  32  40  68  92  60  55  21  24  30  75 118 200 220 126 145  88  74\n",
      " 120 144 265 312 368 180 176 128 138 121 168 154 225 289 326 192 212 172\n",
      " 163 276 298 360 357 321 278 244]\n",
      "\n",
      "tensile_strength: [18 16  8 10  5 24 12 14 27 25 37  9 23 26 33 29 19 11 34 13 22  4 35 28\n",
      " 21 30]\n",
      "\n",
      "elongation: [1.2 1.4 0.8 0.5 0.7 1.1 1.3 1.5 1.7 2.4 1.  2.2 1.9 1.6 2.1 2.  0.9 0.4\n",
      " 1.8 2.9 0.6 2.8 2.3 3.3 3.1 2.7 3.2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(str(column)+\": \"+str(df[column].unique()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>layer_height</th>\n",
       "      <th>wall_thickness</th>\n",
       "      <th>infill_density</th>\n",
       "      <th>infill_pattern</th>\n",
       "      <th>nozzle_temperature</th>\n",
       "      <th>bed_temperature</th>\n",
       "      <th>print_speed</th>\n",
       "      <th>material</th>\n",
       "      <th>fan_speed</th>\n",
       "      <th>roughness</th>\n",
       "      <th>tensile_strength</th>\n",
       "      <th>elongation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>8</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>220</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "      <td>7</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>225</td>\n",
       "      <td>65</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>70</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02</td>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>75</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>68</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>80</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>92</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   layer_height  wall_thickness  infill_density  infill_pattern  \\\n",
       "0          0.02               8              90               0   \n",
       "1          0.02               7              90               1   \n",
       "2          0.02               1              80               0   \n",
       "3          0.02               4              70               1   \n",
       "4          0.02               6              90               0   \n",
       "\n",
       "   nozzle_temperature  bed_temperature  print_speed  material  fan_speed  \\\n",
       "0                 220               60           40         0          0   \n",
       "1                 225               65           40         0         25   \n",
       "2                 230               70           40         0         50   \n",
       "3                 240               75           40         0         75   \n",
       "4                 250               80           40         0        100   \n",
       "\n",
       "   roughness  tensile_strength  elongation  \n",
       "0         25                18         1.2  \n",
       "1         32                16         1.4  \n",
       "2         40                 8         0.8  \n",
       "3         68                10         0.5  \n",
       "4         92                 5         0.7  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this data set, ABS and PLA assigned 0 and 1 values for materials (abs = 0, pla = 1)\n",
    "df.material = [0 if each=='abs' else 1 for each in df.material]\n",
    "\n",
    "#In this data set, grid and honeycomb assigned 0 and 1 values for infill_pattern (grid = 0, honeycomb = 1)\n",
    "df.infill_pattern = [0 if each=='grid' else 1 for each in df.infill_pattern]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.layer_height = df.layer_height*100\n",
    "df.elongation = df.elongation*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['tensile_strength', 'roughness', 'elongation']\n",
    "y = df[target_cols].values\n",
    "x = df.drop(target_cols,axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='fan_speed', ylabel='tensile_strength'>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=df.fan_speed,y=df.tensile_strength,hue=df.material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='layer_height', ylabel='roughness'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=df.layer_height,y=df.roughness,hue=df.material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='infill_pattern', ylabel='elongation'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=df.infill_pattern,y=df.elongation,hue=df.material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='nozzle_temperature', ylabel='roughness'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=df.nozzle_temperature,y=df.roughness,hue=df.material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='print_speed', ylabel='roughness'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=df.print_speed,y=df.roughness,hue=df.material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input data x has shape of: torch.Size([50, 9])\n",
      "The target data y has shape of: torch.Size([50, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cpu\" )\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "y = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "print(\"The input data x has shape of:\",x.shape)\n",
    "print(\"The target data y has shape of:\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strength_loss(output, y):\n",
    "    criterion = nn.MSELoss()\n",
    "    return criterion(output[:, 0], y[:, 0])\n",
    "\n",
    "def rough_loss(output, y):\n",
    "    criterion = nn.MSELoss()\n",
    "    return criterion(output[:, 1], y[:, 1])  # Fix: return computed loss\n",
    "\n",
    "def elongation_loss(output, y):\n",
    "    criterion = nn.MSELoss()\n",
    "    return criterion(output[:, 2], y[:, 2])  # Fix: return computed loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the data using StandardScaler\n",
    "scaler_x = StandardScaler()\n",
    "x_train_scaled = scaler_x.fit_transform(x_train)\n",
    "x_test_scaled = scaler_x.transform(x_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "# Convert the data to PyTorch tensors (no need to use .cuda() for CPU)\n",
    "x_train_tensor = torch.tensor(x_train_scaled, dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_scaled, dtype=torch.float32)\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(TensorDataset(x_train_tensor, y_train_tensor), batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(x_test_tensor, y_test_tensor), batch_size=8, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network for regression\n",
    "class DNNRegressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNNRegressor, self).__init__()\n",
    "        self.fc1 = nn.Linear(9, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 3)  # Output layer (3 outputs for the targets)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = DNNRegressor()\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class One_Chain_Optimizer:\n",
    "    def __init__(self, net, criterion, momentum=0.9, lr=0.1, wdecay=5e-4, T=0.05, total=50000):\n",
    "        self.net = net\n",
    "        self.eta = lr\n",
    "        self.momentum = momentum\n",
    "        self.T = T\n",
    "        self.wdecay = wdecay\n",
    "        self.V = 0.1\n",
    "        self.velocity = []\n",
    "        self.criterion = criterion\n",
    "        self.total = total\n",
    "\n",
    "        self.beta = 0.5 * self.V * self.eta\n",
    "        self.alpha = 1 - self.momentum\n",
    "\n",
    "        if self.beta > self.alpha:\n",
    "            sys.exit('Momentum is too large')\n",
    "\n",
    "        self.sigma = np.sqrt(2.0 * self.eta * (self.alpha - self.beta))\n",
    "        self.scale = self.sigma * np.sqrt(self.T)\n",
    "\n",
    "        for param in net.parameters():\n",
    "            p = torch.zeros_like(param.data)\n",
    "            self.velocity.append(p)\n",
    "\n",
    "    def set_T(self, factor=1):\n",
    "        self.T /= factor\n",
    "        self.scale = self.sigma * np.sqrt(self.T)\n",
    "\n",
    "    def set_eta(self, eta):\n",
    "        self.eta = eta\n",
    "        self.beta = 0.5 * self.V * self.eta\n",
    "        self.sigma = np.sqrt(2.0 * self.eta * (self.alpha - self.beta))\n",
    "        self.scale = self.sigma * np.sqrt(self.T)\n",
    "\n",
    "    def backprop(self, x, y):\n",
    "        self.net.zero_grad()\n",
    "        \"\"\" convert mean loss to sum losses \"\"\"\n",
    "        loss = self.criterion(self.net(x), y) #* self.total\n",
    "        loss.backward()\n",
    "        return loss\n",
    "\n",
    "    def step(self, x, y):\n",
    "      loss = self.backprop(x, y)\n",
    "\n",
    "      # Gradient clipping to prevent exploding gradients\n",
    "      torch.nn.utils.clip_grad_norm_(self.net.parameters(), max_norm=1.0)\n",
    "\n",
    "      for i, param in enumerate(self.net.parameters()):\n",
    "          # Create proposal noise tensor with up-to-date method\n",
    "          proposal = torch.normal(0, self.scale, size=param.data.size(), device=param.data.device)\n",
    "\n",
    "          grads = param.grad.data\n",
    "\n",
    "          # Log parameters and gradients for debugging\n",
    "\n",
    "\n",
    "          if self.wdecay != 0:\n",
    "              grads.add_(self.wdecay, param.data)\n",
    "\n",
    "          self.velocity[i].mul_(self.momentum).add_(-self.eta, grads).add_(proposal)\n",
    "          param.data.add_(self.velocity[i])\n",
    "\n",
    "      return loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import argparse\n",
    "import random\n",
    "import collections\n",
    "from random import shuffle\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm ## better progressbar\n",
    "from math import exp\n",
    "from sys import getsizeof\n",
    "import numpy as np\n",
    "\n",
    "## import pytorch modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "CUDA_EXISTS = torch.cuda.is_available()\n",
    "device = torch.device(\"cpu\" )\n",
    "\n",
    "# Define Your own Parameters in parameters : parameters = [T, lr, num_of_chains, wdecay, total, Tgap, LRgap, num_epoch, period, batch, var_reduce, adapt_c, alpha, bias_F, cool, burn, Tanneal, LRanneal]\n",
    "# T:Temperature for high temperature chain, default=0.05\n",
    "# lr: Sampling learning rate, default=0.1\n",
    "# num_of_chains: Total number of chains, default=1\n",
    "# wdecay: Samling weight decay, default=5e-4\n",
    "# total: Total data points, default=50000\n",
    "# Tgap: Temperature gap between chains, default=0.2\n",
    "# LRgap: Learning rate gap between chains, default=0.66\n",
    "# num_epoch: Sampling Epochs, default=1000\n",
    "# period: estimate adaptive variance every [period] epochs, default=2\n",
    "# batch: Batch size, default=256\n",
    "# var_reduce: n>0 means update variance reduction every n epochs; n divides 10, default=0\n",
    "# adapt_c: adapt_c=1 is equivalent to running Alg. 2 in the appendix, default=0\n",
    "# alpha: forgetting rate, default=0.3\n",
    "# bias_F: correction factor F, default=1.5e5\n",
    "# cool: No swaps happen during the cooling time after a swap, default=1\n",
    "# burn: burn in iterations for sampling (sn * burn), default=0.6\n",
    "# Tanneal: temperature annealing factor, default=1.02\n",
    "# LRanneal: lr annealing factor, default=0.984\n",
    "\n",
    "def trainer(nets, training_data, parameters):\n",
    "  # Loss function\n",
    "  criterion = nn.MSELoss()\n",
    "  # Initial temperature and learning rate\n",
    "  init_T, init_lr = parameters.T, parameters.lr\n",
    "\n",
    "  chains, lr_set, myVars, cooling_time, BMAS = {}, [], [], [], []\n",
    "  for idx in range(parameters.num_of_chains-1, -1, -1):\n",
    "    print('Chain {} Initial learning rate {:.2e} temperature {:.2e}'.format(idx, init_lr, init_T))\n",
    "    chain = One_Chain_Optimizer(nets[idx], criterion, lr=init_lr, wdecay=parameters.wdecay, T=init_T, total=parameters.total)\n",
    "    lr_set.insert(0, init_lr)\n",
    "    init_T /= parameters.Tgap\n",
    "    init_lr /= parameters.LRgap\n",
    "    chains[idx] = chain\n",
    "    myVars.append(sys.float_info.max)\n",
    "\n",
    "  start = time.time()\n",
    "  counter, warm_up, adjusted_corrections = 1., 10, 0\n",
    "  # Initialization for variance reduction\n",
    "  last_full_losses, last_VRnets, corr = [0] * parameters.num_of_chains, [], [-1] * parameters.num_of_chains\n",
    "  for idx in range(parameters.num_of_chains):\n",
    "    last_VRnets.append(pickle.loads(pickle.dumps(nets[idx])))\n",
    "\n",
    "  for epoch in range(parameters.num_epoch):\n",
    "    # Update adaptive variance and variance reduction every [period] epochs\n",
    "    if parameters.period > 0 and epoch % parameters.period ==0:\n",
    "      cur_full_losses = [0] * parameters.num_of_chains\n",
    "      for idx in range(parameters.num_of_chains):\n",
    "        stage_losses, cv_losses = [], []\n",
    "        nets[idx].eval()\n",
    "        for i, (x_batch, y_batch) in enumerate(training_data):\n",
    "          x_batch = x_batch.to(device)\n",
    "          y_batch = y_batch.to(device)\n",
    "          nets[idx].zero_grad()\n",
    "          avg_loss = criterion(nets[idx](x_batch), y_batch).item()\n",
    "          cur_full_losses[idx] += avg_loss * parameters.batch\n",
    "          stage_losses.append(avg_loss * parameters.total)\n",
    "          if parameters.var_reduce:\n",
    "            cv_losses.append(criterion(last_VRnets[idx](x_batch), y_batch).item() * parameters.total)\n",
    "\n",
    "          if parameters.adapt_c:\n",
    "            adaptive_corr = -np.cov(stage_losses, cv_losses, ddof=1)[0][1] / np.var(cv_losses, ddof=1)\n",
    "            corr[idx] = (1 - parameters.alpha) * corr[idx] + parameters.alpha * adaptive_corr\n",
    "\n",
    "          if parameters.var_reduce:\n",
    "            for i in range(len(stage_losses)):\n",
    "              stage_losses[i] = stage_losses[i] + corr[idx] * (cv_losses[i] - np.mean(cv_losses))\n",
    "\n",
    "        std_epoch = np.std(stage_losses, ddof=1)\n",
    "        myVars[idx] = 0.5 * std_epoch**2 if myVars[idx] == sys.float_info.max else ((1 - parameters.alpha) * myVars[idx] + parameters.alpha * 0.5 * std_epoch ** 2)\n",
    "        print('Epoch {} Chain {} loss std {:.2e} variance {:.2e} smooth variance {:.2e} adaptive c {:.2f}'.format(epoch, idx, std_epoch, 0.5 * std_epoch**2, myVars[idx], corr[idx]))\n",
    "        last_VRnets[idx] = pickle.loads(pickle.dumps(nets[idx]))\n",
    "        last_full_losses[idx] = cur_full_losses[idx]\n",
    "\n",
    "    for idx in range(parameters.num_of_chains):\n",
    "      nets[idx].train()\n",
    "\n",
    "    for i, (x_batch, y_batch) in enumerate(training_data):\n",
    "      x_batch = x_batch.to(device)\n",
    "      y_batch = y_batch.to(device)\n",
    "      counter += 1\n",
    "      loss_chains = []\n",
    "      for idx in range(parameters.num_of_chains):\n",
    "        loss = chains[idx].step(x_batch, y_batch)\n",
    "        print(f' Loss: {loss:.6f}')\n",
    "        # variance-reduced negative log posterior\n",
    "        if parameters.var_reduce and epoch > warm_up:\n",
    "          control_variate_loss = criterion(last_VRnets[idx](x), y).item() * parameters.total\n",
    "          loss = loss + corr[idx] * (control_variate_loss - last_full_losses[idx])\n",
    "        loss_chains.append(loss)\n",
    "\n",
    "      # Swap\n",
    "      for idx in range(parameters.num_of_chains - 1):\n",
    "        # exponential average smoothing\n",
    "        delta_invT = 1. / chains[idx].T - 1. / chains[idx+1].T\n",
    "        adjusted_corrections = delta_invT * (myVars[idx] + myVars[idx+1]) / parameters.bias_F\n",
    "        if np.log(np.random.uniform(0, 1)) < delta_invT * (loss_chains[idx] - loss_chains[idx+1] - adjusted_corrections):\n",
    "          if epoch not in cooling_time:\n",
    "            temporary = pickle.loads(pickle.dumps(chains[idx+1].net))\n",
    "            chains[idx+1].net.load_state_dict(chains[idx].net.state_dict())\n",
    "            chains[idx].net.load_state_dict(temporary.state_dict())\n",
    "            print('Epoch {} Swap chain {} with chain {} and increased F {:0.2e}'.format(epoch, idx, idx+1, parameters.bias_F))\n",
    "            cooling_time = range(epoch, epoch+parameters.cool)\n",
    "          else:\n",
    "            print('Epoch {} Cooling period'.format(epoch))\n",
    "\n",
    "    # Anneaing\n",
    "    if epoch < parameters.burn * parameters.num_epoch:\n",
    "      parameters.bias_F *= parameters.Tanneal\n",
    "    for idx in range(parameters.num_of_chains):\n",
    "      if epoch > 0.4 * parameters.num_epoch and parameters.LRanneal <=1:\n",
    "        chains[idx].eta *= parameters.LRanneal\n",
    "      if epoch < parameters.burn * parameters.num_epoch:\n",
    "        chains[idx].set_T(parameters.Tanneal)\n",
    "    \n",
    "    \n",
    "\n",
    "      # add test set here\n",
    "      ##########################################\n",
    "\n",
    "  end = time.time()\n",
    "  print('Time used {:.2f}s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain 1 Initial learning rate 2.00e-04 temperature 1.00e-02\n",
      "Chain 0 Initial learning rate 3.03e-04 temperature 5.00e-02\n",
      "Epoch 0 Chain 0 loss std 2.85e+03 variance 4.05e+06 smooth variance 4.05e+06 adaptive c -1.00\n",
      "Epoch 0 Chain 1 loss std 3.28e+03 variance 5.39e+06 smooth variance 5.39e+06 adaptive c -1.00\n",
      " Loss: 1.053639\n",
      " Loss: 1.117700\n",
      " Loss: 0.763171\n",
      " Loss: 0.750334\n",
      " Loss: 1.260399\n",
      " Loss: 1.252624\n",
      " Loss: 0.623750\n",
      " Loss: 0.609316\n",
      " Loss: 1.349787\n",
      " Loss: 1.337288\n",
      " Loss: 0.680591\n",
      " Loss: 0.623969\n",
      " Loss: 1.219746\n",
      " Loss: 1.266329\n",
      " Loss: 1.110077\n",
      " Loss: 1.123320\n",
      " Loss: 1.139821\n",
      " Loss: 1.201148\n",
      " Loss: 0.875206\n",
      " Loss: 0.848316\n",
      "Epoch 2 Chain 0 loss std 3.12e+03 variance 4.85e+06 smooth variance 4.29e+06 adaptive c -1.00\n",
      "Epoch 2 Chain 1 loss std 2.84e+03 variance 4.04e+06 smooth variance 4.98e+06 adaptive c -1.00\n",
      " Loss: 1.137295\n",
      " Loss: 1.118930\n",
      " Loss: 1.070874\n",
      " Loss: 1.104286\n",
      " Loss: 0.620008\n",
      " Loss: 0.626315\n",
      " Loss: 1.096253\n",
      " Loss: 1.121507\n",
      " Loss: 1.089680\n",
      " Loss: 1.097206\n",
      " Loss: 0.778783\n",
      " Loss: 0.802330\n",
      " Loss: 0.781614\n",
      " Loss: 0.751625\n",
      " Loss: 1.623568\n",
      " Loss: 1.618884\n",
      " Loss: 1.034789\n",
      " Loss: 1.046789\n",
      " Loss: 0.828918\n",
      " Loss: 0.844654\n",
      "Epoch 4 Chain 0 loss std 2.58e+03 variance 3.32e+06 smooth variance 4.00e+06 adaptive c -1.00\n",
      "Epoch 4 Chain 1 loss std 3.21e+03 variance 5.14e+06 smooth variance 5.03e+06 adaptive c -1.00\n",
      " Loss: 0.747890\n",
      " Loss: 0.711295\n",
      " Loss: 1.086111\n",
      " Loss: 1.181095\n",
      " Loss: 0.752724\n",
      " Loss: 0.826508\n",
      " Loss: 1.117810\n",
      " Loss: 1.166057\n",
      " Loss: 1.292917\n",
      " Loss: 1.170274\n",
      " Loss: 1.221717\n",
      " Loss: 1.203604\n",
      " Loss: 0.798937\n",
      " Loss: 0.813690\n",
      " Loss: 1.094544\n",
      " Loss: 1.025669\n",
      " Loss: 1.035077\n",
      " Loss: 1.135454\n",
      " Loss: 0.780348\n",
      " Loss: 0.882511\n",
      "Epoch 6 Chain 0 loss std 3.29e+03 variance 5.42e+06 smooth variance 4.43e+06 adaptive c -1.00\n",
      "Epoch 6 Chain 1 loss std 2.88e+03 variance 4.16e+06 smooth variance 4.77e+06 adaptive c -1.00\n",
      " Loss: 0.781639\n",
      " Loss: 0.786410\n",
      " Loss: 1.074283\n",
      " Loss: 1.162729\n",
      " Loss: 1.155173\n",
      " Loss: 1.167570\n",
      " Loss: 0.682080\n",
      " Loss: 0.699416\n",
      " Loss: 1.219471\n",
      " Loss: 1.251089\n",
      " Loss: 1.014020\n",
      " Loss: 1.000385\n",
      " Loss: 0.859562\n",
      " Loss: 0.954707\n",
      " Loss: 0.867817\n",
      " Loss: 0.961397\n",
      " Loss: 0.848533\n",
      " Loss: 0.863378\n",
      " Loss: 1.376683\n",
      " Loss: 1.302298\n",
      "Epoch 8 Chain 0 loss std 1.70e+03 variance 1.45e+06 smooth variance 3.53e+06 adaptive c -1.00\n",
      "Epoch 8 Chain 1 loss std 2.51e+03 variance 3.15e+06 smooth variance 4.28e+06 adaptive c -1.00\n",
      " Loss: 1.386121\n",
      " Loss: 1.430364\n",
      " Loss: 0.738473\n",
      " Loss: 0.774287\n",
      " Loss: 1.151796\n",
      " Loss: 1.073059\n",
      " Loss: 1.081252\n",
      " Loss: 1.080795\n",
      " Loss: 0.689982\n",
      " Loss: 0.739985\n",
      " Loss: 1.078951\n",
      " Loss: 1.164866\n",
      " Loss: 0.629348\n",
      " Loss: 0.709551\n",
      " Loss: 1.069641\n",
      " Loss: 0.986006\n",
      " Loss: 1.036658\n",
      " Loss: 0.980214\n",
      " Loss: 1.276238\n",
      " Loss: 1.266445\n",
      "Epoch 10 Chain 0 loss std 4.18e+03 variance 8.75e+06 smooth variance 5.10e+06 adaptive c -1.00\n",
      "Epoch 10 Chain 1 loss std 2.28e+03 variance 2.60e+06 smooth variance 3.78e+06 adaptive c -1.00\n",
      " Loss: 1.073451\n",
      " Loss: 1.110861\n",
      " Loss: 0.982722\n",
      " Loss: 1.074237\n",
      " Loss: 0.554205\n",
      " Loss: 0.544507\n",
      " Loss: 1.457739\n",
      " Loss: 1.372980\n",
      " Loss: 1.036335\n",
      " Loss: 1.006944\n",
      " Loss: 1.256332\n",
      " Loss: 1.120529\n",
      " Loss: 1.146719\n",
      " Loss: 1.166620\n",
      " Loss: 0.768470\n",
      " Loss: 0.879337\n",
      " Loss: 0.946996\n",
      " Loss: 0.886601\n",
      " Loss: 0.995930\n",
      " Loss: 1.063136\n",
      "Epoch 12 Chain 0 loss std 2.40e+03 variance 2.89e+06 smooth variance 4.44e+06 adaptive c -1.00\n",
      "Epoch 12 Chain 1 loss std 3.81e+03 variance 7.25e+06 smooth variance 4.82e+06 adaptive c -1.00\n",
      " Loss: 1.008363\n",
      " Loss: 0.890028\n",
      " Loss: 1.150381\n",
      " Loss: 1.261466\n",
      " Loss: 1.080851\n",
      " Loss: 1.248599\n",
      " Loss: 1.063074\n",
      " Loss: 0.951970\n",
      " Loss: 0.847627\n",
      " Loss: 0.765894\n",
      " Loss: 0.616060\n",
      " Loss: 0.517515\n",
      " Loss: 1.666563\n",
      " Loss: 1.485351\n",
      " Loss: 0.841323\n",
      " Loss: 0.998301\n",
      " Loss: 0.797439\n",
      " Loss: 0.845140\n",
      " Loss: 1.301838\n",
      " Loss: 1.261189\n",
      "Epoch 14 Chain 0 loss std 4.35e+03 variance 9.46e+06 smooth variance 5.94e+06 adaptive c -1.00\n",
      "Epoch 14 Chain 1 loss std 1.72e+03 variance 1.48e+06 smooth variance 3.82e+06 adaptive c -1.00\n",
      " Loss: 1.302559\n",
      " Loss: 1.170588\n",
      " Loss: 1.068300\n",
      " Loss: 1.168262\n",
      " Loss: 0.834386\n",
      " Loss: 0.943831\n",
      " Loss: 1.145404\n",
      " Loss: 0.929502\n",
      " Loss: 1.035245\n",
      " Loss: 0.894307\n",
      " Loss: 1.182020\n",
      " Loss: 0.975905\n",
      " Loss: 0.703681\n",
      " Loss: 0.648654\n",
      " Loss: 0.827558\n",
      " Loss: 0.945448\n",
      " Loss: 1.231567\n",
      " Loss: 1.178351\n",
      " Loss: 1.612412\n",
      " Loss: 1.374288\n",
      "Epoch 16 Chain 0 loss std 4.08e+03 variance 8.31e+06 smooth variance 6.65e+06 adaptive c -1.00\n",
      "Epoch 16 Chain 1 loss std 3.13e+03 variance 4.91e+06 smooth variance 4.14e+06 adaptive c -1.00\n",
      " Loss: 1.172341\n",
      " Loss: 0.784158\n",
      " Loss: 1.561252\n",
      " Loss: 1.464248\n",
      " Loss: 1.066535\n",
      " Loss: 0.733824\n",
      " Loss: 0.408647\n",
      " Loss: 0.719166\n",
      " Loss: 1.705710\n",
      " Loss: 1.439474\n",
      " Loss: 1.302220\n",
      " Loss: 1.159411\n",
      " Loss: 1.003370\n",
      " Loss: 1.057115\n",
      " Loss: 0.612227\n",
      " Loss: 0.762689\n",
      " Loss: 1.581178\n",
      " Loss: 1.046679\n",
      " Loss: 1.411325\n",
      " Loss: 1.114296\n",
      "Epoch 18 Chain 0 loss std 4.55e+03 variance 1.03e+07 smooth variance 7.76e+06 adaptive c -1.00\n",
      "Epoch 18 Chain 1 loss std 3.69e+03 variance 6.83e+06 smooth variance 4.95e+06 adaptive c -1.00\n",
      " Loss: 0.710462\n",
      " Loss: 0.818766\n",
      " Loss: 1.384886\n",
      " Loss: 1.240501\n",
      " Loss: 1.696725\n",
      " Loss: 1.392179\n",
      " Loss: 1.350714\n",
      " Loss: 0.971447\n",
      " Loss: 0.889749\n",
      " Loss: 0.708574\n",
      " Loss: 2.044008\n",
      " Loss: 1.494445\n",
      " Loss: 0.808644\n",
      " Loss: 0.702442\n",
      " Loss: 1.630655\n",
      " Loss: 0.997379\n",
      " Loss: 0.565161\n",
      " Loss: 0.654189\n",
      " Loss: 1.268734\n",
      " Loss: 1.276578\n",
      "Epoch 20 Chain 0 loss std 5.24e+03 variance 1.37e+07 smooth variance 9.54e+06 adaptive c -1.00\n",
      "Epoch 20 Chain 1 loss std 3.54e+03 variance 6.28e+06 smooth variance 5.35e+06 adaptive c -1.00\n",
      " Loss: 1.283065\n",
      " Loss: 0.962283\n",
      " Loss: 1.411740\n",
      " Loss: 1.189416\n",
      " Loss: 1.309166\n",
      " Loss: 0.925821\n",
      " Loss: 1.706104\n",
      " Loss: 1.076518\n",
      " Loss: 0.869504\n",
      " Loss: 0.972292\n",
      " Loss: 1.878107\n",
      " Loss: 0.977581\n",
      " Loss: 1.600835\n",
      " Loss: 1.255062\n",
      " Loss: 1.034989\n",
      " Loss: 1.127854\n",
      " Loss: 1.559475\n",
      " Loss: 1.012320\n",
      " Loss: 1.051687\n",
      " Loss: 0.753635\n",
      "Epoch 22 Chain 0 loss std 9.23e+03 variance 4.26e+07 smooth variance 1.95e+07 adaptive c -1.00\n",
      "Epoch 22 Chain 1 loss std 4.14e+03 variance 8.56e+06 smooth variance 6.31e+06 adaptive c -1.00\n",
      " Loss: 2.111555\n",
      " Loss: 1.236035\n",
      " Loss: 1.844439\n",
      " Loss: 1.119545\n",
      " Loss: 0.846864\n",
      " Loss: 0.574028\n",
      " Loss: 1.360770\n",
      " Loss: 1.089576\n",
      " Loss: 1.423130\n",
      " Loss: 1.117634\n",
      " Loss: 2.204311\n",
      " Loss: 1.455894\n",
      " Loss: 1.464308\n",
      " Loss: 0.983739\n",
      " Loss: 1.849723\n",
      " Loss: 1.141191\n",
      " Loss: 0.909596\n",
      " Loss: 0.722509\n",
      " Loss: 1.649614\n",
      " Loss: 0.842224\n",
      "Epoch 24 Chain 0 loss std 6.83e+03 variance 2.33e+07 smooth variance 2.06e+07 adaptive c -1.00\n",
      "Epoch 24 Chain 1 loss std 3.60e+03 variance 6.48e+06 smooth variance 6.36e+06 adaptive c -1.00\n",
      " Loss: 1.617564\n",
      " Loss: 1.019782\n",
      " Loss: 1.387736\n",
      " Loss: 0.965782\n",
      " Loss: 2.253228\n",
      " Loss: 1.123435\n",
      " Loss: 1.448698\n",
      " Loss: 0.930918\n",
      " Loss: 1.817299\n",
      " Loss: 1.101471\n",
      " Loss: 1.087520\n",
      " Loss: 0.718696\n",
      " Loss: 2.355712\n",
      " Loss: 1.233488\n",
      " Loss: 1.394322\n",
      " Loss: 1.230310\n",
      " Loss: 1.482303\n",
      " Loss: 0.837034\n",
      " Loss: 2.900010\n",
      " Loss: 1.123639\n",
      "Epoch 26 Chain 0 loss std 4.16e+03 variance 8.66e+06 smooth variance 1.70e+07 adaptive c -1.00\n",
      "Epoch 26 Chain 1 loss std 4.29e+03 variance 9.20e+06 smooth variance 7.21e+06 adaptive c -1.00\n",
      " Loss: 2.509246\n",
      " Loss: 1.300682\n",
      " Loss: 2.026535\n",
      " Loss: 1.498496\n",
      " Loss: 1.070563\n",
      " Loss: 0.563211\n",
      " Loss: 2.657642\n",
      " Loss: 1.067586\n",
      " Loss: 1.490867\n",
      " Loss: 0.707428\n",
      " Loss: 1.746597\n",
      " Loss: 0.983520\n",
      " Loss: 1.319345\n",
      " Loss: 0.489149\n",
      " Loss: 2.174670\n",
      " Loss: 0.732467\n",
      " Loss: 2.208048\n",
      " Loss: 1.185975\n",
      " Loss: 2.922423\n",
      " Loss: 1.742180\n",
      "Epoch 28 Chain 0 loss std 6.04e+03 variance 1.82e+07 smooth variance 1.74e+07 adaptive c -1.00\n",
      "Epoch 28 Chain 1 loss std 3.70e+03 variance 6.84e+06 smooth variance 7.10e+06 adaptive c -1.00\n",
      " Loss: 1.557087\n",
      " Loss: 0.995256\n",
      " Loss: 1.868524\n",
      " Loss: 0.908634\n",
      " Loss: 2.693327\n",
      " Loss: 1.102739\n",
      " Loss: 2.876458\n",
      " Loss: 1.195423\n",
      " Loss: 1.850382\n",
      " Loss: 0.923000\n",
      " Loss: 1.308846\n",
      " Loss: 0.871171\n",
      " Loss: 2.523926\n",
      " Loss: 0.920081\n",
      " Loss: 3.033600\n",
      " Loss: 1.157401\n",
      " Loss: 2.585909\n",
      " Loss: 1.112596\n",
      " Loss: 2.189944\n",
      " Loss: 1.037469\n",
      "Epoch 30 Chain 0 loss std 8.83e+03 variance 3.89e+07 smooth variance 2.39e+07 adaptive c -1.00\n",
      "Epoch 30 Chain 1 loss std 3.96e+03 variance 7.85e+06 smooth variance 7.33e+06 adaptive c -1.00\n",
      " Loss: 2.570280\n",
      " Loss: 1.085371\n",
      " Loss: 2.646789\n",
      " Loss: 1.172480\n",
      " Loss: 3.439980\n",
      " Loss: 1.102236\n",
      " Loss: 1.521165\n",
      " Loss: 0.887012\n",
      " Loss: 2.454348\n",
      " Loss: 0.836449\n",
      " Loss: 2.842627\n",
      " Loss: 0.933253\n",
      " Loss: 1.876111\n",
      " Loss: 0.548921\n",
      " Loss: 1.935368\n",
      " Loss: 1.035454\n",
      " Loss: 4.095383\n",
      " Loss: 1.448032\n",
      " Loss: 2.445994\n",
      " Loss: 1.122558\n",
      "Epoch 32 Chain 0 loss std 7.19e+03 variance 2.59e+07 smooth variance 2.45e+07 adaptive c -1.00\n",
      "Epoch 32 Chain 1 loss std 3.14e+03 variance 4.92e+06 smooth variance 6.61e+06 adaptive c -1.00\n",
      " Loss: 1.860447\n",
      " Loss: 0.943013\n",
      " Loss: 4.053453\n",
      " Loss: 1.085518\n",
      " Loss: 2.184398\n",
      " Loss: 1.257000\n",
      " Loss: 2.744526\n",
      " Loss: 1.028553\n",
      " Loss: 2.559324\n",
      " Loss: 0.761107\n",
      " Loss: 1.664657\n",
      " Loss: 0.483783\n",
      " Loss: 2.387324\n",
      " Loss: 0.962819\n",
      " Loss: 3.273641\n",
      " Loss: 1.000929\n",
      " Loss: 2.872099\n",
      " Loss: 1.053811\n",
      " Loss: 3.127370\n",
      " Loss: 1.540348\n",
      "Epoch 34 Chain 0 loss std 7.59e+03 variance 2.88e+07 smooth variance 2.58e+07 adaptive c -1.00\n",
      "Epoch 34 Chain 1 loss std 2.55e+03 variance 3.24e+06 smooth variance 5.60e+06 adaptive c -1.00\n",
      " Loss: 2.804453\n",
      " Loss: 0.829889\n",
      " Loss: 1.793799\n",
      " Loss: 0.974591\n",
      " Loss: 2.947231\n",
      " Loss: 1.217766\n",
      " Loss: 4.107646\n",
      " Loss: 1.490311\n",
      " Loss: 1.992606\n",
      " Loss: 0.500516\n",
      " Loss: 4.115887\n",
      " Loss: 1.508375\n",
      " Loss: 1.974830\n",
      " Loss: 0.906350\n",
      " Loss: 3.094014\n",
      " Loss: 0.926377\n",
      " Loss: 2.687158\n",
      " Loss: 0.995408\n",
      " Loss: 2.175346\n",
      " Loss: 0.650396\n",
      "Epoch 36 Chain 0 loss std 9.86e+03 variance 4.86e+07 smooth variance 3.26e+07 adaptive c -1.00\n",
      "Epoch 36 Chain 1 loss std 3.69e+03 variance 6.80e+06 smooth variance 5.96e+06 adaptive c -1.00\n",
      " Loss: 1.896072\n",
      " Loss: 0.790811\n",
      " Loss: 2.810961\n",
      " Loss: 0.931209\n",
      " Loss: 2.633476\n",
      " Loss: 0.824819\n",
      " Loss: 3.365669\n",
      " Loss: 1.458126\n",
      " Loss: 3.427464\n",
      " Loss: 0.939850\n",
      " Loss: 2.168969\n",
      " Loss: 1.092758\n",
      " Loss: 2.774551\n",
      " Loss: 0.716155\n",
      " Loss: 2.862753\n",
      " Loss: 0.868660\n",
      " Loss: 3.445450\n",
      " Loss: 1.224915\n",
      " Loss: 2.080136\n",
      " Loss: 1.044009\n",
      "Epoch 38 Chain 0 loss std 8.39e+03 variance 3.52e+07 smooth variance 3.34e+07 adaptive c -1.00\n",
      "Epoch 38 Chain 1 loss std 1.21e+03 variance 7.34e+05 smooth variance 4.39e+06 adaptive c -1.00\n",
      " Loss: 1.757448\n",
      " Loss: 0.906237\n",
      " Loss: 2.443114\n",
      " Loss: 0.861977\n",
      " Loss: 3.621663\n",
      " Loss: 1.413230\n",
      " Loss: 3.031003\n",
      " Loss: 0.758530\n",
      " Loss: 1.753680\n",
      " Loss: 1.002107\n",
      " Loss: 2.098771\n",
      " Loss: 0.590520\n",
      " Loss: 3.064563\n",
      " Loss: 1.241252\n",
      " Loss: 2.789183\n",
      " Loss: 1.082959\n",
      " Loss: 2.835332\n",
      " Loss: 1.188094\n",
      " Loss: 1.582049\n",
      " Loss: 0.851789\n",
      "Epoch 40 Chain 0 loss std 4.56e+03 variance 1.04e+07 smooth variance 2.65e+07 adaptive c -1.00\n",
      "Epoch 40 Chain 1 loss std 1.13e+03 variance 6.36e+05 smooth variance 3.26e+06 adaptive c -1.00\n",
      " Loss: 1.755290\n",
      " Loss: 0.869259\n",
      " Loss: 2.268815\n",
      " Loss: 0.968880\n",
      " Loss: 2.333050\n",
      " Loss: 0.645060\n",
      " Loss: 2.897223\n",
      " Loss: 0.777028\n",
      " Loss: 3.182797\n",
      " Loss: 1.700008\n",
      " Loss: 2.786175\n",
      " Loss: 1.162297\n",
      " Loss: 2.599246\n",
      " Loss: 1.217548\n",
      " Loss: 2.240317\n",
      " Loss: 1.071284\n",
      " Loss: 1.421445\n",
      " Loss: 0.351292\n",
      " Loss: 2.658850\n",
      " Loss: 1.143019\n",
      "Epoch 42 Chain 0 loss std 3.05e+03 variance 4.66e+06 smooth variance 1.99e+07 adaptive c -1.00\n",
      "Epoch 42 Chain 1 loss std 3.47e+03 variance 6.01e+06 smooth variance 4.09e+06 adaptive c -1.00\n",
      " Loss: 2.660883\n",
      " Loss: 0.644054\n",
      " Loss: 2.255054\n",
      " Loss: 1.292330\n",
      " Loss: 1.637380\n",
      " Loss: 0.985648\n",
      " Loss: 2.967200\n",
      " Loss: 0.964364\n",
      " Loss: 1.283992\n",
      " Loss: 1.055521\n",
      " Loss: 1.878209\n",
      " Loss: 0.944707\n",
      " Loss: 1.663097\n",
      " Loss: 1.206785\n",
      " Loss: 2.174868\n",
      " Loss: 1.269028\n",
      " Loss: 2.063877\n",
      " Loss: 0.971621\n",
      " Loss: 2.231144\n",
      " Loss: 0.535107\n",
      "Epoch 44 Chain 0 loss std 6.85e+03 variance 2.35e+07 smooth variance 2.10e+07 adaptive c -1.00\n",
      "Epoch 44 Chain 1 loss std 3.83e+03 variance 7.34e+06 smooth variance 5.06e+06 adaptive c -1.00\n",
      " Loss: 1.867977\n",
      " Loss: 0.926585\n",
      " Loss: 2.487800\n",
      " Loss: 0.924484\n",
      " Loss: 1.735466\n",
      " Loss: 1.277073\n",
      " Loss: 1.998385\n",
      " Loss: 1.175437\n",
      " Loss: 1.779295\n",
      " Loss: 0.608520\n",
      " Loss: 2.227073\n",
      " Loss: 0.772812\n",
      " Loss: 0.944629\n",
      " Loss: 1.186241\n",
      " Loss: 2.288167\n",
      " Loss: 0.746049\n",
      " Loss: 2.125964\n",
      " Loss: 1.288271\n",
      " Loss: 2.245198\n",
      " Loss: 0.903135\n",
      "Epoch 46 Chain 0 loss std 3.73e+03 variance 6.96e+06 smooth variance 1.68e+07 adaptive c -1.00\n",
      "Epoch 46 Chain 1 loss std 3.28e+03 variance 5.37e+06 smooth variance 5.15e+06 adaptive c -1.00\n",
      " Loss: 2.460726\n",
      " Loss: 0.825095\n",
      " Loss: 2.628370\n",
      " Loss: 1.146850\n",
      " Loss: 1.255606\n",
      " Loss: 1.070616\n",
      " Loss: 1.795651\n",
      " Loss: 0.867130\n",
      " Loss: 1.585294\n",
      " Loss: 0.963023\n",
      " Loss: 1.552010\n",
      " Loss: 1.084297\n",
      " Loss: 1.477192\n",
      " Loss: 1.011921\n",
      " Loss: 2.130696\n",
      " Loss: 0.924764\n",
      " Loss: 1.969049\n",
      " Loss: 1.240330\n",
      " Loss: 2.334096\n",
      " Loss: 0.597409\n",
      "Epoch 48 Chain 0 loss std 6.46e+03 variance 2.09e+07 smooth variance 1.80e+07 adaptive c -1.00\n",
      "Epoch 48 Chain 1 loss std 8.39e+02 variance 3.52e+05 smooth variance 3.71e+06 adaptive c -1.00\n",
      " Loss: 2.068221\n",
      " Loss: 0.912095\n",
      " Loss: 1.322926\n",
      " Loss: 1.009050\n",
      " Loss: 1.664266\n",
      " Loss: 0.958091\n",
      " Loss: 2.066651\n",
      " Loss: 1.302923\n",
      " Loss: 2.149491\n",
      " Loss: 0.663203\n",
      " Loss: 0.939107\n",
      " Loss: 1.011395\n",
      " Loss: 1.273309\n",
      " Loss: 0.792661\n",
      " Loss: 2.546824\n",
      " Loss: 1.216495\n",
      " Loss: 2.313259\n",
      " Loss: 1.008685\n",
      " Loss: 3.196290\n",
      " Loss: 0.802184\n",
      "Epoch 50 Chain 0 loss std 6.90e+03 variance 2.38e+07 smooth variance 1.98e+07 adaptive c -1.00\n",
      "Epoch 50 Chain 1 loss std 2.92e+03 variance 4.26e+06 smooth variance 3.88e+06 adaptive c -1.00\n",
      " Loss: 3.272161\n",
      " Loss: 0.842857\n",
      " Loss: 1.094756\n",
      " Loss: 1.112472\n",
      " Loss: 1.451629\n",
      " Loss: 0.889849\n",
      " Loss: 1.976048\n",
      " Loss: 1.087494\n",
      " Loss: 3.251654\n",
      " Loss: 0.891842\n",
      " Loss: 3.854283\n",
      " Loss: 0.965535\n",
      " Loss: 1.403123\n",
      " Loss: 0.771335\n",
      " Loss: 2.140230\n",
      " Loss: 0.906957\n",
      " Loss: 2.639694\n",
      " Loss: 1.183622\n",
      " Loss: 1.792558\n",
      " Loss: 1.014059\n",
      "Epoch 52 Chain 0 loss std 7.66e+03 variance 2.93e+07 smooth variance 2.26e+07 adaptive c -1.00\n",
      "Epoch 52 Chain 1 loss std 1.66e+03 variance 1.38e+06 smooth variance 3.13e+06 adaptive c -1.00\n",
      " Loss: 3.119719\n",
      " Loss: 1.099658\n",
      " Loss: 4.105837\n",
      " Loss: 1.036070\n",
      " Loss: 1.672497\n",
      " Loss: 0.769665\n",
      " Loss: 0.798412\n",
      " Loss: 0.841618\n",
      " Loss: 1.974442\n",
      " Loss: 1.104913\n",
      " Loss: 1.020504\n",
      " Loss: 0.469329\n",
      " Loss: 2.967306\n",
      " Loss: 0.846238\n",
      " Loss: 3.306789\n",
      " Loss: 1.165845\n",
      " Loss: 2.045197\n",
      " Loss: 1.359116\n",
      " Loss: 1.912373\n",
      " Loss: 1.003760\n",
      "Epoch 54 Chain 0 loss std 9.17e+03 variance 4.21e+07 smooth variance 2.85e+07 adaptive c -1.00\n",
      "Epoch 54 Chain 1 loss std 3.24e+03 variance 5.23e+06 smooth variance 3.76e+06 adaptive c -1.00\n",
      " Loss: 2.032866\n",
      " Loss: 1.030462\n",
      " Loss: 3.381469\n",
      " Loss: 0.960785\n",
      " Loss: 1.454542\n",
      " Loss: 0.959613\n",
      " Loss: 2.082397\n",
      " Loss: 1.549126\n",
      " Loss: 2.420937\n",
      " Loss: 0.329556\n",
      " Loss: 1.417724\n",
      " Loss: 1.259326\n",
      " Loss: 2.900876\n",
      " Loss: 0.561503\n",
      " Loss: 1.787968\n",
      " Loss: 1.046184\n",
      " Loss: 2.971751\n",
      " Loss: 0.993272\n",
      " Loss: 2.458027\n",
      " Loss: 0.969854\n",
      "Epoch 56 Chain 0 loss std 9.99e+03 variance 4.99e+07 smooth variance 3.49e+07 adaptive c -1.00\n",
      "Epoch 56 Chain 1 loss std 2.74e+03 variance 3.75e+06 smooth variance 3.76e+06 adaptive c -1.00\n",
      " Loss: 2.109445\n",
      " Loss: 1.207477\n",
      " Loss: 2.545820\n",
      " Loss: 1.280013\n",
      " Loss: 3.566795\n",
      " Loss: 0.951919\n",
      " Loss: 2.106253\n",
      " Loss: 0.655248\n",
      " Loss: 1.356821\n",
      " Loss: 0.722530\n",
      " Loss: 2.208665\n",
      " Loss: 1.233992\n",
      " Loss: 2.124214\n",
      " Loss: 0.684426\n",
      " Loss: 0.932000\n",
      " Loss: 1.004634\n",
      " Loss: 4.796707\n",
      " Loss: 0.873995\n",
      " Loss: 2.072659\n",
      " Loss: 1.015258\n",
      "Epoch 58 Chain 0 loss std 1.05e+04 variance 5.49e+07 smooth variance 4.09e+07 adaptive c -1.00\n",
      "Epoch 58 Chain 1 loss std 2.06e+03 variance 2.12e+06 smooth variance 3.27e+06 adaptive c -1.00\n",
      " Loss: 2.573847\n",
      " Loss: 1.021635\n",
      " Loss: 3.222582\n",
      " Loss: 1.481668\n",
      " Loss: 2.505907\n",
      " Loss: 0.850847\n",
      " Loss: 2.586107\n",
      " Loss: 0.826043\n",
      " Loss: 1.545435\n",
      " Loss: 0.619350\n",
      " Loss: 1.688270\n",
      " Loss: 1.067963\n",
      " Loss: 3.055232\n",
      " Loss: 0.775006\n",
      " Loss: 1.206145\n",
      " Loss: 0.566240\n",
      " Loss: 3.298726\n",
      " Loss: 1.307476\n",
      " Loss: 3.843864\n",
      " Loss: 1.074274\n",
      "Epoch 60 Chain 0 loss std 6.91e+03 variance 2.39e+07 smooth variance 3.58e+07 adaptive c -1.00\n",
      "Epoch 60 Chain 1 loss std 3.96e+03 variance 7.85e+06 smooth variance 4.64e+06 adaptive c -1.00\n",
      " Loss: 1.522357\n",
      " Loss: 0.541766\n",
      " Loss: 3.029027\n",
      " Loss: 0.752889\n",
      " Loss: 1.653407\n",
      " Loss: 0.775868\n",
      " Loss: 4.290273\n",
      " Loss: 1.217251\n",
      " Loss: 3.477313\n",
      " Loss: 1.500947\n",
      " Loss: 4.269735\n",
      " Loss: 1.008323\n",
      " Loss: 2.611403\n",
      " Loss: 0.923149\n",
      " Loss: 1.876749\n",
      " Loss: 0.792888\n",
      " Loss: 3.913865\n",
      " Loss: 1.196196\n",
      " Loss: 1.601548\n",
      " Loss: 0.868969\n",
      "Epoch 62 Chain 0 loss std 1.21e+04 variance 7.33e+07 smooth variance 4.70e+07 adaptive c -1.00\n",
      "Epoch 62 Chain 1 loss std 3.57e+03 variance 6.38e+06 smooth variance 5.16e+06 adaptive c -1.00\n",
      " Loss: 4.769660\n",
      " Loss: 0.973276\n",
      " Loss: 2.347936\n",
      " Loss: 1.222373\n",
      " Loss: 2.096012\n",
      " Loss: 0.746567\n",
      " Loss: 2.743137\n",
      " Loss: 1.219984\n",
      " Loss: 1.932069\n",
      " Loss: 0.625507\n",
      " Loss: 1.618667\n",
      " Loss: 0.781056\n",
      " Loss: 3.683411\n",
      " Loss: 0.807729\n",
      " Loss: 2.402049\n",
      " Loss: 1.312440\n",
      " Loss: 3.441319\n",
      " Loss: 0.941463\n",
      " Loss: 2.092811\n",
      " Loss: 0.934800\n",
      "Epoch 64 Chain 0 loss std 7.06e+03 variance 2.49e+07 smooth variance 4.04e+07 adaptive c -1.00\n",
      "Epoch 64 Chain 1 loss std 1.93e+03 variance 1.87e+06 smooth variance 4.17e+06 adaptive c -1.00\n",
      " Loss: 3.545695\n",
      " Loss: 1.043754\n",
      " Loss: 1.157215\n",
      " Loss: 0.954156\n",
      " Loss: 3.067303\n",
      " Loss: 0.866986\n",
      " Loss: 2.359807\n",
      " Loss: 0.736676\n",
      " Loss: 2.699798\n",
      " Loss: 1.146280\n",
      " Loss: 4.308114\n",
      " Loss: 1.139877\n",
      " Loss: 1.738680\n",
      " Loss: 0.597452\n",
      " Loss: 2.469381\n",
      " Loss: 0.839931\n",
      " Loss: 1.845901\n",
      " Loss: 1.159647\n",
      " Loss: 2.067492\n",
      " Loss: 0.992053\n",
      "Epoch 66 Chain 0 loss std 3.90e+03 variance 7.60e+06 smooth variance 3.06e+07 adaptive c -1.00\n",
      "Epoch 66 Chain 1 loss std 2.88e+03 variance 4.16e+06 smooth variance 4.17e+06 adaptive c -1.00\n",
      " Loss: 1.992750\n",
      " Loss: 1.071728\n",
      " Loss: 1.859717\n",
      " Loss: 0.958125\n",
      " Loss: 2.281259\n",
      " Loss: 0.913564\n",
      " Loss: 2.613748\n",
      " Loss: 0.907208\n",
      " Loss: 1.947883\n",
      " Loss: 0.864483\n",
      " Loss: 2.476384\n",
      " Loss: 1.208036\n",
      " Loss: 1.887684\n",
      " Loss: 0.914826\n",
      " Loss: 2.199536\n",
      " Loss: 0.876803\n",
      " Loss: 1.435647\n",
      " Loss: 0.712972\n",
      " Loss: 2.163540\n",
      " Loss: 0.994546\n",
      "Epoch 68 Chain 0 loss std 6.95e+03 variance 2.42e+07 smooth variance 2.86e+07 adaptive c -1.00\n",
      "Epoch 68 Chain 1 loss std 3.02e+03 variance 4.55e+06 smooth variance 4.28e+06 adaptive c -1.00\n",
      " Loss: 2.087834\n",
      " Loss: 0.912836\n",
      " Loss: 1.766301\n",
      " Loss: 1.169739\n",
      " Loss: 1.232177\n",
      " Loss: 0.759705\n",
      " Loss: 3.162854\n",
      " Loss: 0.919530\n",
      " Loss: 2.002356\n",
      " Loss: 0.937791\n",
      " Loss: 2.385107\n",
      " Loss: 1.243694\n",
      " Loss: 1.745338\n",
      " Loss: 1.058339\n",
      " Loss: 1.292393\n",
      " Loss: 0.678207\n",
      " Loss: 2.151541\n",
      " Loss: 1.059549\n",
      " Loss: 2.875527\n",
      " Loss: 0.646021\n",
      "Epoch 70 Chain 0 loss std 3.64e+03 variance 6.62e+06 smooth variance 2.20e+07 adaptive c -1.00\n",
      "Epoch 70 Chain 1 loss std 2.06e+03 variance 2.12e+06 smooth variance 3.63e+06 adaptive c -1.00\n",
      " Loss: 1.993648\n",
      " Loss: 0.856238\n",
      " Loss: 1.453035\n",
      " Loss: 0.749403\n",
      " Loss: 1.745833\n",
      " Loss: 1.128158\n",
      " Loss: 2.719178\n",
      " Loss: 1.394298\n",
      " Loss: 2.166007\n",
      " Loss: 0.542455\n",
      " Loss: 1.836941\n",
      " Loss: 0.647967\n",
      " Loss: 1.998754\n",
      " Loss: 1.323646\n",
      " Loss: 2.215878\n",
      " Loss: 1.184590\n",
      " Loss: 1.414854\n",
      " Loss: 0.634561\n",
      " Loss: 2.510778\n",
      " Loss: 0.868485\n",
      "Epoch 72 Chain 0 loss std 3.78e+03 variance 7.16e+06 smooth variance 1.76e+07 adaptive c -1.00\n",
      "Epoch 72 Chain 1 loss std 1.07e+03 variance 5.76e+05 smooth variance 2.72e+06 adaptive c -1.00\n",
      " Loss: 2.364368\n",
      " Loss: 1.051466\n",
      " Loss: 2.653241\n",
      " Loss: 0.925469\n",
      " Loss: 1.943474\n",
      " Loss: 0.851096\n",
      " Loss: 1.546147\n",
      " Loss: 0.846265\n",
      " Loss: 1.875058\n",
      " Loss: 0.977024\n",
      " Loss: 3.050507\n",
      " Loss: 1.071187\n",
      " Loss: 2.568130\n",
      " Loss: 1.142213\n",
      " Loss: 1.232491\n",
      " Loss: 1.004692\n",
      " Loss: 2.282984\n",
      " Loss: 0.850252\n",
      " Loss: 1.878937\n",
      " Loss: 0.573158\n",
      "Epoch 74 Chain 0 loss std 7.82e+03 variance 3.06e+07 smooth variance 2.15e+07 adaptive c -1.00\n",
      "Epoch 74 Chain 1 loss std 4.38e+03 variance 9.60e+06 smooth variance 4.78e+06 adaptive c -1.00\n",
      " Loss: 2.244087\n",
      " Loss: 0.944796\n",
      " Loss: 2.121186\n",
      " Loss: 1.146831\n",
      " Loss: 1.500914\n",
      " Loss: 0.883583\n",
      " Loss: 2.267817\n",
      " Loss: 0.600511\n",
      " Loss: 3.375794\n",
      " Loss: 1.066057\n",
      " Loss: 2.508637\n",
      " Loss: 1.081848\n",
      " Loss: 3.065277\n",
      " Loss: 0.874395\n",
      " Loss: 2.698481\n",
      " Loss: 0.572792\n",
      " Loss: 2.098144\n",
      " Loss: 1.038927\n",
      " Loss: 1.448735\n",
      " Loss: 1.084106\n",
      "Epoch 76 Chain 0 loss std 7.94e+03 variance 3.16e+07 smooth variance 2.45e+07 adaptive c -1.00\n",
      "Epoch 76 Chain 1 loss std 2.26e+03 variance 2.56e+06 smooth variance 4.12e+06 adaptive c -1.00\n",
      " Loss: 1.604459\n",
      " Loss: 0.959497\n",
      " Loss: 3.500211\n",
      " Loss: 1.052170\n",
      " Loss: 1.982357\n",
      " Loss: 0.613372\n",
      " Loss: 2.978238\n",
      " Loss: 0.968731\n",
      " Loss: 2.023067\n",
      " Loss: 1.061943\n",
      " Loss: 1.391878\n",
      " Loss: 1.214906\n",
      " Loss: 3.399865\n",
      " Loss: 0.917037\n",
      " Loss: 1.772589\n",
      " Loss: 0.873641\n",
      " Loss: 1.847452\n",
      " Loss: 0.871010\n",
      " Loss: 4.012905\n",
      " Loss: 0.774997\n",
      "Epoch 78 Chain 0 loss std 5.65e+03 variance 1.60e+07 smooth variance 2.19e+07 adaptive c -1.00\n",
      "Epoch 78 Chain 1 loss std 1.82e+03 variance 1.66e+06 smooth variance 3.38e+06 adaptive c -1.00\n",
      " Loss: 2.512945\n",
      " Loss: 1.030975\n",
      " Loss: 1.353843\n",
      " Loss: 1.032040\n",
      " Loss: 1.360163\n",
      " Loss: 0.829671\n",
      " Loss: 4.531836\n",
      " Loss: 0.812948\n",
      " Loss: 2.442888\n",
      " Loss: 0.949612\n",
      " Loss: 4.684562\n",
      " Loss: 1.319210\n",
      " Loss: 1.056360\n",
      " Loss: 0.739380\n",
      " Loss: 1.515718\n",
      " Loss: 1.043196\n",
      " Loss: 2.496420\n",
      " Loss: 0.804590\n",
      " Loss: 1.953255\n",
      " Loss: 0.737267\n",
      "Epoch 80 Chain 0 loss std 9.51e+03 variance 4.52e+07 smooth variance 2.89e+07 adaptive c -1.00\n",
      "Epoch 80 Chain 1 loss std 1.76e+03 variance 1.55e+06 smooth variance 2.83e+06 adaptive c -1.00\n",
      " Loss: 1.705085\n",
      " Loss: 1.108692\n",
      " Loss: 2.200508\n",
      " Loss: 0.761238\n",
      " Loss: 1.503178\n",
      " Loss: 1.093093\n",
      " Loss: 2.624057\n",
      " Loss: 0.658920\n",
      " Loss: 3.468613\n",
      " Loss: 1.002922\n",
      " Loss: 1.645860\n",
      " Loss: 0.486395\n",
      " Loss: 3.561706\n",
      " Loss: 1.384293\n",
      " Loss: 2.848356\n",
      " Loss: 0.916725\n",
      " Loss: 1.846931\n",
      " Loss: 0.790219\n",
      " Loss: 1.140988\n",
      " Loss: 1.034150\n",
      "Epoch 82 Chain 0 loss std 8.23e+03 variance 3.39e+07 smooth variance 3.04e+07 adaptive c -1.00\n",
      "Epoch 82 Chain 1 loss std 1.77e+03 variance 1.56e+06 smooth variance 2.45e+06 adaptive c -1.00\n",
      " Loss: 2.332519\n",
      " Loss: 1.190194\n",
      " Loss: 1.136141\n",
      " Loss: 1.035521\n",
      " Loss: 3.102481\n",
      " Loss: 0.906701\n",
      " Loss: 2.475392\n",
      " Loss: 0.711800\n",
      " Loss: 1.036281\n",
      " Loss: 0.744077\n",
      " Loss: 1.913578\n",
      " Loss: 0.757735\n",
      " Loss: 2.409436\n",
      " Loss: 0.847467\n",
      " Loss: 1.276924\n",
      " Loss: 0.836184\n",
      " Loss: 1.729779\n",
      " Loss: 1.090630\n",
      " Loss: 2.332674\n",
      " Loss: 1.045737\n",
      "Epoch 84 Chain 0 loss std 1.15e+04 variance 6.56e+07 smooth variance 4.10e+07 adaptive c -1.00\n",
      "Epoch 84 Chain 1 loss std 1.85e+03 variance 1.71e+06 smooth variance 2.23e+06 adaptive c -1.00\n",
      " Loss: 1.149195\n",
      " Loss: 1.437748\n",
      " Loss: 2.945552\n",
      " Loss: 0.657263\n",
      " Loss: 1.131596\n",
      " Loss: 0.445637\n",
      " Loss: 2.886735\n",
      " Loss: 0.777230\n",
      " Loss: 1.133498\n",
      " Loss: 1.246715\n",
      " Loss: 2.620166\n",
      " Loss: 0.950922\n",
      " Loss: 0.835183\n",
      " Loss: 0.749187\n",
      " Loss: 2.516300\n",
      " Loss: 1.044769\n",
      " Loss: 1.547970\n",
      " Loss: 0.849213\n",
      " Loss: 1.792976\n",
      " Loss: 0.956086\n",
      "Epoch 86 Chain 0 loss std 3.27e+03 variance 5.34e+06 smooth variance 3.03e+07 adaptive c -1.00\n",
      "Epoch 86 Chain 1 loss std 2.07e+03 variance 2.15e+06 smooth variance 2.20e+06 adaptive c -1.00\n",
      " Loss: 2.221399\n",
      " Loss: 0.713661\n",
      " Loss: 1.488623\n",
      " Loss: 1.156979\n",
      " Loss: 3.298737\n",
      " Loss: 0.959095\n",
      " Loss: 0.945781\n",
      " Loss: 0.851778\n",
      " Loss: 1.489014\n",
      " Loss: 0.861097\n",
      " Loss: 2.486153\n",
      " Loss: 1.258620\n",
      " Loss: 2.150031\n",
      " Loss: 1.035409\n",
      " Loss: 1.117111\n",
      " Loss: 0.599784\n",
      " Loss: 2.195674\n",
      " Loss: 0.825402\n",
      " Loss: 1.746563\n",
      " Loss: 0.809241\n",
      "Epoch 88 Chain 0 loss std 1.00e+04 variance 5.03e+07 smooth variance 3.63e+07 adaptive c -1.00\n",
      "Epoch 88 Chain 1 loss std 2.05e+03 variance 2.11e+06 smooth variance 2.18e+06 adaptive c -1.00\n",
      " Loss: 1.891337\n",
      " Loss: 0.993428\n",
      " Loss: 2.410691\n",
      " Loss: 1.121297\n",
      " Loss: 2.294239\n",
      " Loss: 0.560606\n",
      " Loss: 2.587064\n",
      " Loss: 0.996030\n",
      " Loss: 1.038935\n",
      " Loss: 0.849384\n",
      " Loss: 2.639842\n",
      " Loss: 0.748918\n",
      " Loss: 3.357557\n",
      " Loss: 0.738390\n",
      " Loss: 0.734180\n",
      " Loss: 1.247149\n",
      " Loss: 1.765344\n",
      " Loss: 0.785464\n",
      " Loss: 2.343629\n",
      " Loss: 0.980507\n",
      "Epoch 90 Chain 0 loss std 7.57e+03 variance 2.86e+07 smooth variance 3.40e+07 adaptive c -1.00\n",
      "Epoch 90 Chain 1 loss std 2.67e+03 variance 3.56e+06 smooth variance 2.59e+06 adaptive c -1.00\n",
      " Loss: 2.345971\n",
      " Loss: 1.022423\n",
      " Loss: 2.860957\n",
      " Loss: 1.072142\n",
      " Loss: 2.586342\n",
      " Loss: 1.144566\n",
      " Loss: 2.056340\n",
      " Loss: 0.692222\n",
      " Loss: 1.520421\n",
      " Loss: 0.562505\n",
      " Loss: 2.142825\n",
      " Loss: 1.479314\n",
      " Loss: 1.843640\n",
      " Loss: 0.823580\n",
      " Loss: 2.964445\n",
      " Loss: 0.840333\n",
      " Loss: 2.821314\n",
      " Loss: 0.692977\n",
      " Loss: 1.876044\n",
      " Loss: 0.656647\n",
      "Epoch 92 Chain 0 loss std 6.16e+03 variance 1.90e+07 smooth variance 2.95e+07 adaptive c -1.00\n",
      "Epoch 92 Chain 1 loss std 2.44e+03 variance 2.97e+06 smooth variance 2.70e+06 adaptive c -1.00\n",
      " Loss: 2.607314\n",
      " Loss: 1.061395\n",
      " Loss: 2.256676\n",
      " Loss: 1.322535\n",
      " Loss: 2.103699\n",
      " Loss: 0.566215\n",
      " Loss: 2.732924\n",
      " Loss: 0.827776\n",
      " Loss: 2.090799\n",
      " Loss: 0.700013\n",
      " Loss: 2.062608\n",
      " Loss: 0.823457\n",
      " Loss: 2.175831\n",
      " Loss: 0.551663\n",
      " Loss: 3.751691\n",
      " Loss: 0.939607\n",
      " Loss: 1.999015\n",
      " Loss: 1.051108\n",
      " Loss: 2.160411\n",
      " Loss: 1.104912\n",
      "Epoch 94 Chain 0 loss std 4.34e+03 variance 9.40e+06 smooth variance 2.35e+07 adaptive c -1.00\n",
      "Epoch 94 Chain 1 loss std 1.32e+03 variance 8.68e+05 smooth variance 2.15e+06 adaptive c -1.00\n",
      " Loss: 2.926759\n",
      " Loss: 1.108928\n",
      " Loss: 1.472036\n",
      " Loss: 1.039043\n",
      " Loss: 3.734099\n",
      " Loss: 0.556083\n",
      " Loss: 1.768075\n",
      " Loss: 0.732679\n",
      " Loss: 2.585524\n",
      " Loss: 1.023934\n",
      " Loss: 1.500999\n",
      " Loss: 0.948355\n",
      " Loss: 3.489143\n",
      " Loss: 0.982656\n",
      " Loss: 3.413151\n",
      " Loss: 0.720021\n",
      " Loss: 1.877681\n",
      " Loss: 0.580966\n",
      " Loss: 2.391037\n",
      " Loss: 1.221183\n",
      "Epoch 96 Chain 0 loss std 6.45e+03 variance 2.08e+07 smooth variance 2.27e+07 adaptive c -1.00\n",
      "Epoch 96 Chain 1 loss std 1.70e+03 variance 1.45e+06 smooth variance 1.94e+06 adaptive c -1.00\n",
      " Loss: 1.941653\n",
      " Loss: 0.762263\n",
      " Loss: 2.298996\n",
      " Loss: 0.867566\n",
      " Loss: 3.030304\n",
      " Loss: 0.965220\n",
      " Loss: 2.719859\n",
      " Loss: 1.158370\n",
      " Loss: 2.900455\n",
      " Loss: 0.691412\n",
      " Loss: 1.145303\n",
      " Loss: 0.359289\n",
      " Loss: 3.775483\n",
      " Loss: 0.731391\n",
      " Loss: 2.780474\n",
      " Loss: 1.127463\n",
      " Loss: 2.589549\n",
      " Loss: 0.995598\n",
      " Loss: 3.473372\n",
      " Loss: 1.216996\n",
      "Epoch 98 Chain 0 loss std 8.40e+03 variance 3.53e+07 smooth variance 2.65e+07 adaptive c -1.00\n",
      "Epoch 98 Chain 1 loss std 1.64e+03 variance 1.34e+06 smooth variance 1.76e+06 adaptive c -1.00\n",
      " Loss: 2.877998\n",
      " Loss: 0.903454\n",
      " Loss: 2.294582\n",
      " Loss: 0.704019\n",
      " Loss: 3.414545\n",
      " Loss: 0.902765\n",
      " Loss: 3.654818\n",
      " Loss: 1.028344\n",
      " Loss: 1.679094\n",
      " Loss: 0.882651\n",
      " Loss: 3.254428\n",
      " Loss: 1.153012\n",
      " Loss: 3.666054\n",
      " Loss: 1.137303\n",
      " Loss: 2.036669\n",
      " Loss: 0.680997\n",
      " Loss: 3.356021\n",
      " Loss: 0.871642\n",
      " Loss: 1.864574\n",
      " Loss: 0.573471\n",
      "Epoch 100 Chain 0 loss std 1.00e+04 variance 5.04e+07 smooth variance 3.36e+07 adaptive c -1.00\n",
      "Epoch 100 Chain 1 loss std 9.59e+02 variance 4.59e+05 smooth variance 1.37e+06 adaptive c -1.00\n",
      " Loss: 3.077801\n",
      " Loss: 0.980238\n",
      " Loss: 2.581530\n",
      " Loss: 0.679578\n",
      " Loss: 2.683151\n",
      " Loss: 1.075854\n",
      " Loss: 3.121388\n",
      " Loss: 0.747637\n",
      " Loss: 3.391821\n",
      " Loss: 0.940311\n",
      " Loss: 2.860534\n",
      " Loss: 1.248626\n",
      " Loss: 5.180953\n",
      " Loss: 0.892338\n",
      " Loss: 1.620860\n",
      " Loss: 1.025717\n",
      " Loss: 3.175823\n",
      " Loss: 0.643818\n",
      " Loss: 1.871545\n",
      " Loss: 0.620220\n",
      "Epoch 102 Chain 0 loss std 8.90e+03 variance 3.96e+07 smooth variance 3.54e+07 adaptive c -1.00\n",
      "Epoch 102 Chain 1 loss std 2.26e+03 variance 2.56e+06 smooth variance 1.73e+06 adaptive c -1.00\n",
      " Loss: 2.162168\n",
      " Loss: 1.013175\n",
      " Loss: 4.146187\n",
      " Loss: 1.129342\n",
      " Loss: 2.825169\n",
      " Loss: 1.026568\n",
      " Loss: 1.983868\n",
      " Loss: 0.561127\n",
      " Loss: 3.144233\n",
      " Loss: 0.708666\n",
      " Loss: 1.871797\n",
      " Loss: 1.100812\n",
      " Loss: 3.773374\n",
      " Loss: 0.949773\n",
      " Loss: 1.717861\n",
      " Loss: 0.519385\n",
      " Loss: 3.494462\n",
      " Loss: 0.701814\n",
      " Loss: 2.863923\n",
      " Loss: 1.160243\n",
      "Epoch 104 Chain 0 loss std 9.75e+03 variance 4.75e+07 smooth variance 3.91e+07 adaptive c -1.00\n",
      "Epoch 104 Chain 1 loss std 1.72e+03 variance 1.48e+06 smooth variance 1.65e+06 adaptive c -1.00\n",
      " Loss: 2.398944\n",
      " Loss: 0.787990\n",
      " Loss: 2.977763\n",
      " Loss: 0.669683\n",
      " Loss: 3.997556\n",
      " Loss: 1.103976\n",
      " Loss: 1.546676\n",
      " Loss: 0.449944\n",
      " Loss: 2.794955\n",
      " Loss: 1.414662\n",
      " Loss: 3.528021\n",
      " Loss: 1.006400\n",
      " Loss: 3.822088\n",
      " Loss: 0.990992\n",
      " Loss: 1.274176\n",
      " Loss: 0.975315\n",
      " Loss: 2.353821\n",
      " Loss: 0.740797\n",
      " Loss: 2.297966\n",
      " Loss: 0.711011\n",
      "Epoch 106 Chain 0 loss std 8.52e+03 variance 3.63e+07 smooth variance 3.82e+07 adaptive c -1.00\n",
      "Epoch 106 Chain 1 loss std 2.68e+03 variance 3.59e+06 smooth variance 2.23e+06 adaptive c -1.00\n",
      " Loss: 2.796284\n",
      " Loss: 1.326326\n",
      " Loss: 2.739167\n",
      " Loss: 0.868377\n",
      " Loss: 1.974918\n",
      " Loss: 0.702143\n",
      " Loss: 1.328229\n",
      " Loss: 0.576458\n",
      " Loss: 4.133521\n",
      " Loss: 0.938426\n",
      " Loss: 2.779236\n",
      " Loss: 0.831454\n",
      " Loss: 2.100905\n",
      " Loss: 1.114250\n",
      " Loss: 3.143439\n",
      " Loss: 0.913868\n",
      " Loss: 1.717175\n",
      " Loss: 0.980188\n",
      " Loss: 2.891131\n",
      " Loss: 0.565073\n",
      "Epoch 108 Chain 0 loss std 1.04e+04 variance 5.44e+07 smooth variance 4.31e+07 adaptive c -1.00\n",
      "Epoch 108 Chain 1 loss std 2.57e+03 variance 3.31e+06 smooth variance 2.56e+06 adaptive c -1.00\n",
      " Loss: 1.962103\n",
      " Loss: 0.493074\n",
      " Loss: 2.576727\n",
      " Loss: 0.858322\n",
      " Loss: 2.502630\n",
      " Loss: 1.153377\n",
      " Loss: 2.314737\n",
      " Loss: 0.919175\n",
      " Loss: 3.458860\n",
      " Loss: 0.977692\n",
      " Loss: 1.455959\n",
      " Loss: 0.792303\n",
      " Loss: 2.420096\n",
      " Loss: 1.165354\n",
      " Loss: 2.501179\n",
      " Loss: 0.689728\n",
      " Loss: 3.977375\n",
      " Loss: 0.933219\n",
      " Loss: 2.492438\n",
      " Loss: 0.816064\n",
      "Epoch 110 Chain 0 loss std 6.46e+03 variance 2.09e+07 smooth variance 3.64e+07 adaptive c -1.00\n",
      "Epoch 110 Chain 1 loss std 2.43e+03 variance 2.94e+06 smooth variance 2.67e+06 adaptive c -1.00\n",
      " Loss: 2.918292\n",
      " Loss: 1.208066\n",
      " Loss: 2.676572\n",
      " Loss: 0.919671\n",
      " Loss: 2.626965\n",
      " Loss: 0.863194\n",
      " Loss: 1.634316\n",
      " Loss: 0.335121\n",
      " Loss: 3.120868\n",
      " Loss: 1.062250\n",
      " Loss: 1.454055\n",
      " Loss: 0.865908\n",
      " Loss: 3.411605\n",
      " Loss: 1.224161\n",
      " Loss: 2.453253\n",
      " Loss: 0.646119\n",
      " Loss: 1.844449\n",
      " Loss: 0.902830\n",
      " Loss: 3.811075\n",
      " Loss: 0.748418\n",
      "Epoch 112 Chain 0 loss std 4.87e+03 variance 1.18e+07 smooth variance 2.90e+07 adaptive c -1.00\n",
      "Epoch 112 Chain 1 loss std 6.26e+02 variance 1.96e+05 smooth variance 1.93e+06 adaptive c -1.00\n",
      " Loss: 2.049198\n",
      " Loss: 0.969724\n",
      " Loss: 2.283027\n",
      " Loss: 0.764352\n",
      " Loss: 2.602089\n",
      " Loss: 0.846978\n",
      " Loss: 3.993488\n",
      " Loss: 0.809896\n",
      " Loss: 2.111465\n",
      " Loss: 0.987088\n",
      " Loss: 2.664490\n",
      " Loss: 1.111185\n",
      " Loss: 2.695565\n",
      " Loss: 0.799480\n",
      " Loss: 2.933939\n",
      " Loss: 0.942809\n",
      " Loss: 2.474445\n",
      " Loss: 0.944496\n",
      " Loss: 2.542104\n",
      " Loss: 0.564541\n",
      "Epoch 114 Chain 0 loss std 4.94e+03 variance 1.22e+07 smooth variance 2.40e+07 adaptive c -1.00\n",
      "Epoch 114 Chain 1 loss std 2.93e+03 variance 4.30e+06 smooth variance 2.64e+06 adaptive c -1.00\n",
      " Loss: 2.293689\n",
      " Loss: 0.708078\n",
      " Loss: 2.058647\n",
      " Loss: 0.714614\n",
      " Loss: 3.260124\n",
      " Loss: 0.891019\n",
      " Loss: 2.837866\n",
      " Loss: 0.562196\n",
      " Loss: 3.281333\n",
      " Loss: 1.470268\n",
      " Loss: 2.074323\n",
      " Loss: 0.576412\n",
      " Loss: 2.841988\n",
      " Loss: 0.792778\n",
      " Loss: 2.724157\n",
      " Loss: 0.925500\n",
      " Loss: 3.718154\n",
      " Loss: 1.245751\n",
      " Loss: 2.379721\n",
      " Loss: 0.788230\n",
      "Epoch 116 Chain 0 loss std 3.63e+03 variance 6.59e+06 smooth variance 1.88e+07 adaptive c -1.00\n",
      "Epoch 116 Chain 1 loss std 2.01e+03 variance 2.03e+06 smooth variance 2.46e+06 adaptive c -1.00\n",
      " Loss: 3.070266\n",
      " Loss: 0.894119\n",
      " Loss: 3.330951\n",
      " Loss: 0.678058\n",
      " Loss: 1.918775\n",
      " Loss: 0.664550\n",
      " Loss: 2.165451\n",
      " Loss: 0.863494\n",
      " Loss: 3.033525\n",
      " Loss: 1.222787\n",
      " Loss: 3.454374\n",
      " Loss: 0.879520\n",
      " Loss: 2.927898\n",
      " Loss: 1.086412\n",
      " Loss: 2.128910\n",
      " Loss: 0.791357\n",
      " Loss: 3.726251\n",
      " Loss: 1.041671\n",
      " Loss: 1.451492\n",
      " Loss: 0.507162\n",
      "Epoch 118 Chain 0 loss std 3.42e+03 variance 5.85e+06 smooth variance 1.49e+07 adaptive c -1.00\n",
      "Epoch 118 Chain 1 loss std 3.10e+03 variance 4.80e+06 smooth variance 3.16e+06 adaptive c -1.00\n",
      " Loss: 2.819284\n",
      " Loss: 0.832056\n",
      " Loss: 2.229898\n",
      " Loss: 0.971203\n",
      " Loss: 1.843231\n",
      " Loss: 0.816845\n",
      " Loss: 3.263769\n",
      " Loss: 1.025624\n",
      " Loss: 3.111773\n",
      " Loss: 0.640883\n",
      " Loss: 3.056293\n",
      " Loss: 0.788717\n",
      " Loss: 2.732044\n",
      " Loss: 0.922940\n",
      " Loss: 1.657326\n",
      " Loss: 0.711480\n",
      " Loss: 2.237520\n",
      " Loss: 0.982753\n",
      " Loss: 2.972273\n",
      " Loss: 0.850325\n",
      "Epoch 120 Chain 0 loss std 3.66e+03 variance 6.72e+06 smooth variance 1.24e+07 adaptive c -1.00\n",
      "Epoch 120 Chain 1 loss std 1.30e+03 variance 8.39e+05 smooth variance 2.46e+06 adaptive c -1.00\n",
      " Loss: 2.153359\n",
      " Loss: 0.681680\n",
      " Loss: 3.235149\n",
      " Loss: 1.320778\n",
      " Loss: 1.971120\n",
      " Loss: 0.927922\n",
      " Loss: 1.775686\n",
      " Loss: 0.597400\n",
      " Loss: 2.836973\n",
      " Loss: 0.703681\n",
      " Loss: 1.665245\n",
      " Loss: 1.007566\n",
      " Loss: 3.734989\n",
      " Loss: 0.669725\n",
      " Loss: 2.373299\n",
      " Loss: 0.805923\n",
      " Loss: 1.332891\n",
      " Loss: 0.978061\n",
      " Loss: 2.323370\n",
      " Loss: 0.747410\n",
      "Epoch 122 Chain 0 loss std 7.46e+03 variance 2.78e+07 smooth variance 1.70e+07 adaptive c -1.00\n",
      "Epoch 122 Chain 1 loss std 2.63e+03 variance 3.45e+06 smooth variance 2.76e+06 adaptive c -1.00\n",
      " Loss: 1.988350\n",
      " Loss: 0.802204\n",
      " Loss: 1.805423\n",
      " Loss: 0.705315\n",
      " Loss: 2.054633\n",
      " Loss: 0.519068\n",
      " Loss: 2.567889\n",
      " Loss: 1.245624\n",
      " Loss: 2.753247\n",
      " Loss: 0.916552\n",
      " Loss: 3.008952\n",
      " Loss: 0.832291\n",
      " Loss: 2.366297\n",
      " Loss: 1.266945\n",
      " Loss: 2.687063\n",
      " Loss: 0.639883\n",
      " Loss: 1.029126\n",
      " Loss: 0.729098\n",
      " Loss: 1.754854\n",
      " Loss: 0.700072\n",
      "Epoch 124 Chain 0 loss std 3.11e+03 variance 4.82e+06 smooth variance 1.34e+07 adaptive c -1.00\n",
      "Epoch 124 Chain 1 loss std 1.18e+03 variance 6.91e+05 smooth variance 2.14e+06 adaptive c -1.00\n",
      " Loss: 2.634293\n",
      " Loss: 0.753213\n",
      " Loss: 2.975779\n",
      " Loss: 0.697771\n",
      " Loss: 1.716553\n",
      " Loss: 1.022752\n",
      " Loss: 1.724388\n",
      " Loss: 1.099549\n",
      " Loss: 1.256809\n",
      " Loss: 0.576283\n",
      " Loss: 2.677556\n",
      " Loss: 0.983630\n",
      " Loss: 2.396392\n",
      " Loss: 0.894068\n",
      " Loss: 1.083660\n",
      " Loss: 0.901538\n",
      " Loss: 2.602006\n",
      " Loss: 0.734565\n",
      " Loss: 1.095953\n",
      " Loss: 0.614258\n",
      "Epoch 126 Chain 0 loss std 5.58e+03 variance 1.56e+07 smooth variance 1.40e+07 adaptive c -1.00\n",
      "Epoch 126 Chain 1 loss std 1.33e+03 variance 8.85e+05 smooth variance 1.76e+06 adaptive c -1.00\n",
      " Loss: 2.176226\n",
      " Loss: 0.814959\n",
      " Loss: 2.767495\n",
      " Loss: 1.083363\n",
      " Loss: 1.264713\n",
      " Loss: 0.627498\n",
      " Loss: 2.224391\n",
      " Loss: 0.739963\n",
      " Loss: 1.316673\n",
      " Loss: 0.840416\n",
      " Loss: 1.910594\n",
      " Loss: 0.774850\n",
      " Loss: 2.873282\n",
      " Loss: 0.801173\n",
      " Loss: 1.374312\n",
      " Loss: 0.737499\n",
      " Loss: 1.722629\n",
      " Loss: 1.038621\n",
      " Loss: 1.664774\n",
      " Loss: 0.735357\n",
      "Epoch 128 Chain 0 loss std 4.23e+03 variance 8.96e+06 smooth variance 1.25e+07 adaptive c -1.00\n",
      "Epoch 128 Chain 1 loss std 1.30e+03 variance 8.49e+05 smooth variance 1.49e+06 adaptive c -1.00\n",
      " Loss: 2.590564\n",
      " Loss: 1.086058\n",
      " Loss: 2.511764\n",
      " Loss: 0.919340\n",
      " Loss: 1.194373\n",
      " Loss: 0.599612\n",
      " Loss: 1.564088\n",
      " Loss: 0.993649\n",
      " Loss: 1.386473\n",
      " Loss: 0.471566\n",
      " Loss: 1.851645\n",
      " Loss: 0.860603\n",
      " Loss: 2.594356\n",
      " Loss: 0.735042\n",
      " Loss: 1.248169\n",
      " Loss: 0.694046\n",
      " Loss: 1.584483\n",
      " Loss: 0.762213\n",
      " Loss: 1.578907\n",
      " Loss: 1.004710\n",
      "Epoch 130 Chain 0 loss std 5.01e+03 variance 1.25e+07 smooth variance 1.25e+07 adaptive c -1.00\n",
      "Epoch 130 Chain 1 loss std 1.82e+03 variance 1.65e+06 smooth variance 1.54e+06 adaptive c -1.00\n",
      " Loss: 1.568464\n",
      " Loss: 0.615261\n",
      " Loss: 2.523299\n",
      " Loss: 0.748571\n",
      " Loss: 2.221741\n",
      " Loss: 0.834654\n",
      " Loss: 0.876481\n",
      " Loss: 0.971169\n",
      " Loss: 1.544240\n",
      " Loss: 0.876707\n",
      " Loss: 1.782700\n",
      " Loss: 0.777155\n",
      " Loss: 1.990212\n",
      " Loss: 0.965313\n",
      " Loss: 2.478923\n",
      " Loss: 0.882355\n",
      " Loss: 1.063662\n",
      " Loss: 0.685372\n",
      " Loss: 1.499767\n",
      " Loss: 0.712140\n",
      "Epoch 132 Chain 0 loss std 5.19e+03 variance 1.35e+07 smooth variance 1.28e+07 adaptive c -1.00\n",
      "Epoch 132 Chain 1 loss std 1.94e+03 variance 1.88e+06 smooth variance 1.64e+06 adaptive c -1.00\n",
      " Loss: 1.370417\n",
      " Loss: 0.501471\n",
      " Loss: 1.458238\n",
      " Loss: 0.708360\n",
      " Loss: 2.052307\n",
      " Loss: 1.026063\n",
      " Loss: 2.023942\n",
      " Loss: 1.024193\n",
      " Loss: 2.033875\n",
      " Loss: 0.747949\n",
      " Loss: 2.150347\n",
      " Loss: 0.862536\n",
      " Loss: 1.391085\n",
      " Loss: 0.944491\n",
      " Loss: 1.713137\n",
      " Loss: 0.895782\n",
      " Loss: 1.763022\n",
      " Loss: 0.560285\n",
      " Loss: 1.821581\n",
      " Loss: 0.725354\n",
      "Epoch 134 Chain 0 loss std 6.83e+03 variance 2.33e+07 smooth variance 1.60e+07 adaptive c -1.00\n",
      "Epoch 134 Chain 1 loss std 1.88e+03 variance 1.76e+06 smooth variance 1.68e+06 adaptive c -1.00\n",
      " Loss: 1.191810\n",
      " Loss: 0.500136\n",
      " Loss: 1.168286\n",
      " Loss: 0.795530\n",
      " Loss: 1.841063\n",
      " Loss: 0.745434\n",
      " Loss: 2.655595\n",
      " Loss: 1.220321\n",
      " Loss: 2.273015\n",
      " Loss: 0.709378\n",
      " Loss: 2.071882\n",
      " Loss: 1.061488\n",
      " Loss: 1.631914\n",
      " Loss: 0.593967\n",
      " Loss: 2.178200\n",
      " Loss: 0.525354\n",
      " Loss: 1.693725\n",
      " Loss: 0.798334\n",
      " Loss: 1.666866\n",
      " Loss: 0.977795\n",
      "Epoch 136 Chain 0 loss std 7.19e+03 variance 2.59e+07 smooth variance 1.89e+07 adaptive c -1.00\n",
      "Epoch 136 Chain 1 loss std 2.37e+03 variance 2.80e+06 smooth variance 2.01e+06 adaptive c -1.00\n",
      " Loss: 1.606291\n",
      " Loss: 1.040890\n",
      " Loss: 1.582262\n",
      " Loss: 0.668585\n",
      " Loss: 2.319176\n",
      " Loss: 0.776977\n",
      " Loss: 2.329766\n",
      " Loss: 0.895177\n",
      " Loss: 1.521269\n",
      " Loss: 0.568044\n",
      " Loss: 1.882462\n",
      " Loss: 0.907607\n",
      " Loss: 2.666143\n",
      " Loss: 0.901899\n",
      " Loss: 1.300405\n",
      " Loss: 0.611139\n",
      " Loss: 1.723782\n",
      " Loss: 0.951283\n",
      " Loss: 1.805798\n",
      " Loss: 0.571353\n",
      "Epoch 138 Chain 0 loss std 2.58e+03 variance 3.32e+06 smooth variance 1.43e+07 adaptive c -1.00\n",
      "Epoch 138 Chain 1 loss std 2.97e+03 variance 4.40e+06 smooth variance 2.73e+06 adaptive c -1.00\n",
      " Loss: 1.626149\n",
      " Loss: 0.626155\n",
      " Loss: 2.161682\n",
      " Loss: 0.879098\n",
      " Loss: 1.961575\n",
      " Loss: 0.891747\n",
      " Loss: 2.146736\n",
      " Loss: 0.700437\n",
      " Loss: 1.525811\n",
      " Loss: 0.839685\n",
      " Loss: 2.142877\n",
      " Loss: 0.981619\n",
      " Loss: 2.295263\n",
      " Loss: 1.038484\n",
      " Loss: 1.704763\n",
      " Loss: 0.536109\n",
      " Loss: 1.656396\n",
      " Loss: 0.925030\n",
      " Loss: 1.543939\n",
      " Loss: 0.451172\n",
      "Epoch 140 Chain 0 loss std 2.85e+03 variance 4.06e+06 smooth variance 1.12e+07 adaptive c -1.00\n",
      "Epoch 140 Chain 1 loss std 1.95e+03 variance 1.89e+06 smooth variance 2.48e+06 adaptive c -1.00\n",
      " Loss: 2.125701\n",
      " Loss: 0.739789\n",
      " Loss: 1.902825\n",
      " Loss: 0.937514\n",
      " Loss: 1.573895\n",
      " Loss: 0.614639\n",
      " Loss: 2.226451\n",
      " Loss: 0.730743\n",
      " Loss: 1.379485\n",
      " Loss: 0.901067\n",
      " Loss: 1.647593\n",
      " Loss: 0.853476\n",
      " Loss: 1.928732\n",
      " Loss: 0.858257\n",
      " Loss: 1.444731\n",
      " Loss: 0.785573\n",
      " Loss: 2.402643\n",
      " Loss: 0.874700\n",
      " Loss: 1.500986\n",
      " Loss: 0.542585\n",
      "Epoch 142 Chain 0 loss std 7.55e+03 variance 2.85e+07 smooth variance 1.64e+07 adaptive c -1.00\n",
      "Epoch 142 Chain 1 loss std 2.37e+03 variance 2.81e+06 smooth variance 2.58e+06 adaptive c -1.00\n",
      " Loss: 2.616452\n",
      " Loss: 0.970235\n",
      " Loss: 1.263064\n",
      " Loss: 0.557549\n",
      " Loss: 1.194127\n",
      " Loss: 0.449236\n",
      " Loss: 1.909868\n",
      " Loss: 0.707136\n",
      " Loss: 1.697531\n",
      " Loss: 1.222449\n",
      " Loss: 1.738441\n",
      " Loss: 0.339156\n",
      " Loss: 1.184924\n",
      " Loss: 0.974904\n",
      " Loss: 2.346491\n",
      " Loss: 1.115728\n",
      " Loss: 2.059917\n",
      " Loss: 0.923583\n",
      " Loss: 1.166892\n",
      " Loss: 0.540654\n",
      "Epoch 144 Chain 0 loss std 2.33e+03 variance 2.72e+06 smooth variance 1.23e+07 adaptive c -1.00\n",
      "Epoch 144 Chain 1 loss std 1.63e+03 variance 1.33e+06 smooth variance 2.20e+06 adaptive c -1.00\n",
      " Loss: 1.754977\n",
      " Loss: 0.750911\n",
      " Loss: 1.933012\n",
      " Loss: 0.535814\n",
      " Loss: 2.453228\n",
      " Loss: 1.090124\n",
      " Loss: 1.368534\n",
      " Loss: 0.973087\n",
      " Loss: 1.121014\n",
      " Loss: 0.521710\n",
      " Loss: 1.631153\n",
      " Loss: 0.975339\n",
      " Loss: 1.265330\n",
      " Loss: 0.725090\n",
      " Loss: 1.908453\n",
      " Loss: 0.880369\n",
      " Loss: 2.540014\n",
      " Loss: 0.656058\n",
      " Loss: 1.189980\n",
      " Loss: 0.612662\n",
      "Epoch 146 Chain 0 loss std 3.59e+03 variance 6.45e+06 smooth variance 1.05e+07 adaptive c -1.00\n",
      "Epoch 146 Chain 1 loss std 2.93e+03 variance 4.30e+06 smooth variance 2.83e+06 adaptive c -1.00\n",
      " Loss: 1.930073\n",
      " Loss: 0.756109\n",
      " Loss: 1.637360\n",
      " Loss: 0.837508\n",
      " Loss: 1.588799\n",
      " Loss: 0.490105\n",
      " Loss: 1.552502\n",
      " Loss: 0.858250\n",
      " Loss: 1.620864\n",
      " Loss: 0.882962\n",
      " Loss: 1.571066\n",
      " Loss: 0.955537\n",
      " Loss: 1.343544\n",
      " Loss: 0.570524\n",
      " Loss: 1.360555\n",
      " Loss: 0.720381\n",
      " Loss: 2.411656\n",
      " Loss: 0.846976\n",
      " Loss: 1.551231\n",
      " Loss: 0.709889\n",
      "Epoch 148 Chain 0 loss std 4.22e+03 variance 8.89e+06 smooth variance 1.00e+07 adaptive c -1.00\n",
      "Epoch 148 Chain 1 loss std 7.52e+02 variance 2.83e+05 smooth variance 2.07e+06 adaptive c -1.00\n",
      " Loss: 1.462508\n",
      " Loss: 1.216966\n",
      " Loss: 1.641908\n",
      " Loss: 0.627759\n",
      " Loss: 1.497316\n",
      " Loss: 0.644881\n",
      " Loss: 2.238294\n",
      " Loss: 0.694981\n",
      " Loss: 1.329139\n",
      " Loss: 0.593791\n",
      " Loss: 1.088722\n",
      " Loss: 0.708962\n",
      " Loss: 1.146614\n",
      " Loss: 0.861562\n",
      " Loss: 2.065227\n",
      " Loss: 0.727497\n",
      " Loss: 2.062374\n",
      " Loss: 0.884394\n",
      " Loss: 1.555834\n",
      " Loss: 0.578510\n",
      "Epoch 150 Chain 0 loss std 3.64e+03 variance 6.62e+06 smooth variance 9.02e+06 adaptive c -1.00\n",
      "Epoch 150 Chain 1 loss std 2.27e+03 variance 2.59e+06 smooth variance 2.22e+06 adaptive c -1.00\n",
      " Loss: 0.846030\n",
      " Loss: 0.822193\n",
      " Loss: 1.452455\n",
      " Loss: 0.894578\n",
      " Loss: 1.617856\n",
      " Loss: 0.627359\n",
      " Loss: 1.426716\n",
      " Loss: 0.641218\n",
      " Loss: 2.221917\n",
      " Loss: 0.757919\n",
      " Loss: 1.568394\n",
      " Loss: 0.548316\n",
      " Loss: 1.192522\n",
      " Loss: 0.763321\n",
      " Loss: 1.708453\n",
      " Loss: 0.889666\n",
      " Loss: 1.226013\n",
      " Loss: 0.718361\n",
      " Loss: 1.684051\n",
      " Loss: 0.817944\n",
      "Epoch 152 Chain 0 loss std 3.28e+03 variance 5.39e+06 smooth variance 7.93e+06 adaptive c -1.00\n",
      "Epoch 152 Chain 1 loss std 2.33e+03 variance 2.72e+06 smooth variance 2.37e+06 adaptive c -1.00\n",
      " Loss: 1.229928\n",
      " Loss: 0.579227\n",
      " Loss: 1.930174\n",
      " Loss: 0.776424\n",
      " Loss: 1.767522\n",
      " Loss: 0.873486\n",
      " Loss: 1.079438\n",
      " Loss: 0.821147\n",
      " Loss: 1.187758\n",
      " Loss: 0.677042\n",
      " Loss: 1.324971\n",
      " Loss: 0.615028\n",
      " Loss: 1.398136\n",
      " Loss: 0.968612\n",
      " Loss: 1.681414\n",
      " Loss: 0.673573\n",
      " Loss: 1.147374\n",
      " Loss: 0.958022\n",
      " Loss: 1.327313\n",
      " Loss: 0.502228\n",
      "Epoch 154 Chain 0 loss std 2.18e+03 variance 2.37e+06 smooth variance 6.26e+06 adaptive c -1.00\n",
      "Epoch 154 Chain 1 loss std 3.54e+03 variance 6.26e+06 smooth variance 3.54e+06 adaptive c -1.00\n",
      " Loss: 1.676343\n",
      " Loss: 1.006060\n",
      " Loss: 1.220371\n",
      " Loss: 0.823722\n",
      " Loss: 1.276869\n",
      " Loss: 0.508728\n",
      " Loss: 0.864678\n",
      " Loss: 0.428492\n",
      " Loss: 1.712105\n",
      " Loss: 0.938440\n",
      " Loss: 0.952716\n",
      " Loss: 0.495439\n",
      " Loss: 1.871318\n",
      " Loss: 0.974734\n",
      " Loss: 1.301078\n",
      " Loss: 0.528445\n",
      " Loss: 1.280691\n",
      " Loss: 0.819363\n",
      " Loss: 1.263821\n",
      " Loss: 0.878328\n",
      "Epoch 156 Chain 0 loss std 2.99e+03 variance 4.48e+06 smooth variance 5.73e+06 adaptive c -1.00\n",
      "Epoch 156 Chain 1 loss std 1.90e+03 variance 1.80e+06 smooth variance 3.02e+06 adaptive c -1.00\n",
      " Loss: 0.780798\n",
      " Loss: 0.720081\n",
      " Loss: 2.050277\n",
      " Loss: 0.779716\n",
      " Loss: 1.313712\n",
      " Loss: 0.448872\n",
      " Loss: 1.407341\n",
      " Loss: 0.708285\n",
      " Loss: 0.940751\n",
      " Loss: 1.033663\n",
      " Loss: 0.830383\n",
      " Loss: 0.717018\n",
      " Loss: 1.416875\n",
      " Loss: 0.867351\n",
      " Loss: 1.062372\n",
      " Loss: 0.643099\n",
      " Loss: 1.789878\n",
      " Loss: 0.724758\n",
      " Loss: 1.163059\n",
      " Loss: 0.730010\n",
      "Epoch 158 Chain 0 loss std 3.55e+03 variance 6.31e+06 smooth variance 5.91e+06 adaptive c -1.00\n",
      "Epoch 158 Chain 1 loss std 2.08e+03 variance 2.16e+06 smooth variance 2.76e+06 adaptive c -1.00\n",
      " Loss: 1.321241\n",
      " Loss: 0.464145\n",
      " Loss: 0.985274\n",
      " Loss: 1.098471\n",
      " Loss: 1.392237\n",
      " Loss: 0.662096\n",
      " Loss: 1.179496\n",
      " Loss: 0.905496\n",
      " Loss: 1.187805\n",
      " Loss: 0.546187\n",
      " Loss: 1.252724\n",
      " Loss: 0.878163\n",
      " Loss: 0.977183\n",
      " Loss: 0.655630\n",
      " Loss: 1.088866\n",
      " Loss: 0.759109\n",
      " Loss: 1.140352\n",
      " Loss: 0.917578\n",
      " Loss: 1.561391\n",
      " Loss: 0.454279\n",
      "Epoch 160 Chain 0 loss std 3.20e+03 variance 5.12e+06 smooth variance 5.67e+06 adaptive c -1.00\n",
      "Epoch 160 Chain 1 loss std 1.36e+03 variance 9.31e+05 smooth variance 2.21e+06 adaptive c -1.00\n",
      " Loss: 1.405782\n",
      " Loss: 1.002589\n",
      " Loss: 1.231948\n",
      " Loss: 0.997123\n",
      " Loss: 1.139635\n",
      " Loss: 0.729505\n",
      " Loss: 1.280545\n",
      " Loss: 0.591418\n",
      " Loss: 0.997288\n",
      " Loss: 0.332255\n",
      " Loss: 1.494953\n",
      " Loss: 0.911967\n",
      " Loss: 1.403832\n",
      " Loss: 0.720079\n",
      " Loss: 0.918879\n",
      " Loss: 0.742801\n",
      " Loss: 1.151337\n",
      " Loss: 0.541407\n",
      " Loss: 1.150329\n",
      " Loss: 0.728405\n",
      "Epoch 162 Chain 0 loss std 3.18e+03 variance 5.04e+06 smooth variance 5.48e+06 adaptive c -1.00\n",
      "Epoch 162 Chain 1 loss std 1.61e+03 variance 1.29e+06 smooth variance 1.93e+06 adaptive c -1.00\n",
      " Loss: 1.197969\n",
      " Loss: 0.866538\n",
      " Loss: 1.480228\n",
      " Loss: 0.976108\n",
      " Loss: 1.179400\n",
      " Loss: 0.644661\n",
      " Loss: 1.197200\n",
      " Loss: 0.503239\n",
      " Loss: 1.146431\n",
      " Loss: 0.649601\n",
      " Loss: 1.340847\n",
      " Loss: 1.282583\n",
      " Loss: 1.398385\n",
      " Loss: 0.413044\n",
      " Loss: 1.027461\n",
      " Loss: 0.547759\n",
      " Loss: 1.067083\n",
      " Loss: 0.656874\n",
      " Loss: 1.309253\n",
      " Loss: 0.734357\n",
      "Epoch 164 Chain 0 loss std 2.68e+03 variance 3.60e+06 smooth variance 4.92e+06 adaptive c -1.00\n",
      "Epoch 164 Chain 1 loss std 1.85e+03 variance 1.72e+06 smooth variance 1.87e+06 adaptive c -1.00\n",
      " Loss: 0.831546\n",
      " Loss: 0.636031\n",
      " Loss: 1.280270\n",
      " Loss: 0.553068\n",
      " Loss: 1.119707\n",
      " Loss: 0.871158\n",
      " Loss: 1.103167\n",
      " Loss: 0.693507\n",
      " Loss: 2.079802\n",
      " Loss: 0.874093\n",
      " Loss: 1.952800\n",
      " Loss: 0.726657\n",
      " Loss: 0.792783\n",
      " Loss: 0.563083\n",
      " Loss: 1.454644\n",
      " Loss: 0.635706\n",
      " Loss: 1.054617\n",
      " Loss: 1.116958\n",
      " Loss: 1.323815\n",
      " Loss: 0.574897\n",
      "Epoch 166 Chain 0 loss std 4.15e+03 variance 8.61e+06 smooth variance 6.03e+06 adaptive c -1.00\n",
      "Epoch 166 Chain 1 loss std 1.83e+03 variance 1.68e+06 smooth variance 1.81e+06 adaptive c -1.00\n",
      " Loss: 1.648544\n",
      " Loss: 0.747144\n",
      " Loss: 1.880923\n",
      " Loss: 0.711443\n",
      " Loss: 0.889888\n",
      " Loss: 0.876311\n",
      " Loss: 1.135941\n",
      " Loss: 0.612743\n",
      " Loss: 0.984556\n",
      " Loss: 0.654882\n",
      " Loss: 1.293620\n",
      " Loss: 0.865873\n",
      " Loss: 1.563863\n",
      " Loss: 0.598957\n",
      " Loss: 1.337327\n",
      " Loss: 0.495270\n",
      " Loss: 0.995533\n",
      " Loss: 0.949886\n",
      " Loss: 1.276850\n",
      " Loss: 0.675351\n",
      "Epoch 168 Chain 0 loss std 3.36e+03 variance 5.63e+06 smooth variance 5.91e+06 adaptive c -1.00\n",
      "Epoch 168 Chain 1 loss std 1.15e+03 variance 6.66e+05 smooth variance 1.47e+06 adaptive c -1.00\n",
      " Loss: 1.244119\n",
      " Loss: 0.609675\n",
      " Loss: 0.887148\n",
      " Loss: 0.727569\n",
      " Loss: 1.312586\n",
      " Loss: 0.755255\n",
      " Loss: 1.742772\n",
      " Loss: 0.695464\n",
      " Loss: 0.965543\n",
      " Loss: 0.781041\n",
      " Loss: 1.305841\n",
      " Loss: 0.809051\n",
      " Loss: 0.878875\n",
      " Loss: 0.373262\n",
      " Loss: 1.561706\n",
      " Loss: 0.643585\n",
      " Loss: 0.998227\n",
      " Loss: 0.549220\n",
      " Loss: 1.215356\n",
      " Loss: 1.176813\n",
      "Epoch 170 Chain 0 loss std 3.21e+03 variance 5.16e+06 smooth variance 5.68e+06 adaptive c -1.00\n",
      "Epoch 170 Chain 1 loss std 2.83e+03 variance 4.02e+06 smooth variance 2.23e+06 adaptive c -1.00\n",
      " Loss: 1.029897\n",
      " Loss: 1.203829\n",
      " Loss: 1.192809\n",
      " Loss: 0.634724\n",
      " Loss: 1.421720\n",
      " Loss: 0.511323\n",
      " Loss: 1.191006\n",
      " Loss: 0.530080\n",
      " Loss: 0.900205\n",
      " Loss: 0.658019\n",
      " Loss: 1.803030\n",
      " Loss: 0.792706\n",
      " Loss: 0.585374\n",
      " Loss: 0.672930\n",
      " Loss: 1.730562\n",
      " Loss: 0.701970\n",
      " Loss: 0.853602\n",
      " Loss: 0.444050\n",
      " Loss: 0.638121\n",
      " Loss: 0.909196\n",
      "Epoch 172 Chain 0 loss std 2.71e+03 variance 3.66e+06 smooth variance 5.07e+06 adaptive c -1.00\n",
      "Epoch 172 Chain 1 loss std 2.57e+03 variance 3.29e+06 smooth variance 2.55e+06 adaptive c -1.00\n",
      " Loss: 0.895360\n",
      " Loss: 0.541530\n",
      " Loss: 1.108544\n",
      " Loss: 0.706329\n",
      " Loss: 1.263286\n",
      " Loss: 0.871896\n",
      " Loss: 1.452174\n",
      " Loss: 0.875160\n",
      " Loss: 0.783823\n",
      " Loss: 0.511697\n",
      " Loss: 0.733143\n",
      " Loss: 0.676065\n",
      " Loss: 1.021598\n",
      " Loss: 0.821538\n",
      " Loss: 1.489791\n",
      " Loss: 0.797396\n",
      " Loss: 0.994113\n",
      " Loss: 0.752566\n",
      " Loss: 1.252233\n",
      " Loss: 0.442450\n",
      "Epoch 174 Chain 0 loss std 1.14e+03 variance 6.53e+05 smooth variance 3.75e+06 adaptive c -1.00\n",
      "Epoch 174 Chain 1 loss std 8.95e+02 variance 4.00e+05 smooth variance 1.91e+06 adaptive c -1.00\n",
      " Loss: 1.515305\n",
      " Loss: 0.633931\n",
      " Loss: 1.112007\n",
      " Loss: 0.761088\n",
      " Loss: 1.246170\n",
      " Loss: 1.032504\n",
      " Loss: 0.956700\n",
      " Loss: 0.365468\n",
      " Loss: 0.761303\n",
      " Loss: 0.678917\n",
      " Loss: 1.075297\n",
      " Loss: 0.613727\n",
      " Loss: 1.336940\n",
      " Loss: 0.801962\n",
      " Loss: 1.267080\n",
      " Loss: 1.094373\n",
      " Loss: 1.404504\n",
      " Loss: 0.560017\n",
      " Loss: 0.571240\n",
      " Loss: 0.382841\n",
      "Epoch 176 Chain 0 loss std 3.12e+03 variance 4.87e+06 smooth variance 4.08e+06 adaptive c -1.00\n",
      "Epoch 176 Chain 1 loss std 6.98e+02 variance 2.43e+05 smooth variance 1.41e+06 adaptive c -1.00\n",
      " Loss: 0.978863\n",
      " Loss: 0.726109\n",
      " Loss: 1.741107\n",
      " Loss: 0.768472\n",
      " Loss: 1.072958\n",
      " Loss: 0.502313\n",
      " Loss: 0.827842\n",
      " Loss: 0.609901\n",
      " Loss: 1.009631\n",
      " Loss: 0.827609\n",
      " Loss: 1.065550\n",
      " Loss: 0.899569\n",
      " Loss: 1.253690\n",
      " Loss: 0.379373\n",
      " Loss: 1.314653\n",
      " Loss: 0.706008\n",
      " Loss: 1.123735\n",
      " Loss: 0.485531\n",
      " Loss: 0.835435\n",
      " Loss: 0.944481\n",
      "Epoch 178 Chain 0 loss std 2.91e+03 variance 4.25e+06 smooth variance 4.13e+06 adaptive c -1.00\n",
      "Epoch 178 Chain 1 loss std 1.47e+03 variance 1.09e+06 smooth variance 1.31e+06 adaptive c -1.00\n",
      " Loss: 0.746225\n",
      " Loss: 0.652498\n",
      " Loss: 1.114158\n",
      " Loss: 0.640052\n",
      " Loss: 1.007325\n",
      " Loss: 0.818260\n",
      " Loss: 1.083783\n",
      " Loss: 0.779176\n",
      " Loss: 1.699012\n",
      " Loss: 0.504166\n",
      " Loss: 1.265024\n",
      " Loss: 0.620389\n",
      " Loss: 1.311966\n",
      " Loss: 0.451933\n",
      " Loss: 0.689053\n",
      " Loss: 0.671824\n",
      " Loss: 1.132604\n",
      " Loss: 0.728307\n",
      " Loss: 1.382390\n",
      " Loss: 0.901781\n",
      "Epoch 180 Chain 0 loss std 9.02e+02 variance 4.06e+05 smooth variance 3.01e+06 adaptive c -1.00\n",
      "Epoch 180 Chain 1 loss std 2.10e+03 variance 2.20e+06 smooth variance 1.58e+06 adaptive c -1.00\n",
      " Loss: 0.433346\n",
      " Loss: 0.628877\n",
      " Loss: 1.293016\n",
      " Loss: 0.561660\n",
      " Loss: 1.248305\n",
      " Loss: 0.819604\n",
      " Loss: 1.503406\n",
      " Loss: 0.738077\n",
      " Loss: 1.461326\n",
      " Loss: 0.602972\n",
      " Loss: 1.750665\n",
      " Loss: 0.467290\n",
      " Loss: 0.866599\n",
      " Loss: 0.796927\n",
      " Loss: 1.010497\n",
      " Loss: 0.599855\n",
      " Loss: 1.717381\n",
      " Loss: 0.666408\n",
      " Loss: 0.812592\n",
      " Loss: 0.798169\n",
      "Epoch 182 Chain 0 loss std 5.08e+03 variance 1.29e+07 smooth variance 5.99e+06 adaptive c -1.00\n",
      "Epoch 182 Chain 1 loss std 1.46e+03 variance 1.07e+06 smooth variance 1.43e+06 adaptive c -1.00\n",
      " Loss: 0.919323\n",
      " Loss: 0.664247\n",
      " Loss: 1.842052\n",
      " Loss: 0.615490\n",
      " Loss: 1.607736\n",
      " Loss: 0.615036\n",
      " Loss: 0.835388\n",
      " Loss: 0.884202\n",
      " Loss: 1.065618\n",
      " Loss: 0.533625\n",
      " Loss: 1.532964\n",
      " Loss: 1.061769\n",
      " Loss: 1.296408\n",
      " Loss: 0.557447\n",
      " Loss: 0.609022\n",
      " Loss: 0.588937\n",
      " Loss: 1.914652\n",
      " Loss: 0.577859\n",
      " Loss: 0.971579\n",
      " Loss: 0.516463\n",
      "Epoch 184 Chain 0 loss std 3.35e+03 variance 5.61e+06 smooth variance 5.87e+06 adaptive c -1.00\n",
      "Epoch 184 Chain 1 loss std 1.55e+03 variance 1.20e+06 smooth variance 1.36e+06 adaptive c -1.00\n",
      " Loss: 1.655330\n",
      " Loss: 0.656552\n",
      " Loss: 1.128746\n",
      " Loss: 0.673792\n",
      " Loss: 1.307105\n",
      " Loss: 0.590798\n",
      " Loss: 1.083095\n",
      " Loss: 0.873436\n",
      " Loss: 1.281434\n",
      " Loss: 0.489943\n",
      " Loss: 1.001309\n",
      " Loss: 0.511988\n",
      " Loss: 0.900839\n",
      " Loss: 0.741264\n",
      " Loss: 0.908880\n",
      " Loss: 0.805758\n",
      " Loss: 1.798073\n",
      " Loss: 0.560955\n",
      " Loss: 1.876415\n",
      " Loss: 0.648636\n",
      "Epoch 186 Chain 0 loss std 2.67e+03 variance 3.57e+06 smooth variance 5.18e+06 adaptive c -1.00\n",
      "Epoch 186 Chain 1 loss std 2.56e+03 variance 3.27e+06 smooth variance 1.93e+06 adaptive c -1.00\n",
      " Loss: 1.142479\n",
      " Loss: 0.791547\n",
      " Loss: 1.426079\n",
      " Loss: 0.928167\n",
      " Loss: 1.201568\n",
      " Loss: 0.371756\n",
      " Loss: 1.927444\n",
      " Loss: 0.581372\n",
      " Loss: 0.691060\n",
      " Loss: 0.578640\n",
      " Loss: 0.971212\n",
      " Loss: 0.785251\n",
      " Loss: 0.935188\n",
      " Loss: 0.600367\n",
      " Loss: 1.457711\n",
      " Loss: 0.631268\n",
      " Loss: 1.019598\n",
      " Loss: 0.490539\n",
      " Loss: 1.982119\n",
      " Loss: 0.727606\n",
      "Epoch 188 Chain 0 loss std 2.09e+03 variance 2.18e+06 smooth variance 4.28e+06 adaptive c -1.00\n",
      "Epoch 188 Chain 1 loss std 2.14e+03 variance 2.30e+06 smooth variance 2.04e+06 adaptive c -1.00\n",
      " Loss: 1.062941\n",
      " Loss: 0.521171\n",
      " Loss: 0.883408\n",
      " Loss: 0.675017\n",
      " Loss: 1.399909\n",
      " Loss: 0.397668\n",
      " Loss: 1.414813\n",
      " Loss: 0.793388\n",
      " Loss: 1.566202\n",
      " Loss: 0.830537\n",
      " Loss: 1.023609\n",
      " Loss: 0.739477\n",
      " Loss: 1.603109\n",
      " Loss: 0.711097\n",
      " Loss: 1.075695\n",
      " Loss: 0.551272\n",
      " Loss: 1.456912\n",
      " Loss: 0.541540\n",
      " Loss: 1.247443\n",
      " Loss: 0.656836\n",
      "Epoch 190 Chain 0 loss std 2.65e+03 variance 3.51e+06 smooth variance 4.05e+06 adaptive c -1.00\n",
      "Epoch 190 Chain 1 loss std 1.35e+03 variance 9.18e+05 smooth variance 1.70e+06 adaptive c -1.00\n",
      " Loss: 1.313897\n",
      " Loss: 0.744142\n",
      " Loss: 1.021132\n",
      " Loss: 0.635802\n",
      " Loss: 1.109066\n",
      " Loss: 0.393378\n",
      " Loss: 0.863736\n",
      " Loss: 0.951863\n",
      " Loss: 2.217563\n",
      " Loss: 0.458709\n",
      " Loss: 1.858390\n",
      " Loss: 0.500468\n",
      " Loss: 1.183138\n",
      " Loss: 0.642708\n",
      " Loss: 1.038903\n",
      " Loss: 0.876205\n",
      " Loss: 0.937285\n",
      " Loss: 0.640941\n",
      " Loss: 1.607348\n",
      " Loss: 0.507174\n",
      "Epoch 192 Chain 0 loss std 3.35e+03 variance 5.63e+06 smooth variance 4.52e+06 adaptive c -1.00\n",
      "Epoch 192 Chain 1 loss std 8.53e+02 variance 3.64e+05 smooth variance 1.30e+06 adaptive c -1.00\n",
      " Loss: 0.999635\n",
      " Loss: 0.593164\n",
      " Loss: 1.312095\n",
      " Loss: 0.594351\n",
      " Loss: 1.409781\n",
      " Loss: 0.573293\n",
      " Loss: 1.512275\n",
      " Loss: 0.779277\n",
      " Loss: 1.407551\n",
      " Loss: 0.612435\n",
      " Loss: 1.462680\n",
      " Loss: 0.545500\n",
      " Loss: 1.352612\n",
      " Loss: 0.851929\n",
      " Loss: 1.072308\n",
      " Loss: 0.723309\n",
      " Loss: 1.242216\n",
      " Loss: 0.470227\n",
      " Loss: 1.487405\n",
      " Loss: 0.551744\n",
      "Epoch 194 Chain 0 loss std 2.90e+03 variance 4.20e+06 smooth variance 4.43e+06 adaptive c -1.00\n",
      "Epoch 194 Chain 1 loss std 2.36e+03 variance 2.78e+06 smooth variance 1.75e+06 adaptive c -1.00\n",
      " Loss: 1.229524\n",
      " Loss: 0.238586\n",
      " Loss: 1.467926\n",
      " Loss: 0.574085\n",
      " Loss: 1.357966\n",
      " Loss: 0.803077\n",
      " Loss: 1.784716\n",
      " Loss: 0.634252\n",
      " Loss: 0.676779\n",
      " Loss: 0.877007\n",
      " Loss: 1.023781\n",
      " Loss: 0.579181\n",
      " Loss: 1.256288\n",
      " Loss: 0.571355\n",
      " Loss: 1.346938\n",
      " Loss: 0.759664\n",
      " Loss: 1.285047\n",
      " Loss: 0.836226\n",
      " Loss: 1.506518\n",
      " Loss: 0.366204\n",
      "Epoch 196 Chain 0 loss std 2.79e+03 variance 3.90e+06 smooth variance 4.27e+06 adaptive c -1.00\n",
      "Epoch 196 Chain 1 loss std 6.19e+02 variance 1.92e+05 smooth variance 1.28e+06 adaptive c -1.00\n",
      " Loss: 1.613855\n",
      " Loss: 0.534329\n",
      " Loss: 1.218710\n",
      " Loss: 0.910177\n",
      " Loss: 1.625390\n",
      " Loss: 0.563300\n",
      " Loss: 1.053838\n",
      " Loss: 0.639735\n",
      " Loss: 0.876743\n",
      " Loss: 0.445829\n",
      " Loss: 1.642668\n",
      " Loss: 0.788488\n",
      " Loss: 0.836020\n",
      " Loss: 0.537388\n",
      " Loss: 1.164892\n",
      " Loss: 0.799854\n",
      " Loss: 1.341611\n",
      " Loss: 0.538088\n",
      " Loss: 1.267170\n",
      " Loss: 0.410162\n",
      "Epoch 198 Chain 0 loss std 2.37e+03 variance 2.81e+06 smooth variance 3.83e+06 adaptive c -1.00\n",
      "Epoch 198 Chain 1 loss std 6.75e+02 variance 2.28e+05 smooth variance 9.64e+05 adaptive c -1.00\n",
      " Loss: 1.383578\n",
      " Loss: 0.671721\n",
      " Loss: 1.183826\n",
      " Loss: 0.749864\n",
      " Loss: 1.306142\n",
      " Loss: 0.518767\n",
      " Loss: 1.534542\n",
      " Loss: 0.599504\n",
      " Loss: 0.663419\n",
      " Loss: 0.514978\n",
      " Loss: 1.287427\n",
      " Loss: 0.770852\n",
      " Loss: 1.272695\n",
      " Loss: 0.494054\n",
      " Loss: 0.960770\n",
      " Loss: 0.651673\n",
      " Loss: 1.276686\n",
      " Loss: 0.627132\n",
      " Loss: 1.122608\n",
      " Loss: 0.494906\n",
      "Epoch 200 Chain 0 loss std 2.93e+03 variance 4.28e+06 smooth variance 3.97e+06 adaptive c -1.00\n",
      "Epoch 200 Chain 1 loss std 1.97e+03 variance 1.93e+06 smooth variance 1.25e+06 adaptive c -1.00\n",
      " Loss: 1.276432\n",
      " Loss: 0.467809\n",
      " Loss: 1.014043\n",
      " Loss: 0.569568\n",
      " Loss: 1.441498\n",
      " Loss: 0.789794\n",
      " Loss: 1.029844\n",
      " Loss: 0.563069\n",
      " Loss: 1.055915\n",
      " Loss: 0.631818\n",
      " Loss: 0.874604\n",
      " Loss: 0.487418\n",
      " Loss: 1.549498\n",
      " Loss: 0.463160\n",
      " Loss: 1.176980\n",
      " Loss: 0.913504\n",
      " Loss: 0.675728\n",
      " Loss: 0.630357\n",
      " Loss: 1.562724\n",
      " Loss: 0.513053\n",
      "Epoch 202 Chain 0 loss std 2.94e+03 variance 4.32e+06 smooth variance 4.07e+06 adaptive c -1.00\n",
      "Epoch 202 Chain 1 loss std 9.98e+02 variance 4.98e+05 smooth variance 1.03e+06 adaptive c -1.00\n",
      " Loss: 1.008659\n",
      " Loss: 0.800808\n",
      " Loss: 1.362436\n",
      " Loss: 0.631499\n",
      " Loss: 1.136873\n",
      " Loss: 0.458338\n",
      " Loss: 0.987605\n",
      " Loss: 0.751632\n",
      " Loss: 1.248215\n",
      " Loss: 0.351784\n",
      " Loss: 0.767295\n",
      " Loss: 0.518371\n",
      " Loss: 1.169587\n",
      " Loss: 0.505988\n",
      " Loss: 1.183199\n",
      " Loss: 0.573668\n",
      " Loss: 1.253962\n",
      " Loss: 0.821471\n",
      " Loss: 1.266777\n",
      " Loss: 0.561424\n",
      "Epoch 204 Chain 0 loss std 3.73e+03 variance 6.94e+06 smooth variance 4.94e+06 adaptive c -1.00\n",
      "Epoch 204 Chain 1 loss std 1.68e+03 variance 1.41e+06 smooth variance 1.14e+06 adaptive c -1.00\n",
      " Loss: 1.179688\n",
      " Loss: 0.598848\n",
      " Loss: 0.679925\n",
      " Loss: 0.519667\n",
      " Loss: 1.520371\n",
      " Loss: 0.544905\n",
      " Loss: 1.169041\n",
      " Loss: 0.550141\n",
      " Loss: 1.019719\n",
      " Loss: 0.756986\n",
      " Loss: 0.982430\n",
      " Loss: 0.685295\n",
      " Loss: 1.471653\n",
      " Loss: 0.539777\n",
      " Loss: 0.763846\n",
      " Loss: 0.676814\n",
      " Loss: 1.158554\n",
      " Loss: 0.484208\n",
      " Loss: 1.035147\n",
      " Loss: 0.571616\n",
      "Epoch 206 Chain 0 loss std 3.19e+03 variance 5.10e+06 smooth variance 4.98e+06 adaptive c -1.00\n",
      "Epoch 206 Chain 1 loss std 1.17e+03 variance 6.84e+05 smooth variance 1.00e+06 adaptive c -1.00\n",
      " Loss: 1.084604\n",
      " Loss: 0.529723\n",
      " Loss: 1.067099\n",
      " Loss: 0.647081\n",
      " Loss: 1.293501\n",
      " Loss: 0.604198\n",
      " Loss: 0.598086\n",
      " Loss: 0.595223\n",
      " Loss: 1.228502\n",
      " Loss: 0.567515\n",
      " Loss: 0.876274\n",
      " Loss: 0.636976\n",
      " Loss: 0.981090\n",
      " Loss: 0.477023\n",
      " Loss: 0.963694\n",
      " Loss: 0.778073\n",
      " Loss: 1.272940\n",
      " Loss: 0.438426\n",
      " Loss: 1.090059\n",
      " Loss: 0.597983\n",
      "Epoch 208 Chain 0 loss std 2.41e+03 variance 2.91e+06 smooth variance 4.36e+06 adaptive c -1.00\n",
      "Epoch 208 Chain 1 loss std 1.66e+03 variance 1.38e+06 smooth variance 1.12e+06 adaptive c -1.00\n",
      " Loss: 1.134693\n",
      " Loss: 0.385996\n",
      " Loss: 0.916773\n",
      " Loss: 0.715096\n",
      " Loss: 0.904934\n",
      " Loss: 0.622096\n",
      " Loss: 1.001193\n",
      " Loss: 0.541181\n",
      " Loss: 1.156660\n",
      " Loss: 0.648830\n",
      " Loss: 1.094753\n",
      " Loss: 0.573054\n",
      " Loss: 1.377950\n",
      " Loss: 0.518417\n",
      " Loss: 0.513935\n",
      " Loss: 0.341046\n",
      " Loss: 1.025049\n",
      " Loss: 0.733075\n",
      " Loss: 1.053924\n",
      " Loss: 0.732982\n",
      "Epoch 210 Chain 0 loss std 2.30e+03 variance 2.64e+06 smooth variance 3.84e+06 adaptive c -1.00\n",
      "Epoch 210 Chain 1 loss std 7.02e+02 variance 2.46e+05 smooth variance 8.57e+05 adaptive c -1.00\n",
      " Loss: 0.934650\n",
      " Loss: 0.863036\n",
      " Loss: 1.203919\n",
      " Loss: 0.606978\n",
      " Loss: 1.507979\n",
      " Loss: 0.497108\n",
      " Loss: 0.591013\n",
      " Loss: 0.413584\n",
      " Loss: 0.801654\n",
      " Loss: 0.504992\n",
      " Loss: 0.665649\n",
      " Loss: 0.607686\n",
      " Loss: 1.023252\n",
      " Loss: 0.689252\n",
      " Loss: 0.990539\n",
      " Loss: 0.478301\n",
      " Loss: 1.016045\n",
      " Loss: 0.714370\n",
      " Loss: 1.346519\n",
      " Loss: 0.381054\n",
      "Epoch 212 Chain 0 loss std 2.37e+03 variance 2.82e+06 smooth variance 3.54e+06 adaptive c -1.00\n",
      "Epoch 212 Chain 1 loss std 1.88e+03 variance 1.76e+06 smooth variance 1.13e+06 adaptive c -1.00\n",
      " Loss: 1.138400\n",
      " Loss: 0.493405\n",
      " Loss: 0.889327\n",
      " Loss: 0.845127\n",
      " Loss: 0.798927\n",
      " Loss: 0.568667\n",
      " Loss: 0.965434\n",
      " Loss: 0.406016\n",
      " Loss: 1.158196\n",
      " Loss: 0.547062\n",
      " Loss: 0.631572\n",
      " Loss: 0.707135\n",
      " Loss: 1.036952\n",
      " Loss: 0.798442\n",
      " Loss: 1.010754\n",
      " Loss: 0.231874\n",
      " Loss: 1.398398\n",
      " Loss: 0.542767\n",
      " Loss: 0.818490\n",
      " Loss: 0.567611\n",
      "Epoch 214 Chain 0 loss std 2.17e+03 variance 2.36e+06 smooth variance 3.18e+06 adaptive c -1.00\n",
      "Epoch 214 Chain 1 loss std 2.51e+03 variance 3.16e+06 smooth variance 1.74e+06 adaptive c -1.00\n",
      " Loss: 1.155801\n",
      " Loss: 0.639199\n",
      " Loss: 1.282298\n",
      " Loss: 0.367651\n",
      " Loss: 0.771316\n",
      " Loss: 0.559984\n",
      " Loss: 0.847112\n",
      " Loss: 0.753947\n",
      " Loss: 0.780981\n",
      " Loss: 0.510444\n",
      " Loss: 0.963401\n",
      " Loss: 0.624355\n",
      " Loss: 0.431836\n",
      " Loss: 0.484907\n",
      " Loss: 1.244066\n",
      " Loss: 0.554225\n",
      " Loss: 0.965670\n",
      " Loss: 0.577577\n",
      " Loss: 1.187819\n",
      " Loss: 0.572424\n",
      "Epoch 216 Chain 0 loss std 2.30e+03 variance 2.66e+06 smooth variance 3.02e+06 adaptive c -1.00\n",
      "Epoch 216 Chain 1 loss std 5.58e+02 variance 1.56e+05 smooth variance 1.26e+06 adaptive c -1.00\n",
      " Loss: 0.634242\n",
      " Loss: 0.625922\n",
      " Loss: 1.424248\n",
      " Loss: 0.419976\n",
      " Loss: 0.984855\n",
      " Loss: 0.539110\n",
      " Loss: 0.832940\n",
      " Loss: 0.526009\n",
      " Loss: 0.850096\n",
      " Loss: 0.685180\n",
      " Loss: 0.503589\n",
      " Loss: 0.587315\n",
      " Loss: 0.971695\n",
      " Loss: 0.523604\n",
      " Loss: 1.156127\n",
      " Loss: 0.683100\n",
      " Loss: 1.050977\n",
      " Loss: 0.660799\n",
      " Loss: 0.988044\n",
      " Loss: 0.326142\n",
      "Epoch 218 Chain 0 loss std 2.54e+03 variance 3.23e+06 smooth variance 3.09e+06 adaptive c -1.00\n",
      "Epoch 218 Chain 1 loss std 5.67e+02 variance 1.61e+05 smooth variance 9.32e+05 adaptive c -1.00\n",
      " Loss: 0.837698\n",
      " Loss: 0.367473\n",
      " Loss: 0.888121\n",
      " Loss: 0.758115\n",
      " Loss: 0.588049\n",
      " Loss: 0.716765\n",
      " Loss: 1.287800\n",
      " Loss: 0.630858\n",
      " Loss: 1.037869\n",
      " Loss: 0.295592\n",
      " Loss: 0.720323\n",
      " Loss: 0.714869\n",
      " Loss: 0.970647\n",
      " Loss: 0.611404\n",
      " Loss: 0.951701\n",
      " Loss: 0.421084\n",
      " Loss: 1.111693\n",
      " Loss: 0.444053\n",
      " Loss: 0.790612\n",
      " Loss: 0.567383\n",
      "Epoch 220 Chain 0 loss std 1.98e+03 variance 1.96e+06 smooth variance 2.75e+06 adaptive c -1.00\n",
      "Epoch 220 Chain 1 loss std 1.10e+03 variance 6.05e+05 smooth variance 8.34e+05 adaptive c -1.00\n",
      " Loss: 1.008178\n",
      " Loss: 0.484188\n",
      " Loss: 0.677752\n",
      " Loss: 0.486406\n",
      " Loss: 0.707705\n",
      " Loss: 0.731167\n",
      " Loss: 0.627578\n",
      " Loss: 0.645266\n",
      " Loss: 1.421437\n",
      " Loss: 0.397145\n",
      " Loss: 0.946126\n",
      " Loss: 0.548216\n",
      " Loss: 1.457365\n",
      " Loss: 0.327869\n",
      " Loss: 0.531966\n",
      " Loss: 0.578070\n",
      " Loss: 0.761788\n",
      " Loss: 0.544536\n",
      " Loss: 0.581884\n",
      " Loss: 0.737399\n",
      "Epoch 222 Chain 0 loss std 3.41e+03 variance 5.80e+06 smooth variance 3.66e+06 adaptive c -1.00\n",
      "Epoch 222 Chain 1 loss std 1.87e+03 variance 1.75e+06 smooth variance 1.11e+06 adaptive c -1.00\n",
      " Loss: 1.096034\n",
      " Loss: 0.225130\n",
      " Loss: 0.908133\n",
      " Loss: 0.531295\n",
      " Loss: 0.869678\n",
      " Loss: 0.940391\n",
      " Loss: 0.631095\n",
      " Loss: 0.680040\n",
      " Loss: 0.637525\n",
      " Loss: 0.344882\n",
      " Loss: 0.742387\n",
      " Loss: 0.710432\n",
      " Loss: 0.871498\n",
      " Loss: 0.325777\n",
      " Loss: 1.293241\n",
      " Loss: 0.620159\n",
      " Loss: 0.639466\n",
      " Loss: 0.506235\n",
      " Loss: 0.549966\n",
      " Loss: 0.544922\n",
      "Epoch 224 Chain 0 loss std 2.37e+03 variance 2.82e+06 smooth variance 3.41e+06 adaptive c -1.00\n",
      "Epoch 224 Chain 1 loss std 1.39e+03 variance 9.62e+05 smooth variance 1.07e+06 adaptive c -1.00\n",
      " Loss: 1.028975\n",
      " Loss: 0.447986\n",
      " Loss: 0.772985\n",
      " Loss: 0.469278\n",
      " Loss: 0.790657\n",
      " Loss: 0.641831\n",
      " Loss: 0.594728\n",
      " Loss: 0.453268\n",
      " Loss: 0.877924\n",
      " Loss: 0.682029\n",
      " Loss: 0.804862\n",
      " Loss: 0.524210\n",
      " Loss: 1.173045\n",
      " Loss: 0.326271\n",
      " Loss: 0.682436\n",
      " Loss: 0.295943\n",
      " Loss: 0.623600\n",
      " Loss: 0.773810\n",
      " Loss: 0.666364\n",
      " Loss: 0.760221\n",
      "Epoch 226 Chain 0 loss std 1.92e+03 variance 1.85e+06 smooth variance 2.94e+06 adaptive c -1.00\n",
      "Epoch 226 Chain 1 loss std 1.23e+03 variance 7.59e+05 smooth variance 9.73e+05 adaptive c -1.00\n",
      " Loss: 0.736206\n",
      " Loss: 0.499083\n",
      " Loss: 1.161039\n",
      " Loss: 0.659089\n",
      " Loss: 0.454562\n",
      " Loss: 0.486556\n",
      " Loss: 0.830990\n",
      " Loss: 0.382765\n",
      " Loss: 0.701816\n",
      " Loss: 0.642959\n",
      " Loss: 0.743776\n",
      " Loss: 0.622266\n",
      " Loss: 0.842655\n",
      " Loss: 0.471426\n",
      " Loss: 0.676206\n",
      " Loss: 0.527101\n",
      " Loss: 0.835374\n",
      " Loss: 0.342975\n",
      " Loss: 0.683221\n",
      " Loss: 0.694423\n",
      "Epoch 228 Chain 0 loss std 2.72e+03 variance 3.71e+06 smooth variance 3.17e+06 adaptive c -1.00\n",
      "Epoch 228 Chain 1 loss std 9.74e+02 variance 4.75e+05 smooth variance 8.24e+05 adaptive c -1.00\n",
      " Loss: 0.689249\n",
      " Loss: 0.509452\n",
      " Loss: 1.021804\n",
      " Loss: 0.522332\n",
      " Loss: 0.633984\n",
      " Loss: 0.577976\n",
      " Loss: 0.434798\n",
      " Loss: 0.394241\n",
      " Loss: 0.880684\n",
      " Loss: 0.640890\n",
      " Loss: 0.640014\n",
      " Loss: 0.806126\n",
      " Loss: 1.012692\n",
      " Loss: 0.569312\n",
      " Loss: 0.688707\n",
      " Loss: 0.618247\n",
      " Loss: 0.609165\n",
      " Loss: 0.394544\n",
      " Loss: 0.649985\n",
      " Loss: 0.244863\n",
      "Epoch 230 Chain 0 loss std 2.49e+03 variance 3.11e+06 smooth variance 3.15e+06 adaptive c -1.00\n",
      "Epoch 230 Chain 1 loss std 7.38e+02 variance 2.72e+05 smooth variance 6.58e+05 adaptive c -1.00\n",
      " Loss: 0.847919\n",
      " Loss: 0.346041\n",
      " Loss: 0.727983\n",
      " Loss: 0.395151\n",
      " Loss: 0.801741\n",
      " Loss: 0.789995\n",
      " Loss: 0.492039\n",
      " Loss: 0.417985\n",
      " Loss: 0.628539\n",
      " Loss: 0.669331\n",
      " Loss: 0.763036\n",
      " Loss: 0.572594\n",
      " Loss: 0.778597\n",
      " Loss: 0.416236\n",
      " Loss: 0.667513\n",
      " Loss: 0.367948\n",
      " Loss: 0.870059\n",
      " Loss: 0.666511\n",
      " Loss: 0.431489\n",
      " Loss: 0.589064\n",
      "Epoch 232 Chain 0 loss std 1.93e+03 variance 1.86e+06 smooth variance 2.77e+06 adaptive c -1.00\n",
      "Epoch 232 Chain 1 loss std 1.67e+03 variance 1.39e+06 smooth variance 8.78e+05 adaptive c -1.00\n",
      " Loss: 0.754950\n",
      " Loss: 0.424318\n",
      " Loss: 0.783390\n",
      " Loss: 0.537941\n",
      " Loss: 1.047312\n",
      " Loss: 0.536254\n",
      " Loss: 0.398381\n",
      " Loss: 0.584465\n",
      " Loss: 0.460437\n",
      " Loss: 0.519916\n",
      " Loss: 0.783362\n",
      " Loss: 0.733007\n",
      " Loss: 0.856904\n",
      " Loss: 0.498601\n",
      " Loss: 0.431889\n",
      " Loss: 0.549383\n",
      " Loss: 0.480653\n",
      " Loss: 0.484550\n",
      " Loss: 0.898786\n",
      " Loss: 0.328624\n",
      "Epoch 234 Chain 0 loss std 2.23e+03 variance 2.48e+06 smooth variance 2.68e+06 adaptive c -1.00\n",
      "Epoch 234 Chain 1 loss std 1.91e+03 variance 1.83e+06 smooth variance 1.16e+06 adaptive c -1.00\n",
      " Loss: 1.111596\n",
      " Loss: 0.446841\n",
      " Loss: 0.953715\n",
      " Loss: 0.177687\n",
      " Loss: 0.642484\n",
      " Loss: 0.526129\n",
      " Loss: 0.465403\n",
      " Loss: 0.813186\n",
      " Loss: 0.290670\n",
      " Loss: 0.619665\n",
      " Loss: 0.485110\n",
      " Loss: 0.377141\n",
      " Loss: 0.405809\n",
      " Loss: 0.570294\n",
      " Loss: 0.651943\n",
      " Loss: 0.679689\n",
      " Loss: 0.519642\n",
      " Loss: 0.638339\n",
      " Loss: 1.323576\n",
      " Loss: 0.308666\n",
      "Epoch 236 Chain 0 loss std 2.44e+03 variance 2.99e+06 smooth variance 2.77e+06 adaptive c -1.00\n",
      "Epoch 236 Chain 1 loss std 1.39e+03 variance 9.65e+05 smooth variance 1.10e+06 adaptive c -1.00\n",
      " Loss: 0.965070\n",
      " Loss: 0.355002\n",
      " Loss: 0.524365\n",
      " Loss: 0.420812\n",
      " Loss: 0.864363\n",
      " Loss: 0.512569\n",
      " Loss: 0.361976\n",
      " Loss: 0.447387\n",
      " Loss: 0.608081\n",
      " Loss: 0.824915\n",
      " Loss: 0.864107\n",
      " Loss: 0.639280\n",
      " Loss: 0.798189\n",
      " Loss: 0.487296\n",
      " Loss: 0.395033\n",
      " Loss: 0.491932\n",
      " Loss: 0.534951\n",
      " Loss: 0.297686\n",
      " Loss: 0.647661\n",
      " Loss: 0.628020\n",
      "Epoch 238 Chain 0 loss std 2.53e+03 variance 3.21e+06 smooth variance 2.90e+06 adaptive c -1.00\n",
      "Epoch 238 Chain 1 loss std 1.83e+03 variance 1.67e+06 smooth variance 1.27e+06 adaptive c -1.00\n",
      " Loss: 0.765048\n",
      " Loss: 0.490492\n",
      " Loss: 0.727477\n",
      " Loss: 0.505804\n",
      " Loss: 0.454846\n",
      " Loss: 0.558862\n",
      " Loss: 0.896493\n",
      " Loss: 0.405045\n",
      " Loss: 0.286112\n",
      " Loss: 0.571472\n",
      " Loss: 0.615722\n",
      " Loss: 0.333485\n",
      " Loss: 0.747320\n",
      " Loss: 0.470888\n",
      " Loss: 0.620411\n",
      " Loss: 0.613033\n",
      " Loss: 0.466274\n",
      " Loss: 0.601876\n",
      " Loss: 0.574282\n",
      " Loss: 0.493671\n",
      "Epoch 240 Chain 0 loss std 2.12e+03 variance 2.25e+06 smooth variance 2.71e+06 adaptive c -1.00\n",
      "Epoch 240 Chain 1 loss std 1.29e+03 variance 8.27e+05 smooth variance 1.14e+06 adaptive c -1.00\n",
      " Loss: 0.407519\n",
      " Loss: 0.488143\n",
      " Loss: 0.595984\n",
      " Loss: 0.494501\n",
      " Loss: 0.509261\n",
      " Loss: 0.737275\n",
      " Loss: 0.960498\n",
      " Loss: 0.421798\n",
      " Loss: 0.483030\n",
      " Loss: 0.358020\n",
      " Loss: 0.795530\n",
      " Loss: 0.425025\n",
      " Loss: 0.364370\n",
      " Loss: 0.535172\n",
      " Loss: 0.889917\n",
      " Loss: 0.232619\n",
      " Loss: 0.416493\n",
      " Loss: 0.564255\n",
      " Loss: 0.423394\n",
      " Loss: 0.727215\n",
      "Epoch 242 Chain 0 loss std 1.99e+03 variance 1.99e+06 smooth variance 2.49e+06 adaptive c -1.00\n",
      "Epoch 242 Chain 1 loss std 8.99e+02 variance 4.04e+05 smooth variance 9.19e+05 adaptive c -1.00\n",
      " Loss: 0.453474\n",
      " Loss: 0.513090\n",
      " Loss: 0.566533\n",
      " Loss: 0.756822\n",
      " Loss: 0.567391\n",
      " Loss: 0.362598\n",
      " Loss: 0.265926\n",
      " Loss: 0.483201\n",
      " Loss: 0.946736\n",
      " Loss: 0.356491\n",
      " Loss: 0.510002\n",
      " Loss: 0.619568\n",
      " Loss: 0.361860\n",
      " Loss: 0.417544\n",
      " Loss: 0.459756\n",
      " Loss: 0.561705\n",
      " Loss: 0.666742\n",
      " Loss: 0.371228\n",
      " Loss: 0.704261\n",
      " Loss: 0.487455\n",
      "Epoch 244 Chain 0 loss std 1.82e+03 variance 1.66e+06 smooth variance 2.24e+06 adaptive c -1.00\n",
      "Epoch 244 Chain 1 loss std 1.13e+03 variance 6.42e+05 smooth variance 8.36e+05 adaptive c -1.00\n",
      " Loss: 0.535640\n",
      " Loss: 0.531594\n",
      " Loss: 0.398792\n",
      " Loss: 0.185321\n",
      " Loss: 0.471404\n",
      " Loss: 0.487488\n",
      " Loss: 0.624949\n",
      " Loss: 0.590481\n",
      " Loss: 0.598757\n",
      " Loss: 0.645835\n",
      " Loss: 0.485115\n",
      " Loss: 0.734052\n",
      " Loss: 0.424821\n",
      " Loss: 0.466528\n",
      " Loss: 0.775221\n",
      " Loss: 0.505555\n",
      " Loss: 0.398708\n",
      " Loss: 0.364724\n",
      " Loss: 0.460052\n",
      " Loss: 0.357555\n",
      "Epoch 246 Chain 0 loss std 2.10e+03 variance 2.20e+06 smooth variance 2.23e+06 adaptive c -1.00\n",
      "Epoch 246 Chain 1 loss std 1.06e+03 variance 5.65e+05 smooth variance 7.54e+05 adaptive c -1.00\n",
      " Loss: 0.361575\n",
      " Loss: 0.611643\n",
      " Loss: 0.791689\n",
      " Loss: 0.399080\n",
      " Loss: 0.562684\n",
      " Loss: 0.491324\n",
      " Loss: 0.446878\n",
      " Loss: 0.522929\n",
      " Loss: 0.311442\n",
      " Loss: 0.386683\n",
      " Loss: 0.531576\n",
      " Loss: 0.495729\n",
      " Loss: 0.709715\n",
      " Loss: 0.391710\n",
      " Loss: 0.366468\n",
      " Loss: 0.515777\n",
      " Loss: 0.403224\n",
      " Loss: 0.532106\n",
      " Loss: 0.417595\n",
      " Loss: 0.462548\n",
      "Epoch 248 Chain 0 loss std 2.44e+03 variance 2.98e+06 smooth variance 2.45e+06 adaptive c -1.00\n",
      "Epoch 248 Chain 1 loss std 1.90e+03 variance 1.81e+06 smooth variance 1.07e+06 adaptive c -1.00\n",
      " Loss: 0.783993\n",
      " Loss: 0.461313\n",
      " Loss: 0.378761\n",
      " Loss: 0.575070\n",
      " Loss: 0.359696\n",
      " Loss: 0.510563\n",
      " Loss: 0.274352\n",
      " Loss: 0.283548\n",
      " Loss: 0.625714\n",
      " Loss: 0.551803\n",
      " Loss: 0.686228\n",
      " Loss: 0.575238\n",
      " Loss: 0.499892\n",
      " Loss: 0.362434\n",
      " Loss: 0.449421\n",
      " Loss: 0.246967\n",
      " Loss: 0.347438\n",
      " Loss: 0.554516\n",
      " Loss: 0.443204\n",
      " Loss: 0.627930\n",
      "Epoch 250 Chain 0 loss std 3.04e+03 variance 4.62e+06 smooth variance 3.11e+06 adaptive c -1.00\n",
      "Epoch 250 Chain 1 loss std 1.07e+03 variance 5.69e+05 smooth variance 9.21e+05 adaptive c -1.00\n",
      " Loss: 0.372871\n",
      " Loss: 0.349164\n",
      " Loss: 0.583987\n",
      " Loss: 0.602668\n",
      " Loss: 0.703638\n",
      " Loss: 0.431258\n",
      " Loss: 0.225338\n",
      " Loss: 0.476215\n",
      " Loss: 0.536624\n",
      " Loss: 0.492330\n",
      " Loss: 0.650179\n",
      " Loss: 0.538955\n",
      " Loss: 0.489596\n",
      " Loss: 0.297198\n",
      " Loss: 0.257959\n",
      " Loss: 0.486951\n",
      " Loss: 0.252348\n",
      " Loss: 0.569090\n",
      " Loss: 0.752193\n",
      " Loss: 0.444197\n",
      "Epoch 252 Chain 0 loss std 1.81e+03 variance 1.63e+06 smooth variance 2.66e+06 adaptive c -1.00\n",
      "Epoch 252 Chain 1 loss std 1.15e+03 variance 6.58e+05 smooth variance 8.42e+05 adaptive c -1.00\n",
      " Loss: 0.460238\n",
      " Loss: 0.284442\n",
      " Loss: 0.289808\n",
      " Loss: 0.553070\n",
      " Loss: 0.476770\n",
      " Loss: 0.640199\n",
      " Loss: 0.975507\n",
      " Loss: 0.331289\n",
      " Loss: 0.197441\n",
      " Loss: 0.514316\n",
      " Loss: 0.237601\n",
      " Loss: 0.535837\n",
      " Loss: 0.478637\n",
      " Loss: 0.381816\n",
      " Loss: 0.626454\n",
      " Loss: 0.665865\n",
      " Loss: 0.641542\n",
      " Loss: 0.308794\n",
      " Loss: 0.397154\n",
      " Loss: 0.416859\n",
      "Epoch 254 Chain 0 loss std 1.77e+03 variance 1.58e+06 smooth variance 2.34e+06 adaptive c -1.00\n",
      "Epoch 254 Chain 1 loss std 1.05e+03 variance 5.49e+05 smooth variance 7.54e+05 adaptive c -1.00\n",
      " Loss: 0.539632\n",
      " Loss: 0.444130\n",
      " Loss: 0.507495\n",
      " Loss: 0.360411\n",
      " Loss: 0.721100\n",
      " Loss: 0.437820\n",
      " Loss: 0.207752\n",
      " Loss: 0.613768\n",
      " Loss: 0.409123\n",
      " Loss: 0.438418\n",
      " Loss: 0.444543\n",
      " Loss: 0.413513\n",
      " Loss: 0.645282\n",
      " Loss: 0.422254\n",
      " Loss: 0.244708\n",
      " Loss: 0.532945\n",
      " Loss: 0.420704\n",
      " Loss: 0.516276\n",
      " Loss: 0.583723\n",
      " Loss: 0.396640\n",
      "Epoch 256 Chain 0 loss std 1.97e+03 variance 1.94e+06 smooth variance 2.22e+06 adaptive c -1.00\n",
      "Epoch 256 Chain 1 loss std 1.96e+03 variance 1.92e+06 smooth variance 1.11e+06 adaptive c -1.00\n",
      " Loss: 0.873536\n",
      " Loss: 0.417655\n",
      " Loss: 0.311383\n",
      " Loss: 0.438345\n",
      " Loss: 0.398674\n",
      " Loss: 0.587523\n",
      " Loss: 0.317623\n",
      " Loss: 0.333549\n",
      " Loss: 0.406280\n",
      " Loss: 0.491943\n",
      " Loss: 0.494659\n",
      " Loss: 0.536985\n",
      " Loss: 0.495808\n",
      " Loss: 0.461052\n",
      " Loss: 0.205501\n",
      " Loss: 0.433702\n",
      " Loss: 0.849126\n",
      " Loss: 0.432999\n",
      " Loss: 0.252136\n",
      " Loss: 0.391796\n",
      "Epoch 258 Chain 0 loss std 2.82e+03 variance 3.98e+06 smooth variance 2.75e+06 adaptive c -1.00\n",
      "Epoch 258 Chain 1 loss std 1.22e+03 variance 7.42e+05 smooth variance 9.96e+05 adaptive c -1.00\n",
      " Loss: 0.529884\n",
      " Loss: 0.539542\n",
      " Loss: 0.301237\n",
      " Loss: 0.343906\n",
      " Loss: 0.248532\n",
      " Loss: 0.563180\n",
      " Loss: 0.380731\n",
      " Loss: 0.449956\n",
      " Loss: 0.818922\n",
      " Loss: 0.346187\n",
      " Loss: 0.195263\n",
      " Loss: 0.527929\n",
      " Loss: 0.570912\n",
      " Loss: 0.399319\n",
      " Loss: 0.365830\n",
      " Loss: 0.446342\n",
      " Loss: 0.649999\n",
      " Loss: 0.394025\n",
      " Loss: 0.472766\n",
      " Loss: 0.460178\n",
      "Epoch 260 Chain 0 loss std 2.41e+03 variance 2.90e+06 smooth variance 2.79e+06 adaptive c -1.00\n",
      "Epoch 260 Chain 1 loss std 7.80e+02 variance 3.04e+05 smooth variance 7.89e+05 adaptive c -1.00\n",
      " Loss: 0.429139\n",
      " Loss: 0.429265\n",
      " Loss: 0.546422\n",
      " Loss: 0.367683\n",
      " Loss: 0.340801\n",
      " Loss: 0.431400\n",
      " Loss: 0.562086\n",
      " Loss: 0.429245\n",
      " Loss: 0.337194\n",
      " Loss: 0.558028\n",
      " Loss: 0.561068\n",
      " Loss: 0.405940\n",
      " Loss: 0.408263\n",
      " Loss: 0.365383\n",
      " Loss: 0.347869\n",
      " Loss: 0.528059\n",
      " Loss: 0.288421\n",
      " Loss: 0.427728\n",
      " Loss: 0.602684\n",
      " Loss: 0.479436\n",
      "Epoch 262 Chain 0 loss std 1.70e+03 variance 1.44e+06 smooth variance 2.39e+06 adaptive c -1.00\n",
      "Epoch 262 Chain 1 loss std 6.02e+02 variance 1.81e+05 smooth variance 6.06e+05 adaptive c -1.00\n",
      " Loss: 0.391531\n",
      " Loss: 0.452096\n",
      " Loss: 0.287681\n",
      " Loss: 0.476302\n",
      " Loss: 0.586959\n",
      " Loss: 0.357810\n",
      " Loss: 0.403899\n",
      " Loss: 0.474528\n",
      " Loss: 0.512493\n",
      " Loss: 0.434574\n",
      " Loss: 0.506960\n",
      " Loss: 0.459631\n",
      " Loss: 0.591210\n",
      " Loss: 0.519392\n",
      " Loss: 0.476938\n",
      " Loss: 0.410882\n",
      " Loss: 0.341092\n",
      " Loss: 0.458937\n",
      " Loss: 0.242244\n",
      " Loss: 0.336349\n",
      "Epoch 264 Chain 0 loss std 1.06e+03 variance 5.60e+05 smooth variance 1.84e+06 adaptive c -1.00\n",
      "Epoch 264 Chain 1 loss std 1.04e+03 variance 5.41e+05 smooth variance 5.87e+05 adaptive c -1.00\n",
      " Loss: 0.597579\n",
      " Loss: 0.230374\n",
      " Loss: 0.255381\n",
      " Loss: 0.671843\n",
      " Loss: 0.473555\n",
      " Loss: 0.494508\n",
      " Loss: 0.540163\n",
      " Loss: 0.371428\n",
      " Loss: 0.262754\n",
      " Loss: 0.402822\n",
      " Loss: 0.327205\n",
      " Loss: 0.580259\n",
      " Loss: 0.488234\n",
      " Loss: 0.308827\n",
      " Loss: 0.434308\n",
      " Loss: 0.243782\n",
      " Loss: 0.565949\n",
      " Loss: 0.353809\n",
      " Loss: 0.279933\n",
      " Loss: 0.670029\n",
      "Epoch 266 Chain 0 loss std 3.24e+03 variance 5.24e+06 smooth variance 2.86e+06 adaptive c -1.00\n",
      "Epoch 266 Chain 1 loss std 8.89e+02 variance 3.95e+05 smooth variance 5.29e+05 adaptive c -1.00\n",
      " Loss: 0.387659\n",
      " Loss: 0.335541\n",
      " Loss: 0.579076\n",
      " Loss: 0.430269\n",
      " Loss: 0.464892\n",
      " Loss: 0.672886\n",
      " Loss: 0.410537\n",
      " Loss: 0.492788\n",
      " Loss: 0.253288\n",
      " Loss: 0.209312\n",
      " Loss: 0.333601\n",
      " Loss: 0.292225\n",
      " Loss: 0.363075\n",
      " Loss: 0.468518\n",
      " Loss: 0.344055\n",
      " Loss: 0.373179\n",
      " Loss: 0.708228\n",
      " Loss: 0.689462\n",
      " Loss: 0.331219\n",
      " Loss: 0.303581\n",
      "Epoch 268 Chain 0 loss std 1.57e+03 variance 1.23e+06 smooth variance 2.37e+06 adaptive c -1.00\n",
      "Epoch 268 Chain 1 loss std 1.50e+03 variance 1.13e+06 smooth variance 7.09e+05 adaptive c -1.00\n",
      " Loss: 0.671551\n",
      " Loss: 0.388428\n",
      " Loss: 0.205418\n",
      " Loss: 0.508544\n",
      " Loss: 0.392226\n",
      " Loss: 0.381039\n",
      " Loss: 0.443839\n",
      " Loss: 0.528764\n",
      " Loss: 0.342160\n",
      " Loss: 0.308630\n",
      " Loss: 0.238553\n",
      " Loss: 0.360655\n",
      " Loss: 0.271793\n",
      " Loss: 0.514397\n",
      " Loss: 0.299472\n",
      " Loss: 0.402420\n",
      " Loss: 0.703434\n",
      " Loss: 0.343175\n",
      " Loss: 0.523484\n",
      " Loss: 0.480006\n",
      "Epoch 270 Chain 0 loss std 1.69e+03 variance 1.42e+06 smooth variance 2.09e+06 adaptive c -1.00\n",
      "Epoch 270 Chain 1 loss std 1.99e+03 variance 1.97e+06 smooth variance 1.09e+06 adaptive c -1.00\n",
      " Loss: 0.569384\n",
      " Loss: 0.332451\n",
      " Loss: 0.345461\n",
      " Loss: 0.740431\n",
      " Loss: 0.387421\n",
      " Loss: 0.332522\n",
      " Loss: 0.316829\n",
      " Loss: 0.265964\n",
      " Loss: 0.399216\n",
      " Loss: 0.417917\n",
      " Loss: 0.203846\n",
      " Loss: 0.486330\n",
      " Loss: 0.790095\n",
      " Loss: 0.390530\n",
      " Loss: 0.356836\n",
      " Loss: 0.397775\n",
      " Loss: 0.227760\n",
      " Loss: 0.515027\n",
      " Loss: 0.420842\n",
      " Loss: 0.286364\n",
      "Epoch 272 Chain 0 loss std 1.68e+03 variance 1.42e+06 smooth variance 1.89e+06 adaptive c -1.00\n",
      "Epoch 272 Chain 1 loss std 2.12e+03 variance 2.25e+06 smooth variance 1.43e+06 adaptive c -1.00\n",
      " Loss: 0.408434\n",
      " Loss: 0.457569\n",
      " Loss: 0.669052\n",
      " Loss: 0.428653\n",
      " Loss: 0.328585\n",
      " Loss: 0.363145\n",
      " Loss: 0.299254\n",
      " Loss: 0.245941\n",
      " Loss: 0.267052\n",
      " Loss: 0.569032\n",
      " Loss: 0.486355\n",
      " Loss: 0.381929\n",
      " Loss: 0.606103\n",
      " Loss: 0.599803\n",
      " Loss: 0.186746\n",
      " Loss: 0.251171\n",
      " Loss: 0.360009\n",
      " Loss: 0.328703\n",
      " Loss: 0.311914\n",
      " Loss: 0.491534\n",
      "Epoch 274 Chain 0 loss std 1.55e+03 variance 1.20e+06 smooth variance 1.68e+06 adaptive c -1.00\n",
      "Epoch 274 Chain 1 loss std 8.92e+02 variance 3.98e+05 smooth variance 1.12e+06 adaptive c -1.00\n",
      " Loss: 0.173997\n",
      " Loss: 0.433378\n",
      " Loss: 0.426062\n",
      " Loss: 0.461264\n",
      " Loss: 0.294099\n",
      " Loss: 0.499810\n",
      " Loss: 0.649986\n",
      " Loss: 0.219542\n",
      " Loss: 0.374471\n",
      " Loss: 0.430146\n",
      " Loss: 0.192260\n",
      " Loss: 0.319535\n",
      " Loss: 0.447346\n",
      " Loss: 0.382464\n",
      " Loss: 0.584425\n",
      " Loss: 0.368137\n",
      " Loss: 0.500901\n",
      " Loss: 0.409087\n",
      " Loss: 0.153612\n",
      " Loss: 0.552782\n",
      "Epoch 276 Chain 0 loss std 8.69e+02 variance 3.78e+05 smooth variance 1.29e+06 adaptive c -1.00\n",
      "Epoch 276 Chain 1 loss std 2.15e+03 variance 2.30e+06 smooth variance 1.48e+06 adaptive c -1.00\n",
      " Loss: 0.226233\n",
      " Loss: 0.463751\n",
      " Loss: 0.282433\n",
      " Loss: 0.434083\n",
      " Loss: 0.525943\n",
      " Loss: 0.345454\n",
      " Loss: 0.483825\n",
      " Loss: 0.578602\n",
      " Loss: 0.313160\n",
      " Loss: 0.201745\n",
      " Loss: 0.623736\n",
      " Loss: 0.547573\n",
      " Loss: 0.332459\n",
      " Loss: 0.279004\n",
      " Loss: 0.202907\n",
      " Loss: 0.260544\n",
      " Loss: 0.175333\n",
      " Loss: 0.472833\n",
      " Loss: 0.458086\n",
      " Loss: 0.454251\n",
      "Epoch 278 Chain 0 loss std 1.64e+03 variance 1.34e+06 smooth variance 1.30e+06 adaptive c -1.00\n",
      "Epoch 278 Chain 1 loss std 8.70e+02 variance 3.78e+05 smooth variance 1.15e+06 adaptive c -1.00\n",
      " Loss: 0.228303\n",
      " Loss: 0.447865\n",
      " Loss: 0.186297\n",
      " Loss: 0.687446\n",
      " Loss: 0.374438\n",
      " Loss: 0.321934\n",
      " Loss: 0.417857\n",
      " Loss: 0.307103\n",
      " Loss: 0.553057\n",
      " Loss: 0.239291\n",
      " Loss: 0.223485\n",
      " Loss: 0.330771\n",
      " Loss: 0.439770\n",
      " Loss: 0.379867\n",
      " Loss: 0.176628\n",
      " Loss: 0.659599\n",
      " Loss: 0.584008\n",
      " Loss: 0.391271\n",
      " Loss: 0.307915\n",
      " Loss: 0.230890\n",
      "Epoch 280 Chain 0 loss std 1.16e+03 variance 6.68e+05 smooth variance 1.11e+06 adaptive c -1.00\n",
      "Epoch 280 Chain 1 loss std 1.59e+03 variance 1.27e+06 smooth variance 1.18e+06 adaptive c -1.00\n",
      " Loss: 0.596373\n",
      " Loss: 0.379664\n",
      " Loss: 0.249504\n",
      " Loss: 0.412398\n",
      " Loss: 0.453011\n",
      " Loss: 0.300417\n",
      " Loss: 0.145391\n",
      " Loss: 0.423026\n",
      " Loss: 0.267573\n",
      " Loss: 0.468858\n",
      " Loss: 0.315899\n",
      " Loss: 0.299853\n",
      " Loss: 0.460698\n",
      " Loss: 0.412894\n",
      " Loss: 0.494529\n",
      " Loss: 0.417705\n",
      " Loss: 0.240648\n",
      " Loss: 0.585167\n",
      " Loss: 0.174570\n",
      " Loss: 0.257984\n",
      "Epoch 282 Chain 0 loss std 1.73e+03 variance 1.49e+06 smooth variance 1.23e+06 adaptive c -1.00\n",
      "Epoch 282 Chain 1 loss std 2.30e+03 variance 2.66e+06 smooth variance 1.62e+06 adaptive c -1.00\n",
      " Loss: 0.408754\n",
      " Loss: 0.233806\n",
      " Loss: 0.251600\n",
      " Loss: 0.467316\n",
      " Loss: 0.327622\n",
      " Loss: 0.229201\n",
      " Loss: 0.158487\n",
      " Loss: 0.608829\n",
      " Loss: 0.509608\n",
      " Loss: 0.424895\n",
      " Loss: 0.241589\n",
      " Loss: 0.714972\n",
      " Loss: 0.446812\n",
      " Loss: 0.370851\n",
      " Loss: 0.507565\n",
      " Loss: 0.197821\n",
      " Loss: 0.257780\n",
      " Loss: 0.330982\n",
      " Loss: 0.165918\n",
      " Loss: 0.334727\n",
      "Epoch 284 Chain 0 loss std 1.40e+03 variance 9.85e+05 smooth variance 1.15e+06 adaptive c -1.00\n",
      "Epoch 284 Chain 1 loss std 6.03e+02 variance 1.82e+05 smooth variance 1.19e+06 adaptive c -1.00\n",
      " Loss: 0.318630\n",
      " Loss: 0.590839\n",
      " Loss: 0.199459\n",
      " Loss: 0.237976\n",
      " Loss: 0.182037\n",
      " Loss: 0.294475\n",
      " Loss: 0.434359\n",
      " Loss: 0.564332\n",
      " Loss: 0.423414\n",
      " Loss: 0.248014\n",
      " Loss: 0.221751\n",
      " Loss: 0.356870\n",
      " Loss: 0.256197\n",
      " Loss: 0.446741\n",
      " Loss: 0.668689\n",
      " Loss: 0.431527\n",
      " Loss: 0.188582\n",
      " Loss: 0.372868\n",
      " Loss: 0.178969\n",
      " Loss: 0.313908\n",
      "Epoch 286 Chain 0 loss std 1.93e+03 variance 1.86e+06 smooth variance 1.37e+06 adaptive c -1.00\n",
      "Epoch 286 Chain 1 loss std 6.23e+02 variance 1.94e+05 smooth variance 8.92e+05 adaptive c -1.00\n",
      " Loss: 0.519076\n",
      " Loss: 0.237505\n",
      " Loss: 0.383434\n",
      " Loss: 0.449209\n",
      " Loss: 0.226831\n",
      " Loss: 0.467705\n",
      " Loss: 0.271638\n",
      " Loss: 0.329049\n",
      " Loss: 0.092955\n",
      " Loss: 0.423309\n",
      " Loss: 0.201750\n",
      " Loss: 0.398208\n",
      " Loss: 0.248222\n",
      " Loss: 0.329599\n",
      " Loss: 0.338291\n",
      " Loss: 0.419995\n",
      " Loss: 0.125984\n",
      " Loss: 0.511806\n",
      " Loss: 0.531384\n",
      " Loss: 0.237012\n",
      "Epoch 288 Chain 0 loss std 8.95e+02 variance 4.00e+05 smooth variance 1.08e+06 adaptive c -1.00\n",
      "Epoch 288 Chain 1 loss std 1.48e+03 variance 1.09e+06 smooth variance 9.51e+05 adaptive c -1.00\n",
      " Loss: 0.211125\n",
      " Loss: 0.419522\n",
      " Loss: 0.314710\n",
      " Loss: 0.392654\n",
      " Loss: 0.377828\n",
      " Loss: 0.413506\n",
      " Loss: 0.240663\n",
      " Loss: 0.302744\n",
      " Loss: 0.289120\n",
      " Loss: 0.356230\n",
      " Loss: 0.388889\n",
      " Loss: 0.652163\n",
      " Loss: 0.163211\n",
      " Loss: 0.474086\n",
      " Loss: 0.237223\n",
      " Loss: 0.250425\n",
      " Loss: 0.392944\n",
      " Loss: 0.212229\n",
      " Loss: 0.219828\n",
      " Loss: 0.284860\n",
      "Epoch 290 Chain 0 loss std 8.83e+02 variance 3.90e+05 smooth variance 8.71e+05 adaptive c -1.00\n",
      "Epoch 290 Chain 1 loss std 1.03e+03 variance 5.27e+05 smooth variance 8.24e+05 adaptive c -1.00\n",
      " Loss: 0.127104\n",
      " Loss: 0.358121\n",
      " Loss: 0.158502\n",
      " Loss: 0.216190\n",
      " Loss: 0.382750\n",
      " Loss: 0.380853\n",
      " Loss: 0.317517\n",
      " Loss: 0.386199\n",
      " Loss: 0.378721\n",
      " Loss: 0.518091\n",
      " Loss: 0.129348\n",
      " Loss: 0.518484\n",
      " Loss: 0.070280\n",
      " Loss: 0.279079\n",
      " Loss: 0.178698\n",
      " Loss: 0.237726\n",
      " Loss: 0.633215\n",
      " Loss: 0.504563\n",
      " Loss: 0.323142\n",
      " Loss: 0.307966\n",
      "Epoch 292 Chain 0 loss std 1.34e+03 variance 8.93e+05 smooth variance 8.78e+05 adaptive c -1.00\n",
      "Epoch 292 Chain 1 loss std 1.85e+03 variance 1.72e+06 smooth variance 1.09e+06 adaptive c -1.00\n",
      " Loss: 0.241769\n",
      " Loss: 0.368690\n",
      " Loss: 0.411331\n",
      " Loss: 0.325851\n",
      " Loss: 0.333909\n",
      " Loss: 0.458401\n",
      " Loss: 0.140164\n",
      " Loss: 0.430377\n",
      " Loss: 0.186555\n",
      " Loss: 0.251619\n",
      " Loss: 0.331032\n",
      " Loss: 0.327196\n",
      " Loss: 0.125472\n",
      " Loss: 0.514351\n",
      " Loss: 0.247603\n",
      " Loss: 0.388093\n",
      " Loss: 0.342845\n",
      " Loss: 0.336553\n",
      " Loss: 0.252369\n",
      " Loss: 0.255843\n",
      "Epoch 294 Chain 0 loss std 1.18e+03 variance 6.96e+05 smooth variance 8.23e+05 adaptive c -1.00\n",
      "Epoch 294 Chain 1 loss std 1.07e+03 variance 5.74e+05 smooth variance 9.36e+05 adaptive c -1.00\n",
      " Loss: 0.400289\n",
      " Loss: 0.364832\n",
      " Loss: 0.273392\n",
      " Loss: 0.318921\n",
      " Loss: 0.248703\n",
      " Loss: 0.196885\n",
      " Loss: 0.243355\n",
      " Loss: 0.446119\n",
      " Loss: 0.119452\n",
      " Loss: 0.481767\n",
      " Loss: 0.230496\n",
      " Loss: 0.588853\n",
      " Loss: 0.188947\n",
      " Loss: 0.306034\n",
      " Loss: 0.394030\n",
      " Loss: 0.223959\n",
      " Loss: 0.144821\n",
      " Loss: 0.310677\n",
      " Loss: 0.303817\n",
      " Loss: 0.367226\n",
      "Epoch 296 Chain 0 loss std 1.33e+03 variance 8.80e+05 smooth variance 8.40e+05 adaptive c -1.00\n",
      "Epoch 296 Chain 1 loss std 1.44e+03 variance 1.03e+06 smooth variance 9.65e+05 adaptive c -1.00\n",
      " Loss: 0.315885\n",
      " Loss: 0.262538\n",
      " Loss: 0.306118\n",
      " Loss: 0.479260\n",
      " Loss: 0.186609\n",
      " Loss: 0.517599\n",
      " Loss: 0.321645\n",
      " Loss: 0.313507\n",
      " Loss: 0.114946\n",
      " Loss: 0.212625\n",
      " Loss: 0.227773\n",
      " Loss: 0.216718\n",
      " Loss: 0.153828\n",
      " Loss: 0.345181\n",
      " Loss: 0.414972\n",
      " Loss: 0.308196\n",
      " Loss: 0.270720\n",
      " Loss: 0.341668\n",
      " Loss: 0.153482\n",
      " Loss: 0.561935\n",
      "Epoch 298 Chain 0 loss std 9.17e+02 variance 4.20e+05 smooth variance 7.14e+05 adaptive c -1.00\n",
      "Epoch 298 Chain 1 loss std 1.18e+03 variance 6.97e+05 smooth variance 8.85e+05 adaptive c -1.00\n",
      " Loss: 0.201167\n",
      " Loss: 0.390967\n",
      " Loss: 0.145134\n",
      " Loss: 0.439591\n",
      " Loss: 0.326795\n",
      " Loss: 0.202307\n",
      " Loss: 0.444319\n",
      " Loss: 0.336014\n",
      " Loss: 0.096638\n",
      " Loss: 0.394981\n",
      " Loss: 0.219765\n",
      " Loss: 0.315426\n",
      " Loss: 0.308854\n",
      " Loss: 0.448880\n",
      " Loss: 0.266537\n",
      " Loss: 0.358821\n",
      " Loss: 0.176426\n",
      " Loss: 0.240200\n",
      " Loss: 0.222089\n",
      " Loss: 0.390130\n",
      "Epoch 300 Chain 0 loss std 9.39e+02 variance 4.41e+05 smooth variance 6.32e+05 adaptive c -1.00\n",
      "Epoch 300 Chain 1 loss std 7.56e+02 variance 2.86e+05 smooth variance 7.05e+05 adaptive c -1.00\n",
      " Loss: 0.244927\n",
      " Loss: 0.311675\n",
      " Loss: 0.397766\n",
      " Loss: 0.294255\n",
      " Loss: 0.156291\n",
      " Loss: 0.502518\n",
      " Loss: 0.237735\n",
      " Loss: 0.121745\n",
      " Loss: 0.134867\n",
      " Loss: 0.510574\n",
      " Loss: 0.200169\n",
      " Loss: 0.450644\n",
      " Loss: 0.315956\n",
      " Loss: 0.344801\n",
      " Loss: 0.178550\n",
      " Loss: 0.361068\n",
      " Loss: 0.197057\n",
      " Loss: 0.172962\n",
      " Loss: 0.259441\n",
      " Loss: 0.399912\n",
      "Epoch 302 Chain 0 loss std 7.39e+02 variance 2.73e+05 smooth variance 5.25e+05 adaptive c -1.00\n",
      "Epoch 302 Chain 1 loss std 7.63e+02 variance 2.91e+05 smooth variance 5.81e+05 adaptive c -1.00\n",
      " Loss: 0.184884\n",
      " Loss: 0.566029\n",
      " Loss: 0.161046\n",
      " Loss: 0.524952\n",
      " Loss: 0.090046\n",
      " Loss: 0.210784\n",
      " Loss: 0.316637\n",
      " Loss: 0.262865\n",
      " Loss: 0.372280\n",
      " Loss: 0.153142\n",
      " Loss: 0.172936\n",
      " Loss: 0.401456\n",
      " Loss: 0.388315\n",
      " Loss: 0.318743\n",
      " Loss: 0.298472\n",
      " Loss: 0.336091\n",
      " Loss: 0.141745\n",
      " Loss: 0.294554\n",
      " Loss: 0.102558\n",
      " Loss: 0.352767\n",
      "Epoch 304 Chain 0 loss std 8.29e+02 variance 3.43e+05 smooth variance 4.70e+05 adaptive c -1.00\n",
      "Epoch 304 Chain 1 loss std 1.25e+03 variance 7.85e+05 smooth variance 6.42e+05 adaptive c -1.00\n",
      " Loss: 0.319315\n",
      " Loss: 0.325904\n",
      " Loss: 0.207864\n",
      " Loss: 0.284621\n",
      " Loss: 0.228549\n",
      " Loss: 0.393329\n",
      " Loss: 0.150838\n",
      " Loss: 0.386952\n",
      " Loss: 0.172120\n",
      " Loss: 0.301478\n",
      " Loss: 0.213048\n",
      " Loss: 0.364970\n",
      " Loss: 0.218598\n",
      " Loss: 0.281023\n",
      " Loss: 0.248617\n",
      " Loss: 0.314847\n",
      " Loss: 0.145422\n",
      " Loss: 0.261977\n",
      " Loss: 0.219936\n",
      " Loss: 0.457843\n",
      "Epoch 306 Chain 0 loss std 9.91e+02 variance 4.91e+05 smooth variance 4.77e+05 adaptive c -1.00\n",
      "Epoch 306 Chain 1 loss std 7.30e+02 variance 2.66e+05 smooth variance 5.29e+05 adaptive c -1.00\n",
      " Loss: 0.186659\n",
      " Loss: 0.242509\n",
      " Loss: 0.139487\n",
      " Loss: 0.490436\n",
      " Loss: 0.078823\n",
      " Loss: 0.366019\n",
      " Loss: 0.349087\n",
      " Loss: 0.361192\n",
      " Loss: 0.262869\n",
      " Loss: 0.209770\n",
      " Loss: 0.191717\n",
      " Loss: 0.156519\n",
      " Loss: 0.098398\n",
      " Loss: 0.250204\n",
      " Loss: 0.227659\n",
      " Loss: 0.483752\n",
      " Loss: 0.280040\n",
      " Loss: 0.432319\n",
      " Loss: 0.200181\n",
      " Loss: 0.334838\n",
      "Epoch 308 Chain 0 loss std 8.55e+02 variance 3.65e+05 smooth variance 4.43e+05 adaptive c -1.00\n",
      "Epoch 308 Chain 1 loss std 1.08e+03 variance 5.82e+05 smooth variance 5.45e+05 adaptive c -1.00\n",
      " Loss: 0.153894\n",
      " Loss: 0.252368\n",
      " Loss: 0.073476\n",
      " Loss: 0.243179\n",
      " Loss: 0.309396\n",
      " Loss: 0.150360\n",
      " Loss: 0.206711\n",
      " Loss: 0.453621\n",
      " Loss: 0.240349\n",
      " Loss: 0.547532\n",
      " Loss: 0.130915\n",
      " Loss: 0.416077\n",
      " Loss: 0.128534\n",
      " Loss: 0.452471\n",
      " Loss: 0.247631\n",
      " Loss: 0.138094\n",
      " Loss: 0.249495\n",
      " Loss: 0.363868\n",
      " Loss: 0.206695\n",
      " Loss: 0.266788\n",
      "Epoch 310 Chain 0 loss std 1.13e+03 variance 6.43e+05 smooth variance 5.03e+05 adaptive c -1.00\n",
      "Epoch 310 Chain 1 loss std 8.45e+02 variance 3.57e+05 smooth variance 4.89e+05 adaptive c -1.00\n",
      " Loss: 0.306840\n",
      " Loss: 0.220109\n",
      " Loss: 0.096909\n",
      " Loss: 0.393879\n",
      " Loss: 0.229286\n",
      " Loss: 0.488297\n",
      " Loss: 0.193924\n",
      " Loss: 0.239526\n",
      " Loss: 0.115111\n",
      " Loss: 0.283987\n",
      " Loss: 0.119002\n",
      " Loss: 0.456413\n",
      " Loss: 0.081495\n",
      " Loss: 0.173725\n",
      " Loss: 0.163679\n",
      " Loss: 0.421050\n",
      " Loss: 0.248468\n",
      " Loss: 0.204854\n",
      " Loss: 0.312362\n",
      " Loss: 0.358841\n",
      "Epoch 312 Chain 0 loss std 7.19e+02 variance 2.58e+05 smooth variance 4.30e+05 adaptive c -1.00\n",
      "Epoch 312 Chain 1 loss std 1.33e+03 variance 8.79e+05 smooth variance 6.06e+05 adaptive c -1.00\n",
      " Loss: 0.376785\n",
      " Loss: 0.131783\n",
      " Loss: 0.125676\n",
      " Loss: 0.269929\n",
      " Loss: 0.084025\n",
      " Loss: 0.486881\n",
      " Loss: 0.238447\n",
      " Loss: 0.251105\n",
      " Loss: 0.086616\n",
      " Loss: 0.465187\n",
      " Loss: 0.129949\n",
      " Loss: 0.206028\n",
      " Loss: 0.134092\n",
      " Loss: 0.320041\n",
      " Loss: 0.218841\n",
      " Loss: 0.423159\n",
      " Loss: 0.174664\n",
      " Loss: 0.311668\n",
      " Loss: 0.231304\n",
      " Loss: 0.334236\n",
      "Epoch 314 Chain 0 loss std 6.72e+02 variance 2.26e+05 smooth variance 3.69e+05 adaptive c -1.00\n",
      "Epoch 314 Chain 1 loss std 7.38e+02 variance 2.72e+05 smooth variance 5.06e+05 adaptive c -1.00\n",
      " Loss: 0.270462\n",
      " Loss: 0.344854\n",
      " Loss: 0.211448\n",
      " Loss: 0.306591\n",
      " Loss: 0.208552\n",
      " Loss: 0.319593\n",
      " Loss: 0.144773\n",
      " Loss: 0.370176\n",
      " Loss: 0.049222\n",
      " Loss: 0.244093\n",
      " Loss: 0.190978\n",
      " Loss: 0.365730\n",
      " Loss: 0.224126\n",
      " Loss: 0.434522\n",
      " Loss: 0.228067\n",
      " Loss: 0.212029\n",
      " Loss: 0.095901\n",
      " Loss: 0.221339\n",
      " Loss: 0.131394\n",
      " Loss: 0.341135\n",
      "Epoch 316 Chain 0 loss std 8.53e+02 variance 3.63e+05 smooth variance 3.67e+05 adaptive c -1.00\n",
      "Epoch 316 Chain 1 loss std 7.94e+02 variance 3.15e+05 smooth variance 4.49e+05 adaptive c -1.00\n",
      " Loss: 0.077876\n",
      " Loss: 0.385487\n",
      " Loss: 0.316684\n",
      " Loss: 0.276552\n",
      " Loss: 0.122739\n",
      " Loss: 0.366884\n",
      " Loss: 0.131109\n",
      " Loss: 0.321310\n",
      " Loss: 0.204069\n",
      " Loss: 0.213217\n",
      " Loss: 0.120082\n",
      " Loss: 0.283148\n",
      " Loss: 0.149247\n",
      " Loss: 0.311410\n",
      " Loss: 0.233372\n",
      " Loss: 0.428312\n",
      " Loss: 0.088842\n",
      " Loss: 0.182320\n",
      " Loss: 0.244111\n",
      " Loss: 0.345614\n",
      "Epoch 318 Chain 0 loss std 8.09e+02 variance 3.27e+05 smooth variance 3.55e+05 adaptive c -1.00\n",
      "Epoch 318 Chain 1 loss std 1.05e+03 variance 5.55e+05 smooth variance 4.81e+05 adaptive c -1.00\n",
      " Loss: 0.171767\n",
      " Loss: 0.262122\n",
      " Loss: 0.152775\n",
      " Loss: 0.218370\n",
      " Loss: 0.211146\n",
      " Loss: 0.350854\n",
      " Loss: 0.179366\n",
      " Loss: 0.323681\n",
      " Loss: 0.101573\n",
      " Loss: 0.385303\n",
      " Loss: 0.071984\n",
      " Loss: 0.216052\n",
      " Loss: 0.210412\n",
      " Loss: 0.356342\n",
      " Loss: 0.098645\n",
      " Loss: 0.377329\n",
      " Loss: 0.136769\n",
      " Loss: 0.358072\n",
      " Loss: 0.283172\n",
      " Loss: 0.220883\n",
      "Epoch 320 Chain 0 loss std 8.04e+02 variance 3.23e+05 smooth variance 3.46e+05 adaptive c -1.00\n",
      "Epoch 320 Chain 1 loss std 3.89e+02 variance 7.56e+04 smooth variance 3.59e+05 adaptive c -1.00\n",
      " Loss: 0.071531\n",
      " Loss: 0.490615\n",
      " Loss: 0.142021\n",
      " Loss: 0.211198\n",
      " Loss: 0.164770\n",
      " Loss: 0.366225\n",
      " Loss: 0.083742\n",
      " Loss: 0.294646\n",
      " Loss: 0.318588\n",
      " Loss: 0.155631\n",
      " Loss: 0.150710\n",
      " Loss: 0.188821\n",
      " Loss: 0.066564\n",
      " Loss: 0.394197\n",
      " Loss: 0.322950\n",
      " Loss: 0.428685\n",
      " Loss: 0.126811\n",
      " Loss: 0.281708\n",
      " Loss: 0.096872\n",
      " Loss: 0.213529\n",
      "Epoch 322 Chain 0 loss std 7.21e+02 variance 2.60e+05 smooth variance 3.20e+05 adaptive c -1.00\n",
      "Epoch 322 Chain 1 loss std 1.12e+03 variance 6.25e+05 smooth variance 4.39e+05 adaptive c -1.00\n",
      " Loss: 0.078579\n",
      " Loss: 0.443076\n",
      " Loss: 0.257209\n",
      " Loss: 0.281444\n",
      " Loss: 0.157404\n",
      " Loss: 0.208304\n",
      " Loss: 0.157469\n",
      " Loss: 0.386766\n",
      " Loss: 0.098075\n",
      " Loss: 0.178226\n",
      " Loss: 0.265186\n",
      " Loss: 0.383808\n",
      " Loss: 0.094295\n",
      " Loss: 0.170684\n",
      " Loss: 0.072388\n",
      " Loss: 0.348197\n",
      " Loss: 0.193724\n",
      " Loss: 0.321678\n",
      " Loss: 0.114303\n",
      " Loss: 0.263002\n",
      "Epoch 324 Chain 0 loss std 6.73e+02 variance 2.26e+05 smooth variance 2.92e+05 adaptive c -1.00\n",
      "Epoch 324 Chain 1 loss std 8.40e+02 variance 3.53e+05 smooth variance 4.13e+05 adaptive c -1.00\n",
      " Loss: 0.297545\n",
      " Loss: 0.219650\n",
      " Loss: 0.139405\n",
      " Loss: 0.395976\n",
      " Loss: 0.050025\n",
      " Loss: 0.187730\n",
      " Loss: 0.109759\n",
      " Loss: 0.376195\n",
      " Loss: 0.124551\n",
      " Loss: 0.299496\n",
      " Loss: 0.065034\n",
      " Loss: 0.386273\n",
      " Loss: 0.185617\n",
      " Loss: 0.179045\n",
      " Loss: 0.162410\n",
      " Loss: 0.242122\n",
      " Loss: 0.105087\n",
      " Loss: 0.409781\n",
      " Loss: 0.186524\n",
      " Loss: 0.251494\n",
      "Epoch 326 Chain 0 loss std 6.51e+02 variance 2.12e+05 smooth variance 2.68e+05 adaptive c -1.00\n",
      "Epoch 326 Chain 1 loss std 1.30e+03 variance 8.47e+05 smooth variance 5.43e+05 adaptive c -1.00\n",
      " Loss: 0.087913\n",
      " Loss: 0.209202\n",
      " Loss: 0.111905\n",
      " Loss: 0.280829\n",
      " Loss: 0.227169\n",
      " Loss: 0.292432\n",
      " Loss: 0.204303\n",
      " Loss: 0.296766\n",
      " Loss: 0.058832\n",
      " Loss: 0.378522\n",
      " Loss: 0.101978\n",
      " Loss: 0.288923\n",
      " Loss: 0.143711\n",
      " Loss: 0.231843\n",
      " Loss: 0.193810\n",
      " Loss: 0.306838\n",
      " Loss: 0.149566\n",
      " Loss: 0.134939\n",
      " Loss: 0.088055\n",
      " Loss: 0.486316\n",
      "Epoch 328 Chain 0 loss std 5.80e+02 variance 1.68e+05 smooth variance 2.38e+05 adaptive c -1.00\n",
      "Epoch 328 Chain 1 loss std 9.96e+02 variance 4.96e+05 smooth variance 5.29e+05 adaptive c -1.00\n",
      " Loss: 0.073517\n",
      " Loss: 0.568643\n",
      " Loss: 0.149554\n",
      " Loss: 0.247978\n",
      " Loss: 0.111448\n",
      " Loss: 0.182216\n",
      " Loss: 0.056917\n",
      " Loss: 0.165598\n",
      " Loss: 0.271941\n",
      " Loss: 0.274367\n",
      " Loss: 0.127200\n",
      " Loss: 0.287701\n",
      " Loss: 0.064923\n",
      " Loss: 0.295688\n",
      " Loss: 0.074031\n",
      " Loss: 0.234572\n",
      " Loss: 0.283907\n",
      " Loss: 0.334582\n",
      " Loss: 0.111954\n",
      " Loss: 0.277224\n",
      "Epoch 330 Chain 0 loss std 7.02e+02 variance 2.47e+05 smooth variance 2.41e+05 adaptive c -1.00\n",
      "Epoch 330 Chain 1 loss std 9.75e+02 variance 4.75e+05 smooth variance 5.13e+05 adaptive c -1.00\n",
      " Loss: 0.128356\n",
      " Loss: 0.322489\n",
      " Loss: 0.161461\n",
      " Loss: 0.263458\n",
      " Loss: 0.063852\n",
      " Loss: 0.390079\n",
      " Loss: 0.202657\n",
      " Loss: 0.227741\n",
      " Loss: 0.098491\n",
      " Loss: 0.215597\n",
      " Loss: 0.214704\n",
      " Loss: 0.308213\n",
      " Loss: 0.088319\n",
      " Loss: 0.352600\n",
      " Loss: 0.157548\n",
      " Loss: 0.216660\n",
      " Loss: 0.126553\n",
      " Loss: 0.198444\n",
      " Loss: 0.051840\n",
      " Loss: 0.333967\n",
      "Epoch 332 Chain 0 loss std 4.74e+02 variance 1.12e+05 smooth variance 2.02e+05 adaptive c -1.00\n",
      "Epoch 332 Chain 1 loss std 6.80e+02 variance 2.31e+05 smooth variance 4.28e+05 adaptive c -1.00\n",
      " Loss: 0.096759\n",
      " Loss: 0.168180\n",
      " Loss: 0.128420\n",
      " Loss: 0.431857\n",
      " Loss: 0.263385\n",
      " Loss: 0.228772\n",
      " Loss: 0.044931\n",
      " Loss: 0.290622\n",
      " Loss: 0.083211\n",
      " Loss: 0.280158\n",
      " Loss: 0.058978\n",
      " Loss: 0.346666\n",
      " Loss: 0.181890\n",
      " Loss: 0.293700\n",
      " Loss: 0.099708\n",
      " Loss: 0.262783\n",
      " Loss: 0.204163\n",
      " Loss: 0.286277\n",
      " Loss: 0.054611\n",
      " Loss: 0.201901\n",
      "Epoch 334 Chain 0 loss std 9.65e+02 variance 4.66e+05 smooth variance 2.81e+05 adaptive c -1.00\n",
      "Epoch 334 Chain 1 loss std 9.37e+02 variance 4.39e+05 smooth variance 4.32e+05 adaptive c -1.00\n",
      " Loss: 0.119221\n",
      " Loss: 0.145120\n",
      " Loss: 0.157977\n",
      " Loss: 0.366814\n",
      " Loss: 0.202571\n",
      " Loss: 0.329834\n",
      " Loss: 0.050784\n",
      " Loss: 0.293238\n",
      " Loss: 0.056316\n",
      " Loss: 0.246286\n",
      " Loss: 0.086869\n",
      " Loss: 0.243716\n",
      " Loss: 0.230228\n",
      " Loss: 0.319927\n",
      " Loss: 0.100236\n",
      " Loss: 0.399811\n",
      " Loss: 0.056706\n",
      " Loss: 0.266129\n",
      " Loss: 0.093222\n",
      " Loss: 0.143453\n",
      "Epoch 336 Chain 0 loss std 3.73e+02 variance 6.97e+04 smooth variance 2.18e+05 adaptive c -1.00\n",
      "Epoch 336 Chain 1 loss std 6.73e+02 variance 2.26e+05 smooth variance 3.70e+05 adaptive c -1.00\n",
      " Loss: 0.141332\n",
      " Loss: 0.253714\n",
      " Loss: 0.159146\n",
      " Loss: 0.396438\n",
      " Loss: 0.060659\n",
      " Loss: 0.267630\n",
      " Loss: 0.147795\n",
      " Loss: 0.285633\n",
      " Loss: 0.041346\n",
      " Loss: 0.160391\n",
      " Loss: 0.192414\n",
      " Loss: 0.281757\n",
      " Loss: 0.040944\n",
      " Loss: 0.276590\n",
      " Loss: 0.090237\n",
      " Loss: 0.222932\n",
      " Loss: 0.137183\n",
      " Loss: 0.403903\n",
      " Loss: 0.076085\n",
      " Loss: 0.169006\n",
      "Epoch 338 Chain 0 loss std 5.49e+02 variance 1.50e+05 smooth variance 1.98e+05 adaptive c -1.00\n",
      "Epoch 338 Chain 1 loss std 1.10e+03 variance 6.06e+05 smooth variance 4.41e+05 adaptive c -1.00\n",
      " Loss: 0.162362\n",
      " Loss: 0.284536\n",
      " Loss: 0.047411\n",
      " Loss: 0.405409\n",
      " Loss: 0.089424\n",
      " Loss: 0.243067\n",
      " Loss: 0.180257\n",
      " Loss: 0.260900\n",
      " Loss: 0.044849\n",
      " Loss: 0.150680\n",
      " Loss: 0.133652\n",
      " Loss: 0.294773\n",
      " Loss: 0.100290\n",
      " Loss: 0.278458\n",
      " Loss: 0.084460\n",
      " Loss: 0.307879\n",
      " Loss: 0.113802\n",
      " Loss: 0.211014\n",
      " Loss: 0.080998\n",
      " Loss: 0.243167\n",
      "Epoch 340 Chain 0 loss std 5.59e+02 variance 1.56e+05 smooth variance 1.85e+05 adaptive c -1.00\n",
      "Epoch 340 Chain 1 loss std 8.99e+02 variance 4.04e+05 smooth variance 4.30e+05 adaptive c -1.00\n",
      " Loss: 0.068683\n",
      " Loss: 0.197375\n",
      " Loss: 0.147319\n",
      " Loss: 0.308250\n",
      " Loss: 0.076206\n",
      " Loss: 0.350207\n",
      " Loss: 0.081180\n",
      " Loss: 0.210232\n",
      " Loss: 0.129165\n",
      " Loss: 0.260230\n",
      " Loss: 0.067077\n",
      " Loss: 0.322895\n",
      " Loss: 0.099136\n",
      " Loss: 0.258863\n",
      " Loss: 0.074201\n",
      " Loss: 0.313124\n",
      " Loss: 0.131637\n",
      " Loss: 0.205814\n",
      " Loss: 0.127309\n",
      " Loss: 0.217044\n",
      "Epoch 342 Chain 0 loss std 5.79e+02 variance 1.67e+05 smooth variance 1.80e+05 adaptive c -1.00\n",
      "Epoch 342 Chain 1 loss std 8.31e+02 variance 3.45e+05 smooth variance 4.04e+05 adaptive c -1.00\n",
      " Loss: 0.050609\n",
      " Loss: 0.276618\n",
      " Loss: 0.084964\n",
      " Loss: 0.285312\n",
      " Loss: 0.245566\n",
      " Loss: 0.206528\n",
      " Loss: 0.064705\n",
      " Loss: 0.136090\n",
      " Loss: 0.048181\n",
      " Loss: 0.404501\n",
      " Loss: 0.212635\n",
      " Loss: 0.235959\n",
      " Loss: 0.041233\n",
      " Loss: 0.218466\n",
      " Loss: 0.131776\n",
      " Loss: 0.142903\n",
      " Loss: 0.068560\n",
      " Loss: 0.484061\n",
      " Loss: 0.036475\n",
      " Loss: 0.217773\n",
      "Epoch 344 Chain 0 loss std 7.31e+02 variance 2.67e+05 smooth variance 2.06e+05 adaptive c -1.00\n",
      "Epoch 344 Chain 1 loss std 7.17e+02 variance 2.57e+05 smooth variance 3.60e+05 adaptive c -1.00\n",
      " Loss: 0.098247\n",
      " Loss: 0.193062\n",
      " Loss: 0.067605\n",
      " Loss: 0.218460\n",
      " Loss: 0.077921\n",
      " Loss: 0.353784\n",
      " Loss: 0.185306\n",
      " Loss: 0.291430\n",
      " Loss: 0.062040\n",
      " Loss: 0.232535\n",
      " Loss: 0.087083\n",
      " Loss: 0.322574\n",
      " Loss: 0.096894\n",
      " Loss: 0.183905\n",
      " Loss: 0.138703\n",
      " Loss: 0.200456\n",
      " Loss: 0.109602\n",
      " Loss: 0.284913\n",
      " Loss: 0.051124\n",
      " Loss: 0.289197\n",
      "Epoch 346 Chain 0 loss std 5.41e+02 variance 1.46e+05 smooth variance 1.88e+05 adaptive c -1.00\n",
      "Epoch 346 Chain 1 loss std 7.38e+02 variance 2.73e+05 smooth variance 3.34e+05 adaptive c -1.00\n",
      " Loss: 0.088528\n",
      " Loss: 0.386122\n",
      " Loss: 0.144032\n",
      " Loss: 0.339857\n",
      " Loss: 0.044837\n",
      " Loss: 0.231274\n",
      " Loss: 0.132879\n",
      " Loss: 0.177563\n",
      " Loss: 0.062144\n",
      " Loss: 0.136196\n",
      " Loss: 0.178071\n",
      " Loss: 0.147863\n",
      " Loss: 0.112930\n",
      " Loss: 0.209687\n",
      " Loss: 0.034328\n",
      " Loss: 0.309636\n",
      " Loss: 0.065900\n",
      " Loss: 0.479549\n",
      " Loss: 0.073238\n",
      " Loss: 0.115132\n",
      "Epoch 348 Chain 0 loss std 3.12e+02 variance 4.88e+04 smooth variance 1.46e+05 adaptive c -1.00\n",
      "Epoch 348 Chain 1 loss std 8.70e+02 variance 3.78e+05 smooth variance 3.47e+05 adaptive c -1.00\n",
      " Loss: 0.093106\n",
      " Loss: 0.284453\n",
      " Loss: 0.029412\n",
      " Loss: 0.169152\n",
      " Loss: 0.100944\n",
      " Loss: 0.241788\n",
      " Loss: 0.161537\n",
      " Loss: 0.183124\n",
      " Loss: 0.063690\n",
      " Loss: 0.376109\n",
      " Loss: 0.053827\n",
      " Loss: 0.211102\n",
      " Loss: 0.045672\n",
      " Loss: 0.253274\n",
      " Loss: 0.186591\n",
      " Loss: 0.139296\n",
      " Loss: 0.064882\n",
      " Loss: 0.342476\n",
      " Loss: 0.089376\n",
      " Loss: 0.300299\n",
      "Epoch 350 Chain 0 loss std 5.21e+02 variance 1.36e+05 smooth variance 1.43e+05 adaptive c -1.00\n",
      "Epoch 350 Chain 1 loss std 4.10e+02 variance 8.42e+04 smooth variance 2.68e+05 adaptive c -1.00\n",
      " Loss: 0.115530\n",
      " Loss: 0.200688\n",
      " Loss: 0.054698\n",
      " Loss: 0.293524\n",
      " Loss: 0.040572\n",
      " Loss: 0.216831\n",
      " Loss: 0.062137\n",
      " Loss: 0.258531\n",
      " Loss: 0.159464\n",
      " Loss: 0.269426\n",
      " Loss: 0.087337\n",
      " Loss: 0.276006\n",
      " Loss: 0.070451\n",
      " Loss: 0.205383\n",
      " Loss: 0.054334\n",
      " Loss: 0.244527\n",
      " Loss: 0.155869\n",
      " Loss: 0.238330\n",
      " Loss: 0.051183\n",
      " Loss: 0.268515\n",
      "Epoch 352 Chain 0 loss std 3.80e+02 variance 7.22e+04 smooth variance 1.22e+05 adaptive c -1.00\n",
      "Epoch 352 Chain 1 loss std 9.32e+02 variance 4.34e+05 smooth variance 3.18e+05 adaptive c -1.00\n",
      " Loss: 0.063561\n",
      " Loss: 0.267325\n",
      " Loss: 0.104032\n",
      " Loss: 0.241573\n",
      " Loss: 0.120640\n",
      " Loss: 0.261716\n",
      " Loss: 0.048130\n",
      " Loss: 0.205449\n",
      " Loss: 0.075818\n",
      " Loss: 0.249244\n",
      " Loss: 0.052446\n",
      " Loss: 0.249336\n",
      " Loss: 0.125617\n",
      " Loss: 0.320738\n",
      " Loss: 0.070930\n",
      " Loss: 0.323033\n",
      " Loss: 0.091892\n",
      " Loss: 0.141731\n",
      " Loss: 0.064802\n",
      " Loss: 0.182019\n",
      "Epoch 354 Chain 0 loss std 4.68e+02 variance 1.10e+05 smooth variance 1.18e+05 adaptive c -1.00\n",
      "Epoch 354 Chain 1 loss std 9.70e+02 variance 4.71e+05 smooth variance 3.64e+05 adaptive c -1.00\n",
      " Loss: 0.119150\n",
      " Loss: 0.218179\n",
      " Loss: 0.085901\n",
      " Loss: 0.178068\n",
      " Loss: 0.067415\n",
      " Loss: 0.198756\n",
      " Loss: 0.070838\n",
      " Loss: 0.264607\n",
      " Loss: 0.054303\n",
      " Loss: 0.349478\n",
      " Loss: 0.070767\n",
      " Loss: 0.167660\n",
      " Loss: 0.083420\n",
      " Loss: 0.457762\n",
      " Loss: 0.039418\n",
      " Loss: 0.262989\n",
      " Loss: 0.136032\n",
      " Loss: 0.158525\n",
      " Loss: 0.060346\n",
      " Loss: 0.154430\n",
      "Epoch 356 Chain 0 loss std 3.27e+02 variance 5.33e+04 smooth variance 9.87e+04 adaptive c -1.00\n",
      "Epoch 356 Chain 1 loss std 7.60e+02 variance 2.89e+05 smooth variance 3.41e+05 adaptive c -1.00\n",
      " Loss: 0.048430\n",
      " Loss: 0.339092\n",
      " Loss: 0.032646\n",
      " Loss: 0.319866\n",
      " Loss: 0.174910\n",
      " Loss: 0.114383\n",
      " Loss: 0.044256\n",
      " Loss: 0.197260\n",
      " Loss: 0.081617\n",
      " Loss: 0.223216\n",
      " Loss: 0.092890\n",
      " Loss: 0.251295\n",
      " Loss: 0.044346\n",
      " Loss: 0.223031\n",
      " Loss: 0.049235\n",
      " Loss: 0.211759\n",
      " Loss: 0.059555\n",
      " Loss: 0.218779\n",
      " Loss: 0.128817\n",
      " Loss: 0.280432\n",
      "Epoch 358 Chain 0 loss std 2.77e+02 variance 3.84e+04 smooth variance 8.06e+04 adaptive c -1.00\n",
      "Epoch 358 Chain 1 loss std 6.35e+02 variance 2.02e+05 smooth variance 2.99e+05 adaptive c -1.00\n",
      " Loss: 0.157325\n",
      " Loss: 0.149856\n",
      " Loss: 0.029168\n",
      " Loss: 0.117404\n",
      " Loss: 0.021670\n",
      " Loss: 0.403703\n",
      " Loss: 0.075039\n",
      " Loss: 0.388085\n",
      " Loss: 0.083415\n",
      " Loss: 0.119440\n",
      " Loss: 0.092935\n",
      " Loss: 0.234937\n",
      " Loss: 0.027778\n",
      " Loss: 0.302482\n",
      " Loss: 0.020992\n",
      " Loss: 0.305954\n",
      " Loss: 0.140141\n",
      " Loss: 0.201417\n",
      " Loss: 0.072612\n",
      " Loss: 0.126855\n",
      "Epoch 360 Chain 0 loss std 3.83e+02 variance 7.33e+04 smooth variance 7.84e+04 adaptive c -1.00\n",
      "Epoch 360 Chain 1 loss std 9.37e+02 variance 4.39e+05 smooth variance 3.41e+05 adaptive c -1.00\n",
      " Loss: 0.059690\n",
      " Loss: 0.224896\n",
      " Loss: 0.050770\n",
      " Loss: 0.211227\n",
      " Loss: 0.075084\n",
      " Loss: 0.195512\n",
      " Loss: 0.032191\n",
      " Loss: 0.191061\n",
      " Loss: 0.130557\n",
      " Loss: 0.341436\n",
      " Loss: 0.023726\n",
      " Loss: 0.137099\n",
      " Loss: 0.083646\n",
      " Loss: 0.245133\n",
      " Loss: 0.141138\n",
      " Loss: 0.325950\n",
      " Loss: 0.031598\n",
      " Loss: 0.256344\n",
      " Loss: 0.059380\n",
      " Loss: 0.192481\n",
      "Epoch 362 Chain 0 loss std 3.32e+02 variance 5.52e+04 smooth variance 7.15e+04 adaptive c -1.00\n",
      "Epoch 362 Chain 1 loss std 5.46e+02 variance 1.49e+05 smooth variance 2.84e+05 adaptive c -1.00\n",
      " Loss: 0.049071\n",
      " Loss: 0.246924\n",
      " Loss: 0.081371\n",
      " Loss: 0.378179\n",
      " Loss: 0.116367\n",
      " Loss: 0.135932\n",
      " Loss: 0.071062\n",
      " Loss: 0.208187\n",
      " Loss: 0.010917\n",
      " Loss: 0.181328\n",
      " Loss: 0.053011\n",
      " Loss: 0.261204\n",
      " Loss: 0.103139\n",
      " Loss: 0.115486\n",
      " Loss: 0.084304\n",
      " Loss: 0.178324\n",
      " Loss: 0.046831\n",
      " Loss: 0.216796\n",
      " Loss: 0.036475\n",
      " Loss: 0.371372\n",
      "Epoch 364 Chain 0 loss std 4.33e+02 variance 9.36e+04 smooth variance 7.81e+04 adaptive c -1.00\n",
      "Epoch 364 Chain 1 loss std 6.90e+02 variance 2.38e+05 smooth variance 2.70e+05 adaptive c -1.00\n",
      " Loss: 0.021945\n",
      " Loss: 0.263116\n",
      " Loss: 0.031129\n",
      " Loss: 0.282602\n",
      " Loss: 0.095312\n",
      " Loss: 0.114530\n",
      " Loss: 0.105373\n",
      " Loss: 0.261520\n",
      " Loss: 0.062202\n",
      " Loss: 0.215445\n",
      " Loss: 0.025893\n",
      " Loss: 0.147520\n",
      " Loss: 0.054162\n",
      " Loss: 0.187898\n",
      " Loss: 0.057037\n",
      " Loss: 0.241685\n",
      " Loss: 0.113394\n",
      " Loss: 0.222676\n",
      " Loss: 0.058853\n",
      " Loss: 0.330469\n",
      "Epoch 366 Chain 0 loss std 3.76e+02 variance 7.07e+04 smooth variance 7.59e+04 adaptive c -1.00\n",
      "Epoch 366 Chain 1 loss std 9.09e+02 variance 4.13e+05 smooth variance 3.13e+05 adaptive c -1.00\n",
      " Loss: 0.142432\n",
      " Loss: 0.153415\n",
      " Loss: 0.055928\n",
      " Loss: 0.232106\n",
      " Loss: 0.040532\n",
      " Loss: 0.337853\n",
      " Loss: 0.031182\n",
      " Loss: 0.178784\n",
      " Loss: 0.035520\n",
      " Loss: 0.221828\n",
      " Loss: 0.047187\n",
      " Loss: 0.257693\n",
      " Loss: 0.017743\n",
      " Loss: 0.259246\n",
      " Loss: 0.129444\n",
      " Loss: 0.223940\n",
      " Loss: 0.039113\n",
      " Loss: 0.144773\n",
      " Loss: 0.063413\n",
      " Loss: 0.231623\n",
      "Epoch 368 Chain 0 loss std 3.09e+02 variance 4.78e+04 smooth variance 6.75e+04 adaptive c -1.00\n",
      "Epoch 368 Chain 1 loss std 1.24e+03 variance 7.70e+05 smooth variance 4.50e+05 adaptive c -1.00\n",
      " Loss: 0.077485\n",
      " Loss: 0.249021\n",
      " Loss: 0.110077\n",
      " Loss: 0.305289\n",
      " Loss: 0.028632\n",
      " Loss: 0.213907\n",
      " Loss: 0.056713\n",
      " Loss: 0.102949\n",
      " Loss: 0.016628\n",
      " Loss: 0.239004\n",
      " Loss: 0.043066\n",
      " Loss: 0.158884\n",
      " Loss: 0.012113\n",
      " Loss: 0.253782\n",
      " Loss: 0.025947\n",
      " Loss: 0.242295\n",
      " Loss: 0.150476\n",
      " Loss: 0.161277\n",
      " Loss: 0.051966\n",
      " Loss: 0.286894\n",
      "Epoch 370 Chain 0 loss std 3.36e+02 variance 5.65e+04 smooth variance 6.42e+04 adaptive c -1.00\n",
      "Epoch 370 Chain 1 loss std 5.94e+02 variance 1.77e+05 smooth variance 3.68e+05 adaptive c -1.00\n",
      " Loss: 0.033451\n",
      " Loss: 0.299756\n",
      " Loss: 0.080133\n",
      " Loss: 0.181219\n",
      " Loss: 0.038336\n",
      " Loss: 0.155416\n",
      " Loss: 0.103056\n",
      " Loss: 0.247974\n",
      " Loss: 0.025613\n",
      " Loss: 0.212032\n",
      " Loss: 0.021467\n",
      " Loss: 0.208787\n",
      " Loss: 0.036724\n",
      " Loss: 0.136508\n",
      " Loss: 0.042381\n",
      " Loss: 0.258491\n",
      " Loss: 0.064054\n",
      " Loss: 0.147634\n",
      " Loss: 0.110862\n",
      " Loss: 0.338077\n",
      "Epoch 372 Chain 0 loss std 3.94e+02 variance 7.77e+04 smooth variance 6.83e+04 adaptive c -1.00\n",
      "Epoch 372 Chain 1 loss std 9.11e+02 variance 4.15e+05 smooth variance 3.82e+05 adaptive c -1.00\n",
      " Loss: 0.026244\n",
      " Loss: 0.157003\n",
      " Loss: 0.029802\n",
      " Loss: 0.208916\n",
      " Loss: 0.063237\n",
      " Loss: 0.182038\n",
      " Loss: 0.115021\n",
      " Loss: 0.426781\n",
      " Loss: 0.036281\n",
      " Loss: 0.107564\n",
      " Loss: 0.020938\n",
      " Loss: 0.216586\n",
      " Loss: 0.034200\n",
      " Loss: 0.333351\n",
      " Loss: 0.055280\n",
      " Loss: 0.220520\n",
      " Loss: 0.017981\n",
      " Loss: 0.140104\n",
      " Loss: 0.134008\n",
      " Loss: 0.165597\n",
      "Epoch 374 Chain 0 loss std 3.78e+02 variance 7.15e+04 smooth variance 6.92e+04 adaptive c -1.00\n",
      "Epoch 374 Chain 1 loss std 8.46e+02 variance 3.58e+05 smooth variance 3.75e+05 adaptive c -1.00\n",
      " Loss: 0.037826\n",
      " Loss: 0.266628\n",
      " Loss: 0.039120\n",
      " Loss: 0.198715\n",
      " Loss: 0.054366\n",
      " Loss: 0.227111\n",
      " Loss: 0.020916\n",
      " Loss: 0.259707\n",
      " Loss: 0.101219\n",
      " Loss: 0.117848\n",
      " Loss: 0.039886\n",
      " Loss: 0.249707\n",
      " Loss: 0.014727\n",
      " Loss: 0.202920\n",
      " Loss: 0.070379\n",
      " Loss: 0.080412\n",
      " Loss: 0.085431\n",
      " Loss: 0.240445\n",
      " Loss: 0.032815\n",
      " Loss: 0.289718\n",
      "Epoch 376 Chain 0 loss std 1.82e+02 variance 1.66e+04 smooth variance 5.35e+04 adaptive c -1.00\n",
      "Epoch 376 Chain 1 loss std 6.47e+02 variance 2.09e+05 smooth variance 3.25e+05 adaptive c -1.00\n",
      " Loss: 0.052212\n",
      " Loss: 0.152320\n",
      " Loss: 0.026128\n",
      " Loss: 0.409902\n",
      " Loss: 0.034359\n",
      " Loss: 0.165927\n",
      " Loss: 0.073735\n",
      " Loss: 0.155398\n",
      " Loss: 0.053970\n",
      " Loss: 0.173282\n",
      " Loss: 0.055238\n",
      " Loss: 0.137876\n",
      " Loss: 0.099207\n",
      " Loss: 0.297768\n",
      " Loss: 0.026582\n",
      " Loss: 0.213480\n",
      " Loss: 0.029627\n",
      " Loss: 0.244627\n",
      " Loss: 0.019724\n",
      " Loss: 0.157018\n",
      "Epoch 378 Chain 0 loss std 2.52e+02 variance 3.16e+04 smooth variance 4.69e+04 adaptive c -1.00\n",
      "Epoch 378 Chain 1 loss std 1.19e+03 variance 7.04e+05 smooth variance 4.39e+05 adaptive c -1.00\n",
      " Loss: 0.032431\n",
      " Loss: 0.154704\n",
      " Loss: 0.027230\n",
      " Loss: 0.136845\n",
      " Loss: 0.076876\n",
      " Loss: 0.266421\n",
      " Loss: 0.015670\n",
      " Loss: 0.312517\n",
      " Loss: 0.073292\n",
      " Loss: 0.173962\n",
      " Loss: 0.088311\n",
      " Loss: 0.301560\n",
      " Loss: 0.020962\n",
      " Loss: 0.219856\n",
      " Loss: 0.031901\n",
      " Loss: 0.079561\n",
      " Loss: 0.031601\n",
      " Loss: 0.180047\n",
      " Loss: 0.047114\n",
      " Loss: 0.257410\n",
      "Epoch 380 Chain 0 loss std 3.40e+02 variance 5.78e+04 smooth variance 5.02e+04 adaptive c -1.00\n",
      "Epoch 380 Chain 1 loss std 9.03e+02 variance 4.08e+05 smooth variance 4.30e+05 adaptive c -1.00\n",
      " Loss: 0.037365\n",
      " Loss: 0.182094\n",
      " Loss: 0.022479\n",
      " Loss: 0.249483\n",
      " Loss: 0.038317\n",
      " Loss: 0.243865\n",
      " Loss: 0.076202\n",
      " Loss: 0.098481\n",
      " Loss: 0.038685\n",
      " Loss: 0.258894\n",
      " Loss: 0.026818\n",
      " Loss: 0.214598\n",
      " Loss: 0.093771\n",
      " Loss: 0.167673\n",
      " Loss: 0.016194\n",
      " Loss: 0.112379\n",
      " Loss: 0.037391\n",
      " Loss: 0.142725\n",
      " Loss: 0.033413\n",
      " Loss: 0.389063\n",
      "Epoch 382 Chain 0 loss std 2.92e+02 variance 4.26e+04 smooth variance 4.79e+04 adaptive c -1.00\n",
      "Epoch 382 Chain 1 loss std 9.66e+02 variance 4.66e+05 smooth variance 4.41e+05 adaptive c -1.00\n",
      " Loss: 0.024852\n",
      " Loss: 0.195385\n",
      " Loss: 0.027956\n",
      " Loss: 0.297950\n",
      " Loss: 0.065812\n",
      " Loss: 0.178077\n",
      " Loss: 0.039871\n",
      " Loss: 0.211956\n",
      " Loss: 0.041399\n",
      " Loss: 0.136023\n",
      " Loss: 0.040531\n",
      " Loss: 0.240753\n",
      " Loss: 0.014562\n",
      " Loss: 0.204628\n",
      " Loss: 0.014845\n",
      " Loss: 0.140707\n",
      " Loss: 0.065011\n",
      " Loss: 0.124608\n",
      " Loss: 0.058724\n",
      " Loss: 0.303394\n",
      "Epoch 384 Chain 0 loss std 1.63e+02 variance 1.32e+04 smooth variance 3.75e+04 adaptive c -1.00\n",
      "Epoch 384 Chain 1 loss std 1.01e+03 variance 5.12e+05 smooth variance 4.62e+05 adaptive c -1.00\n",
      " Loss: 0.057784\n",
      " Loss: 0.215857\n",
      " Loss: 0.042721\n",
      " Loss: 0.141779\n",
      " Loss: 0.034066\n",
      " Loss: 0.190157\n",
      " Loss: 0.016218\n",
      " Loss: 0.220686\n",
      " Loss: 0.039504\n",
      " Loss: 0.238333\n",
      " Loss: 0.024388\n",
      " Loss: 0.192273\n",
      " Loss: 0.073189\n",
      " Loss: 0.117246\n",
      " Loss: 0.033771\n",
      " Loss: 0.204581\n",
      " Loss: 0.018957\n",
      " Loss: 0.134748\n",
      " Loss: 0.036304\n",
      " Loss: 0.351662\n",
      "Epoch 386 Chain 0 loss std 2.60e+02 variance 3.37e+04 smooth variance 3.64e+04 adaptive c -1.00\n",
      "Epoch 386 Chain 1 loss std 5.78e+02 variance 1.67e+05 smooth variance 3.73e+05 adaptive c -1.00\n",
      " Loss: 0.022914\n",
      " Loss: 0.119452\n",
      " Loss: 0.027083\n",
      " Loss: 0.116462\n",
      " Loss: 0.014906\n",
      " Loss: 0.138948\n",
      " Loss: 0.098753\n",
      " Loss: 0.193955\n",
      " Loss: 0.019608\n",
      " Loss: 0.424867\n",
      " Loss: 0.012661\n",
      " Loss: 0.120990\n",
      " Loss: 0.067725\n",
      " Loss: 0.241284\n",
      " Loss: 0.013375\n",
      " Loss: 0.303947\n",
      " Loss: 0.025233\n",
      " Loss: 0.196032\n",
      " Loss: 0.060759\n",
      " Loss: 0.126514\n",
      "Epoch 388 Chain 0 loss std 2.30e+02 variance 2.65e+04 smooth variance 3.34e+04 adaptive c -1.00\n",
      "Epoch 388 Chain 1 loss std 7.18e+02 variance 2.58e+05 smooth variance 3.39e+05 adaptive c -1.00\n",
      " Loss: 0.057735\n",
      " Loss: 0.211037\n",
      " Loss: 0.021203\n",
      " Loss: 0.229620\n",
      " Loss: 0.021753\n",
      " Loss: 0.112293\n",
      " Loss: 0.022777\n",
      " Loss: 0.205207\n",
      " Loss: 0.051347\n",
      " Loss: 0.224872\n",
      " Loss: 0.025481\n",
      " Loss: 0.342924\n",
      " Loss: 0.056535\n",
      " Loss: 0.220104\n",
      " Loss: 0.029180\n",
      " Loss: 0.097715\n",
      " Loss: 0.033524\n",
      " Loss: 0.203529\n",
      " Loss: 0.024059\n",
      " Loss: 0.113101\n",
      "Epoch 390 Chain 0 loss std 1.45e+02 variance 1.05e+04 smooth variance 2.65e+04 adaptive c -1.00\n",
      "Epoch 390 Chain 1 loss std 8.33e+02 variance 3.47e+05 smooth variance 3.41e+05 adaptive c -1.00\n",
      " Loss: 0.008981\n",
      " Loss: 0.149211\n",
      " Loss: 0.018894\n",
      " Loss: 0.126719\n",
      " Loss: 0.032519\n",
      " Loss: 0.126538\n",
      " Loss: 0.059672\n",
      " Loss: 0.377980\n",
      " Loss: 0.043715\n",
      " Loss: 0.191449\n",
      " Loss: 0.031550\n",
      " Loss: 0.192357\n",
      " Loss: 0.059577\n",
      " Loss: 0.174420\n",
      " Loss: 0.033414\n",
      " Loss: 0.161147\n",
      " Loss: 0.016367\n",
      " Loss: 0.267904\n",
      " Loss: 0.019049\n",
      " Loss: 0.170986\n",
      "Epoch 392 Chain 0 loss std 2.07e+02 variance 2.14e+04 smooth variance 2.50e+04 adaptive c -1.00\n",
      "Epoch 392 Chain 1 loss std 8.44e+02 variance 3.56e+05 smooth variance 3.46e+05 adaptive c -1.00\n",
      " Loss: 0.020112\n",
      " Loss: 0.213093\n",
      " Loss: 0.013909\n",
      " Loss: 0.113660\n",
      " Loss: 0.083120\n",
      " Loss: 0.254862\n",
      " Loss: 0.005932\n",
      " Loss: 0.263252\n",
      " Loss: 0.030972\n",
      " Loss: 0.116720\n",
      " Loss: 0.010973\n",
      " Loss: 0.279898\n",
      " Loss: 0.009464\n",
      " Loss: 0.185234\n",
      " Loss: 0.040981\n",
      " Loss: 0.090640\n",
      " Loss: 0.009506\n",
      " Loss: 0.261781\n",
      " Loss: 0.079450\n",
      " Loss: 0.138418\n",
      "Epoch 394 Chain 0 loss std 1.89e+02 variance 1.78e+04 smooth variance 2.28e+04 adaptive c -1.00\n",
      "Epoch 394 Chain 1 loss std 5.74e+02 variance 1.65e+05 smooth variance 2.92e+05 adaptive c -1.00\n",
      " Loss: 0.036911\n",
      " Loss: 0.074326\n",
      " Loss: 0.009600\n",
      " Loss: 0.133816\n",
      " Loss: 0.027938\n",
      " Loss: 0.152353\n",
      " Loss: 0.015173\n",
      " Loss: 0.344154\n",
      " Loss: 0.056617\n",
      " Loss: 0.245654\n",
      " Loss: 0.016449\n",
      " Loss: 0.187540\n",
      " Loss: 0.015765\n",
      " Loss: 0.181848\n",
      " Loss: 0.017607\n",
      " Loss: 0.141599\n",
      " Loss: 0.031049\n",
      " Loss: 0.342928\n",
      " Loss: 0.062424\n",
      " Loss: 0.092540\n",
      "Epoch 396 Chain 0 loss std 1.37e+02 variance 9.34e+03 smooth variance 1.88e+04 adaptive c -1.00\n",
      "Epoch 396 Chain 1 loss std 6.96e+02 variance 2.42e+05 smooth variance 2.77e+05 adaptive c -1.00\n",
      " Loss: 0.011115\n",
      " Loss: 0.242375\n",
      " Loss: 0.031973\n",
      " Loss: 0.219968\n",
      " Loss: 0.055459\n",
      " Loss: 0.118511\n",
      " Loss: 0.019152\n",
      " Loss: 0.126172\n",
      " Loss: 0.021882\n",
      " Loss: 0.234012\n",
      " Loss: 0.007252\n",
      " Loss: 0.115068\n",
      " Loss: 0.017429\n",
      " Loss: 0.249999\n",
      " Loss: 0.034361\n",
      " Loss: 0.164838\n",
      " Loss: 0.060352\n",
      " Loss: 0.250883\n",
      " Loss: 0.015549\n",
      " Loss: 0.155325\n",
      "Epoch 398 Chain 0 loss std 1.19e+02 variance 7.04e+03 smooth variance 1.53e+04 adaptive c -1.00\n",
      "Epoch 398 Chain 1 loss std 5.66e+02 variance 1.60e+05 smooth variance 2.42e+05 adaptive c -1.00\n",
      " Loss: 0.026838\n",
      " Loss: 0.278488\n",
      " Loss: 0.018324\n",
      " Loss: 0.214220\n",
      " Loss: 0.024675\n",
      " Loss: 0.171686\n",
      " Loss: 0.043944\n",
      " Loss: 0.128267\n",
      " Loss: 0.017583\n",
      " Loss: 0.138384\n",
      " Loss: 0.013975\n",
      " Loss: 0.286961\n",
      " Loss: 0.012595\n",
      " Loss: 0.229109\n",
      " Loss: 0.029453\n",
      " Loss: 0.221770\n",
      " Loss: 0.065294\n",
      " Loss: 0.088564\n",
      " Loss: 0.005053\n",
      " Loss: 0.100173\n",
      "Epoch 400 Chain 0 loss std 1.61e+02 variance 1.30e+04 smooth variance 1.46e+04 adaptive c -1.00\n",
      "Epoch 400 Chain 1 loss std 7.06e+02 variance 2.50e+05 smooth variance 2.44e+05 adaptive c -1.00\n",
      " Loss: 0.050276\n",
      " Loss: 0.131226\n",
      " Loss: 0.024036\n",
      " Loss: 0.102625\n",
      " Loss: 0.016902\n",
      " Loss: 0.232488\n",
      " Loss: 0.010397\n",
      " Loss: 0.264530\n",
      " Loss: 0.021690\n",
      " Loss: 0.190210\n",
      " Loss: 0.015471\n",
      " Loss: 0.105853\n",
      " Loss: 0.052360\n",
      " Loss: 0.164718\n",
      " Loss: 0.025835\n",
      " Loss: 0.259974\n",
      " Loss: 0.010271\n",
      " Loss: 0.215047\n",
      " Loss: 0.017418\n",
      " Loss: 0.170851\n",
      "Epoch 402 Chain 0 loss std 2.13e+02 variance 2.26e+04 smooth variance 1.70e+04 adaptive c -1.00\n",
      "Epoch 402 Chain 1 loss std 7.27e+02 variance 2.64e+05 smooth variance 2.50e+05 adaptive c -1.00\n",
      " Loss: 0.009953\n",
      " Loss: 0.207960\n",
      " Loss: 0.060547\n",
      " Loss: 0.103789\n",
      " Loss: 0.022529\n",
      " Loss: 0.276108\n",
      " Loss: 0.012736\n",
      " Loss: 0.160154\n",
      " Loss: 0.012677\n",
      " Loss: 0.163652\n",
      " Loss: 0.024026\n",
      " Loss: 0.287327\n",
      " Loss: 0.007473\n",
      " Loss: 0.192482\n",
      " Loss: 0.045898\n",
      " Loss: 0.117813\n",
      " Loss: 0.018392\n",
      " Loss: 0.196255\n",
      " Loss: 0.020224\n",
      " Loss: 0.113014\n",
      "Epoch 404 Chain 0 loss std 1.17e+02 variance 6.89e+03 smooth variance 1.40e+04 adaptive c -1.00\n",
      "Epoch 404 Chain 1 loss std 8.59e+02 variance 3.69e+05 smooth variance 2.86e+05 adaptive c -1.00\n",
      " Loss: 0.023168\n",
      " Loss: 0.184238\n",
      " Loss: 0.008949\n",
      " Loss: 0.210628\n",
      " Loss: 0.039751\n",
      " Loss: 0.129616\n",
      " Loss: 0.021910\n",
      " Loss: 0.152560\n",
      " Loss: 0.020484\n",
      " Loss: 0.225152\n",
      " Loss: 0.022959\n",
      " Loss: 0.233337\n",
      " Loss: 0.014152\n",
      " Loss: 0.219552\n",
      " Loss: 0.014723\n",
      " Loss: 0.152350\n",
      " Loss: 0.045829\n",
      " Loss: 0.141758\n",
      " Loss: 0.013826\n",
      " Loss: 0.150146\n",
      "Epoch 406 Chain 0 loss std 1.45e+02 variance 1.05e+04 smooth variance 1.29e+04 adaptive c -1.00\n",
      "Epoch 406 Chain 1 loss std 6.60e+02 variance 2.18e+05 smooth variance 2.65e+05 adaptive c -1.00\n",
      " Loss: 0.018111\n",
      " Loss: 0.166310\n",
      " Loss: 0.012515\n",
      " Loss: 0.171073\n",
      " Loss: 0.019871\n",
      " Loss: 0.219721\n",
      " Loss: 0.049386\n",
      " Loss: 0.171646\n",
      " Loss: 0.007680\n",
      " Loss: 0.163720\n",
      " Loss: 0.021151\n",
      " Loss: 0.196987\n",
      " Loss: 0.043981\n",
      " Loss: 0.135850\n",
      " Loss: 0.016495\n",
      " Loss: 0.205552\n",
      " Loss: 0.004438\n",
      " Loss: 0.106355\n",
      " Loss: 0.018620\n",
      " Loss: 0.242931\n",
      "Epoch 408 Chain 0 loss std 1.36e+02 variance 9.25e+03 smooth variance 1.18e+04 adaptive c -1.00\n",
      "Epoch 408 Chain 1 loss std 2.85e+02 variance 4.05e+04 smooth variance 1.98e+05 adaptive c -1.00\n",
      " Loss: 0.057106\n",
      " Loss: 0.167073\n",
      " Loss: 0.005612\n",
      " Loss: 0.105677\n",
      " Loss: 0.016979\n",
      " Loss: 0.076044\n",
      " Loss: 0.015974\n",
      " Loss: 0.257884\n",
      " Loss: 0.008365\n",
      " Loss: 0.276349\n",
      " Loss: 0.014999\n",
      " Loss: 0.165768\n",
      " Loss: 0.031487\n",
      " Loss: 0.180233\n",
      " Loss: 0.006942\n",
      " Loss: 0.173130\n",
      " Loss: 0.032061\n",
      " Loss: 0.135677\n",
      " Loss: 0.014453\n",
      " Loss: 0.223978\n",
      "Epoch 410 Chain 0 loss std 1.74e+02 variance 1.51e+04 smooth variance 1.28e+04 adaptive c -1.00\n",
      "Epoch 410 Chain 1 loss std 5.38e+02 variance 1.45e+05 smooth variance 1.82e+05 adaptive c -1.00\n",
      " Loss: 0.007000\n",
      " Loss: 0.309661\n",
      " Loss: 0.056082\n",
      " Loss: 0.079666\n",
      " Loss: 0.007270\n",
      " Loss: 0.151585\n",
      " Loss: 0.012754\n",
      " Loss: 0.196582\n",
      " Loss: 0.013805\n",
      " Loss: 0.137254\n",
      " Loss: 0.043449\n",
      " Loss: 0.126353\n",
      " Loss: 0.017613\n",
      " Loss: 0.163552\n",
      " Loss: 0.005136\n",
      " Loss: 0.173241\n",
      " Loss: 0.018419\n",
      " Loss: 0.128491\n",
      " Loss: 0.010474\n",
      " Loss: 0.278723\n",
      "Epoch 412 Chain 0 loss std 1.12e+02 variance 6.26e+03 smooth variance 1.08e+04 adaptive c -1.00\n",
      "Epoch 412 Chain 1 loss std 5.41e+02 variance 1.46e+05 smooth variance 1.71e+05 adaptive c -1.00\n",
      " Loss: 0.014604\n",
      " Loss: 0.244546\n",
      " Loss: 0.006970\n",
      " Loss: 0.223281\n",
      " Loss: 0.031757\n",
      " Loss: 0.095510\n",
      " Loss: 0.028924\n",
      " Loss: 0.117004\n",
      " Loss: 0.010092\n",
      " Loss: 0.185638\n",
      " Loss: 0.020347\n",
      " Loss: 0.266022\n",
      " Loss: 0.020417\n",
      " Loss: 0.259896\n",
      " Loss: 0.011162\n",
      " Loss: 0.111285\n",
      " Loss: 0.004720\n",
      " Loss: 0.093290\n",
      " Loss: 0.033583\n",
      " Loss: 0.131344\n",
      "Epoch 414 Chain 0 loss std 1.13e+02 variance 6.39e+03 smooth variance 9.51e+03 adaptive c -1.00\n",
      "Epoch 414 Chain 1 loss std 5.12e+02 variance 1.31e+05 smooth variance 1.59e+05 adaptive c -1.00\n",
      " Loss: 0.011706\n",
      " Loss: 0.120551\n",
      " Loss: 0.035591\n",
      " Loss: 0.133222\n",
      " Loss: 0.008253\n",
      " Loss: 0.319988\n",
      " Loss: 0.013132\n",
      " Loss: 0.100124\n",
      " Loss: 0.018497\n",
      " Loss: 0.183192\n",
      " Loss: 0.019492\n",
      " Loss: 0.107711\n",
      " Loss: 0.008273\n",
      " Loss: 0.205148\n",
      " Loss: 0.005343\n",
      " Loss: 0.129525\n",
      " Loss: 0.019459\n",
      " Loss: 0.302570\n",
      " Loss: 0.032603\n",
      " Loss: 0.108147\n",
      "Epoch 416 Chain 0 loss std 1.29e+02 variance 8.36e+03 smooth variance 9.16e+03 adaptive c -1.00\n",
      "Epoch 416 Chain 1 loss std 7.87e+02 variance 3.10e+05 smooth variance 2.04e+05 adaptive c -1.00\n",
      " Loss: 0.014586\n",
      " Loss: 0.140696\n",
      " Loss: 0.010594\n",
      " Loss: 0.310464\n",
      " Loss: 0.004955\n",
      " Loss: 0.119980\n",
      " Loss: 0.011190\n",
      " Loss: 0.179670\n",
      " Loss: 0.040916\n",
      " Loss: 0.099017\n",
      " Loss: 0.018169\n",
      " Loss: 0.148280\n",
      " Loss: 0.005313\n",
      " Loss: 0.113453\n",
      " Loss: 0.038708\n",
      " Loss: 0.306871\n",
      " Loss: 0.004135\n",
      " Loss: 0.176218\n",
      " Loss: 0.013941\n",
      " Loss: 0.100047\n",
      "Epoch 418 Chain 0 loss std 6.66e+01 variance 2.22e+03 smooth variance 7.08e+03 adaptive c -1.00\n",
      "Epoch 418 Chain 1 loss std 5.50e+02 variance 1.51e+05 smooth variance 1.88e+05 adaptive c -1.00\n",
      " Loss: 0.019389\n",
      " Loss: 0.251170\n",
      " Loss: 0.009162\n",
      " Loss: 0.077528\n",
      " Loss: 0.010765\n",
      " Loss: 0.255427\n",
      " Loss: 0.030291\n",
      " Loss: 0.109069\n",
      " Loss: 0.007645\n",
      " Loss: 0.148240\n",
      " Loss: 0.008802\n",
      " Loss: 0.098290\n",
      " Loss: 0.010431\n",
      " Loss: 0.149297\n",
      " Loss: 0.037548\n",
      " Loss: 0.232611\n",
      " Loss: 0.003711\n",
      " Loss: 0.156985\n",
      " Loss: 0.015693\n",
      " Loss: 0.200881\n",
      "Epoch 420 Chain 0 loss std 1.25e+02 variance 7.85e+03 smooth variance 7.31e+03 adaptive c -1.00\n",
      "Epoch 420 Chain 1 loss std 6.39e+02 variance 2.04e+05 smooth variance 1.93e+05 adaptive c -1.00\n",
      " Loss: 0.011640\n",
      " Loss: 0.269487\n",
      " Loss: 0.010625\n",
      " Loss: 0.145359\n",
      " Loss: 0.004430\n",
      " Loss: 0.169538\n",
      " Loss: 0.037521\n",
      " Loss: 0.121553\n",
      " Loss: 0.008216\n",
      " Loss: 0.128275\n",
      " Loss: 0.009260\n",
      " Loss: 0.078345\n",
      " Loss: 0.004119\n",
      " Loss: 0.087926\n",
      " Loss: 0.035887\n",
      " Loss: 0.188870\n",
      " Loss: 0.013637\n",
      " Loss: 0.317149\n",
      " Loss: 0.007212\n",
      " Loss: 0.157928\n",
      "Epoch 422 Chain 0 loss std 8.88e+01 variance 3.95e+03 smooth variance 6.30e+03 adaptive c -1.00\n",
      "Epoch 422 Chain 1 loss std 9.83e+02 variance 4.83e+05 smooth variance 2.80e+05 adaptive c -1.00\n",
      " Loss: 0.015904\n",
      " Loss: 0.136652\n",
      " Loss: 0.009232\n",
      " Loss: 0.134181\n",
      " Loss: 0.007825\n",
      " Loss: 0.230083\n",
      " Loss: 0.008265\n",
      " Loss: 0.092060\n",
      " Loss: 0.026706\n",
      " Loss: 0.233978\n",
      " Loss: 0.011882\n",
      " Loss: 0.114577\n",
      " Loss: 0.022789\n",
      " Loss: 0.107268\n",
      " Loss: 0.008693\n",
      " Loss: 0.223242\n",
      " Loss: 0.008641\n",
      " Loss: 0.125338\n",
      " Loss: 0.015042\n",
      " Loss: 0.252735\n",
      "Epoch 424 Chain 0 loss std 9.05e+01 variance 4.10e+03 smooth variance 5.64e+03 adaptive c -1.00\n",
      "Epoch 424 Chain 1 loss std 7.23e+02 variance 2.62e+05 smooth variance 2.74e+05 adaptive c -1.00\n",
      " Loss: 0.026995\n",
      " Loss: 0.145755\n",
      " Loss: 0.006355\n",
      " Loss: 0.270151\n",
      " Loss: 0.011915\n",
      " Loss: 0.157906\n",
      " Loss: 0.010071\n",
      " Loss: 0.095442\n",
      " Loss: 0.008714\n",
      " Loss: 0.149780\n",
      " Loss: 0.021841\n",
      " Loss: 0.196546\n",
      " Loss: 0.015975\n",
      " Loss: 0.105032\n",
      " Loss: 0.005389\n",
      " Loss: 0.102025\n",
      " Loss: 0.011148\n",
      " Loss: 0.225243\n",
      " Loss: 0.006780\n",
      " Loss: 0.186766\n",
      "Epoch 426 Chain 0 loss std 6.87e+01 variance 2.36e+03 smooth variance 4.65e+03 adaptive c -1.00\n",
      "Epoch 426 Chain 1 loss std 6.71e+02 variance 2.25e+05 smooth variance 2.60e+05 adaptive c -1.00\n",
      " Loss: 0.009922\n",
      " Loss: 0.106311\n",
      " Loss: 0.010315\n",
      " Loss: 0.107454\n",
      " Loss: 0.023661\n",
      " Loss: 0.133802\n",
      " Loss: 0.005507\n",
      " Loss: 0.330527\n",
      " Loss: 0.010812\n",
      " Loss: 0.133386\n",
      " Loss: 0.002961\n",
      " Loss: 0.101882\n",
      " Loss: 0.002717\n",
      " Loss: 0.108334\n",
      " Loss: 0.014229\n",
      " Loss: 0.221561\n",
      " Loss: 0.013176\n",
      " Loss: 0.149662\n",
      " Loss: 0.024081\n",
      " Loss: 0.226827\n",
      "Epoch 428 Chain 0 loss std 8.70e+01 variance 3.78e+03 smooth variance 4.39e+03 adaptive c -1.00\n",
      "Epoch 428 Chain 1 loss std 6.11e+02 variance 1.86e+05 smooth variance 2.38e+05 adaptive c -1.00\n",
      " Loss: 0.011227\n",
      " Loss: 0.099115\n",
      " Loss: 0.005731\n",
      " Loss: 0.112814\n",
      " Loss: 0.010214\n",
      " Loss: 0.301209\n",
      " Loss: 0.018901\n",
      " Loss: 0.144324\n",
      " Loss: 0.010720\n",
      " Loss: 0.147092\n",
      " Loss: 0.010618\n",
      " Loss: 0.163837\n",
      " Loss: 0.017775\n",
      " Loss: 0.235168\n",
      " Loss: 0.008702\n",
      " Loss: 0.092162\n",
      " Loss: 0.004760\n",
      " Loss: 0.188565\n",
      " Loss: 0.013403\n",
      " Loss: 0.120720\n",
      "Epoch 430 Chain 0 loss std 5.01e+01 variance 1.26e+03 smooth variance 3.45e+03 adaptive c -1.00\n",
      "Epoch 430 Chain 1 loss std 6.37e+02 variance 2.03e+05 smooth variance 2.27e+05 adaptive c -1.00\n",
      " Loss: 0.011996\n",
      " Loss: 0.245698\n",
      " Loss: 0.023961\n",
      " Loss: 0.129042\n",
      " Loss: 0.006299\n",
      " Loss: 0.134268\n",
      " Loss: 0.007726\n",
      " Loss: 0.184419\n",
      " Loss: 0.002980\n",
      " Loss: 0.103823\n",
      " Loss: 0.009464\n",
      " Loss: 0.105947\n",
      " Loss: 0.019299\n",
      " Loss: 0.213616\n",
      " Loss: 0.009393\n",
      " Loss: 0.188902\n",
      " Loss: 0.005515\n",
      " Loss: 0.180684\n",
      " Loss: 0.007254\n",
      " Loss: 0.103979\n",
      "Epoch 432 Chain 0 loss std 8.64e+01 variance 3.73e+03 smooth variance 3.54e+03 adaptive c -1.00\n",
      "Epoch 432 Chain 1 loss std 1.00e+03 variance 5.04e+05 smooth variance 3.11e+05 adaptive c -1.00\n",
      " Loss: 0.009503\n",
      " Loss: 0.106481\n",
      " Loss: 0.009436\n",
      " Loss: 0.241370\n",
      " Loss: 0.006261\n",
      " Loss: 0.127123\n",
      " Loss: 0.004629\n",
      " Loss: 0.099246\n",
      " Loss: 0.018646\n",
      " Loss: 0.215069\n",
      " Loss: 0.003796\n",
      " Loss: 0.282535\n",
      " Loss: 0.017943\n",
      " Loss: 0.124904\n",
      " Loss: 0.007590\n",
      " Loss: 0.124954\n",
      " Loss: 0.006681\n",
      " Loss: 0.143582\n",
      " Loss: 0.012198\n",
      " Loss: 0.110328\n",
      "Epoch 434 Chain 0 loss std 4.32e+01 variance 9.32e+02 smooth variance 2.75e+03 adaptive c -1.00\n",
      "Epoch 434 Chain 1 loss std 6.94e+02 variance 2.41e+05 smooth variance 2.90e+05 adaptive c -1.00\n",
      " Loss: 0.007511\n",
      " Loss: 0.222867\n",
      " Loss: 0.017002\n",
      " Loss: 0.125176\n",
      " Loss: 0.011389\n",
      " Loss: 0.076433\n",
      " Loss: 0.004555\n",
      " Loss: 0.237789\n",
      " Loss: 0.005381\n",
      " Loss: 0.120422\n",
      " Loss: 0.007047\n",
      " Loss: 0.134552\n",
      " Loss: 0.012033\n",
      " Loss: 0.108868\n",
      " Loss: 0.011685\n",
      " Loss: 0.149004\n",
      " Loss: 0.005266\n",
      " Loss: 0.283874\n",
      " Loss: 0.008695\n",
      " Loss: 0.103043\n",
      "Epoch 436 Chain 0 loss std 5.47e+01 variance 1.49e+03 smooth variance 2.38e+03 adaptive c -1.00\n",
      "Epoch 436 Chain 1 loss std 6.00e+02 variance 1.80e+05 smooth variance 2.57e+05 adaptive c -1.00\n",
      " Loss: 0.002909\n",
      " Loss: 0.142532\n",
      " Loss: 0.010973\n",
      " Loss: 0.115230\n",
      " Loss: 0.010000\n",
      " Loss: 0.281449\n",
      " Loss: 0.002476\n",
      " Loss: 0.155098\n",
      " Loss: 0.016708\n",
      " Loss: 0.081518\n",
      " Loss: 0.002907\n",
      " Loss: 0.199781\n",
      " Loss: 0.015348\n",
      " Loss: 0.117192\n",
      " Loss: 0.007146\n",
      " Loss: 0.214055\n",
      " Loss: 0.008531\n",
      " Loss: 0.084842\n",
      " Loss: 0.006955\n",
      " Loss: 0.156438\n",
      "Epoch 438 Chain 0 loss std 4.36e+01 variance 9.51e+02 smooth variance 1.95e+03 adaptive c -1.00\n",
      "Epoch 438 Chain 1 loss std 5.86e+02 variance 1.72e+05 smooth variance 2.31e+05 adaptive c -1.00\n",
      " Loss: 0.005900\n",
      " Loss: 0.094206\n",
      " Loss: 0.009220\n",
      " Loss: 0.130306\n",
      " Loss: 0.004486\n",
      " Loss: 0.099472\n",
      " Loss: 0.005954\n",
      " Loss: 0.275308\n",
      " Loss: 0.013669\n",
      " Loss: 0.169247\n",
      " Loss: 0.011594\n",
      " Loss: 0.130103\n",
      " Loss: 0.004965\n",
      " Loss: 0.198771\n",
      " Loss: 0.012494\n",
      " Loss: 0.101066\n",
      " Loss: 0.002853\n",
      " Loss: 0.083788\n",
      " Loss: 0.006363\n",
      " Loss: 0.251765\n",
      "Epoch 440 Chain 0 loss std 4.45e+01 variance 9.90e+02 smooth variance 1.66e+03 adaptive c -1.00\n",
      "Epoch 440 Chain 1 loss std 5.41e+02 variance 1.46e+05 smooth variance 2.06e+05 adaptive c -1.00\n",
      " Loss: 0.010395\n",
      " Loss: 0.095614\n",
      " Loss: 0.003286\n",
      " Loss: 0.160200\n",
      " Loss: 0.015011\n",
      " Loss: 0.162711\n",
      " Loss: 0.004060\n",
      " Loss: 0.105178\n",
      " Loss: 0.003996\n",
      " Loss: 0.238455\n",
      " Loss: 0.010333\n",
      " Loss: 0.119354\n",
      " Loss: 0.003423\n",
      " Loss: 0.262486\n",
      " Loss: 0.003644\n",
      " Loss: 0.217202\n",
      " Loss: 0.015464\n",
      " Loss: 0.067857\n",
      " Loss: 0.002466\n",
      " Loss: 0.092406\n",
      "Epoch 442 Chain 0 loss std 2.69e+01 variance 3.63e+02 smooth variance 1.27e+03 adaptive c -1.00\n",
      "Epoch 442 Chain 1 loss std 6.12e+02 variance 1.87e+05 smooth variance 2.00e+05 adaptive c -1.00\n",
      " Loss: 0.008952\n",
      " Loss: 0.131584\n",
      " Loss: 0.007317\n",
      " Loss: 0.095775\n",
      " Loss: 0.010417\n",
      " Loss: 0.084404\n",
      " Loss: 0.003465\n",
      " Loss: 0.212663\n",
      " Loss: 0.004197\n",
      " Loss: 0.231287\n",
      " Loss: 0.008576\n",
      " Loss: 0.102339\n",
      " Loss: 0.006860\n",
      " Loss: 0.316479\n",
      " Loss: 0.005745\n",
      " Loss: 0.127791\n",
      " Loss: 0.009857\n",
      " Loss: 0.092654\n",
      " Loss: 0.002115\n",
      " Loss: 0.113774\n",
      "Epoch 444 Chain 0 loss std 3.87e+01 variance 7.50e+02 smooth variance 1.12e+03 adaptive c -1.00\n",
      "Epoch 444 Chain 1 loss std 8.12e+02 variance 3.30e+05 smooth variance 2.39e+05 adaptive c -1.00\n",
      " Loss: 0.009080\n",
      " Loss: 0.172859\n",
      " Loss: 0.004358\n",
      " Loss: 0.216584\n",
      " Loss: 0.009145\n",
      " Loss: 0.149738\n",
      " Loss: 0.004986\n",
      " Loss: 0.122721\n",
      " Loss: 0.005363\n",
      " Loss: 0.087963\n",
      " Loss: 0.002722\n",
      " Loss: 0.106419\n",
      " Loss: 0.009651\n",
      " Loss: 0.253580\n",
      " Loss: 0.007947\n",
      " Loss: 0.098152\n",
      " Loss: 0.002337\n",
      " Loss: 0.142962\n",
      " Loss: 0.008696\n",
      " Loss: 0.145429\n",
      "Epoch 446 Chain 0 loss std 2.79e+01 variance 3.89e+02 smooth variance 8.97e+02 adaptive c -1.00\n",
      "Epoch 446 Chain 1 loss std 8.33e+02 variance 3.47e+05 smooth variance 2.72e+05 adaptive c -1.00\n",
      " Loss: 0.010328\n",
      " Loss: 0.103449\n",
      " Loss: 0.004631\n",
      " Loss: 0.300168\n",
      " Loss: 0.002148\n",
      " Loss: 0.134764\n",
      " Loss: 0.004701\n",
      " Loss: 0.119001\n",
      " Loss: 0.008167\n",
      " Loss: 0.086288\n",
      " Loss: 0.011217\n",
      " Loss: 0.185449\n",
      " Loss: 0.009138\n",
      " Loss: 0.111455\n",
      " Loss: 0.001543\n",
      " Loss: 0.202631\n",
      " Loss: 0.003085\n",
      " Loss: 0.160686\n",
      " Loss: 0.004105\n",
      " Loss: 0.080384\n",
      "Epoch 448 Chain 0 loss std 2.33e+01 variance 2.73e+02 smooth variance 7.10e+02 adaptive c -1.00\n",
      "Epoch 448 Chain 1 loss std 7.07e+02 variance 2.50e+05 smooth variance 2.65e+05 adaptive c -1.00\n",
      " Loss: 0.001969\n",
      " Loss: 0.095647\n",
      " Loss: 0.010397\n",
      " Loss: 0.127199\n",
      " Loss: 0.009815\n",
      " Loss: 0.241496\n",
      " Loss: 0.004139\n",
      " Loss: 0.143827\n",
      " Loss: 0.000953\n",
      " Loss: 0.129636\n",
      " Loss: 0.005245\n",
      " Loss: 0.224789\n",
      " Loss: 0.002063\n",
      " Loss: 0.144284\n",
      " Loss: 0.006909\n",
      " Loss: 0.175910\n",
      " Loss: 0.007759\n",
      " Loss: 0.080169\n",
      " Loss: 0.004070\n",
      " Loss: 0.109880\n",
      "Epoch 450 Chain 0 loss std 1.63e+01 variance 1.33e+02 smooth variance 5.37e+02 adaptive c -1.00\n",
      "Epoch 450 Chain 1 loss std 6.28e+02 variance 1.97e+05 smooth variance 2.45e+05 adaptive c -1.00\n",
      " Loss: 0.001584\n",
      " Loss: 0.138211\n",
      " Loss: 0.004072\n",
      " Loss: 0.206798\n",
      " Loss: 0.009803\n",
      " Loss: 0.111124\n",
      " Loss: 0.006194\n",
      " Loss: 0.115840\n",
      " Loss: 0.003273\n",
      " Loss: 0.159860\n",
      " Loss: 0.000929\n",
      " Loss: 0.148143\n",
      " Loss: 0.006965\n",
      " Loss: 0.117548\n",
      " Loss: 0.003588\n",
      " Loss: 0.093434\n",
      " Loss: 0.004088\n",
      " Loss: 0.148578\n",
      " Loss: 0.008653\n",
      " Loss: 0.221474\n",
      "Epoch 452 Chain 0 loss std 3.85e+01 variance 7.43e+02 smooth variance 5.99e+02 adaptive c -1.00\n",
      "Epoch 452 Chain 1 loss std 7.91e+02 variance 3.13e+05 smooth variance 2.65e+05 adaptive c -1.00\n",
      " Loss: 0.005958\n",
      " Loss: 0.118519\n",
      " Loss: 0.004348\n",
      " Loss: 0.113349\n",
      " Loss: 0.003598\n",
      " Loss: 0.205004\n",
      " Loss: 0.003548\n",
      " Loss: 0.149430\n",
      " Loss: 0.006329\n",
      " Loss: 0.139501\n",
      " Loss: 0.003864\n",
      " Loss: 0.046883\n",
      " Loss: 0.009420\n",
      " Loss: 0.193257\n",
      " Loss: 0.002659\n",
      " Loss: 0.125952\n",
      " Loss: 0.001431\n",
      " Loss: 0.230238\n",
      " Loss: 0.005672\n",
      " Loss: 0.126466\n",
      "Epoch 454 Chain 0 loss std 2.69e+01 variance 3.62e+02 smooth variance 5.28e+02 adaptive c -1.00\n",
      "Epoch 454 Chain 1 loss std 5.97e+02 variance 1.78e+05 smooth variance 2.39e+05 adaptive c -1.00\n",
      " Loss: 0.002161\n",
      " Loss: 0.258118\n",
      " Loss: 0.006173\n",
      " Loss: 0.133912\n",
      " Loss: 0.006335\n",
      " Loss: 0.153752\n",
      " Loss: 0.002535\n",
      " Loss: 0.128758\n",
      " Loss: 0.005749\n",
      " Loss: 0.046153\n",
      " Loss: 0.001898\n",
      " Loss: 0.128665\n",
      " Loss: 0.008470\n",
      " Loss: 0.134601\n",
      " Loss: 0.003908\n",
      " Loss: 0.218988\n",
      " Loss: 0.002695\n",
      " Loss: 0.076836\n",
      " Loss: 0.004686\n",
      " Loss: 0.158552\n",
      "Epoch 456 Chain 0 loss std 1.71e+01 variance 1.45e+02 smooth variance 4.13e+02 adaptive c -1.00\n",
      "Epoch 456 Chain 1 loss std 6.16e+02 variance 1.90e+05 smooth variance 2.24e+05 adaptive c -1.00\n",
      " Loss: 0.001571\n",
      " Loss: 0.106535\n",
      " Loss: 0.005002\n",
      " Loss: 0.281148\n",
      " Loss: 0.005850\n",
      " Loss: 0.135343\n",
      " Loss: 0.006623\n",
      " Loss: 0.092745\n",
      " Loss: 0.002423\n",
      " Loss: 0.099339\n",
      " Loss: 0.002169\n",
      " Loss: 0.099095\n",
      " Loss: 0.005091\n",
      " Loss: 0.080810\n",
      " Loss: 0.006899\n",
      " Loss: 0.141148\n",
      " Loss: 0.002827\n",
      " Loss: 0.166816\n",
      " Loss: 0.003590\n",
      " Loss: 0.224745\n",
      "Epoch 458 Chain 0 loss std 1.31e+01 variance 8.59e+01 smooth variance 3.15e+02 adaptive c -1.00\n",
      "Epoch 458 Chain 1 loss std 6.96e+02 variance 2.42e+05 smooth variance 2.30e+05 adaptive c -1.00\n",
      " Loss: 0.003756\n",
      " Loss: 0.203020\n",
      " Loss: 0.005308\n",
      " Loss: 0.131984\n",
      " Loss: 0.002089\n",
      " Loss: 0.161326\n",
      " Loss: 0.007411\n",
      " Loss: 0.120401\n",
      " Loss: 0.001302\n",
      " Loss: 0.093475\n",
      " Loss: 0.002249\n",
      " Loss: 0.124695\n",
      " Loss: 0.007131\n",
      " Loss: 0.263017\n",
      " Loss: 0.006389\n",
      " Loss: 0.113377\n",
      " Loss: 0.002620\n",
      " Loss: 0.099060\n",
      " Loss: 0.000972\n",
      " Loss: 0.107115\n",
      "Epoch 460 Chain 0 loss std 1.70e+01 variance 1.44e+02 smooth variance 2.64e+02 adaptive c -1.00\n",
      "Epoch 460 Chain 1 loss std 5.54e+02 variance 1.54e+05 smooth variance 2.07e+05 adaptive c -1.00\n",
      " Loss: 0.004134\n",
      " Loss: 0.228174\n",
      " Loss: 0.002414\n",
      " Loss: 0.121278\n",
      " Loss: 0.002765\n",
      " Loss: 0.133752\n",
      " Loss: 0.004912\n",
      " Loss: 0.102205\n",
      " Loss: 0.004899\n",
      " Loss: 0.119109\n",
      " Loss: 0.004718\n",
      " Loss: 0.098055\n",
      " Loss: 0.001924\n",
      " Loss: 0.246180\n",
      " Loss: 0.002285\n",
      " Loss: 0.149189\n",
      " Loss: 0.005594\n",
      " Loss: 0.138354\n",
      " Loss: 0.003881\n",
      " Loss: 0.069594\n",
      "Epoch 462 Chain 0 loss std 2.00e+01 variance 1.99e+02 smooth variance 2.44e+02 adaptive c -1.00\n",
      "Epoch 462 Chain 1 loss std 6.80e+02 variance 2.31e+05 smooth variance 2.14e+05 adaptive c -1.00\n",
      " Loss: 0.002178\n",
      " Loss: 0.093162\n",
      " Loss: 0.002143\n",
      " Loss: 0.133248\n",
      " Loss: 0.005571\n",
      " Loss: 0.213205\n",
      " Loss: 0.005173\n",
      " Loss: 0.103915\n",
      " Loss: 0.002837\n",
      " Loss: 0.155323\n",
      " Loss: 0.002092\n",
      " Loss: 0.085935\n",
      " Loss: 0.002374\n",
      " Loss: 0.236055\n",
      " Loss: 0.002092\n",
      " Loss: 0.097814\n",
      " Loss: 0.002112\n",
      " Loss: 0.146894\n",
      " Loss: 0.008445\n",
      " Loss: 0.129687\n",
      "Epoch 464 Chain 0 loss std 2.40e+01 variance 2.87e+02 smooth variance 2.57e+02 adaptive c -1.00\n",
      "Epoch 464 Chain 1 loss std 7.10e+02 variance 2.52e+05 smooth variance 2.25e+05 adaptive c -1.00\n",
      " Loss: 0.003521\n",
      " Loss: 0.199627\n",
      " Loss: 0.002499\n",
      " Loss: 0.134937\n",
      " Loss: 0.004663\n",
      " Loss: 0.119034\n",
      " Loss: 0.001463\n",
      " Loss: 0.112379\n",
      " Loss: 0.004274\n",
      " Loss: 0.127989\n",
      " Loss: 0.004383\n",
      " Loss: 0.137708\n",
      " Loss: 0.001346\n",
      " Loss: 0.182445\n",
      " Loss: 0.001442\n",
      " Loss: 0.223101\n",
      " Loss: 0.005095\n",
      " Loss: 0.093406\n",
      " Loss: 0.003523\n",
      " Loss: 0.054971\n",
      "Epoch 466 Chain 0 loss std 1.78e+01 variance 1.58e+02 smooth variance 2.28e+02 adaptive c -1.00\n",
      "Epoch 466 Chain 1 loss std 7.32e+02 variance 2.68e+05 smooth variance 2.38e+05 adaptive c -1.00\n",
      " Loss: 0.002737\n",
      " Loss: 0.102118\n",
      " Loss: 0.005093\n",
      " Loss: 0.158920\n",
      " Loss: 0.001473\n",
      " Loss: 0.117875\n",
      " Loss: 0.001969\n",
      " Loss: 0.197408\n",
      " Loss: 0.004256\n",
      " Loss: 0.112326\n",
      " Loss: 0.002809\n",
      " Loss: 0.154085\n",
      " Loss: 0.005186\n",
      " Loss: 0.273059\n",
      " Loss: 0.001474\n",
      " Loss: 0.066676\n",
      " Loss: 0.001366\n",
      " Loss: 0.075775\n",
      " Loss: 0.003793\n",
      " Loss: 0.116672\n",
      "Epoch 468 Chain 0 loss std 1.71e+01 variance 1.46e+02 smooth variance 2.03e+02 adaptive c -1.00\n",
      "Epoch 468 Chain 1 loss std 6.25e+02 variance 1.95e+05 smooth variance 2.25e+05 adaptive c -1.00\n",
      " Loss: 0.004078\n",
      " Loss: 0.181739\n",
      " Loss: 0.003601\n",
      " Loss: 0.115410\n",
      " Loss: 0.001801\n",
      " Loss: 0.125418\n",
      " Loss: 0.002074\n",
      " Loss: 0.167135\n",
      " Loss: 0.003288\n",
      " Loss: 0.093975\n",
      " Loss: 0.005497\n",
      " Loss: 0.094495\n",
      " Loss: 0.001355\n",
      " Loss: 0.132754\n",
      " Loss: 0.002273\n",
      " Loss: 0.153250\n",
      " Loss: 0.003865\n",
      " Loss: 0.186315\n",
      " Loss: 0.000941\n",
      " Loss: 0.114282\n",
      "Epoch 470 Chain 0 loss std 1.58e+01 variance 1.25e+02 smooth variance 1.80e+02 adaptive c -1.00\n",
      "Epoch 470 Chain 1 loss std 6.86e+02 variance 2.35e+05 smooth variance 2.28e+05 adaptive c -1.00\n",
      " Loss: 0.004761\n",
      " Loss: 0.223099\n",
      " Loss: 0.002807\n",
      " Loss: 0.093663\n",
      " Loss: 0.001359\n",
      " Loss: 0.151840\n",
      " Loss: 0.003322\n",
      " Loss: 0.095061\n",
      " Loss: 0.000767\n",
      " Loss: 0.114870\n",
      " Loss: 0.000733\n",
      " Loss: 0.135919\n",
      " Loss: 0.004342\n",
      " Loss: 0.268571\n",
      " Loss: 0.003075\n",
      " Loss: 0.107331\n",
      " Loss: 0.002851\n",
      " Loss: 0.071263\n",
      " Loss: 0.001552\n",
      " Loss: 0.092908\n",
      "Epoch 472 Chain 0 loss std 1.59e+01 variance 1.27e+02 smooth variance 1.64e+02 adaptive c -1.00\n",
      "Epoch 472 Chain 1 loss std 4.80e+02 variance 1.15e+05 smooth variance 1.94e+05 adaptive c -1.00\n",
      " Loss: 0.004463\n",
      " Loss: 0.049916\n",
      " Loss: 0.001367\n",
      " Loss: 0.181661\n",
      " Loss: 0.001292\n",
      " Loss: 0.245211\n",
      " Loss: 0.002589\n",
      " Loss: 0.114743\n",
      " Loss: 0.002549\n",
      " Loss: 0.081870\n",
      " Loss: 0.000857\n",
      " Loss: 0.103283\n",
      " Loss: 0.003014\n",
      " Loss: 0.176099\n",
      " Loss: 0.002796\n",
      " Loss: 0.113530\n",
      " Loss: 0.001705\n",
      " Loss: 0.092571\n",
      " Loss: 0.003485\n",
      " Loss: 0.185584\n",
      "Epoch 474 Chain 0 loss std 1.48e+01 variance 1.09e+02 smooth variance 1.47e+02 adaptive c -1.00\n",
      "Epoch 474 Chain 1 loss std 4.34e+02 variance 9.41e+04 smooth variance 1.64e+05 adaptive c -1.00\n",
      " Loss: 0.004021\n",
      " Loss: 0.092031\n",
      " Loss: 0.001094\n",
      " Loss: 0.105177\n",
      " Loss: 0.000664\n",
      " Loss: 0.098216\n",
      " Loss: 0.004858\n",
      " Loss: 0.091616\n",
      " Loss: 0.001253\n",
      " Loss: 0.281741\n",
      " Loss: 0.000833\n",
      " Loss: 0.103537\n",
      " Loss: 0.001161\n",
      " Loss: 0.085845\n",
      " Loss: 0.003241\n",
      " Loss: 0.121948\n",
      " Loss: 0.001248\n",
      " Loss: 0.163671\n",
      " Loss: 0.004782\n",
      " Loss: 0.191651\n",
      "Epoch 476 Chain 0 loss std 1.05e+01 variance 5.49e+01 smooth variance 1.20e+02 adaptive c -1.00\n",
      "Epoch 476 Chain 1 loss std 5.52e+02 variance 1.52e+05 smooth variance 1.61e+05 adaptive c -1.00\n",
      " Loss: 0.001198\n",
      " Loss: 0.164138\n",
      " Loss: 0.003234\n",
      " Loss: 0.093972\n",
      " Loss: 0.001207\n",
      " Loss: 0.229563\n",
      " Loss: 0.003616\n",
      " Loss: 0.106372\n",
      " Loss: 0.001852\n",
      " Loss: 0.070995\n",
      " Loss: 0.001305\n",
      " Loss: 0.242184\n",
      " Loss: 0.003569\n",
      " Loss: 0.083585\n",
      " Loss: 0.000671\n",
      " Loss: 0.075654\n",
      " Loss: 0.002218\n",
      " Loss: 0.100308\n",
      " Loss: 0.003101\n",
      " Loss: 0.161098\n",
      "Epoch 478 Chain 0 loss std 1.08e+01 variance 5.86e+01 smooth variance 1.01e+02 adaptive c -1.00\n",
      "Epoch 478 Chain 1 loss std 3.56e+02 variance 6.34e+04 smooth variance 1.32e+05 adaptive c -1.00\n",
      " Loss: 0.001918\n",
      " Loss: 0.058095\n",
      " Loss: 0.003736\n",
      " Loss: 0.121755\n",
      " Loss: 0.003520\n",
      " Loss: 0.190593\n",
      " Loss: 0.000938\n",
      " Loss: 0.140411\n",
      " Loss: 0.000764\n",
      " Loss: 0.149149\n",
      " Loss: 0.002374\n",
      " Loss: 0.067829\n",
      " Loss: 0.004859\n",
      " Loss: 0.171635\n",
      " Loss: 0.000846\n",
      " Loss: 0.137981\n",
      " Loss: 0.001655\n",
      " Loss: 0.149070\n",
      " Loss: 0.000756\n",
      " Loss: 0.131061\n",
      "Epoch 480 Chain 0 loss std 7.26e+00 variance 2.64e+01 smooth variance 7.89e+01 adaptive c -1.00\n",
      "Epoch 480 Chain 1 loss std 4.61e+02 variance 1.06e+05 smooth variance 1.24e+05 adaptive c -1.00\n",
      " Loss: 0.002278\n",
      " Loss: 0.075613\n",
      " Loss: 0.002663\n",
      " Loss: 0.128253\n",
      " Loss: 0.000565\n",
      " Loss: 0.112214\n",
      " Loss: 0.001719\n",
      " Loss: 0.217642\n",
      " Loss: 0.002873\n",
      " Loss: 0.121774\n",
      " Loss: 0.002966\n",
      " Loss: 0.156658\n",
      " Loss: 0.001883\n",
      " Loss: 0.098149\n",
      " Loss: 0.003179\n",
      " Loss: 0.239648\n",
      " Loss: 0.000899\n",
      " Loss: 0.078771\n",
      " Loss: 0.000771\n",
      " Loss: 0.080053\n",
      "Epoch 482 Chain 0 loss std 1.04e+01 variance 5.45e+01 smooth variance 7.16e+01 adaptive c -1.00\n",
      "Epoch 482 Chain 1 loss std 5.54e+02 variance 1.54e+05 smooth variance 1.33e+05 adaptive c -1.00\n",
      " Loss: 0.001562\n",
      " Loss: 0.202066\n",
      " Loss: 0.000550\n",
      " Loss: 0.096322\n",
      " Loss: 0.001312\n",
      " Loss: 0.125923\n",
      " Loss: 0.003889\n",
      " Loss: 0.097638\n",
      " Loss: 0.002311\n",
      " Loss: 0.128862\n",
      " Loss: 0.003394\n",
      " Loss: 0.091194\n",
      " Loss: 0.001444\n",
      " Loss: 0.107545\n",
      " Loss: 0.001208\n",
      " Loss: 0.211949\n",
      " Loss: 0.002512\n",
      " Loss: 0.140542\n",
      " Loss: 0.000804\n",
      " Loss: 0.097392\n",
      "Epoch 484 Chain 0 loss std 1.02e+01 variance 5.20e+01 smooth variance 6.57e+01 adaptive c -1.00\n",
      "Epoch 484 Chain 1 loss std 5.28e+02 variance 1.39e+05 smooth variance 1.35e+05 adaptive c -1.00\n",
      " Loss: 0.003573\n",
      " Loss: 0.182352\n",
      " Loss: 0.001493\n",
      " Loss: 0.096243\n",
      " Loss: 0.000945\n",
      " Loss: 0.103262\n",
      " Loss: 0.002135\n",
      " Loss: 0.143531\n",
      " Loss: 0.001111\n",
      " Loss: 0.121386\n",
      " Loss: 0.001656\n",
      " Loss: 0.124898\n",
      " Loss: 0.002500\n",
      " Loss: 0.072878\n",
      " Loss: 0.000522\n",
      " Loss: 0.140726\n",
      " Loss: 0.001195\n",
      " Loss: 0.095719\n",
      " Loss: 0.002980\n",
      " Loss: 0.209862\n",
      "Epoch 486 Chain 0 loss std 9.71e+00 variance 4.72e+01 smooth variance 6.01e+01 adaptive c -1.00\n",
      "Epoch 486 Chain 1 loss std 6.10e+02 variance 1.86e+05 smooth variance 1.50e+05 adaptive c -1.00\n",
      " Loss: 0.001288\n",
      " Loss: 0.076487\n",
      " Loss: 0.003523\n",
      " Loss: 0.175715\n",
      " Loss: 0.002457\n",
      " Loss: 0.096841\n",
      " Loss: 0.000685\n",
      " Loss: 0.162829\n",
      " Loss: 0.000780\n",
      " Loss: 0.130158\n",
      " Loss: 0.001103\n",
      " Loss: 0.245301\n",
      " Loss: 0.001148\n",
      " Loss: 0.097614\n",
      " Loss: 0.000611\n",
      " Loss: 0.079666\n",
      " Loss: 0.002079\n",
      " Loss: 0.113808\n",
      " Loss: 0.003527\n",
      " Loss: 0.103404\n",
      "Epoch 488 Chain 0 loss std 5.92e+00 variance 1.75e+01 smooth variance 4.73e+01 adaptive c -1.00\n",
      "Epoch 488 Chain 1 loss std 9.60e+02 variance 4.61e+05 smooth variance 2.43e+05 adaptive c -1.00\n",
      " Loss: 0.001286\n",
      " Loss: 0.096968\n",
      " Loss: 0.001923\n",
      " Loss: 0.095595\n",
      " Loss: 0.001104\n",
      " Loss: 0.125891\n",
      " Loss: 0.001738\n",
      " Loss: 0.189748\n",
      " Loss: 0.002204\n",
      " Loss: 0.129430\n",
      " Loss: 0.000653\n",
      " Loss: 0.079140\n",
      " Loss: 0.002762\n",
      " Loss: 0.087081\n",
      " Loss: 0.001533\n",
      " Loss: 0.080085\n",
      " Loss: 0.002437\n",
      " Loss: 0.249772\n",
      " Loss: 0.000588\n",
      " Loss: 0.139415\n",
      "Epoch 490 Chain 0 loss std 7.34e+00 variance 2.70e+01 smooth variance 4.12e+01 adaptive c -1.00\n",
      "Epoch 490 Chain 1 loss std 5.15e+02 variance 1.33e+05 smooth variance 2.10e+05 adaptive c -1.00\n",
      " Loss: 0.002538\n",
      " Loss: 0.093275\n",
      " Loss: 0.000810\n",
      " Loss: 0.094031\n",
      " Loss: 0.002386\n",
      " Loss: 0.073422\n",
      " Loss: 0.000790\n",
      " Loss: 0.166056\n",
      " Loss: 0.001082\n",
      " Loss: 0.206748\n",
      " Loss: 0.001026\n",
      " Loss: 0.249095\n",
      " Loss: 0.001206\n",
      " Loss: 0.106290\n",
      " Loss: 0.000741\n",
      " Loss: 0.070911\n",
      " Loss: 0.001913\n",
      " Loss: 0.128113\n",
      " Loss: 0.002488\n",
      " Loss: 0.077013\n",
      "Epoch 492 Chain 0 loss std 9.49e+00 variance 4.50e+01 smooth variance 4.24e+01 adaptive c -1.00\n",
      "Epoch 492 Chain 1 loss std 3.87e+02 variance 7.51e+04 smooth variance 1.70e+05 adaptive c -1.00\n",
      " Loss: 0.002277\n",
      " Loss: 0.087790\n",
      " Loss: 0.000952\n",
      " Loss: 0.214003\n",
      " Loss: 0.001027\n",
      " Loss: 0.121406\n",
      " Loss: 0.002317\n",
      " Loss: 0.082062\n",
      " Loss: 0.000481\n",
      " Loss: 0.123835\n",
      " Loss: 0.001805\n",
      " Loss: 0.046472\n",
      " Loss: 0.000748\n",
      " Loss: 0.198801\n",
      " Loss: 0.001254\n",
      " Loss: 0.082461\n",
      " Loss: 0.000530\n",
      " Loss: 0.183558\n",
      " Loss: 0.002721\n",
      " Loss: 0.115646\n",
      "Epoch 494 Chain 0 loss std 7.01e+00 variance 2.45e+01 smooth variance 3.70e+01 adaptive c -1.00\n",
      "Epoch 494 Chain 1 loss std 3.52e+02 variance 6.19e+04 smooth variance 1.37e+05 adaptive c -1.00\n",
      " Loss: 0.000626\n",
      " Loss: 0.078275\n",
      " Loss: 0.000804\n",
      " Loss: 0.218535\n",
      " Loss: 0.001584\n",
      " Loss: 0.101997\n",
      " Loss: 0.000779\n",
      " Loss: 0.128107\n",
      " Loss: 0.002929\n",
      " Loss: 0.098187\n",
      " Loss: 0.000815\n",
      " Loss: 0.088772\n",
      " Loss: 0.000533\n",
      " Loss: 0.094865\n",
      " Loss: 0.000884\n",
      " Loss: 0.190658\n",
      " Loss: 0.002172\n",
      " Loss: 0.091729\n",
      " Loss: 0.002084\n",
      " Loss: 0.157177\n",
      "Epoch 496 Chain 0 loss std 1.34e+01 variance 8.93e+01 smooth variance 5.27e+01 adaptive c -1.00\n",
      "Epoch 496 Chain 1 loss std 4.59e+02 variance 1.05e+05 smooth variance 1.28e+05 adaptive c -1.00\n",
      " Loss: 0.000585\n",
      " Loss: 0.122637\n",
      " Loss: 0.001370\n",
      " Loss: 0.082503\n",
      " Loss: 0.001486\n",
      " Loss: 0.189966\n",
      " Loss: 0.001938\n",
      " Loss: 0.084567\n",
      " Loss: 0.000929\n",
      " Loss: 0.141701\n",
      " Loss: 0.001424\n",
      " Loss: 0.088205\n",
      " Loss: 0.000533\n",
      " Loss: 0.104356\n",
      " Loss: 0.002095\n",
      " Loss: 0.208912\n",
      " Loss: 0.001393\n",
      " Loss: 0.118427\n",
      " Loss: 0.000666\n",
      " Loss: 0.099491\n",
      "Epoch 498 Chain 0 loss std 5.70e+00 variance 1.63e+01 smooth variance 4.18e+01 adaptive c -1.00\n",
      "Epoch 498 Chain 1 loss std 6.76e+02 variance 2.28e+05 smooth variance 1.58e+05 adaptive c -1.00\n",
      " Loss: 0.002329\n",
      " Loss: 0.056998\n",
      " Loss: 0.001290\n",
      " Loss: 0.151290\n",
      " Loss: 0.000552\n",
      " Loss: 0.143947\n",
      " Loss: 0.001182\n",
      " Loss: 0.101297\n",
      " Loss: 0.000512\n",
      " Loss: 0.163475\n",
      " Loss: 0.001406\n",
      " Loss: 0.108158\n",
      " Loss: 0.001022\n",
      " Loss: 0.183723\n",
      " Loss: 0.000878\n",
      " Loss: 0.049009\n",
      " Loss: 0.000422\n",
      " Loss: 0.172444\n",
      " Loss: 0.002197\n",
      " Loss: 0.102181\n",
      "Epoch 500 Chain 0 loss std 6.96e+00 variance 2.42e+01 smooth variance 3.65e+01 adaptive c -1.00\n",
      "Epoch 500 Chain 1 loss std 2.95e+02 variance 4.35e+04 smooth variance 1.24e+05 adaptive c -1.00\n",
      " Loss: 0.001254\n",
      " Loss: 0.120131\n",
      " Loss: 0.000426\n",
      " Loss: 0.126538\n",
      " Loss: 0.000941\n",
      " Loss: 0.129353\n",
      " Loss: 0.001259\n",
      " Loss: 0.077689\n",
      " Loss: 0.001650\n",
      " Loss: 0.159422\n",
      " Loss: 0.001392\n",
      " Loss: 0.233287\n",
      " Loss: 0.000609\n",
      " Loss: 0.093784\n",
      " Loss: 0.001062\n",
      " Loss: 0.071273\n",
      " Loss: 0.001229\n",
      " Loss: 0.163397\n",
      " Loss: 0.000904\n",
      " Loss: 0.049427\n",
      "Epoch 502 Chain 0 loss std 4.47e+00 variance 9.98e+00 smooth variance 2.85e+01 adaptive c -1.00\n",
      "Epoch 502 Chain 1 loss std 2.90e+02 variance 4.20e+04 smooth variance 9.91e+04 adaptive c -1.00\n",
      " Loss: 0.000757\n",
      " Loss: 0.079301\n",
      " Loss: 0.001193\n",
      " Loss: 0.209399\n",
      " Loss: 0.000847\n",
      " Loss: 0.107173\n",
      " Loss: 0.001751\n",
      " Loss: 0.115404\n",
      " Loss: 0.000547\n",
      " Loss: 0.097487\n",
      " Loss: 0.001462\n",
      " Loss: 0.112941\n",
      " Loss: 0.000837\n",
      " Loss: 0.099461\n",
      " Loss: 0.001739\n",
      " Loss: 0.121393\n",
      " Loss: 0.000266\n",
      " Loss: 0.116307\n",
      " Loss: 0.000606\n",
      " Loss: 0.156895\n",
      "Epoch 504 Chain 0 loss std 5.87e+00 variance 1.72e+01 smooth variance 2.52e+01 adaptive c -1.00\n",
      "Epoch 504 Chain 1 loss std 4.99e+02 variance 1.25e+05 smooth variance 1.07e+05 adaptive c -1.00\n",
      " Loss: 0.000951\n",
      " Loss: 0.078318\n",
      " Loss: 0.000444\n",
      " Loss: 0.162290\n",
      " Loss: 0.001057\n",
      " Loss: 0.109881\n",
      " Loss: 0.002032\n",
      " Loss: 0.186792\n",
      " Loss: 0.000407\n",
      " Loss: 0.067679\n",
      " Loss: 0.000393\n",
      " Loss: 0.144673\n",
      " Loss: 0.001146\n",
      " Loss: 0.080705\n",
      " Loss: 0.000432\n",
      " Loss: 0.145562\n",
      " Loss: 0.002073\n",
      " Loss: 0.054721\n",
      " Loss: 0.000655\n",
      " Loss: 0.177368\n",
      "Epoch 506 Chain 0 loss std 7.52e+00 variance 2.83e+01 smooth variance 2.61e+01 adaptive c -1.00\n",
      "Epoch 506 Chain 1 loss std 4.39e+02 variance 9.63e+04 smooth variance 1.04e+05 adaptive c -1.00\n",
      " Loss: 0.000709\n",
      " Loss: 0.131267\n",
      " Loss: 0.001266\n",
      " Loss: 0.094650\n",
      " Loss: 0.001086\n",
      " Loss: 0.189539\n",
      " Loss: 0.000318\n",
      " Loss: 0.086510\n",
      " Loss: 0.001167\n",
      " Loss: 0.099558\n",
      " Loss: 0.000986\n",
      " Loss: 0.189547\n",
      " Loss: 0.001537\n",
      " Loss: 0.116269\n",
      " Loss: 0.000497\n",
      " Loss: 0.118202\n",
      " Loss: 0.000304\n",
      " Loss: 0.091081\n",
      " Loss: 0.001309\n",
      " Loss: 0.084301\n",
      "Epoch 508 Chain 0 loss std 3.40e+00 variance 5.78e+00 smooth variance 2.00e+01 adaptive c -1.00\n",
      "Epoch 508 Chain 1 loss std 3.58e+02 variance 6.43e+04 smooth variance 9.18e+04 adaptive c -1.00\n",
      " Loss: 0.000920\n",
      " Loss: 0.073391\n",
      " Loss: 0.000414\n",
      " Loss: 0.067745\n",
      " Loss: 0.001959\n",
      " Loss: 0.176870\n",
      " Loss: 0.000528\n",
      " Loss: 0.157695\n",
      " Loss: 0.000633\n",
      " Loss: 0.121594\n",
      " Loss: 0.000352\n",
      " Loss: 0.072086\n",
      " Loss: 0.000502\n",
      " Loss: 0.081472\n",
      " Loss: 0.001946\n",
      " Loss: 0.125697\n",
      " Loss: 0.001182\n",
      " Loss: 0.180047\n",
      " Loss: 0.000314\n",
      " Loss: 0.136147\n",
      "Epoch 510 Chain 0 loss std 2.17e+00 variance 2.36e+00 smooth variance 1.47e+01 adaptive c -1.00\n",
      "Epoch 510 Chain 1 loss std 3.42e+02 variance 5.86e+04 smooth variance 8.18e+04 adaptive c -1.00\n",
      " Loss: 0.000392\n",
      " Loss: 0.152237\n",
      " Loss: 0.000530\n",
      " Loss: 0.130143\n",
      " Loss: 0.001779\n",
      " Loss: 0.071123\n",
      " Loss: 0.001179\n",
      " Loss: 0.102602\n",
      " Loss: 0.000330\n",
      " Loss: 0.137674\n",
      " Loss: 0.000992\n",
      " Loss: 0.109805\n",
      " Loss: 0.001053\n",
      " Loss: 0.068427\n",
      " Loss: 0.000299\n",
      " Loss: 0.100528\n",
      " Loss: 0.000444\n",
      " Loss: 0.128052\n",
      " Loss: 0.001361\n",
      " Loss: 0.185058\n",
      "Epoch 512 Chain 0 loss std 6.41e+00 variance 2.06e+01 smooth variance 1.65e+01 adaptive c -1.00\n",
      "Epoch 512 Chain 1 loss std 5.27e+02 variance 1.39e+05 smooth variance 9.89e+04 adaptive c -1.00\n",
      " Loss: 0.000944\n",
      " Loss: 0.077943\n",
      " Loss: 0.000422\n",
      " Loss: 0.115823\n",
      " Loss: 0.000532\n",
      " Loss: 0.104925\n",
      " Loss: 0.000440\n",
      " Loss: 0.104204\n",
      " Loss: 0.001561\n",
      " Loss: 0.187056\n",
      " Loss: 0.000750\n",
      " Loss: 0.212732\n",
      " Loss: 0.000851\n",
      " Loss: 0.097762\n",
      " Loss: 0.000555\n",
      " Loss: 0.077375\n",
      " Loss: 0.000406\n",
      " Loss: 0.121603\n",
      " Loss: 0.001266\n",
      " Loss: 0.078896\n",
      "Epoch 514 Chain 0 loss std 3.69e+00 variance 6.80e+00 smooth variance 1.36e+01 adaptive c -1.00\n",
      "Epoch 514 Chain 1 loss std 3.96e+02 variance 7.86e+04 smooth variance 9.28e+04 adaptive c -1.00\n",
      " Loss: 0.000400\n",
      " Loss: 0.107455\n",
      " Loss: 0.000665\n",
      " Loss: 0.126287\n",
      " Loss: 0.001188\n",
      " Loss: 0.148975\n",
      " Loss: 0.000542\n",
      " Loss: 0.069445\n",
      " Loss: 0.001077\n",
      " Loss: 0.134028\n",
      " Loss: 0.000725\n",
      " Loss: 0.089282\n",
      " Loss: 0.000376\n",
      " Loss: 0.088547\n",
      " Loss: 0.000540\n",
      " Loss: 0.177912\n",
      " Loss: 0.000244\n",
      " Loss: 0.103747\n",
      " Loss: 0.001743\n",
      " Loss: 0.125402\n",
      "Epoch 516 Chain 0 loss std 3.62e+00 variance 6.57e+00 smooth variance 1.15e+01 adaptive c -1.00\n",
      "Epoch 516 Chain 1 loss std 4.35e+02 variance 9.48e+04 smooth variance 9.34e+04 adaptive c -1.00\n",
      " Loss: 0.000888\n",
      " Loss: 0.169737\n",
      " Loss: 0.000756\n",
      " Loss: 0.076105\n",
      " Loss: 0.000429\n",
      " Loss: 0.096108\n",
      " Loss: 0.001050\n",
      " Loss: 0.170021\n",
      " Loss: 0.000602\n",
      " Loss: 0.070412\n",
      " Loss: 0.000481\n",
      " Loss: 0.087529\n",
      " Loss: 0.000630\n",
      " Loss: 0.130706\n",
      " Loss: 0.001125\n",
      " Loss: 0.181553\n",
      " Loss: 0.000505\n",
      " Loss: 0.055851\n",
      " Loss: 0.000889\n",
      " Loss: 0.124858\n",
      "Epoch 518 Chain 0 loss std 1.72e+00 variance 1.47e+00 smooth variance 8.47e+00 adaptive c -1.00\n",
      "Epoch 518 Chain 1 loss std 4.30e+02 variance 9.27e+04 smooth variance 9.32e+04 adaptive c -1.00\n",
      " Loss: 0.000992\n",
      " Loss: 0.070637\n",
      " Loss: 0.001172\n",
      " Loss: 0.228188\n",
      " Loss: 0.000299\n",
      " Loss: 0.077975\n",
      " Loss: 0.000559\n",
      " Loss: 0.102404\n",
      " Loss: 0.000438\n",
      " Loss: 0.099898\n",
      " Loss: 0.000327\n",
      " Loss: 0.101142\n",
      " Loss: 0.000462\n",
      " Loss: 0.094076\n",
      " Loss: 0.000938\n",
      " Loss: 0.123043\n",
      " Loss: 0.001123\n",
      " Loss: 0.065478\n",
      " Loss: 0.000516\n",
      " Loss: 0.193573\n",
      "Epoch 520 Chain 0 loss std 4.73e+00 variance 1.12e+01 smooth variance 9.28e+00 adaptive c -1.00\n",
      "Epoch 520 Chain 1 loss std 3.17e+02 variance 5.02e+04 smooth variance 8.03e+04 adaptive c -1.00\n",
      " Loss: 0.001077\n",
      " Loss: 0.126635\n",
      " Loss: 0.000911\n",
      " Loss: 0.103995\n",
      " Loss: 0.000824\n",
      " Loss: 0.184292\n",
      " Loss: 0.000234\n",
      " Loss: 0.097061\n",
      " Loss: 0.000243\n",
      " Loss: 0.063423\n",
      " Loss: 0.000679\n",
      " Loss: 0.083779\n",
      " Loss: 0.000688\n",
      " Loss: 0.224092\n",
      " Loss: 0.000902\n",
      " Loss: 0.084411\n",
      " Loss: 0.000475\n",
      " Loss: 0.124215\n",
      " Loss: 0.000618\n",
      " Loss: 0.057165\n",
      "Epoch 522 Chain 0 loss std 2.46e+00 variance 3.03e+00 smooth variance 7.41e+00 adaptive c -1.00\n",
      "Epoch 522 Chain 1 loss std 6.83e+02 variance 2.33e+05 smooth variance 1.26e+05 adaptive c -1.00\n",
      " Loss: 0.000961\n",
      " Loss: 0.140412\n",
      " Loss: 0.000494\n",
      " Loss: 0.206688\n",
      " Loss: 0.000505\n",
      " Loss: 0.074761\n",
      " Loss: 0.000257\n",
      " Loss: 0.077464\n",
      " Loss: 0.001032\n",
      " Loss: 0.072618\n",
      " Loss: 0.000553\n",
      " Loss: 0.214670\n",
      " Loss: 0.001231\n",
      " Loss: 0.115768\n",
      " Loss: 0.000506\n",
      " Loss: 0.082590\n",
      " Loss: 0.000469\n",
      " Loss: 0.089632\n",
      " Loss: 0.000210\n",
      " Loss: 0.067568\n",
      "Epoch 524 Chain 0 loss std 3.65e+00 variance 6.65e+00 smooth variance 7.18e+00 adaptive c -1.00\n",
      "Epoch 524 Chain 1 loss std 6.28e+02 variance 1.97e+05 smooth variance 1.47e+05 adaptive c -1.00\n",
      " Loss: 0.000640\n",
      " Loss: 0.083669\n",
      " Loss: 0.000381\n",
      " Loss: 0.084315\n",
      " Loss: 0.000864\n",
      " Loss: 0.055070\n",
      " Loss: 0.000474\n",
      " Loss: 0.247051\n",
      " Loss: 0.000572\n",
      " Loss: 0.098765\n",
      " Loss: 0.000719\n",
      " Loss: 0.072709\n",
      " Loss: 0.000971\n",
      " Loss: 0.095271\n",
      " Loss: 0.000555\n",
      " Loss: 0.207299\n",
      " Loss: 0.000332\n",
      " Loss: 0.100917\n",
      " Loss: 0.000253\n",
      " Loss: 0.090840\n",
      "Epoch 526 Chain 0 loss std 4.53e+00 variance 1.03e+01 smooth variance 8.11e+00 adaptive c -1.00\n",
      "Epoch 526 Chain 1 loss std 5.03e+02 variance 1.26e+05 smooth variance 1.41e+05 adaptive c -1.00\n",
      " Loss: 0.001135\n",
      " Loss: 0.089311\n",
      " Loss: 0.000771\n",
      " Loss: 0.196203\n",
      " Loss: 0.000248\n",
      " Loss: 0.077711\n",
      " Loss: 0.000191\n",
      " Loss: 0.062641\n",
      " Loss: 0.000418\n",
      " Loss: 0.139750\n",
      " Loss: 0.000863\n",
      " Loss: 0.073515\n",
      " Loss: 0.000777\n",
      " Loss: 0.091660\n",
      " Loss: 0.000433\n",
      " Loss: 0.185124\n",
      " Loss: 0.000178\n",
      " Loss: 0.112855\n",
      " Loss: 0.000393\n",
      " Loss: 0.100871\n",
      "Epoch 528 Chain 0 loss std 3.18e+00 variance 5.07e+00 smooth variance 7.20e+00 adaptive c -1.00\n",
      "Epoch 528 Chain 1 loss std 5.09e+02 variance 1.30e+05 smooth variance 1.38e+05 adaptive c -1.00\n",
      " Loss: 0.000313\n",
      " Loss: 0.098418\n",
      " Loss: 0.000790\n",
      " Loss: 0.068548\n",
      " Loss: 0.000360\n",
      " Loss: 0.183447\n",
      " Loss: 0.000975\n",
      " Loss: 0.087692\n",
      " Loss: 0.000155\n",
      " Loss: 0.124248\n",
      " Loss: 0.000262\n",
      " Loss: 0.088536\n",
      " Loss: 0.000282\n",
      " Loss: 0.126989\n",
      " Loss: 0.000719\n",
      " Loss: 0.170147\n",
      " Loss: 0.000585\n",
      " Loss: 0.097124\n",
      " Loss: 0.000662\n",
      " Loss: 0.078103\n",
      "Epoch 530 Chain 0 loss std 3.02e+00 variance 4.57e+00 smooth variance 6.41e+00 adaptive c -1.00\n",
      "Epoch 530 Chain 1 loss std 4.18e+02 variance 8.74e+04 smooth variance 1.23e+05 adaptive c -1.00\n",
      " Loss: 0.000220\n",
      " Loss: 0.104310\n",
      " Loss: 0.000229\n",
      " Loss: 0.164166\n",
      " Loss: 0.001123\n",
      " Loss: 0.055927\n",
      " Loss: 0.000632\n",
      " Loss: 0.145298\n",
      " Loss: 0.000222\n",
      " Loss: 0.089642\n",
      " Loss: 0.000701\n",
      " Loss: 0.080826\n",
      " Loss: 0.000372\n",
      " Loss: 0.080007\n",
      " Loss: 0.000797\n",
      " Loss: 0.153859\n",
      " Loss: 0.000232\n",
      " Loss: 0.107157\n",
      " Loss: 0.000345\n",
      " Loss: 0.135873\n",
      "Epoch 532 Chain 0 loss std 2.33e+00 variance 2.71e+00 smooth variance 5.30e+00 adaptive c -1.00\n",
      "Epoch 532 Chain 1 loss std 4.41e+02 variance 9.73e+04 smooth variance 1.15e+05 adaptive c -1.00\n",
      " Loss: 0.000289\n",
      " Loss: 0.123274\n",
      " Loss: 0.000575\n",
      " Loss: 0.098238\n",
      " Loss: 0.000794\n",
      " Loss: 0.179359\n",
      " Loss: 0.000353\n",
      " Loss: 0.071859\n",
      " Loss: 0.000412\n",
      " Loss: 0.083861\n",
      " Loss: 0.000383\n",
      " Loss: 0.111065\n",
      " Loss: 0.000527\n",
      " Loss: 0.055064\n",
      " Loss: 0.000241\n",
      " Loss: 0.099181\n",
      " Loss: 0.001015\n",
      " Loss: 0.113318\n",
      " Loss: 0.000241\n",
      " Loss: 0.176402\n",
      "Epoch 534 Chain 0 loss std 3.04e+00 variance 4.61e+00 smooth variance 5.09e+00 adaptive c -1.00\n",
      "Epoch 534 Chain 1 loss std 3.80e+02 variance 7.21e+04 smooth variance 1.02e+05 adaptive c -1.00\n",
      " Loss: 0.000441\n",
      " Loss: 0.251633\n",
      " Loss: 0.000183\n",
      " Loss: 0.076159\n",
      " Loss: 0.000315\n",
      " Loss: 0.080247\n",
      " Loss: 0.000835\n",
      " Loss: 0.085205\n",
      " Loss: 0.000569\n",
      " Loss: 0.060124\n",
      " Loss: 0.000672\n",
      " Loss: 0.090254\n",
      " Loss: 0.000485\n",
      " Loss: 0.135694\n",
      " Loss: 0.000427\n",
      " Loss: 0.157602\n",
      " Loss: 0.000305\n",
      " Loss: 0.093757\n",
      " Loss: 0.000514\n",
      " Loss: 0.074471\n",
      "Epoch 536 Chain 0 loss std 1.75e+00 variance 1.52e+00 smooth variance 4.02e+00 adaptive c -1.00\n",
      "Epoch 536 Chain 1 loss std 5.04e+02 variance 1.27e+05 smooth variance 1.10e+05 adaptive c -1.00\n",
      " Loss: 0.000364\n",
      " Loss: 0.173724\n",
      " Loss: 0.000593\n",
      " Loss: 0.054010\n",
      " Loss: 0.000244\n",
      " Loss: 0.119758\n",
      " Loss: 0.000439\n",
      " Loss: 0.115835\n",
      " Loss: 0.000652\n",
      " Loss: 0.086751\n",
      " Loss: 0.000384\n",
      " Loss: 0.071628\n",
      " Loss: 0.000225\n",
      " Loss: 0.213152\n",
      " Loss: 0.000378\n",
      " Loss: 0.057955\n",
      " Loss: 0.000887\n",
      " Loss: 0.087192\n",
      " Loss: 0.000312\n",
      " Loss: 0.118849\n",
      "Epoch 538 Chain 0 loss std 2.40e+00 variance 2.87e+00 smooth variance 3.68e+00 adaptive c -1.00\n",
      "Epoch 538 Chain 1 loss std 4.35e+02 variance 9.47e+04 smooth variance 1.05e+05 adaptive c -1.00\n",
      " Loss: 0.000359\n",
      " Loss: 0.090390\n",
      " Loss: 0.000402\n",
      " Loss: 0.099218\n",
      " Loss: 0.000211\n",
      " Loss: 0.171223\n",
      " Loss: 0.000260\n",
      " Loss: 0.134274\n",
      " Loss: 0.000996\n",
      " Loss: 0.052096\n",
      " Loss: 0.000542\n",
      " Loss: 0.192073\n",
      " Loss: 0.000136\n",
      " Loss: 0.147488\n",
      " Loss: 0.000471\n",
      " Loss: 0.076944\n",
      " Loss: 0.000646\n",
      " Loss: 0.067540\n",
      " Loss: 0.000315\n",
      " Loss: 0.061951\n",
      "Epoch 540 Chain 0 loss std 9.57e-01 variance 4.58e-01 smooth variance 2.71e+00 adaptive c -1.00\n",
      "Epoch 540 Chain 1 loss std 5.17e+02 variance 1.34e+05 smooth variance 1.14e+05 adaptive c -1.00\n",
      " Loss: 0.000364\n",
      " Loss: 0.088615\n",
      " Loss: 0.000213\n",
      " Loss: 0.097632\n",
      " Loss: 0.000595\n",
      " Loss: 0.052385\n",
      " Loss: 0.000374\n",
      " Loss: 0.182442\n",
      " Loss: 0.000559\n",
      " Loss: 0.123287\n",
      " Loss: 0.000293\n",
      " Loss: 0.106107\n",
      " Loss: 0.000622\n",
      " Loss: 0.059745\n",
      " Loss: 0.000200\n",
      " Loss: 0.108006\n",
      " Loss: 0.000586\n",
      " Loss: 0.088473\n",
      " Loss: 0.000329\n",
      " Loss: 0.180605\n",
      "Epoch 542 Chain 0 loss std 1.23e+00 variance 7.54e-01 smooth variance 2.12e+00 adaptive c -1.00\n",
      "Epoch 542 Chain 1 loss std 4.80e+02 variance 1.15e+05 smooth variance 1.14e+05 adaptive c -1.00\n",
      " Loss: 0.000393\n",
      " Loss: 0.114026\n",
      " Loss: 0.000220\n",
      " Loss: 0.214395\n",
      " Loss: 0.000275\n",
      " Loss: 0.085889\n",
      " Loss: 0.000627\n",
      " Loss: 0.065493\n",
      " Loss: 0.000361\n",
      " Loss: 0.061641\n",
      " Loss: 0.000304\n",
      " Loss: 0.220125\n",
      " Loss: 0.000187\n",
      " Loss: 0.112370\n",
      " Loss: 0.000267\n",
      " Loss: 0.076338\n",
      " Loss: 0.000865\n",
      " Loss: 0.052185\n",
      " Loss: 0.000182\n",
      " Loss: 0.078951\n",
      "Epoch 544 Chain 0 loss std 9.86e-01 variance 4.86e-01 smooth variance 1.63e+00 adaptive c -1.00\n",
      "Epoch 544 Chain 1 loss std 2.70e+02 variance 3.65e+04 smooth variance 9.08e+04 adaptive c -1.00\n",
      " Loss: 0.000399\n",
      " Loss: 0.167112\n",
      " Loss: 0.000169\n",
      " Loss: 0.121268\n",
      " Loss: 0.000248\n",
      " Loss: 0.122690\n",
      " Loss: 0.000358\n",
      " Loss: 0.052571\n",
      " Loss: 0.000660\n",
      " Loss: 0.074798\n",
      " Loss: 0.000620\n",
      " Loss: 0.147377\n",
      " Loss: 0.000291\n",
      " Loss: 0.104699\n",
      " Loss: 0.000334\n",
      " Loss: 0.082553\n",
      " Loss: 0.000289\n",
      " Loss: 0.100447\n",
      " Loss: 0.000212\n",
      " Loss: 0.101919\n",
      "Epoch 546 Chain 0 loss std 9.47e-01 variance 4.49e-01 smooth variance 1.28e+00 adaptive c -1.00\n",
      "Epoch 546 Chain 1 loss std 6.08e+02 variance 1.85e+05 smooth variance 1.19e+05 adaptive c -1.00\n",
      " Loss: 0.000118\n",
      " Loss: 0.100948\n",
      " Loss: 0.000277\n",
      " Loss: 0.178081\n",
      " Loss: 0.000616\n",
      " Loss: 0.055586\n",
      " Loss: 0.000543\n",
      " Loss: 0.103796\n",
      " Loss: 0.000114\n",
      " Loss: 0.097216\n",
      " Loss: 0.000164\n",
      " Loss: 0.158963\n",
      " Loss: 0.000187\n",
      " Loss: 0.159993\n",
      " Loss: 0.000415\n",
      " Loss: 0.082511\n",
      " Loss: 0.000487\n",
      " Loss: 0.068369\n",
      " Loss: 0.000393\n",
      " Loss: 0.064294\n",
      "Epoch 548 Chain 0 loss std 1.64e+00 variance 1.34e+00 smooth variance 1.30e+00 adaptive c -1.00\n",
      "Epoch 548 Chain 1 loss std 2.84e+02 variance 4.03e+04 smooth variance 9.54e+04 adaptive c -1.00\n",
      " Loss: 0.000416\n",
      " Loss: 0.065398\n",
      " Loss: 0.000518\n",
      " Loss: 0.095450\n",
      " Loss: 0.000261\n",
      " Loss: 0.185765\n",
      " Loss: 0.000267\n",
      " Loss: 0.092396\n",
      " Loss: 0.000151\n",
      " Loss: 0.093953\n",
      " Loss: 0.000121\n",
      " Loss: 0.116975\n",
      " Loss: 0.000189\n",
      " Loss: 0.078104\n",
      " Loss: 0.000501\n",
      " Loss: 0.073121\n",
      " Loss: 0.000493\n",
      " Loss: 0.100791\n",
      " Loss: 0.000295\n",
      " Loss: 0.163244\n",
      "Epoch 550 Chain 0 loss std 1.28e+00 variance 8.18e-01 smooth variance 1.15e+00 adaptive c -1.00\n",
      "Epoch 550 Chain 1 loss std 2.35e+02 variance 2.77e+04 smooth variance 7.51e+04 adaptive c -1.00\n",
      " Loss: 0.000366\n",
      " Loss: 0.095157\n",
      " Loss: 0.000348\n",
      " Loss: 0.172932\n",
      " Loss: 0.000209\n",
      " Loss: 0.053991\n",
      " Loss: 0.000439\n",
      " Loss: 0.092742\n",
      " Loss: 0.000229\n",
      " Loss: 0.115283\n",
      " Loss: 0.000161\n",
      " Loss: 0.088633\n",
      " Loss: 0.000239\n",
      " Loss: 0.085029\n",
      " Loss: 0.000484\n",
      " Loss: 0.074701\n",
      " Loss: 0.000249\n",
      " Loss: 0.068704\n",
      " Loss: 0.000418\n",
      " Loss: 0.211889\n",
      "Epoch 552 Chain 0 loss std 1.72e+00 variance 1.47e+00 smooth variance 1.25e+00 adaptive c -1.00\n",
      "Epoch 552 Chain 1 loss std 3.43e+02 variance 5.87e+04 smooth variance 7.02e+04 adaptive c -1.00\n",
      " Loss: 0.000165\n",
      " Loss: 0.066675\n",
      " Loss: 0.000342\n",
      " Loss: 0.084808\n",
      " Loss: 0.000223\n",
      " Loss: 0.174230\n",
      " Loss: 0.000562\n",
      " Loss: 0.070707\n",
      " Loss: 0.000147\n",
      " Loss: 0.130968\n",
      " Loss: 0.000106\n",
      " Loss: 0.180497\n",
      " Loss: 0.000168\n",
      " Loss: 0.104150\n",
      " Loss: 0.000334\n",
      " Loss: 0.074815\n",
      " Loss: 0.000517\n",
      " Loss: 0.099654\n",
      " Loss: 0.000237\n",
      " Loss: 0.066836\n",
      "Epoch 554 Chain 0 loss std 1.09e+00 variance 5.97e-01 smooth variance 1.05e+00 adaptive c -1.00\n",
      "Epoch 554 Chain 1 loss std 5.68e+02 variance 1.61e+05 smooth variance 9.75e+04 adaptive c -1.00\n",
      " Loss: 0.000196\n",
      " Loss: 0.124229\n",
      " Loss: 0.000277\n",
      " Loss: 0.141084\n",
      " Loss: 0.000185\n",
      " Loss: 0.083668\n",
      " Loss: 0.000271\n",
      " Loss: 0.100104\n",
      " Loss: 0.000412\n",
      " Loss: 0.075715\n",
      " Loss: 0.000128\n",
      " Loss: 0.124252\n",
      " Loss: 0.000166\n",
      " Loss: 0.105093\n",
      " Loss: 0.000108\n",
      " Loss: 0.093894\n",
      " Loss: 0.000352\n",
      " Loss: 0.136622\n",
      " Loss: 0.000560\n",
      " Loss: 0.063305\n",
      "Epoch 556 Chain 0 loss std 1.45e+00 variance 1.06e+00 smooth variance 1.05e+00 adaptive c -1.00\n",
      "Epoch 556 Chain 1 loss std 4.56e+02 variance 1.04e+05 smooth variance 9.94e+04 adaptive c -1.00\n",
      " Loss: 0.000174\n",
      " Loss: 0.078014\n",
      " Loss: 0.000105\n",
      " Loss: 0.120661\n",
      " Loss: 0.000299\n",
      " Loss: 0.093469\n",
      " Loss: 0.000195\n",
      " Loss: 0.168061\n",
      " Loss: 0.000492\n",
      " Loss: 0.061514\n",
      " Loss: 0.000078\n",
      " Loss: 0.120790\n",
      " Loss: 0.000398\n",
      " Loss: 0.063960\n",
      " Loss: 0.000209\n",
      " Loss: 0.083951\n",
      " Loss: 0.000218\n",
      " Loss: 0.152343\n",
      " Loss: 0.000404\n",
      " Loss: 0.099232\n",
      "Epoch 558 Chain 0 loss std 9.45e-01 variance 4.46e-01 smooth variance 8.72e-01 adaptive c -1.00\n",
      "Epoch 558 Chain 1 loss std 2.47e+02 variance 3.04e+04 smooth variance 7.87e+04 adaptive c -1.00\n",
      " Loss: 0.000168\n",
      " Loss: 0.165497\n",
      " Loss: 0.000294\n",
      " Loss: 0.111498\n",
      " Loss: 0.000463\n",
      " Loss: 0.069844\n",
      " Loss: 0.000141\n",
      " Loss: 0.076250\n",
      " Loss: 0.000157\n",
      " Loss: 0.096276\n",
      " Loss: 0.000173\n",
      " Loss: 0.082990\n",
      " Loss: 0.000266\n",
      " Loss: 0.184922\n",
      " Loss: 0.000129\n",
      " Loss: 0.080913\n",
      " Loss: 0.000345\n",
      " Loss: 0.080982\n",
      " Loss: 0.000281\n",
      " Loss: 0.087857\n",
      "Epoch 560 Chain 0 loss std 1.41e+00 variance 9.88e-01 smooth variance 9.07e-01 adaptive c -1.00\n",
      "Epoch 560 Chain 1 loss std 6.02e+02 variance 1.81e+05 smooth variance 1.10e+05 adaptive c -1.00\n",
      " Loss: 0.000296\n",
      " Loss: 0.102021\n",
      " Loss: 0.000202\n",
      " Loss: 0.103459\n",
      " Loss: 0.000360\n",
      " Loss: 0.051327\n",
      " Loss: 0.000161\n",
      " Loss: 0.072676\n",
      " Loss: 0.000166\n",
      " Loss: 0.186805\n",
      " Loss: 0.000159\n",
      " Loss: 0.125038\n",
      " Loss: 0.000191\n",
      " Loss: 0.058607\n",
      " Loss: 0.000503\n",
      " Loss: 0.180873\n",
      " Loss: 0.000151\n",
      " Loss: 0.082615\n",
      " Loss: 0.000141\n",
      " Loss: 0.067664\n",
      "Epoch 562 Chain 0 loss std 1.37e+00 variance 9.37e-01 smooth variance 9.16e-01 adaptive c -1.00\n",
      "Epoch 562 Chain 1 loss std 5.56e+02 variance 1.55e+05 smooth variance 1.23e+05 adaptive c -1.00\n",
      " Loss: 0.000144\n",
      " Loss: 0.187570\n",
      " Loss: 0.000361\n",
      " Loss: 0.077116\n",
      " Loss: 0.000219\n",
      " Loss: 0.100558\n",
      " Loss: 0.000126\n",
      " Loss: 0.091860\n",
      " Loss: 0.000310\n",
      " Loss: 0.056379\n",
      " Loss: 0.000111\n",
      " Loss: 0.096788\n",
      " Loss: 0.000207\n",
      " Loss: 0.069139\n",
      " Loss: 0.000329\n",
      " Loss: 0.165996\n",
      " Loss: 0.000260\n",
      " Loss: 0.114508\n",
      " Loss: 0.000183\n",
      " Loss: 0.065991\n",
      "Epoch 564 Chain 0 loss std 1.18e+00 variance 6.91e-01 smooth variance 8.49e-01 adaptive c -1.00\n",
      "Epoch 564 Chain 1 loss std 4.30e+02 variance 9.26e+04 smooth variance 1.14e+05 adaptive c -1.00\n",
      " Loss: 0.000354\n",
      " Loss: 0.045804\n",
      " Loss: 0.000323\n",
      " Loss: 0.108247\n",
      " Loss: 0.000188\n",
      " Loss: 0.164024\n",
      " Loss: 0.000081\n",
      " Loss: 0.080372\n",
      " Loss: 0.000124\n",
      " Loss: 0.112334\n",
      " Loss: 0.000146\n",
      " Loss: 0.151677\n",
      " Loss: 0.000472\n",
      " Loss: 0.070327\n",
      " Loss: 0.000172\n",
      " Loss: 0.081749\n",
      " Loss: 0.000110\n",
      " Loss: 0.122492\n",
      " Loss: 0.000136\n",
      " Loss: 0.083550\n",
      "Epoch 566 Chain 0 loss std 1.38e+00 variance 9.58e-01 smooth variance 8.81e-01 adaptive c -1.00\n",
      "Epoch 566 Chain 1 loss std 5.62e+02 variance 1.58e+05 smooth variance 1.27e+05 adaptive c -1.00\n",
      " Loss: 0.000120\n",
      " Loss: 0.058254\n",
      " Loss: 0.000148\n",
      " Loss: 0.107323\n",
      " Loss: 0.000356\n",
      " Loss: 0.068772\n",
      " Loss: 0.000279\n",
      " Loss: 0.100993\n",
      " Loss: 0.000111\n",
      " Loss: 0.173169\n",
      " Loss: 0.000125\n",
      " Loss: 0.086127\n",
      " Loss: 0.000184\n",
      " Loss: 0.184225\n",
      " Loss: 0.000320\n",
      " Loss: 0.108057\n",
      " Loss: 0.000275\n",
      " Loss: 0.060708\n",
      " Loss: 0.000124\n",
      " Loss: 0.068103\n",
      "Epoch 568 Chain 0 loss std 1.17e+00 variance 6.86e-01 smooth variance 8.23e-01 adaptive c -1.00\n",
      "Epoch 568 Chain 1 loss std 3.20e+02 variance 5.13e+04 smooth variance 1.04e+05 adaptive c -1.00\n",
      " Loss: 0.000104\n",
      " Loss: 0.055105\n",
      " Loss: 0.000303\n",
      " Loss: 0.163182\n",
      " Loss: 0.000141\n",
      " Loss: 0.122039\n",
      " Loss: 0.000144\n",
      " Loss: 0.088093\n",
      " Loss: 0.000335\n",
      " Loss: 0.077407\n",
      " Loss: 0.000379\n",
      " Loss: 0.086126\n",
      " Loss: 0.000287\n",
      " Loss: 0.055230\n",
      " Loss: 0.000059\n",
      " Loss: 0.202739\n",
      " Loss: 0.000133\n",
      " Loss: 0.094400\n",
      " Loss: 0.000161\n",
      " Loss: 0.066067\n",
      "Epoch 570 Chain 0 loss std 1.15e+00 variance 6.63e-01 smooth variance 7.75e-01 adaptive c -1.00\n",
      "Epoch 570 Chain 1 loss std 4.60e+02 variance 1.06e+05 smooth variance 1.05e+05 adaptive c -1.00\n",
      " Loss: 0.000123\n",
      " Loss: 0.116658\n",
      " Loss: 0.000292\n",
      " Loss: 0.055160\n",
      " Loss: 0.000158\n",
      " Loss: 0.064685\n",
      " Loss: 0.000300\n",
      " Loss: 0.092677\n",
      " Loss: 0.000120\n",
      " Loss: 0.174560\n",
      " Loss: 0.000315\n",
      " Loss: 0.112276\n",
      " Loss: 0.000085\n",
      " Loss: 0.142607\n",
      " Loss: 0.000301\n",
      " Loss: 0.079586\n",
      " Loss: 0.000158\n",
      " Loss: 0.078997\n",
      " Loss: 0.000119\n",
      " Loss: 0.088698\n",
      "Epoch 572 Chain 0 loss std 8.06e-01 variance 3.25e-01 smooth variance 6.40e-01 adaptive c -1.00\n",
      "Epoch 572 Chain 1 loss std 3.76e+02 variance 7.05e+04 smooth variance 9.46e+04 adaptive c -1.00\n",
      " Loss: 0.000311\n",
      " Loss: 0.063371\n",
      " Loss: 0.000124\n",
      " Loss: 0.175249\n",
      " Loss: 0.000298\n",
      " Loss: 0.091913\n",
      " Loss: 0.000099\n",
      " Loss: 0.081596\n",
      " Loss: 0.000130\n",
      " Loss: 0.088960\n",
      " Loss: 0.000184\n",
      " Loss: 0.064877\n",
      " Loss: 0.000100\n",
      " Loss: 0.119733\n",
      " Loss: 0.000425\n",
      " Loss: 0.050220\n",
      " Loss: 0.000116\n",
      " Loss: 0.093156\n",
      " Loss: 0.000094\n",
      " Loss: 0.171708\n",
      "Epoch 574 Chain 0 loss std 1.24e+00 variance 7.69e-01 smooth variance 6.78e-01 adaptive c -1.00\n",
      "Epoch 574 Chain 1 loss std 4.36e+02 variance 9.50e+04 smooth variance 9.47e+04 adaptive c -1.00\n",
      " Loss: 0.000131\n",
      " Loss: 0.073332\n",
      " Loss: 0.000132\n",
      " Loss: 0.078776\n",
      " Loss: 0.000192\n",
      " Loss: 0.103784\n",
      " Loss: 0.000158\n",
      " Loss: 0.192992\n",
      " Loss: 0.000321\n",
      " Loss: 0.049501\n",
      " Loss: 0.000177\n",
      " Loss: 0.103697\n",
      " Loss: 0.000105\n",
      " Loss: 0.177217\n",
      " Loss: 0.000133\n",
      " Loss: 0.052580\n",
      " Loss: 0.000300\n",
      " Loss: 0.101284\n",
      " Loss: 0.000172\n",
      " Loss: 0.062766\n",
      "Epoch 576 Chain 0 loss std 1.21e+00 variance 7.31e-01 smooth variance 6.94e-01 adaptive c -1.00\n",
      "Epoch 576 Chain 1 loss std 4.05e+02 variance 8.20e+04 smooth variance 9.09e+04 adaptive c -1.00\n",
      " Loss: 0.000207\n",
      " Loss: 0.182251\n",
      " Loss: 0.000176\n",
      " Loss: 0.095191\n",
      " Loss: 0.000100\n",
      " Loss: 0.075215\n",
      " Loss: 0.000078\n",
      " Loss: 0.099514\n",
      " Loss: 0.000341\n",
      " Loss: 0.044383\n",
      " Loss: 0.000098\n",
      " Loss: 0.070721\n",
      " Loss: 0.000166\n",
      " Loss: 0.117272\n",
      " Loss: 0.000253\n",
      " Loss: 0.064639\n",
      " Loss: 0.000207\n",
      " Loss: 0.048997\n",
      " Loss: 0.000130\n",
      " Loss: 0.193233\n",
      "Epoch 578 Chain 0 loss std 1.11e+00 variance 6.12e-01 smooth variance 6.70e-01 adaptive c -1.00\n",
      "Epoch 578 Chain 1 loss std 2.70e+02 variance 3.65e+04 smooth variance 7.46e+04 adaptive c -1.00\n",
      " Loss: 0.000172\n",
      " Loss: 0.070440\n",
      " Loss: 0.000057\n",
      " Loss: 0.077100\n",
      " Loss: 0.000410\n",
      " Loss: 0.115065\n",
      " Loss: 0.000065\n",
      " Loss: 0.098141\n",
      " Loss: 0.000113\n",
      " Loss: 0.132739\n",
      " Loss: 0.000050\n",
      " Loss: 0.075240\n",
      " Loss: 0.000193\n",
      " Loss: 0.049931\n",
      " Loss: 0.000297\n",
      " Loss: 0.096990\n",
      " Loss: 0.000136\n",
      " Loss: 0.153246\n",
      " Loss: 0.000127\n",
      " Loss: 0.116863\n",
      "Epoch 580 Chain 0 loss std 1.22e+00 variance 7.42e-01 smooth variance 6.91e-01 adaptive c -1.00\n",
      "Epoch 580 Chain 1 loss std 5.20e+02 variance 1.35e+05 smooth variance 9.28e+04 adaptive c -1.00\n",
      " Loss: 0.000180\n",
      " Loss: 0.196283\n",
      " Loss: 0.000140\n",
      " Loss: 0.071250\n",
      " Loss: 0.000104\n",
      " Loss: 0.084225\n",
      " Loss: 0.000331\n",
      " Loss: 0.052207\n",
      " Loss: 0.000050\n",
      " Loss: 0.087743\n",
      " Loss: 0.000106\n",
      " Loss: 0.076007\n",
      " Loss: 0.000114\n",
      " Loss: 0.058464\n",
      " Loss: 0.000112\n",
      " Loss: 0.072981\n",
      " Loss: 0.000292\n",
      " Loss: 0.162728\n",
      " Loss: 0.000132\n",
      " Loss: 0.119585\n",
      "Epoch 582 Chain 0 loss std 6.99e-01 variance 2.44e-01 smooth variance 5.57e-01 adaptive c -1.00\n",
      "Epoch 582 Chain 1 loss std 3.89e+02 variance 7.55e+04 smooth variance 8.76e+04 adaptive c -1.00\n",
      " Loss: 0.000084\n",
      " Loss: 0.053939\n",
      " Loss: 0.000334\n",
      " Loss: 0.086933\n",
      " Loss: 0.000087\n",
      " Loss: 0.142214\n",
      " Loss: 0.000192\n",
      " Loss: 0.099324\n",
      " Loss: 0.000071\n",
      " Loss: 0.106459\n",
      " Loss: 0.000227\n",
      " Loss: 0.187591\n",
      " Loss: 0.000205\n",
      " Loss: 0.080733\n",
      " Loss: 0.000118\n",
      " Loss: 0.050126\n",
      " Loss: 0.000097\n",
      " Loss: 0.062081\n",
      " Loss: 0.000088\n",
      " Loss: 0.107453\n",
      "Epoch 584 Chain 0 loss std 1.01e+00 variance 5.09e-01 smooth variance 5.43e-01 adaptive c -1.00\n",
      "Epoch 584 Chain 1 loss std 4.01e+02 variance 8.05e+04 smooth variance 8.55e+04 adaptive c -1.00\n",
      " Loss: 0.000256\n",
      " Loss: 0.075060\n",
      " Loss: 0.000132\n",
      " Loss: 0.094176\n",
      " Loss: 0.000076\n",
      " Loss: 0.147770\n",
      " Loss: 0.000074\n",
      " Loss: 0.068876\n",
      " Loss: 0.000195\n",
      " Loss: 0.100700\n",
      " Loss: 0.000107\n",
      " Loss: 0.087548\n",
      " Loss: 0.000119\n",
      " Loss: 0.067783\n",
      " Loss: 0.000070\n",
      " Loss: 0.098273\n",
      " Loss: 0.000161\n",
      " Loss: 0.086889\n",
      " Loss: 0.000281\n",
      " Loss: 0.145122\n",
      "Epoch 586 Chain 0 loss std 8.90e-01 variance 3.96e-01 smooth variance 4.99e-01 adaptive c -1.00\n",
      "Epoch 586 Chain 1 loss std 2.33e+02 variance 2.72e+04 smooth variance 6.80e+04 adaptive c -1.00\n",
      " Loss: 0.000200\n",
      " Loss: 0.120081\n",
      " Loss: 0.000126\n",
      " Loss: 0.078166\n",
      " Loss: 0.000081\n",
      " Loss: 0.088814\n",
      " Loss: 0.000257\n",
      " Loss: 0.093000\n",
      " Loss: 0.000074\n",
      " Loss: 0.104176\n",
      " Loss: 0.000238\n",
      " Loss: 0.057802\n",
      " Loss: 0.000085\n",
      " Loss: 0.080842\n",
      " Loss: 0.000074\n",
      " Loss: 0.093456\n",
      " Loss: 0.000205\n",
      " Loss: 0.092345\n",
      " Loss: 0.000124\n",
      " Loss: 0.158523\n",
      "Epoch 588 Chain 0 loss std 7.59e-01 variance 2.88e-01 smooth variance 4.35e-01 adaptive c -1.00\n",
      "Epoch 588 Chain 1 loss std 2.92e+02 variance 4.27e+04 smooth variance 6.04e+04 adaptive c -1.00\n",
      " Loss: 0.000162\n",
      " Loss: 0.081726\n",
      " Loss: 0.000102\n",
      " Loss: 0.048992\n",
      " Loss: 0.000261\n",
      " Loss: 0.118107\n",
      " Loss: 0.000103\n",
      " Loss: 0.076015\n",
      " Loss: 0.000067\n",
      " Loss: 0.156931\n",
      " Loss: 0.000167\n",
      " Loss: 0.074323\n",
      " Loss: 0.000060\n",
      " Loss: 0.167330\n",
      " Loss: 0.000095\n",
      " Loss: 0.076471\n",
      " Loss: 0.000289\n",
      " Loss: 0.097356\n",
      " Loss: 0.000067\n",
      " Loss: 0.065374\n",
      "Epoch 590 Chain 0 loss std 7.06e-01 variance 2.49e-01 smooth variance 3.80e-01 adaptive c -1.00\n",
      "Epoch 590 Chain 1 loss std 3.08e+02 variance 4.73e+04 smooth variance 5.65e+04 adaptive c -1.00\n",
      " Loss: 0.000087\n",
      " Loss: 0.139636\n",
      " Loss: 0.000084\n",
      " Loss: 0.080464\n",
      " Loss: 0.000086\n",
      " Loss: 0.081902\n",
      " Loss: 0.000319\n",
      " Loss: 0.032868\n",
      " Loss: 0.000097\n",
      " Loss: 0.145109\n",
      " Loss: 0.000104\n",
      " Loss: 0.161184\n",
      " Loss: 0.000213\n",
      " Loss: 0.086998\n",
      " Loss: 0.000069\n",
      " Loss: 0.045386\n",
      " Loss: 0.000183\n",
      " Loss: 0.092935\n",
      " Loss: 0.000103\n",
      " Loss: 0.092850\n",
      "Epoch 592 Chain 0 loss std 8.33e-01 variance 3.47e-01 smooth variance 3.70e-01 adaptive c -1.00\n",
      "Epoch 592 Chain 1 loss std 4.07e+02 variance 8.27e+04 smooth variance 6.44e+04 adaptive c -1.00\n",
      " Loss: 0.000055\n",
      " Loss: 0.069091\n",
      " Loss: 0.000204\n",
      " Loss: 0.076042\n",
      " Loss: 0.000240\n",
      " Loss: 0.109317\n",
      " Loss: 0.000050\n",
      " Loss: 0.173096\n",
      " Loss: 0.000095\n",
      " Loss: 0.050227\n",
      " Loss: 0.000116\n",
      " Loss: 0.162215\n",
      " Loss: 0.000054\n",
      " Loss: 0.108724\n",
      " Loss: 0.000218\n",
      " Loss: 0.047297\n",
      " Loss: 0.000169\n",
      " Loss: 0.086485\n",
      " Loss: 0.000073\n",
      " Loss: 0.071892\n",
      "Epoch 594 Chain 0 loss std 6.54e-01 variance 2.14e-01 smooth variance 3.23e-01 adaptive c -1.00\n",
      "Epoch 594 Chain 1 loss std 4.06e+02 variance 8.24e+04 smooth variance 6.98e+04 adaptive c -1.00\n",
      " Loss: 0.000051\n",
      " Loss: 0.102065\n",
      " Loss: 0.000164\n",
      " Loss: 0.052014\n",
      " Loss: 0.000260\n",
      " Loss: 0.061440\n",
      " Loss: 0.000068\n",
      " Loss: 0.180549\n",
      " Loss: 0.000079\n",
      " Loss: 0.079153\n",
      " Loss: 0.000071\n",
      " Loss: 0.082060\n",
      " Loss: 0.000128\n",
      " Loss: 0.097151\n",
      " Loss: 0.000210\n",
      " Loss: 0.161576\n",
      " Loss: 0.000084\n",
      " Loss: 0.085191\n",
      " Loss: 0.000119\n",
      " Loss: 0.048277\n",
      "Epoch 596 Chain 0 loss std 8.90e-01 variance 3.96e-01 smooth variance 3.45e-01 adaptive c -1.00\n",
      "Epoch 596 Chain 1 loss std 5.36e+02 variance 1.44e+05 smooth variance 9.19e+04 adaptive c -1.00\n",
      " Loss: 0.000086\n",
      " Loss: 0.071893\n",
      " Loss: 0.000213\n",
      " Loss: 0.105709\n",
      " Loss: 0.000092\n",
      " Loss: 0.072510\n",
      " Loss: 0.000076\n",
      " Loss: 0.134335\n",
      " Loss: 0.000151\n",
      " Loss: 0.088703\n",
      " Loss: 0.000162\n",
      " Loss: 0.089655\n",
      " Loss: 0.000054\n",
      " Loss: 0.058882\n",
      " Loss: 0.000060\n",
      " Loss: 0.090562\n",
      " Loss: 0.000053\n",
      " Loss: 0.076630\n",
      " Loss: 0.000277\n",
      " Loss: 0.156368\n",
      "Epoch 598 Chain 0 loss std 1.07e+00 variance 5.73e-01 smooth variance 4.13e-01 adaptive c -1.00\n",
      "Epoch 598 Chain 1 loss std 3.89e+02 variance 7.55e+04 smooth variance 8.70e+04 adaptive c -1.00\n",
      " Loss: 0.000259\n",
      " Loss: 0.082571\n",
      " Loss: 0.000058\n",
      " Loss: 0.166630\n",
      " Loss: 0.000047\n",
      " Loss: 0.079239\n",
      " Loss: 0.000141\n",
      " Loss: 0.051853\n",
      " Loss: 0.000058\n",
      " Loss: 0.090559\n",
      " Loss: 0.000069\n",
      " Loss: 0.071039\n",
      " Loss: 0.000147\n",
      " Loss: 0.059696\n",
      " Loss: 0.000049\n",
      " Loss: 0.108791\n",
      " Loss: 0.000194\n",
      " Loss: 0.100801\n",
      " Loss: 0.000091\n",
      " Loss: 0.129685\n",
      "Epoch 600 Chain 0 loss std 7.39e-01 variance 2.73e-01 smooth variance 3.71e-01 adaptive c -1.00\n",
      "Epoch 600 Chain 1 loss std 4.04e+02 variance 8.15e+04 smooth variance 8.54e+04 adaptive c -1.00\n",
      " Loss: 0.000038\n",
      " Loss: 0.053238\n",
      " Loss: 0.000070\n",
      " Loss: 0.102362\n",
      " Loss: 0.000124\n",
      " Loss: 0.080969\n",
      " Loss: 0.000220\n",
      " Loss: 0.161558\n",
      " Loss: 0.000070\n",
      " Loss: 0.070620\n",
      " Loss: 0.000058\n",
      " Loss: 0.147476\n",
      " Loss: 0.000284\n",
      " Loss: 0.058556\n",
      " Loss: 0.000035\n",
      " Loss: 0.049297\n",
      " Loss: 0.000041\n",
      " Loss: 0.110861\n",
      " Loss: 0.000085\n",
      " Loss: 0.101439\n",
      "Epoch 602 Chain 0 loss std 6.31e-01 variance 1.99e-01 smooth variance 3.20e-01 adaptive c -1.00\n",
      "Epoch 602 Chain 1 loss std 2.88e+02 variance 4.16e+04 smooth variance 7.22e+04 adaptive c -1.00\n",
      " Loss: 0.000125\n",
      " Loss: 0.089324\n",
      " Loss: 0.000042\n",
      " Loss: 0.069431\n",
      " Loss: 0.000210\n",
      " Loss: 0.076279\n",
      " Loss: 0.000067\n",
      " Loss: 0.140830\n",
      " Loss: 0.000059\n",
      " Loss: 0.090787\n",
      " Loss: 0.000072\n",
      " Loss: 0.055581\n",
      " Loss: 0.000044\n",
      " Loss: 0.095708\n",
      " Loss: 0.000048\n",
      " Loss: 0.101345\n",
      " Loss: 0.000184\n",
      " Loss: 0.167362\n",
      " Loss: 0.000146\n",
      " Loss: 0.045525\n",
      "Epoch 604 Chain 0 loss std 4.93e-01 variance 1.21e-01 smooth variance 2.60e-01 adaptive c -1.00\n",
      "Epoch 604 Chain 1 loss std 4.29e+02 variance 9.22e+04 smooth variance 7.82e+04 adaptive c -1.00\n",
      " Loss: 0.000054\n",
      " Loss: 0.053582\n",
      " Loss: 0.000178\n",
      " Loss: 0.104326\n",
      " Loss: 0.000065\n",
      " Loss: 0.044944\n",
      " Loss: 0.000157\n",
      " Loss: 0.086556\n",
      " Loss: 0.000038\n",
      " Loss: 0.175129\n",
      " Loss: 0.000077\n",
      " Loss: 0.156112\n",
      " Loss: 0.000242\n",
      " Loss: 0.047872\n",
      " Loss: 0.000045\n",
      " Loss: 0.083993\n",
      " Loss: 0.000063\n",
      " Loss: 0.058863\n",
      " Loss: 0.000040\n",
      " Loss: 0.116390\n",
      "Epoch 606 Chain 0 loss std 5.11e-01 variance 1.30e-01 smooth variance 2.21e-01 adaptive c -1.00\n",
      "Epoch 606 Chain 1 loss std 5.51e+02 variance 1.52e+05 smooth variance 1.00e+05 adaptive c -1.00\n",
      " Loss: 0.000058\n",
      " Loss: 0.077684\n",
      " Loss: 0.000116\n",
      " Loss: 0.154242\n",
      " Loss: 0.000061\n",
      " Loss: 0.083191\n",
      " Loss: 0.000160\n",
      " Loss: 0.072979\n",
      " Loss: 0.000080\n",
      " Loss: 0.074072\n",
      " Loss: 0.000174\n",
      " Loss: 0.082685\n",
      " Loss: 0.000121\n",
      " Loss: 0.064324\n",
      " Loss: 0.000069\n",
      " Loss: 0.070195\n",
      " Loss: 0.000056\n",
      " Loss: 0.084076\n",
      " Loss: 0.000042\n",
      " Loss: 0.160066\n",
      "Epoch 608 Chain 0 loss std 7.91e-01 variance 3.13e-01 smooth variance 2.49e-01 adaptive c -1.00\n",
      "Epoch 608 Chain 1 loss std 2.68e+02 variance 3.59e+04 smooth variance 8.10e+04 adaptive c -1.00\n",
      " Loss: 0.000146\n",
      " Loss: 0.164248\n",
      " Loss: 0.000137\n",
      " Loss: 0.050033\n",
      " Loss: 0.000050\n",
      " Loss: 0.050598\n",
      " Loss: 0.000068\n",
      " Loss: 0.081334\n",
      " Loss: 0.000043\n",
      " Loss: 0.113785\n",
      " Loss: 0.000037\n",
      " Loss: 0.176029\n",
      " Loss: 0.000067\n",
      " Loss: 0.091169\n",
      " Loss: 0.000031\n",
      " Loss: 0.044113\n",
      " Loss: 0.000237\n",
      " Loss: 0.059468\n",
      " Loss: 0.000056\n",
      " Loss: 0.088297\n",
      "Epoch 610 Chain 0 loss std 7.58e-01 variance 2.87e-01 smooth variance 2.60e-01 adaptive c -1.00\n",
      "Epoch 610 Chain 1 loss std 3.22e+02 variance 5.20e+04 smooth variance 7.23e+04 adaptive c -1.00\n",
      " Loss: 0.000035\n",
      " Loss: 0.106380\n",
      " Loss: 0.000066\n",
      " Loss: 0.059763\n",
      " Loss: 0.000143\n",
      " Loss: 0.144841\n",
      " Loss: 0.000033\n",
      " Loss: 0.087053\n",
      " Loss: 0.000140\n",
      " Loss: 0.060254\n",
      " Loss: 0.000051\n",
      " Loss: 0.056840\n",
      " Loss: 0.000148\n",
      " Loss: 0.147466\n",
      " Loss: 0.000050\n",
      " Loss: 0.111866\n",
      " Loss: 0.000049\n",
      " Loss: 0.061739\n",
      " Loss: 0.000117\n",
      " Loss: 0.078991\n",
      "Epoch 612 Chain 0 loss std 3.95e-01 variance 7.81e-02 smooth variance 2.06e-01 adaptive c -1.00\n",
      "Epoch 612 Chain 1 loss std 3.47e+02 variance 6.03e+04 smooth variance 6.87e+04 adaptive c -1.00\n",
      " Loss: 0.000046\n",
      " Loss: 0.157557\n",
      " Loss: 0.000047\n",
      " Loss: 0.059628\n",
      " Loss: 0.000039\n",
      " Loss: 0.106030\n",
      " Loss: 0.000135\n",
      " Loss: 0.067137\n",
      " Loss: 0.000144\n",
      " Loss: 0.065893\n",
      " Loss: 0.000047\n",
      " Loss: 0.080015\n",
      " Loss: 0.000042\n",
      " Loss: 0.084117\n",
      " Loss: 0.000135\n",
      " Loss: 0.087338\n",
      " Loss: 0.000136\n",
      " Loss: 0.055276\n",
      " Loss: 0.000039\n",
      " Loss: 0.148382\n",
      "Epoch 614 Chain 0 loss std 7.92e-01 variance 3.13e-01 smooth variance 2.38e-01 adaptive c -1.00\n",
      "Epoch 614 Chain 1 loss std 6.50e+02 variance 2.11e+05 smooth variance 1.11e+05 adaptive c -1.00\n",
      " Loss: 0.000030\n",
      " Loss: 0.056439\n",
      " Loss: 0.000049\n",
      " Loss: 0.093489\n",
      " Loss: 0.000154\n",
      " Loss: 0.054681\n",
      " Loss: 0.000101\n",
      " Loss: 0.094502\n",
      " Loss: 0.000059\n",
      " Loss: 0.155007\n",
      " Loss: 0.000102\n",
      " Loss: 0.108739\n",
      " Loss: 0.000030\n",
      " Loss: 0.080405\n",
      " Loss: 0.000050\n",
      " Loss: 0.078191\n",
      " Loss: 0.000050\n",
      " Loss: 0.056347\n",
      " Loss: 0.000172\n",
      " Loss: 0.129396\n",
      "Epoch 616 Chain 0 loss std 5.19e-01 variance 1.35e-01 smooth variance 2.07e-01 adaptive c -1.00\n",
      "Epoch 616 Chain 1 loss std 2.71e+02 variance 3.67e+04 smooth variance 8.90e+04 adaptive c -1.00\n",
      " Loss: 0.000060\n",
      " Loss: 0.084875\n",
      " Loss: 0.000086\n",
      " Loss: 0.105806\n",
      " Loss: 0.000153\n",
      " Loss: 0.052192\n",
      " Loss: 0.000052\n",
      " Loss: 0.122695\n",
      " Loss: 0.000023\n",
      " Loss: 0.086473\n",
      " Loss: 0.000048\n",
      " Loss: 0.118466\n",
      " Loss: 0.000176\n",
      " Loss: 0.037436\n",
      " Loss: 0.000051\n",
      " Loss: 0.134210\n",
      " Loss: 0.000034\n",
      " Loss: 0.104393\n",
      " Loss: 0.000045\n",
      " Loss: 0.056839\n",
      "Epoch 618 Chain 0 loss std 3.68e-01 variance 6.76e-02 smooth variance 1.65e-01 adaptive c -1.00\n",
      "Epoch 618 Chain 1 loss std 3.56e+02 variance 6.35e+04 smooth variance 8.14e+04 adaptive c -1.00\n",
      " Loss: 0.000049\n",
      " Loss: 0.090909\n",
      " Loss: 0.000132\n",
      " Loss: 0.112764\n",
      " Loss: 0.000026\n",
      " Loss: 0.081828\n",
      " Loss: 0.000056\n",
      " Loss: 0.067888\n",
      " Loss: 0.000095\n",
      " Loss: 0.096804\n",
      " Loss: 0.000113\n",
      " Loss: 0.146925\n",
      " Loss: 0.000040\n",
      " Loss: 0.088411\n",
      " Loss: 0.000092\n",
      " Loss: 0.074375\n",
      " Loss: 0.000033\n",
      " Loss: 0.085251\n",
      " Loss: 0.000074\n",
      " Loss: 0.053958\n",
      "Epoch 620 Chain 0 loss std 4.52e-01 variance 1.02e-01 smooth variance 1.46e-01 adaptive c -1.00\n",
      "Epoch 620 Chain 1 loss std 3.42e+02 variance 5.85e+04 smooth variance 7.45e+04 adaptive c -1.00\n",
      " Loss: 0.000045\n",
      " Loss: 0.081327\n",
      " Loss: 0.000041\n",
      " Loss: 0.139908\n",
      " Loss: 0.000139\n",
      " Loss: 0.056281\n",
      " Loss: 0.000079\n",
      " Loss: 0.060805\n",
      " Loss: 0.000034\n",
      " Loss: 0.109554\n",
      " Loss: 0.000143\n",
      " Loss: 0.059545\n",
      " Loss: 0.000039\n",
      " Loss: 0.071657\n",
      " Loss: 0.000041\n",
      " Loss: 0.086153\n",
      " Loss: 0.000076\n",
      " Loss: 0.047959\n",
      " Loss: 0.000027\n",
      " Loss: 0.182076\n",
      "Epoch 622 Chain 0 loss std 6.96e-01 variance 2.42e-01 smooth variance 1.75e-01 adaptive c -1.00\n",
      "Epoch 622 Chain 1 loss std 2.94e+02 variance 4.34e+04 smooth variance 6.52e+04 adaptive c -1.00\n",
      " Loss: 0.000086\n",
      " Loss: 0.063673\n",
      " Loss: 0.000046\n",
      " Loss: 0.100105\n",
      " Loss: 0.000041\n",
      " Loss: 0.068812\n",
      " Loss: 0.000042\n",
      " Loss: 0.145666\n",
      " Loss: 0.000121\n",
      " Loss: 0.068120\n",
      " Loss: 0.000032\n",
      " Loss: 0.059163\n",
      " Loss: 0.000059\n",
      " Loss: 0.161148\n",
      " Loss: 0.000031\n",
      " Loss: 0.058119\n",
      " Loss: 0.000047\n",
      " Loss: 0.118708\n",
      " Loss: 0.000145\n",
      " Loss: 0.048305\n",
      "Epoch 624 Chain 0 loss std 3.86e-01 variance 7.45e-02 smooth variance 1.45e-01 adaptive c -1.00\n",
      "Epoch 624 Chain 1 loss std 2.02e+02 variance 2.05e+04 smooth variance 5.17e+04 adaptive c -1.00\n",
      " Loss: 0.000125\n",
      " Loss: 0.146230\n",
      " Loss: 0.000057\n",
      " Loss: 0.054324\n",
      " Loss: 0.000054\n",
      " Loss: 0.048807\n",
      " Loss: 0.000032\n",
      " Loss: 0.081118\n",
      " Loss: 0.000043\n",
      " Loss: 0.113797\n",
      " Loss: 0.000040\n",
      " Loss: 0.084799\n",
      " Loss: 0.000157\n",
      " Loss: 0.128575\n",
      " Loss: 0.000035\n",
      " Loss: 0.053350\n",
      " Loss: 0.000038\n",
      " Loss: 0.082828\n",
      " Loss: 0.000035\n",
      " Loss: 0.094008\n",
      "Epoch 626 Chain 0 loss std 3.48e-01 variance 6.06e-02 smooth variance 1.20e-01 adaptive c -1.00\n",
      "Epoch 626 Chain 1 loss std 4.87e+02 variance 1.19e+05 smooth variance 7.19e+04 adaptive c -1.00\n",
      " Loss: 0.000032\n",
      " Loss: 0.077897\n",
      " Loss: 0.000035\n",
      " Loss: 0.102803\n",
      " Loss: 0.000114\n",
      " Loss: 0.054850\n",
      " Loss: 0.000041\n",
      " Loss: 0.064123\n",
      " Loss: 0.000076\n",
      " Loss: 0.142807\n",
      " Loss: 0.000029\n",
      " Loss: 0.138489\n",
      " Loss: 0.000028\n",
      " Loss: 0.081904\n",
      " Loss: 0.000031\n",
      " Loss: 0.058064\n",
      " Loss: 0.000121\n",
      " Loss: 0.079958\n",
      " Loss: 0.000084\n",
      " Loss: 0.082860\n",
      "Epoch 628 Chain 0 loss std 4.69e-01 variance 1.10e-01 smooth variance 1.17e-01 adaptive c -1.00\n",
      "Epoch 628 Chain 1 loss std 2.06e+02 variance 2.13e+04 smooth variance 5.67e+04 adaptive c -1.00\n",
      " Loss: 0.000032\n",
      " Loss: 0.133811\n",
      " Loss: 0.000037\n",
      " Loss: 0.091422\n",
      " Loss: 0.000123\n",
      " Loss: 0.058906\n",
      " Loss: 0.000035\n",
      " Loss: 0.102198\n",
      " Loss: 0.000064\n",
      " Loss: 0.054159\n",
      " Loss: 0.000112\n",
      " Loss: 0.092853\n",
      " Loss: 0.000039\n",
      " Loss: 0.127355\n",
      " Loss: 0.000062\n",
      " Loss: 0.056160\n",
      " Loss: 0.000016\n",
      " Loss: 0.110675\n",
      " Loss: 0.000049\n",
      " Loss: 0.052285\n",
      "Epoch 630 Chain 0 loss std 5.55e-01 variance 1.54e-01 smooth variance 1.28e-01 adaptive c -1.00\n",
      "Epoch 630 Chain 1 loss std 4.30e+02 variance 9.26e+04 smooth variance 6.74e+04 adaptive c -1.00\n",
      " Loss: 0.000025\n",
      " Loss: 0.053522\n",
      " Loss: 0.000025\n",
      " Loss: 0.111716\n",
      " Loss: 0.000023\n",
      " Loss: 0.067561\n",
      " Loss: 0.000144\n",
      " Loss: 0.134019\n",
      " Loss: 0.000044\n",
      " Loss: 0.071586\n",
      " Loss: 0.000024\n",
      " Loss: 0.110953\n",
      " Loss: 0.000030\n",
      " Loss: 0.053485\n",
      " Loss: 0.000117\n",
      " Loss: 0.129591\n",
      " Loss: 0.000025\n",
      " Loss: 0.087839\n",
      " Loss: 0.000058\n",
      " Loss: 0.055674\n",
      "Epoch 632 Chain 0 loss std 3.89e-01 variance 7.57e-02 smooth variance 1.12e-01 adaptive c -1.00\n",
      "Epoch 632 Chain 1 loss std 3.93e+02 variance 7.72e+04 smooth variance 7.04e+04 adaptive c -1.00\n",
      " Loss: 0.000025\n",
      " Loss: 0.149775\n",
      " Loss: 0.000027\n",
      " Loss: 0.059562\n",
      " Loss: 0.000037\n",
      " Loss: 0.095222\n",
      " Loss: 0.000119\n",
      " Loss: 0.080967\n",
      " Loss: 0.000031\n",
      " Loss: 0.051328\n",
      " Loss: 0.000062\n",
      " Loss: 0.058253\n",
      " Loss: 0.000024\n",
      " Loss: 0.083919\n",
      " Loss: 0.000103\n",
      " Loss: 0.162842\n",
      " Loss: 0.000024\n",
      " Loss: 0.075622\n",
      " Loss: 0.000032\n",
      " Loss: 0.055132\n",
      "Epoch 634 Chain 0 loss std 3.07e-01 variance 4.70e-02 smooth variance 9.27e-02 adaptive c -1.00\n",
      "Epoch 634 Chain 1 loss std 3.42e+02 variance 5.86e+04 smooth variance 6.68e+04 adaptive c -1.00\n",
      " Loss: 0.000029\n",
      " Loss: 0.062543\n",
      " Loss: 0.000128\n",
      " Loss: 0.067896\n",
      " Loss: 0.000024\n",
      " Loss: 0.070780\n",
      " Loss: 0.000019\n",
      " Loss: 0.110463\n",
      " Loss: 0.000041\n",
      " Loss: 0.123145\n",
      " Loss: 0.000026\n",
      " Loss: 0.061781\n",
      " Loss: 0.000052\n",
      " Loss: 0.054764\n",
      " Loss: 0.000019\n",
      " Loss: 0.102537\n",
      " Loss: 0.000115\n",
      " Loss: 0.162295\n",
      " Loss: 0.000028\n",
      " Loss: 0.052560\n",
      "Epoch 636 Chain 0 loss std 3.20e-01 variance 5.11e-02 smooth variance 8.02e-02 adaptive c -1.00\n",
      "Epoch 636 Chain 1 loss std 5.03e+02 variance 1.27e+05 smooth variance 8.48e+04 adaptive c -1.00\n",
      " Loss: 0.000036\n",
      " Loss: 0.147802\n",
      " Loss: 0.000021\n",
      " Loss: 0.073700\n",
      " Loss: 0.000055\n",
      " Loss: 0.050914\n",
      " Loss: 0.000020\n",
      " Loss: 0.058653\n",
      " Loss: 0.000100\n",
      " Loss: 0.102766\n",
      " Loss: 0.000020\n",
      " Loss: 0.163460\n",
      " Loss: 0.000020\n",
      " Loss: 0.093729\n",
      " Loss: 0.000026\n",
      " Loss: 0.076458\n",
      " Loss: 0.000125\n",
      " Loss: 0.052157\n",
      " Loss: 0.000030\n",
      " Loss: 0.046278\n",
      "Epoch 638 Chain 0 loss std 3.58e-01 variance 6.42e-02 smooth variance 7.54e-02 adaptive c -1.00\n",
      "Epoch 638 Chain 1 loss std 4.03e+02 variance 8.12e+04 smooth variance 8.37e+04 adaptive c -1.00\n",
      " Loss: 0.000091\n",
      " Loss: 0.068245\n",
      " Loss: 0.000027\n",
      " Loss: 0.145488\n",
      " Loss: 0.000064\n",
      " Loss: 0.057692\n",
      " Loss: 0.000028\n",
      " Loss: 0.066582\n",
      " Loss: 0.000018\n",
      " Loss: 0.093147\n",
      " Loss: 0.000024\n",
      " Loss: 0.083598\n",
      " Loss: 0.000026\n",
      " Loss: 0.089924\n",
      " Loss: 0.000031\n",
      " Loss: 0.035814\n",
      " Loss: 0.000019\n",
      " Loss: 0.138742\n",
      " Loss: 0.000112\n",
      " Loss: 0.082154\n",
      "Epoch 640 Chain 0 loss std 2.65e-01 variance 3.51e-02 smooth variance 6.33e-02 adaptive c -1.00\n",
      "Epoch 640 Chain 1 loss std 2.90e+02 variance 4.21e+04 smooth variance 7.12e+04 adaptive c -1.00\n",
      " Loss: 0.000058\n",
      " Loss: 0.040240\n",
      " Loss: 0.000018\n",
      " Loss: 0.075601\n",
      " Loss: 0.000084\n",
      " Loss: 0.090777\n",
      " Loss: 0.000033\n",
      " Loss: 0.068005\n",
      " Loss: 0.000020\n",
      " Loss: 0.154513\n",
      " Loss: 0.000085\n",
      " Loss: 0.068143\n",
      " Loss: 0.000055\n",
      " Loss: 0.113082\n",
      " Loss: 0.000028\n",
      " Loss: 0.052316\n",
      " Loss: 0.000018\n",
      " Loss: 0.093285\n",
      " Loss: 0.000018\n",
      " Loss: 0.101512\n",
      "Epoch 642 Chain 0 loss std 2.44e-01 variance 2.99e-02 smooth variance 5.33e-02 adaptive c -1.00\n",
      "Epoch 642 Chain 1 loss std 4.38e+02 variance 9.61e+04 smooth variance 7.87e+04 adaptive c -1.00\n",
      " Loss: 0.000018\n",
      " Loss: 0.159826\n",
      " Loss: 0.000087\n",
      " Loss: 0.053273\n",
      " Loss: 0.000048\n",
      " Loss: 0.084524\n",
      " Loss: 0.000024\n",
      " Loss: 0.052880\n",
      " Loss: 0.000023\n",
      " Loss: 0.077072\n",
      " Loss: 0.000050\n",
      " Loss: 0.068903\n",
      " Loss: 0.000071\n",
      " Loss: 0.093532\n",
      " Loss: 0.000023\n",
      " Loss: 0.136396\n",
      " Loss: 0.000028\n",
      " Loss: 0.055922\n",
      " Loss: 0.000023\n",
      " Loss: 0.071817\n",
      "Epoch 644 Chain 0 loss std 1.96e-01 variance 1.93e-02 smooth variance 4.31e-02 adaptive c -1.00\n",
      "Epoch 644 Chain 1 loss std 3.47e+02 variance 6.02e+04 smooth variance 7.31e+04 adaptive c -1.00\n",
      " Loss: 0.000103\n",
      " Loss: 0.045086\n",
      " Loss: 0.000025\n",
      " Loss: 0.177647\n",
      " Loss: 0.000022\n",
      " Loss: 0.064889\n",
      " Loss: 0.000018\n",
      " Loss: 0.081184\n",
      " Loss: 0.000027\n",
      " Loss: 0.056811\n",
      " Loss: 0.000106\n",
      " Loss: 0.075561\n",
      " Loss: 0.000014\n",
      " Loss: 0.092488\n",
      " Loss: 0.000025\n",
      " Loss: 0.161716\n",
      " Loss: 0.000027\n",
      " Loss: 0.035963\n",
      " Loss: 0.000025\n",
      " Loss: 0.058959\n",
      "Epoch 646 Chain 0 loss std 2.49e-01 variance 3.10e-02 smooth variance 3.95e-02 adaptive c -1.00\n",
      "Epoch 646 Chain 1 loss std 3.71e+02 variance 6.87e+04 smooth variance 7.18e+04 adaptive c -1.00\n",
      " Loss: 0.000024\n",
      " Loss: 0.137112\n",
      " Loss: 0.000021\n",
      " Loss: 0.053142\n",
      " Loss: 0.000021\n",
      " Loss: 0.077019\n",
      " Loss: 0.000014\n",
      " Loss: 0.125750\n",
      " Loss: 0.000105\n",
      " Loss: 0.030839\n",
      " Loss: 0.000061\n",
      " Loss: 0.088285\n",
      " Loss: 0.000013\n",
      " Loss: 0.039552\n",
      " Loss: 0.000025\n",
      " Loss: 0.152538\n",
      " Loss: 0.000026\n",
      " Loss: 0.079131\n",
      " Loss: 0.000064\n",
      " Loss: 0.063469\n",
      "Epoch 648 Chain 0 loss std 2.24e-01 variance 2.52e-02 smooth variance 3.52e-02 adaptive c -1.00\n",
      "Epoch 648 Chain 1 loss std 4.02e+02 variance 8.08e+04 smooth variance 7.45e+04 adaptive c -1.00\n",
      " Loss: 0.000063\n",
      " Loss: 0.063480\n",
      " Loss: 0.000023\n",
      " Loss: 0.049111\n",
      " Loss: 0.000020\n",
      " Loss: 0.063035\n",
      " Loss: 0.000065\n",
      " Loss: 0.079752\n",
      " Loss: 0.000022\n",
      " Loss: 0.166811\n",
      " Loss: 0.000053\n",
      " Loss: 0.085231\n",
      " Loss: 0.000026\n",
      " Loss: 0.047282\n",
      " Loss: 0.000011\n",
      " Loss: 0.081905\n",
      " Loss: 0.000019\n",
      " Loss: 0.057181\n",
      " Loss: 0.000085\n",
      " Loss: 0.149619\n",
      "Epoch 650 Chain 0 loss std 2.52e-01 variance 3.17e-02 smooth variance 3.41e-02 adaptive c -1.00\n",
      "Epoch 650 Chain 1 loss std 3.99e+02 variance 7.95e+04 smooth variance 7.60e+04 adaptive c -1.00\n",
      " Loss: 0.000015\n",
      " Loss: 0.049672\n",
      " Loss: 0.000029\n",
      " Loss: 0.121724\n",
      " Loss: 0.000088\n",
      " Loss: 0.082079\n",
      " Loss: 0.000029\n",
      " Loss: 0.062176\n",
      " Loss: 0.000018\n",
      " Loss: 0.104570\n",
      " Loss: 0.000070\n",
      " Loss: 0.034605\n",
      " Loss: 0.000027\n",
      " Loss: 0.141488\n",
      " Loss: 0.000051\n",
      " Loss: 0.087799\n",
      " Loss: 0.000012\n",
      " Loss: 0.051540\n",
      " Loss: 0.000018\n",
      " Loss: 0.104115\n",
      "Epoch 652 Chain 0 loss std 2.58e-01 variance 3.33e-02 smooth variance 3.39e-02 adaptive c -1.00\n",
      "Epoch 652 Chain 1 loss std 3.33e+02 variance 5.55e+04 smooth variance 6.99e+04 adaptive c -1.00\n",
      " Loss: 0.000027\n",
      " Loss: 0.156048\n",
      " Loss: 0.000015\n",
      " Loss: 0.067888\n",
      " Loss: 0.000019\n",
      " Loss: 0.097272\n",
      " Loss: 0.000021\n",
      " Loss: 0.051692\n",
      " Loss: 0.000091\n",
      " Loss: 0.045813\n",
      " Loss: 0.000016\n",
      " Loss: 0.137855\n",
      " Loss: 0.000057\n",
      " Loss: 0.070605\n",
      " Loss: 0.000024\n",
      " Loss: 0.061309\n",
      " Loss: 0.000024\n",
      " Loss: 0.098925\n",
      " Loss: 0.000055\n",
      " Loss: 0.048970\n",
      "Epoch 654 Chain 0 loss std 2.08e-01 variance 2.17e-02 smooth variance 3.02e-02 adaptive c -1.00\n",
      "Epoch 654 Chain 1 loss std 5.87e+02 variance 1.72e+05 smooth variance 1.01e+05 adaptive c -1.00\n",
      " Loss: 0.000061\n",
      " Loss: 0.033366\n",
      " Loss: 0.000018\n",
      " Loss: 0.107920\n",
      " Loss: 0.000019\n",
      " Loss: 0.167168\n",
      " Loss: 0.000046\n",
      " Loss: 0.034120\n",
      " Loss: 0.000019\n",
      " Loss: 0.074128\n",
      " Loss: 0.000046\n",
      " Loss: 0.045408\n",
      " Loss: 0.000046\n",
      " Loss: 0.119676\n",
      " Loss: 0.000018\n",
      " Loss: 0.068863\n",
      " Loss: 0.000028\n",
      " Loss: 0.125374\n",
      " Loss: 0.000015\n",
      " Loss: 0.057013\n",
      "Epoch 656 Chain 0 loss std 1.54e-01 variance 1.18e-02 smooth variance 2.47e-02 adaptive c -1.00\n",
      "Epoch 656 Chain 1 loss std 3.81e+02 variance 7.27e+04 smooth variance 9.22e+04 adaptive c -1.00\n",
      " Loss: 0.000023\n",
      " Loss: 0.161069\n",
      " Loss: 0.000043\n",
      " Loss: 0.064325\n",
      " Loss: 0.000012\n",
      " Loss: 0.048373\n",
      " Loss: 0.000016\n",
      " Loss: 0.070388\n",
      " Loss: 0.000050\n",
      " Loss: 0.070794\n",
      " Loss: 0.000019\n",
      " Loss: 0.083463\n",
      " Loss: 0.000013\n",
      " Loss: 0.107503\n",
      " Loss: 0.000015\n",
      " Loss: 0.052126\n",
      " Loss: 0.000047\n",
      " Loss: 0.123018\n",
      " Loss: 0.000045\n",
      " Loss: 0.048033\n",
      "Epoch 658 Chain 0 loss std 1.83e-01 variance 1.68e-02 smooth variance 2.23e-02 adaptive c -1.00\n",
      "Epoch 658 Chain 1 loss std 4.15e+02 variance 8.63e+04 smooth variance 9.04e+04 adaptive c -1.00\n",
      " Loss: 0.000052\n",
      " Loss: 0.084879\n",
      " Loss: 0.000050\n",
      " Loss: 0.029080\n",
      " Loss: 0.000014\n",
      " Loss: 0.091913\n",
      " Loss: 0.000010\n",
      " Loss: 0.135645\n",
      " Loss: 0.000009\n",
      " Loss: 0.071995\n",
      " Loss: 0.000041\n",
      " Loss: 0.143696\n",
      " Loss: 0.000041\n",
      " Loss: 0.084916\n",
      " Loss: 0.000015\n",
      " Loss: 0.060828\n",
      " Loss: 0.000020\n",
      " Loss: 0.072964\n",
      " Loss: 0.000017\n",
      " Loss: 0.050022\n",
      "Epoch 660 Chain 0 loss std 1.67e-01 variance 1.39e-02 smooth variance 1.98e-02 adaptive c -1.00\n",
      "Epoch 660 Chain 1 loss std 4.14e+02 variance 8.57e+04 smooth variance 8.90e+04 adaptive c -1.00\n",
      " Loss: 0.000013\n",
      " Loss: 0.045676\n",
      " Loss: 0.000042\n",
      " Loss: 0.072942\n",
      " Loss: 0.000017\n",
      " Loss: 0.132416\n",
      " Loss: 0.000008\n",
      " Loss: 0.110722\n",
      " Loss: 0.000051\n",
      " Loss: 0.049878\n",
      " Loss: 0.000011\n",
      " Loss: 0.080075\n",
      " Loss: 0.000008\n",
      " Loss: 0.074165\n",
      " Loss: 0.000016\n",
      " Loss: 0.135359\n",
      " Loss: 0.000037\n",
      " Loss: 0.083692\n",
      " Loss: 0.000053\n",
      " Loss: 0.037508\n",
      "Epoch 662 Chain 0 loss std 1.86e-01 variance 1.72e-02 smooth variance 1.90e-02 adaptive c -1.00\n",
      "Epoch 662 Chain 1 loss std 4.74e+02 variance 1.12e+05 smooth variance 9.60e+04 adaptive c -1.00\n",
      " Loss: 0.000014\n",
      " Loss: 0.068732\n",
      " Loss: 0.000032\n",
      " Loss: 0.104404\n",
      " Loss: 0.000011\n",
      " Loss: 0.044586\n",
      " Loss: 0.000053\n",
      " Loss: 0.140469\n",
      " Loss: 0.000010\n",
      " Loss: 0.051745\n",
      " Loss: 0.000008\n",
      " Loss: 0.094637\n",
      " Loss: 0.000046\n",
      " Loss: 0.036171\n",
      " Loss: 0.000008\n",
      " Loss: 0.063439\n",
      " Loss: 0.000046\n",
      " Loss: 0.057305\n",
      " Loss: 0.000012\n",
      " Loss: 0.157833\n",
      "Epoch 664 Chain 0 loss std 1.31e-01 variance 8.55e-03 smooth variance 1.59e-02 adaptive c -1.00\n",
      "Epoch 664 Chain 1 loss std 3.40e+02 variance 5.80e+04 smooth variance 8.46e+04 adaptive c -1.00\n",
      " Loss: 0.000015\n",
      " Loss: 0.082036\n",
      " Loss: 0.000014\n",
      " Loss: 0.053511\n",
      " Loss: 0.000008\n",
      " Loss: 0.089316\n",
      " Loss: 0.000037\n",
      " Loss: 0.055076\n",
      " Loss: 0.000041\n",
      " Loss: 0.128400\n",
      " Loss: 0.000012\n",
      " Loss: 0.043271\n",
      " Loss: 0.000014\n",
      " Loss: 0.172434\n",
      " Loss: 0.000013\n",
      " Loss: 0.075898\n",
      " Loss: 0.000007\n",
      " Loss: 0.071650\n",
      " Loss: 0.000066\n",
      " Loss: 0.044165\n",
      "Epoch 666 Chain 0 loss std 1.49e-01 variance 1.11e-02 smooth variance 1.45e-02 adaptive c -1.00\n",
      "Epoch 666 Chain 1 loss std 4.02e+02 variance 8.08e+04 smooth variance 8.34e+04 adaptive c -1.00\n",
      " Loss: 0.000040\n",
      " Loss: 0.053022\n",
      " Loss: 0.000014\n",
      " Loss: 0.148704\n",
      " Loss: 0.000008\n",
      " Loss: 0.074469\n",
      " Loss: 0.000044\n",
      " Loss: 0.076362\n",
      " Loss: 0.000009\n",
      " Loss: 0.054232\n",
      " Loss: 0.000037\n",
      " Loss: 0.053013\n",
      " Loss: 0.000014\n",
      " Loss: 0.089549\n",
      " Loss: 0.000005\n",
      " Loss: 0.054397\n",
      " Loss: 0.000012\n",
      " Loss: 0.123916\n",
      " Loss: 0.000041\n",
      " Loss: 0.084830\n",
      "Epoch 668 Chain 0 loss std 1.37e-01 variance 9.43e-03 smooth variance 1.29e-02 adaptive c -1.00\n",
      "Epoch 668 Chain 1 loss std 2.44e+02 variance 2.98e+04 smooth variance 6.74e+04 adaptive c -1.00\n",
      " Loss: 0.000013\n",
      " Loss: 0.074190\n",
      " Loss: 0.000011\n",
      " Loss: 0.051839\n",
      " Loss: 0.000009\n",
      " Loss: 0.082599\n",
      " Loss: 0.000062\n",
      " Loss: 0.057392\n",
      " Loss: 0.000009\n",
      " Loss: 0.139188\n",
      " Loss: 0.000010\n",
      " Loss: 0.073815\n",
      " Loss: 0.000038\n",
      " Loss: 0.035769\n",
      " Loss: 0.000031\n",
      " Loss: 0.071169\n",
      " Loss: 0.000013\n",
      " Loss: 0.155234\n",
      " Loss: 0.000011\n",
      " Loss: 0.068158\n",
      "Epoch 670 Chain 0 loss std 1.35e-01 variance 9.07e-03 smooth variance 1.18e-02 adaptive c -1.00\n",
      "Epoch 670 Chain 1 loss std 4.44e+02 variance 9.84e+04 smooth variance 7.67e+04 adaptive c -1.00\n",
      " Loss: 0.000009\n",
      " Loss: 0.088545\n",
      " Loss: 0.000043\n",
      " Loss: 0.065590\n",
      " Loss: 0.000012\n",
      " Loss: 0.131305\n",
      " Loss: 0.000034\n",
      " Loss: 0.071314\n",
      " Loss: 0.000005\n",
      " Loss: 0.046576\n",
      " Loss: 0.000006\n",
      " Loss: 0.057478\n",
      " Loss: 0.000009\n",
      " Loss: 0.057964\n",
      " Loss: 0.000015\n",
      " Loss: 0.144091\n",
      " Loss: 0.000057\n",
      " Loss: 0.039227\n",
      " Loss: 0.000011\n",
      " Loss: 0.103672\n",
      "Epoch 672 Chain 0 loss std 2.15e-01 variance 2.32e-02 smooth variance 1.52e-02 adaptive c -1.00\n",
      "Epoch 672 Chain 1 loss std 4.52e+02 variance 1.02e+05 smooth variance 8.43e+04 adaptive c -1.00\n",
      " Loss: 0.000028\n",
      " Loss: 0.075987\n",
      " Loss: 0.000037\n",
      " Loss: 0.070021\n",
      " Loss: 0.000013\n",
      " Loss: 0.125566\n",
      " Loss: 0.000009\n",
      " Loss: 0.053698\n",
      " Loss: 0.000009\n",
      " Loss: 0.076412\n",
      " Loss: 0.000037\n",
      " Loss: 0.053435\n",
      " Loss: 0.000013\n",
      " Loss: 0.160427\n",
      " Loss: 0.000025\n",
      " Loss: 0.065012\n",
      " Loss: 0.000010\n",
      " Loss: 0.071326\n",
      " Loss: 0.000008\n",
      " Loss: 0.050820\n",
      "Epoch 674 Chain 0 loss std 1.24e-01 variance 7.66e-03 smooth variance 1.29e-02 adaptive c -1.00\n",
      "Epoch 674 Chain 1 loss std 2.27e+02 variance 2.57e+04 smooth variance 6.67e+04 adaptive c -1.00\n",
      " Loss: 0.000034\n",
      " Loss: 0.068576\n",
      " Loss: 0.000024\n",
      " Loss: 0.062062\n",
      " Loss: 0.000011\n",
      " Loss: 0.145303\n",
      " Loss: 0.000010\n",
      " Loss: 0.055292\n",
      " Loss: 0.000011\n",
      " Loss: 0.068917\n",
      " Loss: 0.000010\n",
      " Loss: 0.044663\n",
      " Loss: 0.000035\n",
      " Loss: 0.061370\n",
      " Loss: 0.000005\n",
      " Loss: 0.067515\n",
      " Loss: 0.000029\n",
      " Loss: 0.156564\n",
      " Loss: 0.000011\n",
      " Loss: 0.069153\n",
      "Epoch 676 Chain 0 loss std 1.41e-01 variance 9.93e-03 smooth variance 1.20e-02 adaptive c -1.00\n",
      "Epoch 676 Chain 1 loss std 4.52e+02 variance 1.02e+05 smooth variance 7.73e+04 adaptive c -1.00\n",
      " Loss: 0.000007\n",
      " Loss: 0.077493\n",
      " Loss: 0.000011\n",
      " Loss: 0.072022\n",
      " Loss: 0.000035\n",
      " Loss: 0.137568\n",
      " Loss: 0.000027\n",
      " Loss: 0.068791\n",
      " Loss: 0.000007\n",
      " Loss: 0.042689\n",
      " Loss: 0.000005\n",
      " Loss: 0.060676\n",
      " Loss: 0.000009\n",
      " Loss: 0.106450\n",
      " Loss: 0.000010\n",
      " Loss: 0.040516\n",
      " Loss: 0.000026\n",
      " Loss: 0.054314\n",
      " Loss: 0.000040\n",
      " Loss: 0.135715\n",
      "Epoch 678 Chain 0 loss std 1.40e-01 variance 9.81e-03 smooth variance 1.14e-02 adaptive c -1.00\n",
      "Epoch 678 Chain 1 loss std 3.30e+02 variance 5.43e+04 smooth variance 7.04e+04 adaptive c -1.00\n",
      " Loss: 0.000023\n",
      " Loss: 0.057676\n",
      " Loss: 0.000009\n",
      " Loss: 0.093001\n",
      " Loss: 0.000009\n",
      " Loss: 0.056567\n",
      " Loss: 0.000042\n",
      " Loss: 0.138956\n",
      " Loss: 0.000009\n",
      " Loss: 0.050698\n",
      " Loss: 0.000010\n",
      " Loss: 0.062816\n",
      " Loss: 0.000013\n",
      " Loss: 0.068660\n",
      " Loss: 0.000033\n",
      " Loss: 0.041846\n",
      " Loss: 0.000009\n",
      " Loss: 0.087038\n",
      " Loss: 0.000026\n",
      " Loss: 0.135816\n",
      "Epoch 680 Chain 0 loss std 1.16e-01 variance 6.68e-03 smooth variance 9.96e-03 adaptive c -1.00\n",
      "Epoch 680 Chain 1 loss std 4.20e+02 variance 8.80e+04 smooth variance 7.57e+04 adaptive c -1.00\n",
      " Loss: 0.000013\n",
      " Loss: 0.141315\n",
      " Loss: 0.000027\n",
      " Loss: 0.028942\n",
      " Loss: 0.000031\n",
      " Loss: 0.062192\n",
      " Loss: 0.000010\n",
      " Loss: 0.088399\n",
      " Loss: 0.000005\n",
      " Loss: 0.074733\n",
      " Loss: 0.000009\n",
      " Loss: 0.060197\n",
      " Loss: 0.000024\n",
      " Loss: 0.056133\n",
      " Loss: 0.000010\n",
      " Loss: 0.132339\n",
      " Loss: 0.000006\n",
      " Loss: 0.101728\n",
      " Loss: 0.000036\n",
      " Loss: 0.044301\n",
      "Epoch 682 Chain 0 loss std 1.17e-01 variance 6.83e-03 smooth variance 9.02e-03 adaptive c -1.00\n",
      "Epoch 682 Chain 1 loss std 2.89e+02 variance 4.19e+04 smooth variance 6.56e+04 adaptive c -1.00\n",
      " Loss: 0.000011\n",
      " Loss: 0.055503\n",
      " Loss: 0.000013\n",
      " Loss: 0.089154\n",
      " Loss: 0.000020\n",
      " Loss: 0.114826\n",
      " Loss: 0.000030\n",
      " Loss: 0.074545\n",
      " Loss: 0.000010\n",
      " Loss: 0.059817\n",
      " Loss: 0.000007\n",
      " Loss: 0.080049\n",
      " Loss: 0.000010\n",
      " Loss: 0.081981\n",
      " Loss: 0.000026\n",
      " Loss: 0.060338\n",
      " Loss: 0.000027\n",
      " Loss: 0.125140\n",
      " Loss: 0.000009\n",
      " Loss: 0.045608\n",
      "Epoch 684 Chain 0 loss std 9.80e-02 variance 4.80e-03 smooth variance 7.76e-03 adaptive c -1.00\n",
      "Epoch 684 Chain 1 loss std 2.23e+02 variance 2.49e+04 smooth variance 5.34e+04 adaptive c -1.00\n",
      " Loss: 0.000011\n",
      " Loss: 0.141253\n",
      " Loss: 0.000009\n",
      " Loss: 0.062656\n",
      " Loss: 0.000007\n",
      " Loss: 0.061121\n",
      " Loss: 0.000023\n",
      " Loss: 0.070954\n",
      " Loss: 0.000029\n",
      " Loss: 0.056336\n",
      " Loss: 0.000023\n",
      " Loss: 0.115707\n",
      " Loss: 0.000008\n",
      " Loss: 0.049756\n",
      " Loss: 0.000009\n",
      " Loss: 0.063944\n",
      " Loss: 0.000030\n",
      " Loss: 0.073366\n",
      " Loss: 0.000008\n",
      " Loss: 0.088975\n",
      "Epoch 686 Chain 0 loss std 1.01e-01 variance 5.05e-03 smooth variance 6.94e-03 adaptive c -1.00\n",
      "Epoch 686 Chain 1 loss std 2.60e+02 variance 3.37e+04 smooth variance 4.75e+04 adaptive c -1.00\n",
      " Loss: 0.000007\n",
      " Loss: 0.120783\n",
      " Loss: 0.000022\n",
      " Loss: 0.050510\n",
      " Loss: 0.000006\n",
      " Loss: 0.059739\n",
      " Loss: 0.000027\n",
      " Loss: 0.071215\n",
      " Loss: 0.000012\n",
      " Loss: 0.088681\n",
      " Loss: 0.000011\n",
      " Loss: 0.072412\n",
      " Loss: 0.000007\n",
      " Loss: 0.045334\n",
      " Loss: 0.000023\n",
      " Loss: 0.064373\n",
      " Loss: 0.000025\n",
      " Loss: 0.121507\n",
      " Loss: 0.000009\n",
      " Loss: 0.086614\n",
      "Epoch 688 Chain 0 loss std 1.07e-01 variance 5.72e-03 smooth variance 6.58e-03 adaptive c -1.00\n",
      "Epoch 688 Chain 1 loss std 4.39e+02 variance 9.65e+04 smooth variance 6.22e+04 adaptive c -1.00\n",
      " Loss: 0.000024\n",
      " Loss: 0.072149\n",
      " Loss: 0.000009\n",
      " Loss: 0.078880\n",
      " Loss: 0.000005\n",
      " Loss: 0.073777\n",
      " Loss: 0.000006\n",
      " Loss: 0.050023\n",
      " Loss: 0.000031\n",
      " Loss: 0.114632\n",
      " Loss: 0.000022\n",
      " Loss: 0.061215\n",
      " Loss: 0.000008\n",
      " Loss: 0.062269\n",
      " Loss: 0.000027\n",
      " Loss: 0.059457\n",
      " Loss: 0.000008\n",
      " Loss: 0.084962\n",
      " Loss: 0.000009\n",
      " Loss: 0.120530\n",
      "Epoch 690 Chain 0 loss std 1.43e-01 variance 1.03e-02 smooth variance 7.69e-03 adaptive c -1.00\n",
      "Epoch 690 Chain 1 loss std 4.50e+02 variance 1.01e+05 smooth variance 7.39e+04 adaptive c -1.00\n",
      " Loss: 0.000041\n",
      " Loss: 0.049979\n",
      " Loss: 0.000005\n",
      " Loss: 0.058779\n",
      " Loss: 0.000008\n",
      " Loss: 0.083196\n",
      " Loss: 0.000008\n",
      " Loss: 0.112021\n",
      " Loss: 0.000006\n",
      " Loss: 0.083657\n",
      " Loss: 0.000029\n",
      " Loss: 0.076461\n",
      " Loss: 0.000005\n",
      " Loss: 0.133686\n",
      " Loss: 0.000027\n",
      " Loss: 0.057683\n",
      " Loss: 0.000003\n",
      " Loss: 0.047031\n",
      " Loss: 0.000007\n",
      " Loss: 0.072196\n",
      "Epoch 692 Chain 0 loss std 9.51e-02 variance 4.53e-03 smooth variance 6.74e-03 adaptive c -1.00\n",
      "Epoch 692 Chain 1 loss std 5.28e+02 variance 1.39e+05 smooth variance 9.35e+04 adaptive c -1.00\n",
      " Loss: 0.000005\n",
      " Loss: 0.119515\n",
      " Loss: 0.000022\n",
      " Loss: 0.034136\n",
      " Loss: 0.000028\n",
      " Loss: 0.074373\n",
      " Loss: 0.000009\n",
      " Loss: 0.075461\n",
      " Loss: 0.000005\n",
      " Loss: 0.082903\n",
      " Loss: 0.000041\n",
      " Loss: 0.063803\n",
      " Loss: 0.000008\n",
      " Loss: 0.040289\n",
      " Loss: 0.000006\n",
      " Loss: 0.044852\n",
      " Loss: 0.000006\n",
      " Loss: 0.068642\n",
      " Loss: 0.000005\n",
      " Loss: 0.167899\n",
      "Epoch 694 Chain 0 loss std 8.82e-02 variance 3.89e-03 smooth variance 5.89e-03 adaptive c -1.00\n",
      "Epoch 694 Chain 1 loss std 4.58e+02 variance 1.05e+05 smooth variance 9.70e+04 adaptive c -1.00\n",
      " Loss: 0.000036\n",
      " Loss: 0.066746\n",
      " Loss: 0.000007\n",
      " Loss: 0.058107\n",
      " Loss: 0.000005\n",
      " Loss: 0.041345\n",
      " Loss: 0.000005\n",
      " Loss: 0.136056\n",
      " Loss: 0.000011\n",
      " Loss: 0.082662\n",
      " Loss: 0.000022\n",
      " Loss: 0.082592\n",
      " Loss: 0.000008\n",
      " Loss: 0.049001\n",
      " Loss: 0.000005\n",
      " Loss: 0.145271\n",
      " Loss: 0.000025\n",
      " Loss: 0.033108\n",
      " Loss: 0.000007\n",
      " Loss: 0.074194\n",
      "Epoch 696 Chain 0 loss std 7.93e-02 variance 3.14e-03 smooth variance 5.06e-03 adaptive c -1.00\n",
      "Epoch 696 Chain 1 loss std 3.00e+02 variance 4.50e+04 smooth variance 8.14e+04 adaptive c -1.00\n",
      " Loss: 0.000019\n",
      " Loss: 0.031597\n",
      " Loss: 0.000006\n",
      " Loss: 0.170288\n",
      " Loss: 0.000005\n",
      " Loss: 0.040919\n",
      " Loss: 0.000007\n",
      " Loss: 0.094760\n",
      " Loss: 0.000029\n",
      " Loss: 0.045881\n",
      " Loss: 0.000007\n",
      " Loss: 0.086207\n",
      " Loss: 0.000004\n",
      " Loss: 0.051211\n",
      " Loss: 0.000020\n",
      " Loss: 0.110027\n",
      " Loss: 0.000006\n",
      " Loss: 0.095113\n",
      " Loss: 0.000026\n",
      " Loss: 0.040048\n",
      "Epoch 698 Chain 0 loss std 1.31e-01 variance 8.61e-03 smooth variance 6.13e-03 adaptive c -1.00\n",
      "Epoch 698 Chain 1 loss std 3.70e+02 variance 6.83e+04 smooth variance 7.75e+04 adaptive c -1.00\n",
      " Loss: 0.000008\n",
      " Loss: 0.053014\n",
      " Loss: 0.000002\n",
      " Loss: 0.070746\n",
      " Loss: 0.000023\n",
      " Loss: 0.149181\n",
      " Loss: 0.000022\n",
      " Loss: 0.027366\n",
      " Loss: 0.000006\n",
      " Loss: 0.081631\n",
      " Loss: 0.000021\n",
      " Loss: 0.059007\n",
      " Loss: 0.000006\n",
      " Loss: 0.146640\n",
      " Loss: 0.000022\n",
      " Loss: 0.043123\n",
      " Loss: 0.000007\n",
      " Loss: 0.054438\n",
      " Loss: 0.000006\n",
      " Loss: 0.077996\n",
      "Epoch 700 Chain 0 loss std 8.66e-02 variance 3.75e-03 smooth variance 5.41e-03 adaptive c -1.00\n",
      "Epoch 700 Chain 1 loss std 2.76e+02 variance 3.80e+04 smooth variance 6.56e+04 adaptive c -1.00\n",
      " Loss: 0.000005\n",
      " Loss: 0.138468\n",
      " Loss: 0.000019\n",
      " Loss: 0.044420\n",
      " Loss: 0.000006\n",
      " Loss: 0.063952\n",
      " Loss: 0.000005\n",
      " Loss: 0.083464\n",
      " Loss: 0.000028\n",
      " Loss: 0.050063\n",
      " Loss: 0.000004\n",
      " Loss: 0.139096\n",
      " Loss: 0.000005\n",
      " Loss: 0.061551\n",
      " Loss: 0.000029\n",
      " Loss: 0.027885\n",
      " Loss: 0.000007\n",
      " Loss: 0.059891\n",
      " Loss: 0.000015\n",
      " Loss: 0.091215\n",
      "Epoch 702 Chain 0 loss std 8.65e-02 variance 3.74e-03 smooth variance 4.91e-03 adaptive c -1.00\n",
      "Epoch 702 Chain 1 loss std 5.53e+02 variance 1.53e+05 smooth variance 9.18e+04 adaptive c -1.00\n",
      " Loss: 0.000023\n",
      " Loss: 0.082556\n",
      " Loss: 0.000003\n",
      " Loss: 0.053560\n",
      " Loss: 0.000005\n",
      " Loss: 0.129089\n",
      " Loss: 0.000020\n",
      " Loss: 0.048765\n",
      " Loss: 0.000008\n",
      " Loss: 0.065068\n",
      " Loss: 0.000016\n",
      " Loss: 0.053566\n",
      " Loss: 0.000005\n",
      " Loss: 0.076129\n",
      " Loss: 0.000004\n",
      " Loss: 0.060185\n",
      " Loss: 0.000028\n",
      " Loss: 0.144260\n",
      " Loss: 0.000006\n",
      " Loss: 0.044144\n",
      "Epoch 704 Chain 0 loss std 8.28e-02 variance 3.42e-03 smooth variance 4.47e-03 adaptive c -1.00\n",
      "Epoch 704 Chain 1 loss std 2.72e+02 variance 3.70e+04 smooth variance 7.53e+04 adaptive c -1.00\n",
      " Loss: 0.000013\n",
      " Loss: 0.044230\n",
      " Loss: 0.000007\n",
      " Loss: 0.054411\n",
      " Loss: 0.000007\n",
      " Loss: 0.145415\n",
      " Loss: 0.000028\n",
      " Loss: 0.062549\n",
      " Loss: 0.000003\n",
      " Loss: 0.070911\n",
      " Loss: 0.000007\n",
      " Loss: 0.051255\n",
      " Loss: 0.000012\n",
      " Loss: 0.162627\n",
      " Loss: 0.000004\n",
      " Loss: 0.033425\n",
      " Loss: 0.000004\n",
      " Loss: 0.074731\n",
      " Loss: 0.000029\n",
      " Loss: 0.054972\n",
      "Epoch 706 Chain 0 loss std 8.55e-02 variance 3.66e-03 smooth variance 4.22e-03 adaptive c -1.00\n",
      "Epoch 706 Chain 1 loss std 4.38e+02 variance 9.60e+04 smooth variance 8.15e+04 adaptive c -1.00\n",
      " Loss: 0.000005\n",
      " Loss: 0.060861\n",
      " Loss: 0.000004\n",
      " Loss: 0.129316\n",
      " Loss: 0.000005\n",
      " Loss: 0.048166\n",
      " Loss: 0.000022\n",
      " Loss: 0.078673\n",
      " Loss: 0.000019\n",
      " Loss: 0.059237\n",
      " Loss: 0.000006\n",
      " Loss: 0.079810\n",
      " Loss: 0.000005\n",
      " Loss: 0.130472\n",
      " Loss: 0.000019\n",
      " Loss: 0.058742\n",
      " Loss: 0.000006\n",
      " Loss: 0.067496\n",
      " Loss: 0.000018\n",
      " Loss: 0.038903\n",
      "Epoch 708 Chain 0 loss std 7.17e-02 variance 2.57e-03 smooth variance 3.73e-03 adaptive c -1.00\n",
      "Epoch 708 Chain 1 loss std 2.90e+02 variance 4.20e+04 smooth variance 6.97e+04 adaptive c -1.00\n",
      " Loss: 0.000005\n",
      " Loss: 0.063763\n",
      " Loss: 0.000006\n",
      " Loss: 0.185016\n",
      " Loss: 0.000017\n",
      " Loss: 0.039259\n",
      " Loss: 0.000006\n",
      " Loss: 0.043453\n",
      " Loss: 0.000020\n",
      " Loss: 0.043246\n",
      " Loss: 0.000004\n",
      " Loss: 0.046211\n",
      " Loss: 0.000032\n",
      " Loss: 0.076304\n",
      " Loss: 0.000006\n",
      " Loss: 0.131324\n",
      " Loss: 0.000006\n",
      " Loss: 0.056053\n",
      " Loss: 0.000003\n",
      " Loss: 0.064095\n",
      "Epoch 710 Chain 0 loss std 7.72e-02 variance 2.98e-03 smooth variance 3.50e-03 adaptive c -1.00\n",
      "Epoch 710 Chain 1 loss std 3.70e+02 variance 6.86e+04 smooth variance 6.93e+04 adaptive c -1.00\n",
      " Loss: 0.000004\n",
      " Loss: 0.088981\n",
      " Loss: 0.000005\n",
      " Loss: 0.046869\n",
      " Loss: 0.000007\n",
      " Loss: 0.066640\n",
      " Loss: 0.000014\n",
      " Loss: 0.117530\n",
      " Loss: 0.000023\n",
      " Loss: 0.053631\n",
      " Loss: 0.000013\n",
      " Loss: 0.031110\n",
      " Loss: 0.000004\n",
      " Loss: 0.170589\n",
      " Loss: 0.000006\n",
      " Loss: 0.056585\n",
      " Loss: 0.000006\n",
      " Loss: 0.064040\n",
      " Loss: 0.000024\n",
      " Loss: 0.050378\n",
      "Epoch 712 Chain 0 loss std 1.19e-01 variance 7.07e-03 smooth variance 4.57e-03 adaptive c -1.00\n",
      "Epoch 712 Chain 1 loss std 3.40e+02 variance 5.79e+04 smooth variance 6.59e+04 adaptive c -1.00\n",
      " Loss: 0.000005\n",
      " Loss: 0.071104\n",
      " Loss: 0.000005\n",
      " Loss: 0.057270\n",
      " Loss: 0.000004\n",
      " Loss: 0.139026\n",
      " Loss: 0.000004\n",
      " Loss: 0.036815\n",
      " Loss: 0.000030\n",
      " Loss: 0.067936\n",
      " Loss: 0.000005\n",
      " Loss: 0.050939\n",
      " Loss: 0.000018\n",
      " Loss: 0.160207\n",
      " Loss: 0.000015\n",
      " Loss: 0.058155\n",
      " Loss: 0.000005\n",
      " Loss: 0.050558\n",
      " Loss: 0.000007\n",
      " Loss: 0.051330\n",
      "Epoch 714 Chain 0 loss std 6.18e-02 variance 1.91e-03 smooth variance 3.77e-03 adaptive c -1.00\n",
      "Epoch 714 Chain 1 loss std 4.90e+02 variance 1.20e+05 smooth variance 8.22e+04 adaptive c -1.00\n",
      " Loss: 0.000004\n",
      " Loss: 0.060659\n",
      " Loss: 0.000014\n",
      " Loss: 0.084420\n",
      " Loss: 0.000006\n",
      " Loss: 0.131387\n",
      " Loss: 0.000006\n",
      " Loss: 0.045649\n",
      " Loss: 0.000021\n",
      " Loss: 0.048481\n",
      " Loss: 0.000022\n",
      " Loss: 0.060068\n",
      " Loss: 0.000004\n",
      " Loss: 0.075730\n",
      " Loss: 0.000014\n",
      " Loss: 0.039588\n",
      " Loss: 0.000004\n",
      " Loss: 0.078563\n",
      " Loss: 0.000006\n",
      " Loss: 0.116361\n",
      "Epoch 716 Chain 0 loss std 5.14e-02 variance 1.32e-03 smooth variance 3.04e-03 adaptive c -1.00\n",
      "Epoch 716 Chain 1 loss std 3.75e+02 variance 7.03e+04 smooth variance 7.86e+04 adaptive c -1.00\n",
      " Loss: 0.000005\n",
      " Loss: 0.134206\n",
      " Loss: 0.000013\n",
      " Loss: 0.057185\n",
      " Loss: 0.000020\n",
      " Loss: 0.026288\n",
      " Loss: 0.000003\n",
      " Loss: 0.065359\n",
      " Loss: 0.000004\n",
      " Loss: 0.086584\n",
      " Loss: 0.000013\n",
      " Loss: 0.061931\n",
      " Loss: 0.000006\n",
      " Loss: 0.040170\n",
      " Loss: 0.000003\n",
      " Loss: 0.065898\n",
      " Loss: 0.000020\n",
      " Loss: 0.063625\n",
      " Loss: 0.000003\n",
      " Loss: 0.137052\n",
      "Epoch 718 Chain 0 loss std 6.66e-02 variance 2.22e-03 smooth variance 2.79e-03 adaptive c -1.00\n",
      "Epoch 718 Chain 1 loss std 3.85e+02 variance 7.41e+04 smooth variance 7.73e+04 adaptive c -1.00\n",
      " Loss: 0.000003\n",
      " Loss: 0.041793\n",
      " Loss: 0.000004\n",
      " Loss: 0.075519\n",
      " Loss: 0.000013\n",
      " Loss: 0.041140\n",
      " Loss: 0.000020\n",
      " Loss: 0.064207\n",
      " Loss: 0.000003\n",
      " Loss: 0.145326\n",
      " Loss: 0.000003\n",
      " Loss: 0.066212\n",
      " Loss: 0.000003\n",
      " Loss: 0.038631\n",
      " Loss: 0.000014\n",
      " Loss: 0.051317\n",
      " Loss: 0.000003\n",
      " Loss: 0.096598\n",
      " Loss: 0.000019\n",
      " Loss: 0.114369\n",
      "Epoch 720 Chain 0 loss std 1.09e-01 variance 5.96e-03 smooth variance 3.74e-03 adaptive c -1.00\n",
      "Epoch 720 Chain 1 loss std 3.44e+02 variance 5.90e+04 smooth variance 7.18e+04 adaptive c -1.00\n",
      " Loss: 0.000018\n",
      " Loss: 0.130632\n",
      " Loss: 0.000005\n",
      " Loss: 0.069757\n",
      " Loss: 0.000011\n",
      " Loss: 0.051160\n",
      " Loss: 0.000004\n",
      " Loss: 0.059610\n",
      " Loss: 0.000003\n",
      " Loss: 0.055714\n",
      " Loss: 0.000003\n",
      " Loss: 0.046437\n",
      " Loss: 0.000004\n",
      " Loss: 0.117009\n",
      " Loss: 0.000003\n",
      " Loss: 0.069692\n",
      " Loss: 0.000014\n",
      " Loss: 0.082391\n",
      " Loss: 0.000017\n",
      " Loss: 0.050300\n",
      "Epoch 722 Chain 0 loss std 6.26e-02 variance 1.96e-03 smooth variance 3.21e-03 adaptive c -1.00\n",
      "Epoch 722 Chain 1 loss std 2.77e+02 variance 3.85e+04 smooth variance 6.18e+04 adaptive c -1.00\n",
      " Loss: 0.000003\n",
      " Loss: 0.065140\n",
      " Loss: 0.000004\n",
      " Loss: 0.060260\n",
      " Loss: 0.000018\n",
      " Loss: 0.040088\n",
      " Loss: 0.000012\n",
      " Loss: 0.134245\n",
      " Loss: 0.000003\n",
      " Loss: 0.065439\n",
      " Loss: 0.000013\n",
      " Loss: 0.051353\n",
      " Loss: 0.000003\n",
      " Loss: 0.111897\n",
      " Loss: 0.000004\n",
      " Loss: 0.088821\n",
      " Loss: 0.000002\n",
      " Loss: 0.038006\n",
      " Loss: 0.000019\n",
      " Loss: 0.074460\n",
      "Epoch 724 Chain 0 loss std 6.63e-02 variance 2.20e-03 smooth variance 2.90e-03 adaptive c -1.00\n",
      "Epoch 724 Chain 1 loss std 3.82e+02 variance 7.31e+04 smooth variance 6.52e+04 adaptive c -1.00\n",
      " Loss: 0.000017\n",
      " Loss: 0.090466\n",
      " Loss: 0.000013\n",
      " Loss: 0.031936\n",
      " Loss: 0.000002\n",
      " Loss: 0.069531\n",
      " Loss: 0.000003\n",
      " Loss: 0.127047\n",
      " Loss: 0.000004\n",
      " Loss: 0.044880\n",
      " Loss: 0.000004\n",
      " Loss: 0.125835\n",
      " Loss: 0.000015\n",
      " Loss: 0.072910\n",
      " Loss: 0.000003\n",
      " Loss: 0.070074\n",
      " Loss: 0.000003\n",
      " Loss: 0.059173\n",
      " Loss: 0.000016\n",
      " Loss: 0.035015\n",
      "Epoch 726 Chain 0 loss std 6.38e-02 variance 2.03e-03 smooth variance 2.64e-03 adaptive c -1.00\n",
      "Epoch 726 Chain 1 loss std 2.48e+02 variance 3.08e+04 smooth variance 5.49e+04 adaptive c -1.00\n",
      " Loss: 0.000005\n",
      " Loss: 0.059729\n",
      " Loss: 0.000014\n",
      " Loss: 0.074910\n",
      " Loss: 0.000015\n",
      " Loss: 0.122829\n",
      " Loss: 0.000002\n",
      " Loss: 0.043751\n",
      " Loss: 0.000002\n",
      " Loss: 0.061198\n",
      " Loss: 0.000004\n",
      " Loss: 0.133167\n",
      " Loss: 0.000016\n",
      " Loss: 0.057249\n",
      " Loss: 0.000003\n",
      " Loss: 0.076739\n",
      " Loss: 0.000003\n",
      " Loss: 0.038098\n",
      " Loss: 0.000012\n",
      " Loss: 0.056678\n",
      "Epoch 728 Chain 0 loss std 6.17e-02 variance 1.90e-03 smooth variance 2.42e-03 adaptive c -1.00\n",
      "Epoch 728 Chain 1 loss std 2.85e+02 variance 4.07e+04 smooth variance 5.06e+04 adaptive c -1.00\n",
      " Loss: 0.000012\n",
      " Loss: 0.137303\n",
      " Loss: 0.000002\n",
      " Loss: 0.064561\n",
      " Loss: 0.000020\n",
      " Loss: 0.058713\n",
      " Loss: 0.000002\n",
      " Loss: 0.044998\n",
      " Loss: 0.000003\n",
      " Loss: 0.055715\n",
      " Loss: 0.000003\n",
      " Loss: 0.040360\n",
      " Loss: 0.000016\n",
      " Loss: 0.113343\n",
      " Loss: 0.000004\n",
      " Loss: 0.062603\n",
      " Loss: 0.000012\n",
      " Loss: 0.067432\n",
      " Loss: 0.000004\n",
      " Loss: 0.076448\n",
      "Epoch 730 Chain 0 loss std 5.75e-02 variance 1.65e-03 smooth variance 2.19e-03 adaptive c -1.00\n",
      "Epoch 730 Chain 1 loss std 3.77e+02 variance 7.09e+04 smooth variance 5.67e+04 adaptive c -1.00\n",
      " Loss: 0.000012\n",
      " Loss: 0.050149\n",
      " Loss: 0.000003\n",
      " Loss: 0.068808\n",
      " Loss: 0.000003\n",
      " Loss: 0.139192\n",
      " Loss: 0.000003\n",
      " Loss: 0.056522\n",
      " Loss: 0.000016\n",
      " Loss: 0.044855\n",
      " Loss: 0.000003\n",
      " Loss: 0.121964\n",
      " Loss: 0.000003\n",
      " Loss: 0.077456\n",
      " Loss: 0.000011\n",
      " Loss: 0.039821\n",
      " Loss: 0.000016\n",
      " Loss: 0.039661\n",
      " Loss: 0.000003\n",
      " Loss: 0.080233\n",
      "Epoch 732 Chain 0 loss std 5.83e-02 variance 1.70e-03 smooth variance 2.04e-03 adaptive c -1.00\n",
      "Epoch 732 Chain 1 loss std 2.71e+02 variance 3.67e+04 smooth variance 5.07e+04 adaptive c -1.00\n",
      " Loss: 0.000003\n",
      " Loss: 0.049642\n",
      " Loss: 0.000003\n",
      " Loss: 0.049868\n",
      " Loss: 0.000003\n",
      " Loss: 0.056370\n",
      " Loss: 0.000003\n",
      " Loss: 0.113112\n",
      " Loss: 0.000022\n",
      " Loss: 0.089539\n",
      " Loss: 0.000003\n",
      " Loss: 0.132923\n",
      " Loss: 0.000003\n",
      " Loss: 0.098347\n",
      " Loss: 0.000003\n",
      " Loss: 0.044966\n",
      " Loss: 0.000011\n",
      " Loss: 0.051828\n",
      " Loss: 0.000015\n",
      " Loss: 0.029713\n",
      "Epoch 734 Chain 0 loss std 5.12e-02 variance 1.31e-03 smooth variance 1.82e-03 adaptive c -1.00\n",
      "Epoch 734 Chain 1 loss std 3.14e+02 variance 4.93e+04 smooth variance 5.03e+04 adaptive c -1.00\n",
      " Loss: 0.000010\n",
      " Loss: 0.051832\n",
      " Loss: 0.000015\n",
      " Loss: 0.042247\n",
      " Loss: 0.000003\n",
      " Loss: 0.069514\n",
      " Loss: 0.000002\n",
      " Loss: 0.102049\n",
      " Loss: 0.000002\n",
      " Loss: 0.091205\n",
      " Loss: 0.000002\n",
      " Loss: 0.043961\n",
      " Loss: 0.000013\n",
      " Loss: 0.048842\n",
      " Loss: 0.000011\n",
      " Loss: 0.120231\n",
      " Loss: 0.000004\n",
      " Loss: 0.094517\n",
      " Loss: 0.000003\n",
      " Loss: 0.048808\n",
      "Epoch 736 Chain 0 loss std 5.94e-02 variance 1.76e-03 smooth variance 1.81e-03 adaptive c -1.00\n",
      "Epoch 736 Chain 1 loss std 3.21e+02 variance 5.14e+04 smooth variance 5.06e+04 adaptive c -1.00\n",
      " Loss: 0.000002\n",
      " Loss: 0.065580\n",
      " Loss: 0.000022\n",
      " Loss: 0.026961\n",
      " Loss: 0.000003\n",
      " Loss: 0.091982\n",
      " Loss: 0.000003\n",
      " Loss: 0.114668\n",
      " Loss: 0.000003\n",
      " Loss: 0.056498\n",
      " Loss: 0.000002\n",
      " Loss: 0.066623\n",
      " Loss: 0.000010\n",
      " Loss: 0.047089\n",
      " Loss: 0.000002\n",
      " Loss: 0.050354\n",
      " Loss: 0.000015\n",
      " Loss: 0.061486\n",
      " Loss: 0.000004\n",
      " Loss: 0.129485\n",
      "Epoch 738 Chain 0 loss std 5.90e-02 variance 1.74e-03 smooth variance 1.79e-03 adaptive c -1.00\n",
      "Epoch 738 Chain 1 loss std 3.58e+02 variance 6.42e+04 smooth variance 5.47e+04 adaptive c -1.00\n",
      " Loss: 0.000002\n",
      " Loss: 0.039105\n",
      " Loss: 0.000002\n",
      " Loss: 0.132898\n",
      " Loss: 0.000002\n",
      " Loss: 0.050940\n",
      " Loss: 0.000017\n",
      " Loss: 0.044984\n",
      " Loss: 0.000009\n",
      " Loss: 0.086583\n",
      " Loss: 0.000002\n",
      " Loss: 0.052097\n",
      " Loss: 0.000002\n",
      " Loss: 0.069982\n",
      " Loss: 0.000003\n",
      " Loss: 0.056787\n",
      " Loss: 0.000021\n",
      " Loss: 0.055392\n",
      " Loss: 0.000002\n",
      " Loss: 0.119517\n",
      "Epoch 740 Chain 0 loss std 5.22e-02 variance 1.36e-03 smooth variance 1.66e-03 adaptive c -1.00\n",
      "Epoch 740 Chain 1 loss std 3.07e+02 variance 4.72e+04 smooth variance 5.24e+04 adaptive c -1.00\n",
      " Loss: 0.000003\n",
      " Loss: 0.065138\n",
      " Loss: 0.000015\n",
      " Loss: 0.130679\n",
      " Loss: 0.000002\n",
      " Loss: 0.048094\n",
      " Loss: 0.000003\n",
      " Loss: 0.041882\n",
      " Loss: 0.000009\n",
      " Loss: 0.067193\n",
      " Loss: 0.000009\n",
      " Loss: 0.045957\n",
      " Loss: 0.000013\n",
      " Loss: 0.113178\n",
      " Loss: 0.000002\n",
      " Loss: 0.075875\n",
      " Loss: 0.000001\n",
      " Loss: 0.055045\n",
      " Loss: 0.000004\n",
      " Loss: 0.062755\n",
      "Epoch 742 Chain 0 loss std 4.92e-02 variance 1.21e-03 smooth variance 1.52e-03 adaptive c -1.00\n",
      "Epoch 742 Chain 1 loss std 2.42e+02 variance 2.92e+04 smooth variance 4.55e+04 adaptive c -1.00\n",
      " Loss: 0.000013\n",
      " Loss: 0.038995\n",
      " Loss: 0.000002\n",
      " Loss: 0.118153\n",
      " Loss: 0.000002\n",
      " Loss: 0.087428\n",
      " Loss: 0.000002\n",
      " Loss: 0.065219\n",
      " Loss: 0.000010\n",
      " Loss: 0.041992\n",
      " Loss: 0.000001\n",
      " Loss: 0.069855\n",
      " Loss: 0.000011\n",
      " Loss: 0.052332\n",
      " Loss: 0.000002\n",
      " Loss: 0.059177\n",
      " Loss: 0.000011\n",
      " Loss: 0.130081\n",
      " Loss: 0.000003\n",
      " Loss: 0.039513\n",
      "Epoch 744 Chain 0 loss std 4.13e-02 variance 8.54e-04 smooth variance 1.32e-03 adaptive c -1.00\n",
      "Epoch 744 Chain 1 loss std 3.16e+02 variance 5.00e+04 smooth variance 4.68e+04 adaptive c -1.00\n",
      " Loss: 0.000002\n",
      " Loss: 0.108799\n",
      " Loss: 0.000002\n",
      " Loss: 0.048579\n",
      " Loss: 0.000002\n",
      " Loss: 0.086269\n",
      " Loss: 0.000009\n",
      " Loss: 0.053092\n",
      " Loss: 0.000013\n",
      " Loss: 0.053712\n",
      " Loss: 0.000002\n",
      " Loss: 0.049494\n",
      " Loss: 0.000002\n",
      " Loss: 0.113636\n",
      " Loss: 0.000002\n",
      " Loss: 0.055929\n",
      " Loss: 0.000007\n",
      " Loss: 0.052530\n",
      " Loss: 0.000014\n",
      " Loss: 0.078128\n",
      "Epoch 746 Chain 0 loss std 5.39e-02 variance 1.45e-03 smooth variance 1.36e-03 adaptive c -1.00\n",
      "Epoch 746 Chain 1 loss std 3.28e+02 variance 5.39e+04 smooth variance 4.90e+04 adaptive c -1.00\n",
      " Loss: 0.000006\n",
      " Loss: 0.052131\n",
      " Loss: 0.000013\n",
      " Loss: 0.035258\n",
      " Loss: 0.000001\n",
      " Loss: 0.052946\n",
      " Loss: 0.000003\n",
      " Loss: 0.051280\n",
      " Loss: 0.000002\n",
      " Loss: 0.157445\n",
      " Loss: 0.000002\n",
      " Loss: 0.044022\n",
      " Loss: 0.000001\n",
      " Loss: 0.101036\n",
      " Loss: 0.000001\n",
      " Loss: 0.060602\n",
      " Loss: 0.000008\n",
      " Loss: 0.105032\n",
      " Loss: 0.000012\n",
      " Loss: 0.038110\n",
      "Epoch 748 Chain 0 loss std 4.96e-02 variance 1.23e-03 smooth variance 1.32e-03 adaptive c -1.00\n",
      "Epoch 748 Chain 1 loss std 3.41e+02 variance 5.80e+04 smooth variance 5.17e+04 adaptive c -1.00\n",
      " Loss: 0.000002\n",
      " Loss: 0.057017\n",
      " Loss: 0.000003\n",
      " Loss: 0.105355\n",
      " Loss: 0.000006\n",
      " Loss: 0.084254\n",
      " Loss: 0.000002\n",
      " Loss: 0.061716\n",
      " Loss: 0.000013\n",
      " Loss: 0.039553\n",
      " Loss: 0.000018\n",
      " Loss: 0.040896\n",
      " Loss: 0.000002\n",
      " Loss: 0.120284\n",
      " Loss: 0.000003\n",
      " Loss: 0.063839\n",
      " Loss: 0.000001\n",
      " Loss: 0.049067\n",
      " Loss: 0.000001\n",
      " Loss: 0.073094\n",
      "Epoch 750 Chain 0 loss std 3.90e-02 variance 7.59e-04 smooth variance 1.15e-03 adaptive c -1.00\n",
      "Epoch 750 Chain 1 loss std 2.92e+02 variance 4.26e+04 smooth variance 4.90e+04 adaptive c -1.00\n",
      " Loss: 0.000008\n",
      " Loss: 0.043907\n",
      " Loss: 0.000001\n",
      " Loss: 0.070207\n",
      " Loss: 0.000002\n",
      " Loss: 0.066423\n",
      " Loss: 0.000012\n",
      " Loss: 0.127028\n",
      " Loss: 0.000003\n",
      " Loss: 0.039112\n",
      " Loss: 0.000002\n",
      " Loss: 0.064535\n",
      " Loss: 0.000002\n",
      " Loss: 0.118626\n",
      " Loss: 0.000017\n",
      " Loss: 0.044829\n",
      " Loss: 0.000002\n",
      " Loss: 0.059298\n",
      " Loss: 0.000002\n",
      " Loss: 0.058913\n",
      "Epoch 752 Chain 0 loss std 3.96e-02 variance 7.82e-04 smooth variance 1.04e-03 adaptive c -1.00\n",
      "Epoch 752 Chain 1 loss std 3.91e+02 variance 7.63e+04 smooth variance 5.72e+04 adaptive c -1.00\n",
      " Loss: 0.000010\n",
      " Loss: 0.065069\n",
      " Loss: 0.000003\n",
      " Loss: 0.032546\n",
      " Loss: 0.000009\n",
      " Loss: 0.140076\n",
      " Loss: 0.000002\n",
      " Loss: 0.058150\n",
      " Loss: 0.000002\n",
      " Loss: 0.049372\n",
      " Loss: 0.000010\n",
      " Loss: 0.058395\n",
      " Loss: 0.000002\n",
      " Loss: 0.063986\n",
      " Loss: 0.000009\n",
      " Loss: 0.120222\n",
      " Loss: 0.000002\n",
      " Loss: 0.040231\n",
      " Loss: 0.000002\n",
      " Loss: 0.061931\n",
      "Epoch 754 Chain 0 loss std 3.76e-02 variance 7.06e-04 smooth variance 9.41e-04 adaptive c -1.00\n",
      "Epoch 754 Chain 1 loss std 4.28e+02 variance 9.17e+04 smooth variance 6.75e+04 adaptive c -1.00\n",
      " Loss: 0.000003\n",
      " Loss: 0.042680\n",
      " Loss: 0.000008\n",
      " Loss: 0.129532\n",
      " Loss: 0.000003\n",
      " Loss: 0.067567\n",
      " Loss: 0.000010\n",
      " Loss: 0.026509\n",
      " Loss: 0.000002\n",
      " Loss: 0.077738\n",
      " Loss: 0.000010\n",
      " Loss: 0.029793\n",
      " Loss: 0.000002\n",
      " Loss: 0.076456\n",
      " Loss: 0.000008\n",
      " Loss: 0.034745\n",
      " Loss: 0.000001\n",
      " Loss: 0.059790\n",
      " Loss: 0.000003\n",
      " Loss: 0.142484\n",
      "Epoch 756 Chain 0 loss std 3.70e-02 variance 6.86e-04 smooth variance 8.65e-04 adaptive c -1.00\n",
      "Epoch 756 Chain 1 loss std 3.08e+02 variance 4.75e+04 smooth variance 6.15e+04 adaptive c -1.00\n",
      " Loss: 0.000011\n",
      " Loss: 0.106382\n",
      " Loss: 0.000002\n",
      " Loss: 0.082605\n",
      " Loss: 0.000007\n",
      " Loss: 0.058117\n",
      " Loss: 0.000002\n",
      " Loss: 0.058846\n",
      " Loss: 0.000003\n",
      " Loss: 0.036839\n",
      " Loss: 0.000010\n",
      " Loss: 0.052301\n",
      " Loss: 0.000002\n",
      " Loss: 0.137801\n",
      " Loss: 0.000002\n",
      " Loss: 0.054377\n",
      " Loss: 0.000008\n",
      " Loss: 0.036808\n",
      " Loss: 0.000002\n",
      " Loss: 0.060883\n",
      "Epoch 758 Chain 0 loss std 3.75e-02 variance 7.04e-04 smooth variance 8.16e-04 adaptive c -1.00\n",
      "Epoch 758 Chain 1 loss std 4.58e+02 variance 1.05e+05 smooth variance 7.45e+04 adaptive c -1.00\n",
      " Loss: 0.000006\n",
      " Loss: 0.035234\n",
      " Loss: 0.000003\n",
      " Loss: 0.122535\n",
      " Loss: 0.000011\n",
      " Loss: 0.069120\n",
      " Loss: 0.000003\n",
      " Loss: 0.068902\n",
      " Loss: 0.000001\n",
      " Loss: 0.045667\n",
      " Loss: 0.000012\n",
      " Loss: 0.118342\n",
      " Loss: 0.000005\n",
      " Loss: 0.042040\n",
      " Loss: 0.000001\n",
      " Loss: 0.039989\n",
      " Loss: 0.000002\n",
      " Loss: 0.068852\n",
      " Loss: 0.000002\n",
      " Loss: 0.071734\n",
      "Epoch 760 Chain 0 loss std 3.93e-02 variance 7.71e-04 smooth variance 8.03e-04 adaptive c -1.00\n",
      "Epoch 760 Chain 1 loss std 4.28e+02 variance 9.17e+04 smooth variance 7.97e+04 adaptive c -1.00\n",
      " Loss: 0.000002\n",
      " Loss: 0.039850\n",
      " Loss: 0.000002\n",
      " Loss: 0.069641\n",
      " Loss: 0.000002\n",
      " Loss: 0.048989\n",
      " Loss: 0.000014\n",
      " Loss: 0.048533\n",
      " Loss: 0.000002\n",
      " Loss: 0.133222\n",
      " Loss: 0.000010\n",
      " Loss: 0.069345\n",
      " Loss: 0.000002\n",
      " Loss: 0.035652\n",
      " Loss: 0.000002\n",
      " Loss: 0.131570\n",
      " Loss: 0.000007\n",
      " Loss: 0.026903\n",
      " Loss: 0.000002\n",
      " Loss: 0.076241\n",
      "Epoch 762 Chain 0 loss std 5.56e-02 variance 1.55e-03 smooth variance 1.03e-03 adaptive c -1.00\n",
      "Epoch 762 Chain 1 loss std 2.87e+02 variance 4.11e+04 smooth variance 6.81e+04 adaptive c -1.00\n",
      " Loss: 0.000002\n",
      " Loss: 0.049650\n",
      " Loss: 0.000002\n",
      " Loss: 0.123257\n",
      " Loss: 0.000001\n",
      " Loss: 0.066867\n",
      " Loss: 0.000014\n",
      " Loss: 0.028715\n",
      " Loss: 0.000002\n",
      " Loss: 0.070638\n",
      " Loss: 0.000002\n",
      " Loss: 0.104494\n",
      " Loss: 0.000009\n",
      " Loss: 0.085922\n",
      " Loss: 0.000001\n",
      " Loss: 0.053949\n",
      " Loss: 0.000001\n",
      " Loss: 0.061868\n",
      " Loss: 0.000007\n",
      " Loss: 0.032224\n",
      "Epoch 764 Chain 0 loss std 3.41e-02 variance 5.80e-04 smooth variance 8.92e-04 adaptive c -1.00\n",
      "Epoch 764 Chain 1 loss std 3.05e+02 variance 4.67e+04 smooth variance 6.17e+04 adaptive c -1.00\n",
      " Loss: 0.000002\n",
      " Loss: 0.053879\n",
      " Loss: 0.000008\n",
      " Loss: 0.077531\n",
      " Loss: 0.000007\n",
      " Loss: 0.095433\n",
      " Loss: 0.000001\n",
      " Loss: 0.040797\n",
      " Loss: 0.000002\n",
      " Loss: 0.070169\n",
      " Loss: 0.000009\n",
      " Loss: 0.113188\n",
      " Loss: 0.000006\n",
      " Loss: 0.089909\n",
      " Loss: 0.000001\n",
      " Loss: 0.050697\n",
      " Loss: 0.000002\n",
      " Loss: 0.042821\n",
      " Loss: 0.000001\n",
      " Loss: 0.040510\n",
      "Epoch 766 Chain 0 loss std 2.83e-02 variance 4.00e-04 smooth variance 7.45e-04 adaptive c -1.00\n",
      "Epoch 766 Chain 1 loss std 4.39e+02 variance 9.62e+04 smooth variance 7.20e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.037453\n",
      " Loss: 0.000001\n",
      " Loss: 0.056066\n",
      " Loss: 0.000002\n",
      " Loss: 0.048284\n",
      " Loss: 0.000002\n",
      " Loss: 0.080626\n",
      " Loss: 0.000013\n",
      " Loss: 0.114247\n",
      " Loss: 0.000001\n",
      " Loss: 0.029092\n",
      " Loss: 0.000008\n",
      " Loss: 0.063063\n",
      " Loss: 0.000002\n",
      " Loss: 0.064168\n",
      " Loss: 0.000007\n",
      " Loss: 0.128917\n",
      " Loss: 0.000001\n",
      " Loss: 0.050859\n",
      "Epoch 768 Chain 0 loss std 2.79e-02 variance 3.90e-04 smooth variance 6.38e-04 adaptive c -1.00\n",
      "Epoch 768 Chain 1 loss std 2.83e+02 variance 4.00e+04 smooth variance 6.24e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.039032\n",
      " Loss: 0.000002\n",
      " Loss: 0.119259\n",
      " Loss: 0.000012\n",
      " Loss: 0.057294\n",
      " Loss: 0.000002\n",
      " Loss: 0.058524\n",
      " Loss: 0.000002\n",
      " Loss: 0.061155\n",
      " Loss: 0.000001\n",
      " Loss: 0.052898\n",
      " Loss: 0.000001\n",
      " Loss: 0.063037\n",
      " Loss: 0.000007\n",
      " Loss: 0.037976\n",
      " Loss: 0.000002\n",
      " Loss: 0.056322\n",
      " Loss: 0.000007\n",
      " Loss: 0.124429\n",
      "Epoch 770 Chain 0 loss std 2.69e-02 variance 3.62e-04 smooth variance 5.56e-04 adaptive c -1.00\n",
      "Epoch 770 Chain 1 loss std 3.29e+02 variance 5.42e+04 smooth variance 5.99e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.041145\n",
      " Loss: 0.000002\n",
      " Loss: 0.117512\n",
      " Loss: 0.000001\n",
      " Loss: 0.048266\n",
      " Loss: 0.000006\n",
      " Loss: 0.049185\n",
      " Loss: 0.000007\n",
      " Loss: 0.078189\n",
      " Loss: 0.000001\n",
      " Loss: 0.053920\n",
      " Loss: 0.000007\n",
      " Loss: 0.045701\n",
      " Loss: 0.000002\n",
      " Loss: 0.044826\n",
      " Loss: 0.000002\n",
      " Loss: 0.132607\n",
      " Loss: 0.000005\n",
      " Loss: 0.056562\n",
      "Epoch 772 Chain 0 loss std 4.03e-02 variance 8.13e-04 smooth variance 6.33e-04 adaptive c -1.00\n",
      "Epoch 772 Chain 1 loss std 3.38e+02 variance 5.71e+04 smooth variance 5.91e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.041609\n",
      " Loss: 0.000001\n",
      " Loss: 0.065784\n",
      " Loss: 0.000001\n",
      " Loss: 0.120101\n",
      " Loss: 0.000007\n",
      " Loss: 0.043429\n",
      " Loss: 0.000006\n",
      " Loss: 0.062206\n",
      " Loss: 0.000001\n",
      " Loss: 0.052384\n",
      " Loss: 0.000001\n",
      " Loss: 0.113292\n",
      " Loss: 0.000001\n",
      " Loss: 0.064132\n",
      " Loss: 0.000011\n",
      " Loss: 0.035510\n",
      " Loss: 0.000002\n",
      " Loss: 0.067115\n",
      "Epoch 774 Chain 0 loss std 2.72e-02 variance 3.70e-04 smooth variance 5.54e-04 adaptive c -1.00\n",
      "Epoch 774 Chain 1 loss std 2.75e+02 variance 3.78e+04 smooth variance 5.27e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.064097\n",
      " Loss: 0.000007\n",
      " Loss: 0.097033\n",
      " Loss: 0.000005\n",
      " Loss: 0.062580\n",
      " Loss: 0.000001\n",
      " Loss: 0.048100\n",
      " Loss: 0.000001\n",
      " Loss: 0.059989\n",
      " Loss: 0.000002\n",
      " Loss: 0.047286\n",
      " Loss: 0.000002\n",
      " Loss: 0.055159\n",
      " Loss: 0.000001\n",
      " Loss: 0.041477\n",
      " Loss: 0.000006\n",
      " Loss: 0.060355\n",
      " Loss: 0.000005\n",
      " Loss: 0.127050\n",
      "Epoch 776 Chain 0 loss std 2.31e-02 variance 2.66e-04 smooth variance 4.68e-04 adaptive c -1.00\n",
      "Epoch 776 Chain 1 loss std 3.68e+02 variance 6.77e+04 smooth variance 5.72e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.107974\n",
      " Loss: 0.000002\n",
      " Loss: 0.041026\n",
      " Loss: 0.000001\n",
      " Loss: 0.074681\n",
      " Loss: 0.000001\n",
      " Loss: 0.034444\n",
      " Loss: 0.000010\n",
      " Loss: 0.072767\n",
      " Loss: 0.000001\n",
      " Loss: 0.047430\n",
      " Loss: 0.000002\n",
      " Loss: 0.095660\n",
      " Loss: 0.000001\n",
      " Loss: 0.046541\n",
      " Loss: 0.000006\n",
      " Loss: 0.051076\n",
      " Loss: 0.000005\n",
      " Loss: 0.089450\n",
      "Epoch 778 Chain 0 loss std 2.38e-02 variance 2.83e-04 smooth variance 4.12e-04 adaptive c -1.00\n",
      "Epoch 778 Chain 1 loss std 5.15e+02 variance 1.33e+05 smooth variance 7.98e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.066975\n",
      " Loss: 0.000006\n",
      " Loss: 0.114543\n",
      " Loss: 0.000001\n",
      " Loss: 0.050584\n",
      " Loss: 0.000005\n",
      " Loss: 0.050771\n",
      " Loss: 0.000001\n",
      " Loss: 0.046529\n",
      " Loss: 0.000005\n",
      " Loss: 0.044434\n",
      " Loss: 0.000006\n",
      " Loss: 0.095488\n",
      " Loss: 0.000002\n",
      " Loss: 0.084893\n",
      " Loss: 0.000001\n",
      " Loss: 0.060726\n",
      " Loss: 0.000001\n",
      " Loss: 0.043305\n",
      "Epoch 780 Chain 0 loss std 2.38e-02 variance 2.83e-04 smooth variance 3.74e-04 adaptive c -1.00\n",
      "Epoch 780 Chain 1 loss std 2.33e+02 variance 2.71e+04 smooth variance 6.40e+04 adaptive c -1.00\n",
      " Loss: 0.000005\n",
      " Loss: 0.040014\n",
      " Loss: 0.000001\n",
      " Loss: 0.043201\n",
      " Loss: 0.000002\n",
      " Loss: 0.141210\n",
      " Loss: 0.000006\n",
      " Loss: 0.052085\n",
      " Loss: 0.000001\n",
      " Loss: 0.051850\n",
      " Loss: 0.000001\n",
      " Loss: 0.059840\n",
      " Loss: 0.000005\n",
      " Loss: 0.097141\n",
      " Loss: 0.000001\n",
      " Loss: 0.048270\n",
      " Loss: 0.000001\n",
      " Loss: 0.047756\n",
      " Loss: 0.000006\n",
      " Loss: 0.074714\n",
      "Epoch 782 Chain 0 loss std 3.97e-02 variance 7.89e-04 smooth variance 4.98e-04 adaptive c -1.00\n",
      "Epoch 782 Chain 1 loss std 4.27e+02 variance 9.11e+04 smooth variance 7.22e+04 adaptive c -1.00\n",
      " Loss: 0.000005\n",
      " Loss: 0.044218\n",
      " Loss: 0.000001\n",
      " Loss: 0.040840\n",
      " Loss: 0.000007\n",
      " Loss: 0.109840\n",
      " Loss: 0.000001\n",
      " Loss: 0.073631\n",
      " Loss: 0.000001\n",
      " Loss: 0.058597\n",
      " Loss: 0.000001\n",
      " Loss: 0.116483\n",
      " Loss: 0.000001\n",
      " Loss: 0.070436\n",
      " Loss: 0.000001\n",
      " Loss: 0.038186\n",
      " Loss: 0.000006\n",
      " Loss: 0.048683\n",
      " Loss: 0.000005\n",
      " Loss: 0.052726\n",
      "Epoch 784 Chain 0 loss std 2.31e-02 variance 2.66e-04 smooth variance 4.28e-04 adaptive c -1.00\n",
      "Epoch 784 Chain 1 loss std 3.08e+02 variance 4.75e+04 smooth variance 6.48e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.059644\n",
      " Loss: 0.000009\n",
      " Loss: 0.049092\n",
      " Loss: 0.000001\n",
      " Loss: 0.054598\n",
      " Loss: 0.000002\n",
      " Loss: 0.107547\n",
      " Loss: 0.000001\n",
      " Loss: 0.055072\n",
      " Loss: 0.000005\n",
      " Loss: 0.066838\n",
      " Loss: 0.000001\n",
      " Loss: 0.042472\n",
      " Loss: 0.000001\n",
      " Loss: 0.116870\n",
      " Loss: 0.000001\n",
      " Loss: 0.048306\n",
      " Loss: 0.000006\n",
      " Loss: 0.051140\n",
      "Epoch 786 Chain 0 loss std 2.32e-02 variance 2.69e-04 smooth variance 3.81e-04 adaptive c -1.00\n",
      "Epoch 786 Chain 1 loss std 3.21e+02 variance 5.16e+04 smooth variance 6.08e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.047265\n",
      " Loss: 0.000004\n",
      " Loss: 0.049937\n",
      " Loss: 0.000001\n",
      " Loss: 0.060567\n",
      " Loss: 0.000006\n",
      " Loss: 0.110457\n",
      " Loss: 0.000002\n",
      " Loss: 0.056651\n",
      " Loss: 0.000005\n",
      " Loss: 0.063485\n",
      " Loss: 0.000001\n",
      " Loss: 0.039218\n",
      " Loss: 0.000002\n",
      " Loss: 0.118778\n",
      " Loss: 0.000005\n",
      " Loss: 0.025350\n",
      " Loss: 0.000001\n",
      " Loss: 0.077497\n",
      "Epoch 788 Chain 0 loss std 3.11e-02 variance 4.84e-04 smooth variance 4.12e-04 adaptive c -1.00\n",
      "Epoch 788 Chain 1 loss std 3.20e+02 variance 5.11e+04 smooth variance 5.79e+04 adaptive c -1.00\n",
      " Loss: 0.000005\n",
      " Loss: 0.045984\n",
      " Loss: 0.000001\n",
      " Loss: 0.067887\n",
      " Loss: 0.000004\n",
      " Loss: 0.052108\n",
      " Loss: 0.000001\n",
      " Loss: 0.112511\n",
      " Loss: 0.000001\n",
      " Loss: 0.045244\n",
      " Loss: 0.000000\n",
      " Loss: 0.058561\n",
      " Loss: 0.000001\n",
      " Loss: 0.097495\n",
      " Loss: 0.000004\n",
      " Loss: 0.061801\n",
      " Loss: 0.000001\n",
      " Loss: 0.057942\n",
      " Loss: 0.000006\n",
      " Loss: 0.047252\n",
      "Epoch 790 Chain 0 loss std 2.09e-02 variance 2.18e-04 smooth variance 3.53e-04 adaptive c -1.00\n",
      "Epoch 790 Chain 1 loss std 2.95e+02 variance 4.36e+04 smooth variance 5.36e+04 adaptive c -1.00\n",
      " Loss: 0.000003\n",
      " Loss: 0.051459\n",
      " Loss: 0.000001\n",
      " Loss: 0.040690\n",
      " Loss: 0.000006\n",
      " Loss: 0.050589\n",
      " Loss: 0.000001\n",
      " Loss: 0.050768\n",
      " Loss: 0.000001\n",
      " Loss: 0.129219\n",
      " Loss: 0.000005\n",
      " Loss: 0.065654\n",
      " Loss: 0.000001\n",
      " Loss: 0.119351\n",
      " Loss: 0.000005\n",
      " Loss: 0.048557\n",
      " Loss: 0.000001\n",
      " Loss: 0.033470\n",
      " Loss: 0.000001\n",
      " Loss: 0.055164\n",
      "Epoch 792 Chain 0 loss std 1.96e-02 variance 1.92e-04 smooth variance 3.05e-04 adaptive c -1.00\n",
      "Epoch 792 Chain 1 loss std 2.87e+02 variance 4.12e+04 smooth variance 4.99e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.086064\n",
      " Loss: 0.000001\n",
      " Loss: 0.035664\n",
      " Loss: 0.000004\n",
      " Loss: 0.036237\n",
      " Loss: 0.000002\n",
      " Loss: 0.120067\n",
      " Loss: 0.000005\n",
      " Loss: 0.043390\n",
      " Loss: 0.000004\n",
      " Loss: 0.039583\n",
      " Loss: 0.000001\n",
      " Loss: 0.054636\n",
      " Loss: 0.000005\n",
      " Loss: 0.059553\n",
      " Loss: 0.000001\n",
      " Loss: 0.102588\n",
      " Loss: 0.000001\n",
      " Loss: 0.064584\n",
      "Epoch 794 Chain 0 loss std 1.71e-02 variance 1.45e-04 smooth variance 2.57e-04 adaptive c -1.00\n",
      "Epoch 794 Chain 1 loss std 2.06e+02 variance 2.12e+04 smooth variance 4.13e+04 adaptive c -1.00\n",
      " Loss: 0.000004\n",
      " Loss: 0.035560\n",
      " Loss: 0.000001\n",
      " Loss: 0.065067\n",
      " Loss: 0.000005\n",
      " Loss: 0.104626\n",
      " Loss: 0.000001\n",
      " Loss: 0.051840\n",
      " Loss: 0.000001\n",
      " Loss: 0.063387\n",
      " Loss: 0.000001\n",
      " Loss: 0.109098\n",
      " Loss: 0.000005\n",
      " Loss: 0.067473\n",
      " Loss: 0.000004\n",
      " Loss: 0.070024\n",
      " Loss: 0.000001\n",
      " Loss: 0.029741\n",
      " Loss: 0.000001\n",
      " Loss: 0.043489\n",
      "Epoch 796 Chain 0 loss std 1.68e-02 variance 1.41e-04 smooth variance 2.22e-04 adaptive c -1.00\n",
      "Epoch 796 Chain 1 loss std 3.26e+02 variance 5.30e+04 smooth variance 4.48e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.076055\n",
      " Loss: 0.000004\n",
      " Loss: 0.046500\n",
      " Loss: 0.000001\n",
      " Loss: 0.026759\n",
      " Loss: 0.000005\n",
      " Loss: 0.044548\n",
      " Loss: 0.000001\n",
      " Loss: 0.125388\n",
      " Loss: 0.000001\n",
      " Loss: 0.108736\n",
      " Loss: 0.000001\n",
      " Loss: 0.040044\n",
      " Loss: 0.000004\n",
      " Loss: 0.061375\n",
      " Loss: 0.000001\n",
      " Loss: 0.052937\n",
      " Loss: 0.000005\n",
      " Loss: 0.055747\n",
      "Epoch 798 Chain 0 loss std 1.79e-02 variance 1.60e-04 smooth variance 2.04e-04 adaptive c -1.00\n",
      "Epoch 798 Chain 1 loss std 3.35e+02 variance 5.62e+04 smooth variance 4.82e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.069533\n",
      " Loss: 0.000007\n",
      " Loss: 0.035541\n",
      " Loss: 0.000001\n",
      " Loss: 0.039083\n",
      " Loss: 0.000001\n",
      " Loss: 0.040465\n",
      " Loss: 0.000001\n",
      " Loss: 0.134010\n",
      " Loss: 0.000001\n",
      " Loss: 0.060159\n",
      " Loss: 0.000001\n",
      " Loss: 0.052508\n",
      " Loss: 0.000001\n",
      " Loss: 0.065714\n",
      " Loss: 0.000007\n",
      " Loss: 0.105394\n",
      " Loss: 0.000001\n",
      " Loss: 0.034008\n",
      "Epoch 800 Chain 0 loss std 1.85e-02 variance 1.70e-04 smooth variance 1.94e-04 adaptive c -1.00\n",
      "Epoch 800 Chain 1 loss std 2.80e+02 variance 3.92e+04 smooth variance 4.55e+04 adaptive c -1.00\n",
      " Loss: 0.000005\n",
      " Loss: 0.031411\n",
      " Loss: 0.000001\n",
      " Loss: 0.062587\n",
      " Loss: 0.000004\n",
      " Loss: 0.060952\n",
      " Loss: 0.000001\n",
      " Loss: 0.113663\n",
      " Loss: 0.000001\n",
      " Loss: 0.048511\n",
      " Loss: 0.000004\n",
      " Loss: 0.038074\n",
      " Loss: 0.000001\n",
      " Loss: 0.080067\n",
      " Loss: 0.000001\n",
      " Loss: 0.059631\n",
      " Loss: 0.000004\n",
      " Loss: 0.104390\n",
      " Loss: 0.000001\n",
      " Loss: 0.034342\n",
      "Epoch 802 Chain 0 loss std 1.59e-02 variance 1.27e-04 smooth variance 1.74e-04 adaptive c -1.00\n",
      "Epoch 802 Chain 1 loss std 3.23e+02 variance 5.22e+04 smooth variance 4.75e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.047034\n",
      " Loss: 0.000001\n",
      " Loss: 0.031265\n",
      " Loss: 0.000001\n",
      " Loss: 0.043337\n",
      " Loss: 0.000001\n",
      " Loss: 0.068000\n",
      " Loss: 0.000007\n",
      " Loss: 0.126220\n",
      " Loss: 0.000001\n",
      " Loss: 0.054678\n",
      " Loss: 0.000007\n",
      " Loss: 0.043570\n",
      " Loss: 0.000001\n",
      " Loss: 0.059450\n",
      " Loss: 0.000001\n",
      " Loss: 0.040902\n",
      " Loss: 0.000001\n",
      " Loss: 0.116899\n",
      "Epoch 804 Chain 0 loss std 1.66e-02 variance 1.38e-04 smooth variance 1.63e-04 adaptive c -1.00\n",
      "Epoch 804 Chain 1 loss std 3.58e+02 variance 6.42e+04 smooth variance 5.25e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.065295\n",
      " Loss: 0.000004\n",
      " Loss: 0.048232\n",
      " Loss: 0.000001\n",
      " Loss: 0.053769\n",
      " Loss: 0.000004\n",
      " Loss: 0.103196\n",
      " Loss: 0.000001\n",
      " Loss: 0.044407\n",
      " Loss: 0.000001\n",
      " Loss: 0.042331\n",
      " Loss: 0.000001\n",
      " Loss: 0.037339\n",
      " Loss: 0.000006\n",
      " Loss: 0.030170\n",
      " Loss: 0.000001\n",
      " Loss: 0.160637\n",
      " Loss: 0.000001\n",
      " Loss: 0.043759\n",
      "Epoch 806 Chain 0 loss std 1.53e-02 variance 1.17e-04 smooth variance 1.49e-04 adaptive c -1.00\n",
      "Epoch 806 Chain 1 loss std 3.10e+02 variance 4.80e+04 smooth variance 5.12e+04 adaptive c -1.00\n",
      " Loss: 0.000007\n",
      " Loss: 0.032882\n",
      " Loss: 0.000001\n",
      " Loss: 0.104398\n",
      " Loss: 0.000001\n",
      " Loss: 0.060826\n",
      " Loss: 0.000001\n",
      " Loss: 0.066485\n",
      " Loss: 0.000001\n",
      " Loss: 0.049149\n",
      " Loss: 0.000001\n",
      " Loss: 0.061930\n",
      " Loss: 0.000001\n",
      " Loss: 0.038715\n",
      " Loss: 0.000003\n",
      " Loss: 0.029131\n",
      " Loss: 0.000004\n",
      " Loss: 0.063865\n",
      " Loss: 0.000001\n",
      " Loss: 0.119911\n",
      "Epoch 808 Chain 0 loss std 2.27e-02 variance 2.57e-04 smooth variance 1.81e-04 adaptive c -1.00\n",
      "Epoch 808 Chain 1 loss std 2.88e+02 variance 4.14e+04 smooth variance 4.83e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.062330\n",
      " Loss: 0.000001\n",
      " Loss: 0.044877\n",
      " Loss: 0.000004\n",
      " Loss: 0.093236\n",
      " Loss: 0.000003\n",
      " Loss: 0.042197\n",
      " Loss: 0.000001\n",
      " Loss: 0.070297\n",
      " Loss: 0.000001\n",
      " Loss: 0.114486\n",
      " Loss: 0.000004\n",
      " Loss: 0.074139\n",
      " Loss: 0.000001\n",
      " Loss: 0.032769\n",
      " Loss: 0.000003\n",
      " Loss: 0.061290\n",
      " Loss: 0.000001\n",
      " Loss: 0.029591\n",
      "Epoch 810 Chain 0 loss std 1.52e-02 variance 1.16e-04 smooth variance 1.62e-04 adaptive c -1.00\n",
      "Epoch 810 Chain 1 loss std 3.85e+02 variance 7.42e+04 smooth variance 5.60e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.070549\n",
      " Loss: 0.000001\n",
      " Loss: 0.049562\n",
      " Loss: 0.000004\n",
      " Loss: 0.025576\n",
      " Loss: 0.000003\n",
      " Loss: 0.092676\n",
      " Loss: 0.000001\n",
      " Loss: 0.073314\n",
      " Loss: 0.000001\n",
      " Loss: 0.039283\n",
      " Loss: 0.000004\n",
      " Loss: 0.062953\n",
      " Loss: 0.000001\n",
      " Loss: 0.058428\n",
      " Loss: 0.000003\n",
      " Loss: 0.109939\n",
      " Loss: 0.000001\n",
      " Loss: 0.040506\n",
      "Epoch 812 Chain 0 loss std 1.37e-02 variance 9.43e-05 smooth variance 1.42e-04 adaptive c -1.00\n",
      "Epoch 812 Chain 1 loss std 1.84e+02 variance 1.68e+04 smooth variance 4.43e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.068356\n",
      " Loss: 0.000006\n",
      " Loss: 0.043038\n",
      " Loss: 0.000001\n",
      " Loss: 0.112527\n",
      " Loss: 0.000001\n",
      " Loss: 0.032201\n",
      " Loss: 0.000001\n",
      " Loss: 0.054510\n",
      " Loss: 0.000001\n",
      " Loss: 0.058649\n",
      " Loss: 0.000000\n",
      " Loss: 0.049422\n",
      " Loss: 0.000001\n",
      " Loss: 0.122846\n",
      " Loss: 0.000001\n",
      " Loss: 0.050231\n",
      " Loss: 0.000006\n",
      " Loss: 0.029088\n",
      "Epoch 814 Chain 0 loss std 2.02e-02 variance 2.04e-04 smooth variance 1.60e-04 adaptive c -1.00\n",
      "Epoch 814 Chain 1 loss std 3.42e+02 variance 5.86e+04 smooth variance 4.86e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.037677\n",
      " Loss: 0.000001\n",
      " Loss: 0.113531\n",
      " Loss: 0.000004\n",
      " Loss: 0.049991\n",
      " Loss: 0.000003\n",
      " Loss: 0.069360\n",
      " Loss: 0.000001\n",
      " Loss: 0.038973\n",
      " Loss: 0.000003\n",
      " Loss: 0.040902\n",
      " Loss: 0.000001\n",
      " Loss: 0.048532\n",
      " Loss: 0.000003\n",
      " Loss: 0.133905\n",
      " Loss: 0.000001\n",
      " Loss: 0.035070\n",
      " Loss: 0.000001\n",
      " Loss: 0.050458\n",
      "Epoch 816 Chain 0 loss std 1.35e-02 variance 9.08e-05 smooth variance 1.39e-04 adaptive c -1.00\n",
      "Epoch 816 Chain 1 loss std 1.59e+02 variance 1.26e+04 smooth variance 3.78e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.104305\n",
      " Loss: 0.000001\n",
      " Loss: 0.037548\n",
      " Loss: 0.000003\n",
      " Loss: 0.047007\n",
      " Loss: 0.000003\n",
      " Loss: 0.062187\n",
      " Loss: 0.000001\n",
      " Loss: 0.057451\n",
      " Loss: 0.000002\n",
      " Loss: 0.066100\n",
      " Loss: 0.000001\n",
      " Loss: 0.035233\n",
      " Loss: 0.000003\n",
      " Loss: 0.057580\n",
      " Loss: 0.000001\n",
      " Loss: 0.112822\n",
      " Loss: 0.000001\n",
      " Loss: 0.036055\n",
      "Epoch 818 Chain 0 loss std 2.01e-02 variance 2.03e-04 smooth variance 1.58e-04 adaptive c -1.00\n",
      "Epoch 818 Chain 1 loss std 2.15e+02 variance 2.31e+04 smooth variance 3.34e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.042088\n",
      " Loss: 0.000003\n",
      " Loss: 0.036393\n",
      " Loss: 0.000003\n",
      " Loss: 0.108028\n",
      " Loss: 0.000001\n",
      " Loss: 0.080546\n",
      " Loss: 0.000001\n",
      " Loss: 0.040306\n",
      " Loss: 0.000001\n",
      " Loss: 0.046328\n",
      " Loss: 0.000003\n",
      " Loss: 0.108874\n",
      " Loss: 0.000001\n",
      " Loss: 0.047280\n",
      " Loss: 0.000003\n",
      " Loss: 0.059208\n",
      " Loss: 0.000001\n",
      " Loss: 0.045130\n",
      "Epoch 820 Chain 0 loss std 1.23e-02 variance 7.60e-05 smooth variance 1.34e-04 adaptive c -1.00\n",
      "Epoch 820 Chain 1 loss std 3.63e+02 variance 6.60e+04 smooth variance 4.32e+04 adaptive c -1.00\n",
      " Loss: 0.000003\n",
      " Loss: 0.051157\n",
      " Loss: 0.000003\n",
      " Loss: 0.058450\n",
      " Loss: 0.000001\n",
      " Loss: 0.105715\n",
      " Loss: 0.000001\n",
      " Loss: 0.058203\n",
      " Loss: 0.000001\n",
      " Loss: 0.032836\n",
      " Loss: 0.000003\n",
      " Loss: 0.040086\n",
      " Loss: 0.000001\n",
      " Loss: 0.123050\n",
      " Loss: 0.000001\n",
      " Loss: 0.041857\n",
      " Loss: 0.000002\n",
      " Loss: 0.060582\n",
      " Loss: 0.000001\n",
      " Loss: 0.040133\n",
      "Epoch 822 Chain 0 loss std 1.24e-02 variance 7.70e-05 smooth variance 1.17e-04 adaptive c -1.00\n",
      "Epoch 822 Chain 1 loss std 3.47e+02 variance 6.01e+04 smooth variance 4.83e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.039842\n",
      " Loss: 0.000005\n",
      " Loss: 0.088815\n",
      " Loss: 0.000000\n",
      " Loss: 0.054127\n",
      " Loss: 0.000001\n",
      " Loss: 0.073055\n",
      " Loss: 0.000000\n",
      " Loss: 0.049444\n",
      " Loss: 0.000003\n",
      " Loss: 0.061083\n",
      " Loss: 0.000001\n",
      " Loss: 0.042435\n",
      " Loss: 0.000000\n",
      " Loss: 0.030234\n",
      " Loss: 0.000003\n",
      " Loss: 0.048812\n",
      " Loss: 0.000001\n",
      " Loss: 0.122051\n",
      "Epoch 824 Chain 0 loss std 1.15e-02 variance 6.59e-05 smooth variance 1.01e-04 adaptive c -1.00\n",
      "Epoch 824 Chain 1 loss std 2.99e+02 variance 4.46e+04 smooth variance 4.72e+04 adaptive c -1.00\n",
      " Loss: 0.000003\n",
      " Loss: 0.103266\n",
      " Loss: 0.000000\n",
      " Loss: 0.059315\n",
      " Loss: 0.000003\n",
      " Loss: 0.033758\n",
      " Loss: 0.000000\n",
      " Loss: 0.048876\n",
      " Loss: 0.000001\n",
      " Loss: 0.058987\n",
      " Loss: 0.000003\n",
      " Loss: 0.104197\n",
      " Loss: 0.000003\n",
      " Loss: 0.042056\n",
      " Loss: 0.000001\n",
      " Loss: 0.051770\n",
      " Loss: 0.000001\n",
      " Loss: 0.043316\n",
      " Loss: 0.000001\n",
      " Loss: 0.062563\n",
      "Epoch 826 Chain 0 loss std 1.15e-02 variance 6.66e-05 smooth variance 9.10e-05 adaptive c -1.00\n",
      "Epoch 826 Chain 1 loss std 2.48e+02 variance 3.07e+04 smooth variance 4.22e+04 adaptive c -1.00\n",
      " Loss: 0.000003\n",
      " Loss: 0.041758\n",
      " Loss: 0.000000\n",
      " Loss: 0.033885\n",
      " Loss: 0.000001\n",
      " Loss: 0.056127\n",
      " Loss: 0.000000\n",
      " Loss: 0.059136\n",
      " Loss: 0.000003\n",
      " Loss: 0.112081\n",
      " Loss: 0.000003\n",
      " Loss: 0.108390\n",
      " Loss: 0.000001\n",
      " Loss: 0.043019\n",
      " Loss: 0.000001\n",
      " Loss: 0.038060\n",
      " Loss: 0.000000\n",
      " Loss: 0.044210\n",
      " Loss: 0.000003\n",
      " Loss: 0.068964\n",
      "Epoch 828 Chain 0 loss std 1.22e-02 variance 7.49e-05 smooth variance 8.62e-05 adaptive c -1.00\n",
      "Epoch 828 Chain 1 loss std 3.35e+02 variance 5.63e+04 smooth variance 4.64e+04 adaptive c -1.00\n",
      " Loss: 0.000003\n",
      " Loss: 0.055369\n",
      " Loss: 0.000000\n",
      " Loss: 0.038767\n",
      " Loss: 0.000000\n",
      " Loss: 0.046255\n",
      " Loss: 0.000001\n",
      " Loss: 0.058125\n",
      " Loss: 0.000004\n",
      " Loss: 0.103824\n",
      " Loss: 0.000001\n",
      " Loss: 0.041094\n",
      " Loss: 0.000001\n",
      " Loss: 0.101334\n",
      " Loss: 0.000000\n",
      " Loss: 0.071146\n",
      " Loss: 0.000001\n",
      " Loss: 0.029750\n",
      " Loss: 0.000005\n",
      " Loss: 0.058462\n",
      "Epoch 830 Chain 0 loss std 1.39e-02 variance 9.61e-05 smooth variance 8.91e-05 adaptive c -1.00\n",
      "Epoch 830 Chain 1 loss std 2.42e+02 variance 2.93e+04 smooth variance 4.13e+04 adaptive c -1.00\n",
      " Loss: 0.000002\n",
      " Loss: 0.040960\n",
      " Loss: 0.000001\n",
      " Loss: 0.055562\n",
      " Loss: 0.000001\n",
      " Loss: 0.040429\n",
      " Loss: 0.000003\n",
      " Loss: 0.107648\n",
      " Loss: 0.000000\n",
      " Loss: 0.056510\n",
      " Loss: 0.000001\n",
      " Loss: 0.114252\n",
      " Loss: 0.000003\n",
      " Loss: 0.066147\n",
      " Loss: 0.000001\n",
      " Loss: 0.039658\n",
      " Loss: 0.000003\n",
      " Loss: 0.045137\n",
      " Loss: 0.000001\n",
      " Loss: 0.035406\n",
      "Epoch 832 Chain 0 loss std 1.10e-02 variance 6.08e-05 smooth variance 8.07e-05 adaptive c -1.00\n",
      "Epoch 832 Chain 1 loss std 3.92e+02 variance 7.67e+04 smooth variance 5.19e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.125843\n",
      " Loss: 0.000002\n",
      " Loss: 0.051504\n",
      " Loss: 0.000000\n",
      " Loss: 0.036989\n",
      " Loss: 0.000001\n",
      " Loss: 0.038398\n",
      " Loss: 0.000003\n",
      " Loss: 0.047216\n",
      " Loss: 0.000001\n",
      " Loss: 0.052112\n",
      " Loss: 0.000000\n",
      " Loss: 0.067927\n",
      " Loss: 0.000002\n",
      " Loss: 0.042215\n",
      " Loss: 0.000003\n",
      " Loss: 0.034649\n",
      " Loss: 0.000000\n",
      " Loss: 0.102717\n",
      "Epoch 834 Chain 0 loss std 1.13e-02 variance 6.35e-05 smooth variance 7.55e-05 adaptive c -1.00\n",
      "Epoch 834 Chain 1 loss std 2.80e+02 variance 3.93e+04 smooth variance 4.81e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.057352\n",
      " Loss: 0.000001\n",
      " Loss: 0.058847\n",
      " Loss: 0.000005\n",
      " Loss: 0.114212\n",
      " Loss: 0.000000\n",
      " Loss: 0.034310\n",
      " Loss: 0.000001\n",
      " Loss: 0.034167\n",
      " Loss: 0.000001\n",
      " Loss: 0.034270\n",
      " Loss: 0.000001\n",
      " Loss: 0.035329\n",
      " Loss: 0.000002\n",
      " Loss: 0.114161\n",
      " Loss: 0.000000\n",
      " Loss: 0.065581\n",
      " Loss: 0.000003\n",
      " Loss: 0.049185\n",
      "Epoch 836 Chain 0 loss std 1.02e-02 variance 5.16e-05 smooth variance 6.83e-05 adaptive c -1.00\n",
      "Epoch 836 Chain 1 loss std 3.28e+02 variance 5.38e+04 smooth variance 4.98e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.043797\n",
      " Loss: 0.000002\n",
      " Loss: 0.034405\n",
      " Loss: 0.000000\n",
      " Loss: 0.045948\n",
      " Loss: 0.000000\n",
      " Loss: 0.059086\n",
      " Loss: 0.000003\n",
      " Loss: 0.114795\n",
      " Loss: 0.000001\n",
      " Loss: 0.040300\n",
      " Loss: 0.000000\n",
      " Loss: 0.111592\n",
      " Loss: 0.000002\n",
      " Loss: 0.072954\n",
      " Loss: 0.000001\n",
      " Loss: 0.034140\n",
      " Loss: 0.000003\n",
      " Loss: 0.038370\n",
      "Epoch 838 Chain 0 loss std 1.14e-02 variance 6.54e-05 smooth variance 6.75e-05 adaptive c -1.00\n",
      "Epoch 838 Chain 1 loss std 2.30e+02 variance 2.64e+04 smooth variance 4.28e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.065489\n",
      " Loss: 0.000000\n",
      " Loss: 0.051829\n",
      " Loss: 0.000003\n",
      " Loss: 0.038471\n",
      " Loss: 0.000001\n",
      " Loss: 0.095525\n",
      " Loss: 0.000002\n",
      " Loss: 0.045700\n",
      " Loss: 0.000001\n",
      " Loss: 0.045441\n",
      " Loss: 0.000002\n",
      " Loss: 0.047246\n",
      " Loss: 0.000003\n",
      " Loss: 0.093717\n",
      " Loss: 0.000000\n",
      " Loss: 0.050410\n",
      " Loss: 0.000001\n",
      " Loss: 0.059536\n",
      "Epoch 840 Chain 0 loss std 1.66e-02 variance 1.38e-04 smooth variance 8.87e-05 adaptive c -1.00\n",
      "Epoch 840 Chain 1 loss std 4.46e+02 variance 9.93e+04 smooth variance 5.97e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.105981\n",
      " Loss: 0.000000\n",
      " Loss: 0.069202\n",
      " Loss: 0.000000\n",
      " Loss: 0.033229\n",
      " Loss: 0.000004\n",
      " Loss: 0.046744\n",
      " Loss: 0.000001\n",
      " Loss: 0.040709\n",
      " Loss: 0.000001\n",
      " Loss: 0.131700\n",
      " Loss: 0.000000\n",
      " Loss: 0.045427\n",
      " Loss: 0.000000\n",
      " Loss: 0.038042\n",
      " Loss: 0.000000\n",
      " Loss: 0.037394\n",
      " Loss: 0.000004\n",
      " Loss: 0.042902\n",
      "Epoch 842 Chain 0 loss std 9.71e-03 variance 4.71e-05 smooth variance 7.63e-05 adaptive c -1.00\n",
      "Epoch 842 Chain 1 loss std 2.97e+02 variance 4.42e+04 smooth variance 5.51e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.031392\n",
      " Loss: 0.000001\n",
      " Loss: 0.064652\n",
      " Loss: 0.000004\n",
      " Loss: 0.039175\n",
      " Loss: 0.000000\n",
      " Loss: 0.034270\n",
      " Loss: 0.000000\n",
      " Loss: 0.125783\n",
      " Loss: 0.000002\n",
      " Loss: 0.031812\n",
      " Loss: 0.000002\n",
      " Loss: 0.030607\n",
      " Loss: 0.000000\n",
      " Loss: 0.081360\n",
      " Loss: 0.000000\n",
      " Loss: 0.039242\n",
      " Loss: 0.000001\n",
      " Loss: 0.111360\n",
      "Epoch 844 Chain 0 loss std 1.69e-02 variance 1.42e-04 smooth variance 9.61e-05 adaptive c -1.00\n",
      "Epoch 844 Chain 1 loss std 3.68e+02 variance 6.78e+04 smooth variance 5.89e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.041031\n",
      " Loss: 0.000004\n",
      " Loss: 0.024674\n",
      " Loss: 0.000000\n",
      " Loss: 0.068420\n",
      " Loss: 0.000001\n",
      " Loss: 0.036857\n",
      " Loss: 0.000000\n",
      " Loss: 0.122825\n",
      " Loss: 0.000000\n",
      " Loss: 0.052355\n",
      " Loss: 0.000000\n",
      " Loss: 0.057232\n",
      " Loss: 0.000003\n",
      " Loss: 0.034770\n",
      " Loss: 0.000002\n",
      " Loss: 0.064008\n",
      " Loss: 0.000001\n",
      " Loss: 0.085114\n",
      "Epoch 846 Chain 0 loss std 8.87e-03 variance 3.93e-05 smooth variance 7.90e-05 adaptive c -1.00\n",
      "Epoch 846 Chain 1 loss std 1.86e+02 variance 1.73e+04 smooth variance 4.64e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.102469\n",
      " Loss: 0.000001\n",
      " Loss: 0.047131\n",
      " Loss: 0.000000\n",
      " Loss: 0.045982\n",
      " Loss: 0.000002\n",
      " Loss: 0.019989\n",
      " Loss: 0.000002\n",
      " Loss: 0.077608\n",
      " Loss: 0.000002\n",
      " Loss: 0.037622\n",
      " Loss: 0.000000\n",
      " Loss: 0.044822\n",
      " Loss: 0.000003\n",
      " Loss: 0.050667\n",
      " Loss: 0.000001\n",
      " Loss: 0.109589\n",
      " Loss: 0.000001\n",
      " Loss: 0.049668\n",
      "Epoch 848 Chain 0 loss std 8.78e-03 variance 3.85e-05 smooth variance 6.69e-05 adaptive c -1.00\n",
      "Epoch 848 Chain 1 loss std 2.86e+02 variance 4.08e+04 smooth variance 4.47e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.068993\n",
      " Loss: 0.000002\n",
      " Loss: 0.049623\n",
      " Loss: 0.000000\n",
      " Loss: 0.104052\n",
      " Loss: 0.000002\n",
      " Loss: 0.036909\n",
      " Loss: 0.000001\n",
      " Loss: 0.032491\n",
      " Loss: 0.000000\n",
      " Loss: 0.053072\n",
      " Loss: 0.000002\n",
      " Loss: 0.090567\n",
      " Loss: 0.000001\n",
      " Loss: 0.045157\n",
      " Loss: 0.000000\n",
      " Loss: 0.060879\n",
      " Loss: 0.000002\n",
      " Loss: 0.041711\n",
      "Epoch 850 Chain 0 loss std 9.35e-03 variance 4.37e-05 smooth variance 5.99e-05 adaptive c -1.00\n",
      "Epoch 850 Chain 1 loss std 4.41e+02 variance 9.74e+04 smooth variance 6.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.049166\n",
      " Loss: 0.000001\n",
      " Loss: 0.095417\n",
      " Loss: 0.000002\n",
      " Loss: 0.052698\n",
      " Loss: 0.000002\n",
      " Loss: 0.041043\n",
      " Loss: 0.000000\n",
      " Loss: 0.052504\n",
      " Loss: 0.000000\n",
      " Loss: 0.057420\n",
      " Loss: 0.000002\n",
      " Loss: 0.032279\n",
      " Loss: 0.000000\n",
      " Loss: 0.064505\n",
      " Loss: 0.000002\n",
      " Loss: 0.094029\n",
      " Loss: 0.000001\n",
      " Loss: 0.042088\n",
      "Epoch 852 Chain 0 loss std 8.06e-03 variance 3.24e-05 smooth variance 5.17e-05 adaptive c -1.00\n",
      "Epoch 852 Chain 1 loss std 2.41e+02 variance 2.89e+04 smooth variance 5.10e+04 adaptive c -1.00\n",
      " Loss: 0.000002\n",
      " Loss: 0.049890\n",
      " Loss: 0.000000\n",
      " Loss: 0.044155\n",
      " Loss: 0.000000\n",
      " Loss: 0.043796\n",
      " Loss: 0.000002\n",
      " Loss: 0.097964\n",
      " Loss: 0.000000\n",
      " Loss: 0.054416\n",
      " Loss: 0.000000\n",
      " Loss: 0.056046\n",
      " Loss: 0.000000\n",
      " Loss: 0.046852\n",
      " Loss: 0.000000\n",
      " Loss: 0.063294\n",
      " Loss: 0.000002\n",
      " Loss: 0.028649\n",
      " Loss: 0.000002\n",
      " Loss: 0.094671\n",
      "Epoch 854 Chain 0 loss std 1.29e-02 variance 8.34e-05 smooth variance 6.12e-05 adaptive c -1.00\n",
      "Epoch 854 Chain 1 loss std 2.94e+02 variance 4.34e+04 smooth variance 4.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029730\n",
      " Loss: 0.000002\n",
      " Loss: 0.060778\n",
      " Loss: 0.000001\n",
      " Loss: 0.032202\n",
      " Loss: 0.000002\n",
      " Loss: 0.046015\n",
      " Loss: 0.000001\n",
      " Loss: 0.120212\n",
      " Loss: 0.000000\n",
      " Loss: 0.040391\n",
      " Loss: 0.000002\n",
      " Loss: 0.044911\n",
      " Loss: 0.000000\n",
      " Loss: 0.079258\n",
      " Loss: 0.000001\n",
      " Loss: 0.083659\n",
      " Loss: 0.000002\n",
      " Loss: 0.040207\n",
      "Epoch 856 Chain 0 loss std 7.66e-03 variance 2.93e-05 smooth variance 5.16e-05 adaptive c -1.00\n",
      "Epoch 856 Chain 1 loss std 2.83e+02 variance 4.00e+04 smooth variance 4.61e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.093775\n",
      " Loss: 0.000002\n",
      " Loss: 0.021669\n",
      " Loss: 0.000001\n",
      " Loss: 0.092028\n",
      " Loss: 0.000000\n",
      " Loss: 0.039661\n",
      " Loss: 0.000002\n",
      " Loss: 0.040912\n",
      " Loss: 0.000002\n",
      " Loss: 0.038607\n",
      " Loss: 0.000002\n",
      " Loss: 0.030045\n",
      " Loss: 0.000000\n",
      " Loss: 0.103502\n",
      " Loss: 0.000000\n",
      " Loss: 0.058042\n",
      " Loss: 0.000000\n",
      " Loss: 0.057272\n",
      "Epoch 858 Chain 0 loss std 8.84e-03 variance 3.91e-05 smooth variance 4.79e-05 adaptive c -1.00\n",
      "Epoch 858 Chain 1 loss std 1.73e+02 variance 1.49e+04 smooth variance 3.67e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035405\n",
      " Loss: 0.000002\n",
      " Loss: 0.060672\n",
      " Loss: 0.000000\n",
      " Loss: 0.059923\n",
      " Loss: 0.000002\n",
      " Loss: 0.095800\n",
      " Loss: 0.000000\n",
      " Loss: 0.035100\n",
      " Loss: 0.000000\n",
      " Loss: 0.040415\n",
      " Loss: 0.000000\n",
      " Loss: 0.082456\n",
      " Loss: 0.000002\n",
      " Loss: 0.031266\n",
      " Loss: 0.000000\n",
      " Loss: 0.073354\n",
      " Loss: 0.000001\n",
      " Loss: 0.059120\n",
      "Epoch 860 Chain 0 loss std 8.68e-03 variance 3.77e-05 smooth variance 4.48e-05 adaptive c -1.00\n",
      "Epoch 860 Chain 1 loss std 2.59e+02 variance 3.35e+04 smooth variance 3.58e+04 adaptive c -1.00\n",
      " Loss: 0.000002\n",
      " Loss: 0.026322\n",
      " Loss: 0.000000\n",
      " Loss: 0.051189\n",
      " Loss: 0.000002\n",
      " Loss: 0.037140\n",
      " Loss: 0.000000\n",
      " Loss: 0.062311\n",
      " Loss: 0.000001\n",
      " Loss: 0.109068\n",
      " Loss: 0.000001\n",
      " Loss: 0.054766\n",
      " Loss: 0.000000\n",
      " Loss: 0.044475\n",
      " Loss: 0.000000\n",
      " Loss: 0.098915\n",
      " Loss: 0.000000\n",
      " Loss: 0.056647\n",
      " Loss: 0.000003\n",
      " Loss: 0.030769\n",
      "Epoch 862 Chain 0 loss std 9.66e-03 variance 4.67e-05 smooth variance 4.54e-05 adaptive c -1.00\n",
      "Epoch 862 Chain 1 loss std 2.39e+02 variance 2.85e+04 smooth variance 3.36e+04 adaptive c -1.00\n",
      " Loss: 0.000003\n",
      " Loss: 0.052256\n",
      " Loss: 0.000000\n",
      " Loss: 0.093267\n",
      " Loss: 0.000000\n",
      " Loss: 0.043776\n",
      " Loss: 0.000001\n",
      " Loss: 0.056976\n",
      " Loss: 0.000000\n",
      " Loss: 0.038697\n",
      " Loss: 0.000000\n",
      " Loss: 0.103209\n",
      " Loss: 0.000002\n",
      " Loss: 0.063373\n",
      " Loss: 0.000000\n",
      " Loss: 0.032501\n",
      " Loss: 0.000000\n",
      " Loss: 0.052176\n",
      " Loss: 0.000002\n",
      " Loss: 0.033497\n",
      "Epoch 864 Chain 0 loss std 7.47e-03 variance 2.79e-05 smooth variance 4.01e-05 adaptive c -1.00\n",
      "Epoch 864 Chain 1 loss std 3.18e+02 variance 5.06e+04 smooth variance 3.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.069724\n",
      " Loss: 0.000003\n",
      " Loss: 0.045097\n",
      " Loss: 0.000000\n",
      " Loss: 0.029934\n",
      " Loss: 0.000000\n",
      " Loss: 0.046965\n",
      " Loss: 0.000000\n",
      " Loss: 0.093053\n",
      " Loss: 0.000002\n",
      " Loss: 0.040948\n",
      " Loss: 0.000001\n",
      " Loss: 0.068502\n",
      " Loss: 0.000000\n",
      " Loss: 0.104254\n",
      " Loss: 0.000000\n",
      " Loss: 0.034695\n",
      " Loss: 0.000000\n",
      " Loss: 0.035125\n",
      "Epoch 866 Chain 0 loss std 8.55e-03 variance 3.65e-05 smooth variance 3.90e-05 adaptive c -1.00\n",
      "Epoch 866 Chain 1 loss std 2.85e+02 variance 4.07e+04 smooth variance 3.93e+04 adaptive c -1.00\n",
      " Loss: 0.000002\n",
      " Loss: 0.028443\n",
      " Loss: 0.000000\n",
      " Loss: 0.041128\n",
      " Loss: 0.000000\n",
      " Loss: 0.046037\n",
      " Loss: 0.000001\n",
      " Loss: 0.110395\n",
      " Loss: 0.000000\n",
      " Loss: 0.057059\n",
      " Loss: 0.000000\n",
      " Loss: 0.026459\n",
      " Loss: 0.000001\n",
      " Loss: 0.046068\n",
      " Loss: 0.000000\n",
      " Loss: 0.033130\n",
      " Loss: 0.000000\n",
      " Loss: 0.105002\n",
      " Loss: 0.000002\n",
      " Loss: 0.071891\n",
      "Epoch 868 Chain 0 loss std 8.47e-03 variance 3.59e-05 smooth variance 3.81e-05 adaptive c -1.00\n",
      "Epoch 868 Chain 1 loss std 2.73e+02 variance 3.73e+04 smooth variance 3.87e+04 adaptive c -1.00\n",
      " Loss: 0.000002\n",
      " Loss: 0.057997\n",
      " Loss: 0.000000\n",
      " Loss: 0.100032\n",
      " Loss: 0.000001\n",
      " Loss: 0.023802\n",
      " Loss: 0.000000\n",
      " Loss: 0.051495\n",
      " Loss: 0.000000\n",
      " Loss: 0.048817\n",
      " Loss: 0.000000\n",
      " Loss: 0.052749\n",
      " Loss: 0.000000\n",
      " Loss: 0.061100\n",
      " Loss: 0.000002\n",
      " Loss: 0.028740\n",
      " Loss: 0.000001\n",
      " Loss: 0.098848\n",
      " Loss: 0.000000\n",
      " Loss: 0.040312\n",
      "Epoch 870 Chain 0 loss std 1.07e-02 variance 5.76e-05 smooth variance 4.39e-05 adaptive c -1.00\n",
      "Epoch 870 Chain 1 loss std 3.78e+02 variance 7.14e+04 smooth variance 4.85e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027423\n",
      " Loss: 0.000002\n",
      " Loss: 0.059408\n",
      " Loss: 0.000001\n",
      " Loss: 0.092391\n",
      " Loss: 0.000000\n",
      " Loss: 0.041301\n",
      " Loss: 0.000000\n",
      " Loss: 0.060678\n",
      " Loss: 0.000001\n",
      " Loss: 0.068972\n",
      " Loss: 0.000000\n",
      " Loss: 0.029505\n",
      " Loss: 0.000000\n",
      " Loss: 0.041404\n",
      " Loss: 0.000002\n",
      " Loss: 0.054416\n",
      " Loss: 0.000001\n",
      " Loss: 0.086790\n",
      "Epoch 872 Chain 0 loss std 8.04e-03 variance 3.23e-05 smooth variance 4.04e-05 adaptive c -1.00\n",
      "Epoch 872 Chain 1 loss std 4.09e+02 variance 8.35e+04 smooth variance 5.90e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.066079\n",
      " Loss: 0.000000\n",
      " Loss: 0.104033\n",
      " Loss: 0.000001\n",
      " Loss: 0.033493\n",
      " Loss: 0.000000\n",
      " Loss: 0.024867\n",
      " Loss: 0.000002\n",
      " Loss: 0.052175\n",
      " Loss: 0.000002\n",
      " Loss: 0.038222\n",
      " Loss: 0.000001\n",
      " Loss: 0.032569\n",
      " Loss: 0.000000\n",
      " Loss: 0.027916\n",
      " Loss: 0.000000\n",
      " Loss: 0.115893\n",
      " Loss: 0.000000\n",
      " Loss: 0.065056\n",
      "Epoch 874 Chain 0 loss std 7.51e-03 variance 2.82e-05 smooth variance 3.68e-05 adaptive c -1.00\n",
      "Epoch 874 Chain 1 loss std 3.12e+02 variance 4.88e+04 smooth variance 5.59e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.042567\n",
      " Loss: 0.000002\n",
      " Loss: 0.108278\n",
      " Loss: 0.000000\n",
      " Loss: 0.044199\n",
      " Loss: 0.000002\n",
      " Loss: 0.049313\n",
      " Loss: 0.000000\n",
      " Loss: 0.034938\n",
      " Loss: 0.000001\n",
      " Loss: 0.043998\n",
      " Loss: 0.000000\n",
      " Loss: 0.114068\n",
      " Loss: 0.000001\n",
      " Loss: 0.020357\n",
      " Loss: 0.000000\n",
      " Loss: 0.044008\n",
      " Loss: 0.000000\n",
      " Loss: 0.056409\n",
      "Epoch 876 Chain 0 loss std 6.03e-03 variance 1.82e-05 smooth variance 3.12e-05 adaptive c -1.00\n",
      "Epoch 876 Chain 1 loss std 2.12e+02 variance 2.25e+04 smooth variance 4.59e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.052924\n",
      " Loss: 0.000000\n",
      " Loss: 0.043270\n",
      " Loss: 0.000000\n",
      " Loss: 0.040936\n",
      " Loss: 0.000003\n",
      " Loss: 0.033247\n",
      " Loss: 0.000000\n",
      " Loss: 0.108081\n",
      " Loss: 0.000002\n",
      " Loss: 0.074685\n",
      " Loss: 0.000000\n",
      " Loss: 0.036233\n",
      " Loss: 0.000001\n",
      " Loss: 0.034755\n",
      " Loss: 0.000000\n",
      " Loss: 0.038902\n",
      " Loss: 0.000000\n",
      " Loss: 0.093388\n",
      "Epoch 878 Chain 0 loss std 6.67e-03 variance 2.22e-05 smooth variance 2.85e-05 adaptive c -1.00\n",
      "Epoch 878 Chain 1 loss std 3.48e+02 variance 6.05e+04 smooth variance 5.03e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.058286\n",
      " Loss: 0.000000\n",
      " Loss: 0.039636\n",
      " Loss: 0.000000\n",
      " Loss: 0.033339\n",
      " Loss: 0.000002\n",
      " Loss: 0.054438\n",
      " Loss: 0.000001\n",
      " Loss: 0.091656\n",
      " Loss: 0.000000\n",
      " Loss: 0.102355\n",
      " Loss: 0.000002\n",
      " Loss: 0.036857\n",
      " Loss: 0.000000\n",
      " Loss: 0.057134\n",
      " Loss: 0.000001\n",
      " Loss: 0.022590\n",
      " Loss: 0.000000\n",
      " Loss: 0.058434\n",
      "Epoch 880 Chain 0 loss std 9.30e-03 variance 4.32e-05 smooth variance 3.29e-05 adaptive c -1.00\n",
      "Epoch 880 Chain 1 loss std 2.39e+02 variance 2.85e+04 smooth variance 4.37e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.055415\n",
      " Loss: 0.000002\n",
      " Loss: 0.096616\n",
      " Loss: 0.000000\n",
      " Loss: 0.033549\n",
      " Loss: 0.000001\n",
      " Loss: 0.054763\n",
      " Loss: 0.000000\n",
      " Loss: 0.036261\n",
      " Loss: 0.000003\n",
      " Loss: 0.100971\n",
      " Loss: 0.000000\n",
      " Loss: 0.028546\n",
      " Loss: 0.000000\n",
      " Loss: 0.059644\n",
      " Loss: 0.000000\n",
      " Loss: 0.049474\n",
      " Loss: 0.000000\n",
      " Loss: 0.037489\n",
      "Epoch 882 Chain 0 loss std 6.81e-03 variance 2.32e-05 smooth variance 3.00e-05 adaptive c -1.00\n",
      "Epoch 882 Chain 1 loss std 3.68e+02 variance 6.78e+04 smooth variance 5.09e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.064782\n",
      " Loss: 0.000000\n",
      " Loss: 0.037406\n",
      " Loss: 0.000002\n",
      " Loss: 0.043258\n",
      " Loss: 0.000001\n",
      " Loss: 0.093984\n",
      " Loss: 0.000001\n",
      " Loss: 0.036428\n",
      " Loss: 0.000000\n",
      " Loss: 0.028272\n",
      " Loss: 0.000000\n",
      " Loss: 0.043576\n",
      " Loss: 0.000002\n",
      " Loss: 0.050203\n",
      " Loss: 0.000000\n",
      " Loss: 0.030709\n",
      " Loss: 0.000001\n",
      " Loss: 0.122288\n",
      "Epoch 884 Chain 0 loss std 6.57e-03 variance 2.16e-05 smooth variance 2.75e-05 adaptive c -1.00\n",
      "Epoch 884 Chain 1 loss std 2.47e+02 variance 3.05e+04 smooth variance 4.48e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.057574\n",
      " Loss: 0.000000\n",
      " Loss: 0.106118\n",
      " Loss: 0.000002\n",
      " Loss: 0.059281\n",
      " Loss: 0.000000\n",
      " Loss: 0.029461\n",
      " Loss: 0.000001\n",
      " Loss: 0.022202\n",
      " Loss: 0.000001\n",
      " Loss: 0.036334\n",
      " Loss: 0.000000\n",
      " Loss: 0.039492\n",
      " Loss: 0.000000\n",
      " Loss: 0.111106\n",
      " Loss: 0.000002\n",
      " Loss: 0.045337\n",
      " Loss: 0.000000\n",
      " Loss: 0.041795\n",
      "Epoch 886 Chain 0 loss std 6.55e-03 variance 2.15e-05 smooth variance 2.57e-05 adaptive c -1.00\n",
      "Epoch 886 Chain 1 loss std 2.80e+02 variance 3.93e+04 smooth variance 4.31e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.040925\n",
      " Loss: 0.000000\n",
      " Loss: 0.035698\n",
      " Loss: 0.000000\n",
      " Loss: 0.130241\n",
      " Loss: 0.000000\n",
      " Loss: 0.022751\n",
      " Loss: 0.000002\n",
      " Loss: 0.044066\n",
      " Loss: 0.000001\n",
      " Loss: 0.045572\n",
      " Loss: 0.000000\n",
      " Loss: 0.039451\n",
      " Loss: 0.000000\n",
      " Loss: 0.027819\n",
      " Loss: 0.000002\n",
      " Loss: 0.100351\n",
      " Loss: 0.000000\n",
      " Loss: 0.060126\n",
      "Epoch 888 Chain 0 loss std 5.48e-03 variance 1.50e-05 smooth variance 2.25e-05 adaptive c -1.00\n",
      "Epoch 888 Chain 1 loss std 3.70e+02 variance 6.84e+04 smooth variance 5.07e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.044869\n",
      " Loss: 0.000000\n",
      " Loss: 0.037186\n",
      " Loss: 0.000000\n",
      " Loss: 0.101893\n",
      " Loss: 0.000001\n",
      " Loss: 0.050514\n",
      " Loss: 0.000001\n",
      " Loss: 0.038354\n",
      " Loss: 0.000001\n",
      " Loss: 0.031218\n",
      " Loss: 0.000000\n",
      " Loss: 0.091769\n",
      " Loss: 0.000001\n",
      " Loss: 0.036722\n",
      " Loss: 0.000000\n",
      " Loss: 0.044454\n",
      " Loss: 0.000000\n",
      " Loss: 0.068240\n",
      "Epoch 890 Chain 0 loss std 5.38e-03 variance 1.44e-05 smooth variance 2.01e-05 adaptive c -1.00\n",
      "Epoch 890 Chain 1 loss std 2.89e+02 variance 4.16e+04 smooth variance 4.80e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.122941\n",
      " Loss: 0.000001\n",
      " Loss: 0.045578\n",
      " Loss: 0.000000\n",
      " Loss: 0.033724\n",
      " Loss: 0.000000\n",
      " Loss: 0.027911\n",
      " Loss: 0.000001\n",
      " Loss: 0.041845\n",
      " Loss: 0.000000\n",
      " Loss: 0.050831\n",
      " Loss: 0.000000\n",
      " Loss: 0.040510\n",
      " Loss: 0.000002\n",
      " Loss: 0.060733\n",
      " Loss: 0.000000\n",
      " Loss: 0.088635\n",
      " Loss: 0.000000\n",
      " Loss: 0.030690\n",
      "Epoch 892 Chain 0 loss std 6.04e-03 variance 1.82e-05 smooth variance 1.95e-05 adaptive c -1.00\n",
      "Epoch 892 Chain 1 loss std 2.42e+02 variance 2.92e+04 smooth variance 4.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026554\n",
      " Loss: 0.000000\n",
      " Loss: 0.056333\n",
      " Loss: 0.000001\n",
      " Loss: 0.094514\n",
      " Loss: 0.000001\n",
      " Loss: 0.027065\n",
      " Loss: 0.000002\n",
      " Loss: 0.066425\n",
      " Loss: 0.000000\n",
      " Loss: 0.051457\n",
      " Loss: 0.000000\n",
      " Loss: 0.063985\n",
      " Loss: 0.000002\n",
      " Loss: 0.083175\n",
      " Loss: 0.000001\n",
      " Loss: 0.038557\n",
      " Loss: 0.000000\n",
      " Loss: 0.033323\n",
      "Epoch 894 Chain 0 loss std 8.32e-03 variance 3.46e-05 smooth variance 2.40e-05 adaptive c -1.00\n",
      "Epoch 894 Chain 1 loss std 3.21e+02 variance 5.14e+04 smooth variance 4.51e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.097259\n",
      " Loss: 0.000000\n",
      " Loss: 0.042396\n",
      " Loss: 0.000001\n",
      " Loss: 0.048873\n",
      " Loss: 0.000000\n",
      " Loss: 0.036262\n",
      " Loss: 0.000001\n",
      " Loss: 0.045601\n",
      " Loss: 0.000001\n",
      " Loss: 0.036117\n",
      " Loss: 0.000000\n",
      " Loss: 0.116995\n",
      " Loss: 0.000000\n",
      " Loss: 0.040634\n",
      " Loss: 0.000001\n",
      " Loss: 0.045059\n",
      " Loss: 0.000000\n",
      " Loss: 0.030805\n",
      "Epoch 896 Chain 0 loss std 7.82e-03 variance 3.06e-05 smooth variance 2.60e-05 adaptive c -1.00\n",
      "Epoch 896 Chain 1 loss std 2.17e+02 variance 2.35e+04 smooth variance 3.86e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.106805\n",
      " Loss: 0.000000\n",
      " Loss: 0.030309\n",
      " Loss: 0.000002\n",
      " Loss: 0.042585\n",
      " Loss: 0.000000\n",
      " Loss: 0.057442\n",
      " Loss: 0.000000\n",
      " Loss: 0.032009\n",
      " Loss: 0.000002\n",
      " Loss: 0.034173\n",
      " Loss: 0.000000\n",
      " Loss: 0.032709\n",
      " Loss: 0.000000\n",
      " Loss: 0.037774\n",
      " Loss: 0.000001\n",
      " Loss: 0.113591\n",
      " Loss: 0.000000\n",
      " Loss: 0.050501\n",
      "Epoch 898 Chain 0 loss std 4.83e-03 variance 1.17e-05 smooth variance 2.17e-05 adaptive c -1.00\n",
      "Epoch 898 Chain 1 loss std 2.31e+02 variance 2.67e+04 smooth variance 3.50e+04 adaptive c -1.00\n",
      " Loss: 0.000002\n",
      " Loss: 0.036637\n",
      " Loss: 0.000000\n",
      " Loss: 0.106976\n",
      " Loss: 0.000000\n",
      " Loss: 0.050356\n",
      " Loss: 0.000000\n",
      " Loss: 0.044995\n",
      " Loss: 0.000000\n",
      " Loss: 0.029437\n",
      " Loss: 0.000000\n",
      " Loss: 0.048723\n",
      " Loss: 0.000000\n",
      " Loss: 0.123007\n",
      " Loss: 0.000001\n",
      " Loss: 0.031448\n",
      " Loss: 0.000001\n",
      " Loss: 0.025638\n",
      " Loss: 0.000000\n",
      " Loss: 0.038986\n",
      "Epoch 900 Chain 0 loss std 5.39e-03 variance 1.45e-05 smooth variance 1.96e-05 adaptive c -1.00\n",
      "Epoch 900 Chain 1 loss std 3.23e+02 variance 5.20e+04 smooth variance 4.01e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032556\n",
      " Loss: 0.000001\n",
      " Loss: 0.040009\n",
      " Loss: 0.000000\n",
      " Loss: 0.106222\n",
      " Loss: 0.000000\n",
      " Loss: 0.060233\n",
      " Loss: 0.000001\n",
      " Loss: 0.028297\n",
      " Loss: 0.000000\n",
      " Loss: 0.052441\n",
      " Loss: 0.000000\n",
      " Loss: 0.086108\n",
      " Loss: 0.000002\n",
      " Loss: 0.040473\n",
      " Loss: 0.000000\n",
      " Loss: 0.035112\n",
      " Loss: 0.000000\n",
      " Loss: 0.052943\n",
      "Epoch 902 Chain 0 loss std 5.75e-03 variance 1.65e-05 smooth variance 1.86e-05 adaptive c -1.00\n",
      "Epoch 902 Chain 1 loss std 2.56e+02 variance 3.28e+04 smooth variance 3.79e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.085606\n",
      " Loss: 0.000001\n",
      " Loss: 0.037536\n",
      " Loss: 0.000001\n",
      " Loss: 0.047496\n",
      " Loss: 0.000000\n",
      " Loss: 0.059388\n",
      " Loss: 0.000000\n",
      " Loss: 0.036675\n",
      " Loss: 0.000001\n",
      " Loss: 0.037899\n",
      " Loss: 0.000000\n",
      " Loss: 0.035748\n",
      " Loss: 0.000000\n",
      " Loss: 0.040070\n",
      " Loss: 0.000000\n",
      " Loss: 0.040146\n",
      " Loss: 0.000002\n",
      " Loss: 0.112134\n",
      "Epoch 904 Chain 0 loss std 4.91e-03 variance 1.20e-05 smooth variance 1.67e-05 adaptive c -1.00\n",
      "Epoch 904 Chain 1 loss std 2.23e+02 variance 2.48e+04 smooth variance 3.40e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.094506\n",
      " Loss: 0.000001\n",
      " Loss: 0.047900\n",
      " Loss: 0.000000\n",
      " Loss: 0.052753\n",
      " Loss: 0.000000\n",
      " Loss: 0.024389\n",
      " Loss: 0.000001\n",
      " Loss: 0.046243\n",
      " Loss: 0.000000\n",
      " Loss: 0.052651\n",
      " Loss: 0.000001\n",
      " Loss: 0.037811\n",
      " Loss: 0.000001\n",
      " Loss: 0.024256\n",
      " Loss: 0.000000\n",
      " Loss: 0.104002\n",
      " Loss: 0.000000\n",
      " Loss: 0.046606\n",
      "Epoch 906 Chain 0 loss std 4.70e-03 variance 1.10e-05 smooth variance 1.50e-05 adaptive c -1.00\n",
      "Epoch 906 Chain 1 loss std 2.59e+02 variance 3.37e+04 smooth variance 3.39e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.038777\n",
      " Loss: 0.000000\n",
      " Loss: 0.050480\n",
      " Loss: 0.000001\n",
      " Loss: 0.035652\n",
      " Loss: 0.000001\n",
      " Loss: 0.102524\n",
      " Loss: 0.000000\n",
      " Loss: 0.037373\n",
      " Loss: 0.000000\n",
      " Loss: 0.084857\n",
      " Loss: 0.000000\n",
      " Loss: 0.052737\n",
      " Loss: 0.000000\n",
      " Loss: 0.033055\n",
      " Loss: 0.000001\n",
      " Loss: 0.045644\n",
      " Loss: 0.000001\n",
      " Loss: 0.048219\n",
      "Epoch 908 Chain 0 loss std 7.74e-03 variance 3.00e-05 smooth variance 1.95e-05 adaptive c -1.00\n",
      "Epoch 908 Chain 1 loss std 2.10e+02 variance 2.20e+04 smooth variance 3.03e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.051615\n",
      " Loss: 0.000002\n",
      " Loss: 0.032408\n",
      " Loss: 0.000000\n",
      " Loss: 0.040938\n",
      " Loss: 0.000000\n",
      " Loss: 0.093383\n",
      " Loss: 0.000000\n",
      " Loss: 0.045795\n",
      " Loss: 0.000000\n",
      " Loss: 0.058567\n",
      " Loss: 0.000000\n",
      " Loss: 0.106174\n",
      " Loss: 0.000001\n",
      " Loss: 0.032535\n",
      " Loss: 0.000000\n",
      " Loss: 0.045187\n",
      " Loss: 0.000001\n",
      " Loss: 0.021042\n",
      "Epoch 910 Chain 0 loss std 4.03e-03 variance 8.13e-06 smooth variance 1.61e-05 adaptive c -1.00\n",
      "Epoch 910 Chain 1 loss std 2.65e+02 variance 3.50e+04 smooth variance 3.17e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.107224\n",
      " Loss: 0.000001\n",
      " Loss: 0.057641\n",
      " Loss: 0.000000\n",
      " Loss: 0.030697\n",
      " Loss: 0.000000\n",
      " Loss: 0.039273\n",
      " Loss: 0.000001\n",
      " Loss: 0.028425\n",
      " Loss: 0.000000\n",
      " Loss: 0.064430\n",
      " Loss: 0.000001\n",
      " Loss: 0.093436\n",
      " Loss: 0.000000\n",
      " Loss: 0.051973\n",
      " Loss: 0.000001\n",
      " Loss: 0.026503\n",
      " Loss: 0.000000\n",
      " Loss: 0.026411\n",
      "Epoch 912 Chain 0 loss std 4.56e-03 variance 1.04e-05 smooth variance 1.44e-05 adaptive c -1.00\n",
      "Epoch 912 Chain 1 loss std 3.18e+02 variance 5.07e+04 smooth variance 3.74e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.089871\n",
      " Loss: 0.000001\n",
      " Loss: 0.045277\n",
      " Loss: 0.000001\n",
      " Loss: 0.050688\n",
      " Loss: 0.000000\n",
      " Loss: 0.041850\n",
      " Loss: 0.000000\n",
      " Loss: 0.034650\n",
      " Loss: 0.000001\n",
      " Loss: 0.038189\n",
      " Loss: 0.000000\n",
      " Loss: 0.026579\n",
      " Loss: 0.000000\n",
      " Loss: 0.129580\n",
      " Loss: 0.000000\n",
      " Loss: 0.030241\n",
      " Loss: 0.000001\n",
      " Loss: 0.037230\n",
      "Epoch 914 Chain 0 loss std 6.38e-03 variance 2.04e-05 smooth variance 1.62e-05 adaptive c -1.00\n",
      "Epoch 914 Chain 1 loss std 2.69e+02 variance 3.61e+04 smooth variance 3.70e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021069\n",
      " Loss: 0.000000\n",
      " Loss: 0.072287\n",
      " Loss: 0.000000\n",
      " Loss: 0.035801\n",
      " Loss: 0.000001\n",
      " Loss: 0.093428\n",
      " Loss: 0.000001\n",
      " Loss: 0.038937\n",
      " Loss: 0.000001\n",
      " Loss: 0.032746\n",
      " Loss: 0.000000\n",
      " Loss: 0.098957\n",
      " Loss: 0.000000\n",
      " Loss: 0.048442\n",
      " Loss: 0.000001\n",
      " Loss: 0.024810\n",
      " Loss: 0.000000\n",
      " Loss: 0.056170\n",
      "Epoch 916 Chain 0 loss std 3.47e-03 variance 6.03e-06 smooth variance 1.31e-05 adaptive c -1.00\n",
      "Epoch 916 Chain 1 loss std 3.44e+02 variance 5.92e+04 smooth variance 4.37e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.088508\n",
      " Loss: 0.000000\n",
      " Loss: 0.035374\n",
      " Loss: 0.000001\n",
      " Loss: 0.024236\n",
      " Loss: 0.000000\n",
      " Loss: 0.053725\n",
      " Loss: 0.000001\n",
      " Loss: 0.058902\n",
      " Loss: 0.000000\n",
      " Loss: 0.044175\n",
      " Loss: 0.000001\n",
      " Loss: 0.095784\n",
      " Loss: 0.000000\n",
      " Loss: 0.020849\n",
      " Loss: 0.000001\n",
      " Loss: 0.050375\n",
      " Loss: 0.000000\n",
      " Loss: 0.049048\n",
      "Epoch 918 Chain 0 loss std 3.85e-03 variance 7.40e-06 smooth variance 1.14e-05 adaptive c -1.00\n",
      "Epoch 918 Chain 1 loss std 2.35e+02 variance 2.76e+04 smooth variance 3.88e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.046028\n",
      " Loss: 0.000001\n",
      " Loss: 0.033321\n",
      " Loss: 0.000000\n",
      " Loss: 0.048622\n",
      " Loss: 0.000001\n",
      " Loss: 0.046087\n",
      " Loss: 0.000000\n",
      " Loss: 0.085871\n",
      " Loss: 0.000001\n",
      " Loss: 0.029606\n",
      " Loss: 0.000000\n",
      " Loss: 0.042056\n",
      " Loss: 0.000001\n",
      " Loss: 0.051840\n",
      " Loss: 0.000000\n",
      " Loss: 0.043275\n",
      " Loss: 0.000000\n",
      " Loss: 0.092691\n",
      "Epoch 920 Chain 0 loss std 3.86e-03 variance 7.44e-06 smooth variance 1.02e-05 adaptive c -1.00\n",
      "Epoch 920 Chain 1 loss std 2.52e+02 variance 3.17e+04 smooth variance 3.67e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.105990\n",
      " Loss: 0.000000\n",
      " Loss: 0.034169\n",
      " Loss: 0.000000\n",
      " Loss: 0.055718\n",
      " Loss: 0.000001\n",
      " Loss: 0.035237\n",
      " Loss: 0.000001\n",
      " Loss: 0.027744\n",
      " Loss: 0.000000\n",
      " Loss: 0.109623\n",
      " Loss: 0.000001\n",
      " Loss: 0.033200\n",
      " Loss: 0.000000\n",
      " Loss: 0.039958\n",
      " Loss: 0.000000\n",
      " Loss: 0.032145\n",
      " Loss: 0.000001\n",
      " Loss: 0.043914\n",
      "Epoch 922 Chain 0 loss std 6.39e-03 variance 2.04e-05 smooth variance 1.33e-05 adaptive c -1.00\n",
      "Epoch 922 Chain 1 loss std 3.26e+02 variance 5.32e+04 smooth variance 4.16e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027171\n",
      " Loss: 0.000000\n",
      " Loss: 0.057312\n",
      " Loss: 0.000000\n",
      " Loss: 0.031329\n",
      " Loss: 0.000001\n",
      " Loss: 0.097226\n",
      " Loss: 0.000001\n",
      " Loss: 0.045077\n",
      " Loss: 0.000000\n",
      " Loss: 0.052010\n",
      " Loss: 0.000000\n",
      " Loss: 0.105054\n",
      " Loss: 0.000002\n",
      " Loss: 0.034687\n",
      " Loss: 0.000000\n",
      " Loss: 0.039918\n",
      " Loss: 0.000000\n",
      " Loss: 0.026045\n",
      "Epoch 924 Chain 0 loss std 6.12e-03 variance 1.87e-05 smooth variance 1.49e-05 adaptive c -1.00\n",
      "Epoch 924 Chain 1 loss std 3.14e+02 variance 4.94e+04 smooth variance 4.40e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029245\n",
      " Loss: 0.000000\n",
      " Loss: 0.096733\n",
      " Loss: 0.000000\n",
      " Loss: 0.035527\n",
      " Loss: 0.000000\n",
      " Loss: 0.050188\n",
      " Loss: 0.000002\n",
      " Loss: 0.046138\n",
      " Loss: 0.000001\n",
      " Loss: 0.079712\n",
      " Loss: 0.000001\n",
      " Loss: 0.060021\n",
      " Loss: 0.000000\n",
      " Loss: 0.039307\n",
      " Loss: 0.000000\n",
      " Loss: 0.049356\n",
      " Loss: 0.000000\n",
      " Loss: 0.028477\n",
      "Epoch 926 Chain 0 loss std 3.55e-03 variance 6.29e-06 smooth variance 1.23e-05 adaptive c -1.00\n",
      "Epoch 926 Chain 1 loss std 4.04e+02 variance 8.18e+04 smooth variance 5.53e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.089875\n",
      " Loss: 0.000000\n",
      " Loss: 0.033735\n",
      " Loss: 0.000000\n",
      " Loss: 0.069241\n",
      " Loss: 0.000001\n",
      " Loss: 0.029245\n",
      " Loss: 0.000000\n",
      " Loss: 0.034374\n",
      " Loss: 0.000001\n",
      " Loss: 0.052413\n",
      " Loss: 0.000000\n",
      " Loss: 0.028433\n",
      " Loss: 0.000000\n",
      " Loss: 0.033623\n",
      " Loss: 0.000000\n",
      " Loss: 0.042241\n",
      " Loss: 0.000001\n",
      " Loss: 0.099420\n",
      "Epoch 928 Chain 0 loss std 5.22e-03 variance 1.36e-05 smooth variance 1.27e-05 adaptive c -1.00\n",
      "Epoch 928 Chain 1 loss std 2.24e+02 variance 2.52e+04 smooth variance 4.63e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018689\n",
      " Loss: 0.000000\n",
      " Loss: 0.030403\n",
      " Loss: 0.000001\n",
      " Loss: 0.035890\n",
      " Loss: 0.000000\n",
      " Loss: 0.082726\n",
      " Loss: 0.000001\n",
      " Loss: 0.087896\n",
      " Loss: 0.000000\n",
      " Loss: 0.047031\n",
      " Loss: 0.000000\n",
      " Loss: 0.043047\n",
      " Loss: 0.000000\n",
      " Loss: 0.087389\n",
      " Loss: 0.000001\n",
      " Loss: 0.041982\n",
      " Loss: 0.000001\n",
      " Loss: 0.035908\n",
      "Epoch 930 Chain 0 loss std 3.09e-03 variance 4.77e-06 smooth variance 1.03e-05 adaptive c -1.00\n",
      "Epoch 930 Chain 1 loss std 3.50e+02 variance 6.11e+04 smooth variance 5.07e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.090165\n",
      " Loss: 0.000001\n",
      " Loss: 0.032823\n",
      " Loss: 0.000000\n",
      " Loss: 0.052349\n",
      " Loss: 0.000000\n",
      " Loss: 0.051002\n",
      " Loss: 0.000001\n",
      " Loss: 0.028779\n",
      " Loss: 0.000000\n",
      " Loss: 0.051680\n",
      " Loss: 0.000000\n",
      " Loss: 0.021581\n",
      " Loss: 0.000001\n",
      " Loss: 0.089879\n",
      " Loss: 0.000001\n",
      " Loss: 0.053161\n",
      " Loss: 0.000000\n",
      " Loss: 0.038145\n",
      "Epoch 932 Chain 0 loss std 3.82e-03 variance 7.30e-06 smooth variance 9.42e-06 adaptive c -1.00\n",
      "Epoch 932 Chain 1 loss std 3.75e+02 variance 7.04e+04 smooth variance 5.66e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023775\n",
      " Loss: 0.000001\n",
      " Loss: 0.034232\n",
      " Loss: 0.000001\n",
      " Loss: 0.043781\n",
      " Loss: 0.000000\n",
      " Loss: 0.104449\n",
      " Loss: 0.000000\n",
      " Loss: 0.047677\n",
      " Loss: 0.000000\n",
      " Loss: 0.033098\n",
      " Loss: 0.000000\n",
      " Loss: 0.050898\n",
      " Loss: 0.000000\n",
      " Loss: 0.044839\n",
      " Loss: 0.000001\n",
      " Loss: 0.086668\n",
      " Loss: 0.000001\n",
      " Loss: 0.038070\n",
      "Epoch 934 Chain 0 loss std 3.95e-03 variance 7.78e-06 smooth variance 8.93e-06 adaptive c -1.00\n",
      "Epoch 934 Chain 1 loss std 2.48e+02 variance 3.07e+04 smooth variance 4.88e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035058\n",
      " Loss: 0.000000\n",
      " Loss: 0.099809\n",
      " Loss: 0.000001\n",
      " Loss: 0.029959\n",
      " Loss: 0.000000\n",
      " Loss: 0.066492\n",
      " Loss: 0.000001\n",
      " Loss: 0.021882\n",
      " Loss: 0.000001\n",
      " Loss: 0.028216\n",
      " Loss: 0.000000\n",
      " Loss: 0.119131\n",
      " Loss: 0.000000\n",
      " Loss: 0.030465\n",
      " Loss: 0.000000\n",
      " Loss: 0.045575\n",
      " Loss: 0.000001\n",
      " Loss: 0.029304\n",
      "Epoch 936 Chain 0 loss std 3.96e-03 variance 7.85e-06 smooth variance 8.61e-06 adaptive c -1.00\n",
      "Epoch 936 Chain 1 loss std 2.87e+02 variance 4.12e+04 smooth variance 4.66e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.042366\n",
      " Loss: 0.000000\n",
      " Loss: 0.035240\n",
      " Loss: 0.000000\n",
      " Loss: 0.088639\n",
      " Loss: 0.000000\n",
      " Loss: 0.042476\n",
      " Loss: 0.000001\n",
      " Loss: 0.043761\n",
      " Loss: 0.000000\n",
      " Loss: 0.033736\n",
      " Loss: 0.000000\n",
      " Loss: 0.050036\n",
      " Loss: 0.000000\n",
      " Loss: 0.055821\n",
      " Loss: 0.000000\n",
      " Loss: 0.089062\n",
      " Loss: 0.000001\n",
      " Loss: 0.023304\n",
      "Epoch 938 Chain 0 loss std 3.84e-03 variance 7.39e-06 smooth variance 8.24e-06 adaptive c -1.00\n",
      "Epoch 938 Chain 1 loss std 2.82e+02 variance 3.97e+04 smooth variance 4.45e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.106472\n",
      " Loss: 0.000000\n",
      " Loss: 0.024874\n",
      " Loss: 0.000001\n",
      " Loss: 0.029500\n",
      " Loss: 0.000001\n",
      " Loss: 0.045441\n",
      " Loss: 0.000000\n",
      " Loss: 0.045418\n",
      " Loss: 0.000000\n",
      " Loss: 0.095239\n",
      " Loss: 0.000000\n",
      " Loss: 0.055231\n",
      " Loss: 0.000000\n",
      " Loss: 0.035890\n",
      " Loss: 0.000000\n",
      " Loss: 0.040194\n",
      " Loss: 0.000001\n",
      " Loss: 0.024603\n",
      "Epoch 940 Chain 0 loss std 2.86e-03 variance 4.09e-06 smooth variance 7.00e-06 adaptive c -1.00\n",
      "Epoch 940 Chain 1 loss std 3.51e+02 variance 6.14e+04 smooth variance 4.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.098275\n",
      " Loss: 0.000001\n",
      " Loss: 0.057718\n",
      " Loss: 0.000001\n",
      " Loss: 0.026582\n",
      " Loss: 0.000000\n",
      " Loss: 0.026564\n",
      " Loss: 0.000000\n",
      " Loss: 0.041782\n",
      " Loss: 0.000000\n",
      " Loss: 0.043824\n",
      " Loss: 0.000000\n",
      " Loss: 0.083981\n",
      " Loss: 0.000000\n",
      " Loss: 0.052338\n",
      " Loss: 0.000000\n",
      " Loss: 0.034014\n",
      " Loss: 0.000001\n",
      " Loss: 0.036168\n",
      "Epoch 942 Chain 0 loss std 5.50e-03 variance 1.51e-05 smooth variance 9.44e-06 adaptive c -1.00\n",
      "Epoch 942 Chain 1 loss std 2.88e+02 variance 4.15e+04 smooth variance 4.72e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.055624\n",
      " Loss: 0.000000\n",
      " Loss: 0.019505\n",
      " Loss: 0.000001\n",
      " Loss: 0.034657\n",
      " Loss: 0.000000\n",
      " Loss: 0.089247\n",
      " Loss: 0.000000\n",
      " Loss: 0.051106\n",
      " Loss: 0.000000\n",
      " Loss: 0.088962\n",
      " Loss: 0.000000\n",
      " Loss: 0.044138\n",
      " Loss: 0.000001\n",
      " Loss: 0.036674\n",
      " Loss: 0.000001\n",
      " Loss: 0.047536\n",
      " Loss: 0.000000\n",
      " Loss: 0.032353\n",
      "Epoch 944 Chain 0 loss std 3.22e-03 variance 5.17e-06 smooth variance 8.16e-06 adaptive c -1.00\n",
      "Epoch 944 Chain 1 loss std 2.24e+02 variance 2.50e+04 smooth variance 4.05e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.030591\n",
      " Loss: 0.000001\n",
      " Loss: 0.087809\n",
      " Loss: 0.000000\n",
      " Loss: 0.032810\n",
      " Loss: 0.000000\n",
      " Loss: 0.054104\n",
      " Loss: 0.000000\n",
      " Loss: 0.043994\n",
      " Loss: 0.000001\n",
      " Loss: 0.086427\n",
      " Loss: 0.000000\n",
      " Loss: 0.031940\n",
      " Loss: 0.000000\n",
      " Loss: 0.042154\n",
      " Loss: 0.000000\n",
      " Loss: 0.026951\n",
      " Loss: 0.000000\n",
      " Loss: 0.061405\n",
      "Epoch 946 Chain 0 loss std 3.32e-03 variance 5.52e-06 smooth variance 7.37e-06 adaptive c -1.00\n",
      "Epoch 946 Chain 1 loss std 2.66e+02 variance 3.54e+04 smooth variance 3.90e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.029702\n",
      " Loss: 0.000000\n",
      " Loss: 0.033253\n",
      " Loss: 0.000000\n",
      " Loss: 0.053343\n",
      " Loss: 0.000000\n",
      " Loss: 0.047717\n",
      " Loss: 0.000000\n",
      " Loss: 0.084438\n",
      " Loss: 0.000000\n",
      " Loss: 0.026427\n",
      " Loss: 0.000001\n",
      " Loss: 0.035489\n",
      " Loss: 0.000000\n",
      " Loss: 0.028529\n",
      " Loss: 0.000000\n",
      " Loss: 0.058909\n",
      " Loss: 0.000001\n",
      " Loss: 0.098695\n",
      "Epoch 948 Chain 0 loss std 3.46e-03 variance 5.99e-06 smooth variance 6.95e-06 adaptive c -1.00\n",
      "Epoch 948 Chain 1 loss std 2.55e+02 variance 3.25e+04 smooth variance 3.70e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.023923\n",
      " Loss: 0.000000\n",
      " Loss: 0.028963\n",
      " Loss: 0.000001\n",
      " Loss: 0.032361\n",
      " Loss: 0.000000\n",
      " Loss: 0.069320\n",
      " Loss: 0.000000\n",
      " Loss: 0.093101\n",
      " Loss: 0.000000\n",
      " Loss: 0.037151\n",
      " Loss: 0.000001\n",
      " Loss: 0.105166\n",
      " Loss: 0.000001\n",
      " Loss: 0.043739\n",
      " Loss: 0.000000\n",
      " Loss: 0.026051\n",
      " Loss: 0.000000\n",
      " Loss: 0.035177\n",
      "Epoch 950 Chain 0 loss std 2.94e-03 variance 4.32e-06 smooth variance 6.16e-06 adaptive c -1.00\n",
      "Epoch 950 Chain 1 loss std 3.05e+02 variance 4.64e+04 smooth variance 3.98e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.085159\n",
      " Loss: 0.000000\n",
      " Loss: 0.038577\n",
      " Loss: 0.000000\n",
      " Loss: 0.023030\n",
      " Loss: 0.000000\n",
      " Loss: 0.034668\n",
      " Loss: 0.000001\n",
      " Loss: 0.065489\n",
      " Loss: 0.000001\n",
      " Loss: 0.085849\n",
      " Loss: 0.000000\n",
      " Loss: 0.029227\n",
      " Loss: 0.000000\n",
      " Loss: 0.051224\n",
      " Loss: 0.000000\n",
      " Loss: 0.047193\n",
      " Loss: 0.000001\n",
      " Loss: 0.033017\n",
      "Epoch 952 Chain 0 loss std 2.66e-03 variance 3.53e-06 smooth variance 5.37e-06 adaptive c -1.00\n",
      "Epoch 952 Chain 1 loss std 3.00e+02 variance 4.50e+04 smooth variance 4.14e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.075524\n",
      " Loss: 0.000001\n",
      " Loss: 0.026420\n",
      " Loss: 0.000000\n",
      " Loss: 0.051053\n",
      " Loss: 0.000000\n",
      " Loss: 0.036530\n",
      " Loss: 0.000000\n",
      " Loss: 0.056587\n",
      " Loss: 0.000000\n",
      " Loss: 0.034910\n",
      " Loss: 0.000001\n",
      " Loss: 0.023969\n",
      " Loss: 0.000000\n",
      " Loss: 0.052646\n",
      " Loss: 0.000000\n",
      " Loss: 0.077306\n",
      " Loss: 0.000000\n",
      " Loss: 0.056827\n",
      "Epoch 954 Chain 0 loss std 3.11e-03 variance 4.83e-06 smooth variance 5.21e-06 adaptive c -1.00\n",
      "Epoch 954 Chain 1 loss std 3.28e+02 variance 5.36e+04 smooth variance 4.51e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.034964\n",
      " Loss: 0.000000\n",
      " Loss: 0.096343\n",
      " Loss: 0.000001\n",
      " Loss: 0.063094\n",
      " Loss: 0.000000\n",
      " Loss: 0.016183\n",
      " Loss: 0.000001\n",
      " Loss: 0.034763\n",
      " Loss: 0.000000\n",
      " Loss: 0.026281\n",
      " Loss: 0.000000\n",
      " Loss: 0.056496\n",
      " Loss: 0.000001\n",
      " Loss: 0.087328\n",
      " Loss: 0.000000\n",
      " Loss: 0.033281\n",
      " Loss: 0.000000\n",
      " Loss: 0.041486\n",
      "Epoch 956 Chain 0 loss std 2.38e-03 variance 2.83e-06 smooth variance 4.50e-06 adaptive c -1.00\n",
      "Epoch 956 Chain 1 loss std 2.18e+02 variance 2.37e+04 smooth variance 3.86e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.119709\n",
      " Loss: 0.000001\n",
      " Loss: 0.016161\n",
      " Loss: 0.000000\n",
      " Loss: 0.037374\n",
      " Loss: 0.000001\n",
      " Loss: 0.024774\n",
      " Loss: 0.000000\n",
      " Loss: 0.046393\n",
      " Loss: 0.000001\n",
      " Loss: 0.023575\n",
      " Loss: 0.000000\n",
      " Loss: 0.103598\n",
      " Loss: 0.000000\n",
      " Loss: 0.020613\n",
      " Loss: 0.000000\n",
      " Loss: 0.052726\n",
      " Loss: 0.000000\n",
      " Loss: 0.043760\n",
      "Epoch 958 Chain 0 loss std 2.38e-03 variance 2.82e-06 smooth variance 3.99e-06 adaptive c -1.00\n",
      "Epoch 958 Chain 1 loss std 2.48e+02 variance 3.06e+04 smooth variance 3.62e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.081739\n",
      " Loss: 0.000001\n",
      " Loss: 0.029206\n",
      " Loss: 0.000000\n",
      " Loss: 0.047837\n",
      " Loss: 0.000000\n",
      " Loss: 0.054021\n",
      " Loss: 0.000001\n",
      " Loss: 0.030892\n",
      " Loss: 0.000001\n",
      " Loss: 0.088378\n",
      " Loss: 0.000000\n",
      " Loss: 0.025743\n",
      " Loss: 0.000000\n",
      " Loss: 0.071071\n",
      " Loss: 0.000000\n",
      " Loss: 0.030419\n",
      " Loss: 0.000001\n",
      " Loss: 0.027730\n",
      "Epoch 960 Chain 0 loss std 4.70e-03 variance 1.10e-05 smooth variance 6.11e-06 adaptive c -1.00\n",
      "Epoch 960 Chain 1 loss std 2.20e+02 variance 2.42e+04 smooth variance 3.26e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.086714\n",
      " Loss: 0.000000\n",
      " Loss: 0.043799\n",
      " Loss: 0.000001\n",
      " Loss: 0.040127\n",
      " Loss: 0.000000\n",
      " Loss: 0.019820\n",
      " Loss: 0.000000\n",
      " Loss: 0.052643\n",
      " Loss: 0.000000\n",
      " Loss: 0.041043\n",
      " Loss: 0.000000\n",
      " Loss: 0.022676\n",
      " Loss: 0.000001\n",
      " Loss: 0.036321\n",
      " Loss: 0.000001\n",
      " Loss: 0.039781\n",
      " Loss: 0.000000\n",
      " Loss: 0.102649\n",
      "Epoch 962 Chain 0 loss std 2.18e-03 variance 2.38e-06 smooth variance 4.99e-06 adaptive c -1.00\n",
      "Epoch 962 Chain 1 loss std 3.78e+02 variance 7.14e+04 smooth variance 4.43e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.043014\n",
      " Loss: 0.000001\n",
      " Loss: 0.026463\n",
      " Loss: 0.000000\n",
      " Loss: 0.036767\n",
      " Loss: 0.000001\n",
      " Loss: 0.031924\n",
      " Loss: 0.000000\n",
      " Loss: 0.103966\n",
      " Loss: 0.000000\n",
      " Loss: 0.106890\n",
      " Loss: 0.000000\n",
      " Loss: 0.020404\n",
      " Loss: 0.000001\n",
      " Loss: 0.039369\n",
      " Loss: 0.000000\n",
      " Loss: 0.035963\n",
      " Loss: 0.000000\n",
      " Loss: 0.039109\n",
      "Epoch 964 Chain 0 loss std 4.03e-03 variance 8.10e-06 smooth variance 5.92e-06 adaptive c -1.00\n",
      "Epoch 964 Chain 1 loss std 3.31e+02 variance 5.48e+04 smooth variance 4.74e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.051782\n",
      " Loss: 0.000000\n",
      " Loss: 0.027005\n",
      " Loss: 0.000000\n",
      " Loss: 0.097643\n",
      " Loss: 0.000000\n",
      " Loss: 0.026783\n",
      " Loss: 0.000001\n",
      " Loss: 0.038376\n",
      " Loss: 0.000000\n",
      " Loss: 0.041697\n",
      " Loss: 0.000000\n",
      " Loss: 0.029976\n",
      " Loss: 0.000000\n",
      " Loss: 0.110085\n",
      " Loss: 0.000001\n",
      " Loss: 0.027582\n",
      " Loss: 0.000000\n",
      " Loss: 0.031667\n",
      "Epoch 966 Chain 0 loss std 2.45e-03 variance 3.01e-06 smooth variance 5.05e-06 adaptive c -1.00\n",
      "Epoch 966 Chain 1 loss std 2.62e+02 variance 3.43e+04 smooth variance 4.35e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.018164\n",
      " Loss: 0.000000\n",
      " Loss: 0.080761\n",
      " Loss: 0.000000\n",
      " Loss: 0.040938\n",
      " Loss: 0.000000\n",
      " Loss: 0.033099\n",
      " Loss: 0.000001\n",
      " Loss: 0.067791\n",
      " Loss: 0.000000\n",
      " Loss: 0.046142\n",
      " Loss: 0.000000\n",
      " Loss: 0.049053\n",
      " Loss: 0.000000\n",
      " Loss: 0.075424\n",
      " Loss: 0.000000\n",
      " Loss: 0.030448\n",
      " Loss: 0.000001\n",
      " Loss: 0.039282\n",
      "Epoch 968 Chain 0 loss std 2.73e-03 variance 3.72e-06 smooth variance 4.65e-06 adaptive c -1.00\n",
      "Epoch 968 Chain 1 loss std 2.60e+02 variance 3.37e+04 smooth variance 4.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026191\n",
      " Loss: 0.000001\n",
      " Loss: 0.057254\n",
      " Loss: 0.000000\n",
      " Loss: 0.025157\n",
      " Loss: 0.000001\n",
      " Loss: 0.091204\n",
      " Loss: 0.000000\n",
      " Loss: 0.040293\n",
      " Loss: 0.000000\n",
      " Loss: 0.029802\n",
      " Loss: 0.000001\n",
      " Loss: 0.045810\n",
      " Loss: 0.000000\n",
      " Loss: 0.085511\n",
      " Loss: 0.000000\n",
      " Loss: 0.047446\n",
      " Loss: 0.000001\n",
      " Loss: 0.031096\n",
      "Epoch 970 Chain 0 loss std 2.34e-03 variance 2.75e-06 smooth variance 4.08e-06 adaptive c -1.00\n",
      "Epoch 970 Chain 1 loss std 3.51e+02 variance 6.17e+04 smooth variance 4.69e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.026975\n",
      " Loss: 0.000001\n",
      " Loss: 0.087439\n",
      " Loss: 0.000000\n",
      " Loss: 0.045784\n",
      " Loss: 0.000000\n",
      " Loss: 0.047292\n",
      " Loss: 0.000000\n",
      " Loss: 0.031631\n",
      " Loss: 0.000000\n",
      " Loss: 0.087309\n",
      " Loss: 0.000001\n",
      " Loss: 0.045116\n",
      " Loss: 0.000000\n",
      " Loss: 0.039021\n",
      " Loss: 0.000000\n",
      " Loss: 0.028043\n",
      " Loss: 0.000000\n",
      " Loss: 0.039313\n",
      "Epoch 972 Chain 0 loss std 2.09e-03 variance 2.18e-06 smooth variance 3.51e-06 adaptive c -1.00\n",
      "Epoch 972 Chain 1 loss std 2.70e+02 variance 3.63e+04 smooth variance 4.37e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035603\n",
      " Loss: 0.000000\n",
      " Loss: 0.077429\n",
      " Loss: 0.000000\n",
      " Loss: 0.057685\n",
      " Loss: 0.000001\n",
      " Loss: 0.028693\n",
      " Loss: 0.000000\n",
      " Loss: 0.039127\n",
      " Loss: 0.000000\n",
      " Loss: 0.028721\n",
      " Loss: 0.000000\n",
      " Loss: 0.034792\n",
      " Loss: 0.000000\n",
      " Loss: 0.099055\n",
      " Loss: 0.000000\n",
      " Loss: 0.046796\n",
      " Loss: 0.000001\n",
      " Loss: 0.028637\n",
      "Epoch 974 Chain 0 loss std 2.93e-03 variance 4.30e-06 smooth variance 3.75e-06 adaptive c -1.00\n",
      "Epoch 974 Chain 1 loss std 2.22e+02 variance 2.46e+04 smooth variance 3.80e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.044285\n",
      " Loss: 0.000000\n",
      " Loss: 0.026940\n",
      " Loss: 0.000001\n",
      " Loss: 0.026120\n",
      " Loss: 0.000000\n",
      " Loss: 0.104670\n",
      " Loss: 0.000000\n",
      " Loss: 0.035899\n",
      " Loss: 0.000000\n",
      " Loss: 0.052567\n",
      " Loss: 0.000001\n",
      " Loss: 0.046837\n",
      " Loss: 0.000000\n",
      " Loss: 0.086367\n",
      " Loss: 0.000000\n",
      " Loss: 0.023974\n",
      " Loss: 0.000000\n",
      " Loss: 0.027710\n",
      "Epoch 976 Chain 0 loss std 1.95e-03 variance 1.90e-06 smooth variance 3.19e-06 adaptive c -1.00\n",
      "Epoch 976 Chain 1 loss std 3.64e+02 variance 6.64e+04 smooth variance 4.65e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.019387\n",
      " Loss: 0.000001\n",
      " Loss: 0.036716\n",
      " Loss: 0.000000\n",
      " Loss: 0.097219\n",
      " Loss: 0.000000\n",
      " Loss: 0.034621\n",
      " Loss: 0.000000\n",
      " Loss: 0.049134\n",
      " Loss: 0.000000\n",
      " Loss: 0.034779\n",
      " Loss: 0.000000\n",
      " Loss: 0.057028\n",
      " Loss: 0.000001\n",
      " Loss: 0.026399\n",
      " Loss: 0.000000\n",
      " Loss: 0.091835\n",
      " Loss: 0.000001\n",
      " Loss: 0.026558\n",
      "Epoch 978 Chain 0 loss std 2.84e-03 variance 4.03e-06 smooth variance 3.45e-06 adaptive c -1.00\n",
      "Epoch 978 Chain 1 loss std 2.19e+02 variance 2.40e+04 smooth variance 3.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.109763\n",
      " Loss: 0.000000\n",
      " Loss: 0.035185\n",
      " Loss: 0.000000\n",
      " Loss: 0.034201\n",
      " Loss: 0.000001\n",
      " Loss: 0.027665\n",
      " Loss: 0.000000\n",
      " Loss: 0.029527\n",
      " Loss: 0.000000\n",
      " Loss: 0.031116\n",
      " Loss: 0.000000\n",
      " Loss: 0.076900\n",
      " Loss: 0.000000\n",
      " Loss: 0.067482\n",
      " Loss: 0.000000\n",
      " Loss: 0.033534\n",
      " Loss: 0.000001\n",
      " Loss: 0.026822\n",
      "Epoch 980 Chain 0 loss std 2.41e-03 variance 2.90e-06 smooth variance 3.28e-06 adaptive c -1.00\n",
      "Epoch 980 Chain 1 loss std 1.83e+02 variance 1.68e+04 smooth variance 3.29e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.048554\n",
      " Loss: 0.000000\n",
      " Loss: 0.039840\n",
      " Loss: 0.000000\n",
      " Loss: 0.028404\n",
      " Loss: 0.000000\n",
      " Loss: 0.089834\n",
      " Loss: 0.000001\n",
      " Loss: 0.028889\n",
      " Loss: 0.000000\n",
      " Loss: 0.109537\n",
      " Loss: 0.000000\n",
      " Loss: 0.029221\n",
      " Loss: 0.000000\n",
      " Loss: 0.034705\n",
      " Loss: 0.000000\n",
      " Loss: 0.023892\n",
      " Loss: 0.000001\n",
      " Loss: 0.037798\n",
      "Epoch 982 Chain 0 loss std 2.31e-03 variance 2.66e-06 smooth variance 3.09e-06 adaptive c -1.00\n",
      "Epoch 982 Chain 1 loss std 2.13e+02 variance 2.26e+04 smooth variance 2.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.054668\n",
      " Loss: 0.000000\n",
      " Loss: 0.022356\n",
      " Loss: 0.000001\n",
      " Loss: 0.027880\n",
      " Loss: 0.000000\n",
      " Loss: 0.091727\n",
      " Loss: 0.000000\n",
      " Loss: 0.038278\n",
      " Loss: 0.000000\n",
      " Loss: 0.031283\n",
      " Loss: 0.000001\n",
      " Loss: 0.036083\n",
      " Loss: 0.000000\n",
      " Loss: 0.041315\n",
      " Loss: 0.000000\n",
      " Loss: 0.091528\n",
      " Loss: 0.000000\n",
      " Loss: 0.034229\n",
      "Epoch 984 Chain 0 loss std 2.16e-03 variance 2.34e-06 smooth variance 2.87e-06 adaptive c -1.00\n",
      "Epoch 984 Chain 1 loss std 2.58e+02 variance 3.32e+04 smooth variance 3.08e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029491\n",
      " Loss: 0.000000\n",
      " Loss: 0.037640\n",
      " Loss: 0.000000\n",
      " Loss: 0.053608\n",
      " Loss: 0.000001\n",
      " Loss: 0.035419\n",
      " Loss: 0.000000\n",
      " Loss: 0.077989\n",
      " Loss: 0.000000\n",
      " Loss: 0.046478\n",
      " Loss: 0.000000\n",
      " Loss: 0.094639\n",
      " Loss: 0.000000\n",
      " Loss: 0.016589\n",
      " Loss: 0.000001\n",
      " Loss: 0.020266\n",
      " Loss: 0.000000\n",
      " Loss: 0.055704\n",
      "Epoch 986 Chain 0 loss std 3.09e-03 variance 4.77e-06 smooth variance 3.44e-06 adaptive c -1.00\n",
      "Epoch 986 Chain 1 loss std 3.46e+02 variance 5.98e+04 smooth variance 3.95e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.029240\n",
      " Loss: 0.000000\n",
      " Loss: 0.030837\n",
      " Loss: 0.000000\n",
      " Loss: 0.044451\n",
      " Loss: 0.000000\n",
      " Loss: 0.084748\n",
      " Loss: 0.000000\n",
      " Loss: 0.044102\n",
      " Loss: 0.000000\n",
      " Loss: 0.065653\n",
      " Loss: 0.000000\n",
      " Loss: 0.024999\n",
      " Loss: 0.000000\n",
      " Loss: 0.043376\n",
      " Loss: 0.000000\n",
      " Loss: 0.018468\n",
      " Loss: 0.000001\n",
      " Loss: 0.080647\n",
      "Epoch 988 Chain 0 loss std 2.51e-03 variance 3.16e-06 smooth variance 3.35e-06 adaptive c -1.00\n",
      "Epoch 988 Chain 1 loss std 3.16e+02 variance 4.99e+04 smooth variance 4.26e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.046212\n",
      " Loss: 0.000000\n",
      " Loss: 0.032592\n",
      " Loss: 0.000000\n",
      " Loss: 0.042345\n",
      " Loss: 0.000001\n",
      " Loss: 0.083226\n",
      " Loss: 0.000000\n",
      " Loss: 0.028257\n",
      " Loss: 0.000001\n",
      " Loss: 0.034220\n",
      " Loss: 0.000000\n",
      " Loss: 0.026177\n",
      " Loss: 0.000000\n",
      " Loss: 0.048982\n",
      " Loss: 0.000000\n",
      " Loss: 0.034668\n",
      " Loss: 0.000000\n",
      " Loss: 0.088201\n",
      "Epoch 990 Chain 0 loss std 1.95e-03 variance 1.89e-06 smooth variance 2.92e-06 adaptive c -1.00\n",
      "Epoch 990 Chain 1 loss std 3.33e+02 variance 5.55e+04 smooth variance 4.65e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.045987\n",
      " Loss: 0.000000\n",
      " Loss: 0.018139\n",
      " Loss: 0.000001\n",
      " Loss: 0.059308\n",
      " Loss: 0.000000\n",
      " Loss: 0.023386\n",
      " Loss: 0.000000\n",
      " Loss: 0.085090\n",
      " Loss: 0.000000\n",
      " Loss: 0.040289\n",
      " Loss: 0.000000\n",
      " Loss: 0.042509\n",
      " Loss: 0.000001\n",
      " Loss: 0.075060\n",
      " Loss: 0.000000\n",
      " Loss: 0.057318\n",
      " Loss: 0.000000\n",
      " Loss: 0.016392\n",
      "Epoch 992 Chain 0 loss std 3.26e-03 variance 5.32e-06 smooth variance 3.64e-06 adaptive c -1.00\n",
      "Epoch 992 Chain 1 loss std 1.74e+02 variance 1.52e+04 smooth variance 3.71e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026205\n",
      " Loss: 0.000000\n",
      " Loss: 0.105460\n",
      " Loss: 0.000001\n",
      " Loss: 0.035585\n",
      " Loss: 0.000000\n",
      " Loss: 0.034137\n",
      " Loss: 0.000000\n",
      " Loss: 0.029751\n",
      " Loss: 0.000001\n",
      " Loss: 0.033847\n",
      " Loss: 0.000000\n",
      " Loss: 0.023573\n",
      " Loss: 0.000000\n",
      " Loss: 0.077967\n",
      " Loss: 0.000000\n",
      " Loss: 0.025697\n",
      " Loss: 0.000000\n",
      " Loss: 0.069836\n",
      "Epoch 994 Chain 0 loss std 1.70e-03 variance 1.44e-06 smooth variance 2.98e-06 adaptive c -1.00\n",
      "Epoch 994 Chain 1 loss std 2.58e+02 variance 3.32e+04 smooth variance 3.59e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.095097\n",
      " Loss: 0.000000\n",
      " Loss: 0.035200\n",
      " Loss: 0.000000\n",
      " Loss: 0.029561\n",
      " Loss: 0.000001\n",
      " Loss: 0.038303\n",
      " Loss: 0.000000\n",
      " Loss: 0.032271\n",
      " Loss: 0.000000\n",
      " Loss: 0.036987\n",
      " Loss: 0.000001\n",
      " Loss: 0.034892\n",
      " Loss: 0.000000\n",
      " Loss: 0.028776\n",
      " Loss: 0.000000\n",
      " Loss: 0.079305\n",
      " Loss: 0.000000\n",
      " Loss: 0.050363\n",
      "Epoch 996 Chain 0 loss std 1.97e-03 variance 1.94e-06 smooth variance 2.66e-06 adaptive c -1.00\n",
      "Epoch 996 Chain 1 loss std 2.03e+02 variance 2.06e+04 smooth variance 3.13e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.040954\n",
      " Loss: 0.000000\n",
      " Loss: 0.049739\n",
      " Loss: 0.000000\n",
      " Loss: 0.033010\n",
      " Loss: 0.000000\n",
      " Loss: 0.076897\n",
      " Loss: 0.000001\n",
      " Loss: 0.029282\n",
      " Loss: 0.000000\n",
      " Loss: 0.037531\n",
      " Loss: 0.000000\n",
      " Loss: 0.041379\n",
      " Loss: 0.000001\n",
      " Loss: 0.077309\n",
      " Loss: 0.000000\n",
      " Loss: 0.026326\n",
      " Loss: 0.000000\n",
      " Loss: 0.046905\n",
      "Epoch 998 Chain 0 loss std 1.70e-03 variance 1.44e-06 smooth variance 2.30e-06 adaptive c -1.00\n",
      "Epoch 998 Chain 1 loss std 2.15e+02 variance 2.32e+04 smooth variance 2.89e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.022076\n",
      " Loss: 0.000000\n",
      " Loss: 0.028993\n",
      " Loss: 0.000000\n",
      " Loss: 0.034145\n",
      " Loss: 0.000000\n",
      " Loss: 0.104454\n",
      " Loss: 0.000000\n",
      " Loss: 0.039402\n",
      " Loss: 0.000000\n",
      " Loss: 0.090868\n",
      " Loss: 0.000000\n",
      " Loss: 0.031901\n",
      " Loss: 0.000000\n",
      " Loss: 0.043620\n",
      " Loss: 0.000001\n",
      " Loss: 0.022828\n",
      " Loss: 0.000000\n",
      " Loss: 0.039878\n",
      "Epoch 1000 Chain 0 loss std 2.33e-03 variance 2.72e-06 smooth variance 2.42e-06 adaptive c -1.00\n",
      "Epoch 1000 Chain 1 loss std 3.62e+02 variance 6.53e+04 smooth variance 3.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029091\n",
      " Loss: 0.000001\n",
      " Loss: 0.053577\n",
      " Loss: 0.000000\n",
      " Loss: 0.018135\n",
      " Loss: 0.000000\n",
      " Loss: 0.082085\n",
      " Loss: 0.000000\n",
      " Loss: 0.045556\n",
      " Loss: 0.000001\n",
      " Loss: 0.043684\n",
      " Loss: 0.000000\n",
      " Loss: 0.048100\n",
      " Loss: 0.000000\n",
      " Loss: 0.029893\n",
      " Loss: 0.000000\n",
      " Loss: 0.092252\n",
      " Loss: 0.000000\n",
      " Loss: 0.014314\n",
      "Epoch 1002 Chain 0 loss std 1.66e-03 variance 1.38e-06 smooth variance 2.11e-06 adaptive c -1.00\n",
      "Epoch 1002 Chain 1 loss std 2.48e+02 variance 3.07e+04 smooth variance 3.71e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.047896\n",
      " Loss: 0.000000\n",
      " Loss: 0.027067\n",
      " Loss: 0.000000\n",
      " Loss: 0.032592\n",
      " Loss: 0.000000\n",
      " Loss: 0.024196\n",
      " Loss: 0.000000\n",
      " Loss: 0.096272\n",
      " Loss: 0.000000\n",
      " Loss: 0.094011\n",
      " Loss: 0.000000\n",
      " Loss: 0.037300\n",
      " Loss: 0.000001\n",
      " Loss: 0.023212\n",
      " Loss: 0.000000\n",
      " Loss: 0.048734\n",
      " Loss: 0.000000\n",
      " Loss: 0.024520\n",
      "Epoch 1004 Chain 0 loss std 1.94e-03 variance 1.87e-06 smooth variance 2.04e-06 adaptive c -1.00\n",
      "Epoch 1004 Chain 1 loss std 2.62e+02 variance 3.42e+04 smooth variance 3.62e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.081571\n",
      " Loss: 0.000001\n",
      " Loss: 0.034379\n",
      " Loss: 0.000000\n",
      " Loss: 0.022456\n",
      " Loss: 0.000000\n",
      " Loss: 0.041418\n",
      " Loss: 0.000000\n",
      " Loss: 0.047337\n",
      " Loss: 0.000000\n",
      " Loss: 0.048665\n",
      " Loss: 0.000000\n",
      " Loss: 0.018241\n",
      " Loss: 0.000001\n",
      " Loss: 0.082646\n",
      " Loss: 0.000000\n",
      " Loss: 0.050124\n",
      " Loss: 0.000000\n",
      " Loss: 0.027070\n",
      "Epoch 1006 Chain 0 loss std 2.04e-03 variance 2.08e-06 smooth variance 2.05e-06 adaptive c -1.00\n",
      "Epoch 1006 Chain 1 loss std 3.13e+02 variance 4.90e+04 smooth variance 4.01e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.096441\n",
      " Loss: 0.000000\n",
      " Loss: 0.025800\n",
      " Loss: 0.000000\n",
      " Loss: 0.036651\n",
      " Loss: 0.000001\n",
      " Loss: 0.035507\n",
      " Loss: 0.000000\n",
      " Loss: 0.031998\n",
      " Loss: 0.000000\n",
      " Loss: 0.090497\n",
      " Loss: 0.000000\n",
      " Loss: 0.029083\n",
      " Loss: 0.000000\n",
      " Loss: 0.038652\n",
      " Loss: 0.000001\n",
      " Loss: 0.027398\n",
      " Loss: 0.000000\n",
      " Loss: 0.040431\n",
      "Epoch 1008 Chain 0 loss std 1.79e-03 variance 1.61e-06 smooth variance 1.92e-06 adaptive c -1.00\n",
      "Epoch 1008 Chain 1 loss std 1.76e+02 variance 1.55e+04 smooth variance 3.27e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.095403\n",
      " Loss: 0.000000\n",
      " Loss: 0.023372\n",
      " Loss: 0.000001\n",
      " Loss: 0.028626\n",
      " Loss: 0.000000\n",
      " Loss: 0.050944\n",
      " Loss: 0.000000\n",
      " Loss: 0.027543\n",
      " Loss: 0.000000\n",
      " Loss: 0.037795\n",
      " Loss: 0.000000\n",
      " Loss: 0.016067\n",
      " Loss: 0.000000\n",
      " Loss: 0.031283\n",
      " Loss: 0.000001\n",
      " Loss: 0.057699\n",
      " Loss: 0.000000\n",
      " Loss: 0.082658\n",
      "Epoch 1010 Chain 0 loss std 2.55e-03 variance 3.26e-06 smooth variance 2.32e-06 adaptive c -1.00\n",
      "Epoch 1010 Chain 1 loss std 2.88e+02 variance 4.14e+04 smooth variance 3.53e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029809\n",
      " Loss: 0.000000\n",
      " Loss: 0.088051\n",
      " Loss: 0.000000\n",
      " Loss: 0.021856\n",
      " Loss: 0.000000\n",
      " Loss: 0.054206\n",
      " Loss: 0.000001\n",
      " Loss: 0.031131\n",
      " Loss: 0.000001\n",
      " Loss: 0.024374\n",
      " Loss: 0.000000\n",
      " Loss: 0.079881\n",
      " Loss: 0.000000\n",
      " Loss: 0.022493\n",
      " Loss: 0.000000\n",
      " Loss: 0.039716\n",
      " Loss: 0.000000\n",
      " Loss: 0.058495\n",
      "Epoch 1012 Chain 0 loss std 1.56e-03 variance 1.22e-06 smooth variance 1.99e-06 adaptive c -1.00\n",
      "Epoch 1012 Chain 1 loss std 3.38e+02 variance 5.70e+04 smooth variance 4.18e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.037185\n",
      " Loss: 0.000000\n",
      " Loss: 0.040679\n",
      " Loss: 0.000000\n",
      " Loss: 0.071850\n",
      " Loss: 0.000000\n",
      " Loss: 0.029590\n",
      " Loss: 0.000000\n",
      " Loss: 0.045112\n",
      " Loss: 0.000000\n",
      " Loss: 0.028974\n",
      " Loss: 0.000001\n",
      " Loss: 0.078692\n",
      " Loss: 0.000000\n",
      " Loss: 0.047221\n",
      " Loss: 0.000000\n",
      " Loss: 0.027375\n",
      " Loss: 0.000000\n",
      " Loss: 0.041783\n",
      "Epoch 1014 Chain 0 loss std 1.33e-03 variance 8.85e-07 smooth variance 1.66e-06 adaptive c -1.00\n",
      "Epoch 1014 Chain 1 loss std 3.05e+02 variance 4.66e+04 smooth variance 4.32e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.034633\n",
      " Loss: 0.000000\n",
      " Loss: 0.032117\n",
      " Loss: 0.000000\n",
      " Loss: 0.096291\n",
      " Loss: 0.000000\n",
      " Loss: 0.043887\n",
      " Loss: 0.000001\n",
      " Loss: 0.016735\n",
      " Loss: 0.000001\n",
      " Loss: 0.025035\n",
      " Loss: 0.000000\n",
      " Loss: 0.078105\n",
      " Loss: 0.000000\n",
      " Loss: 0.067941\n",
      " Loss: 0.000000\n",
      " Loss: 0.021970\n",
      " Loss: 0.000000\n",
      " Loss: 0.030316\n",
      "Epoch 1016 Chain 0 loss std 1.46e-03 variance 1.06e-06 smooth variance 1.48e-06 adaptive c -1.00\n",
      "Epoch 1016 Chain 1 loss std 2.52e+02 variance 3.18e+04 smooth variance 3.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032358\n",
      " Loss: 0.000000\n",
      " Loss: 0.053224\n",
      " Loss: 0.000001\n",
      " Loss: 0.018372\n",
      " Loss: 0.000000\n",
      " Loss: 0.091127\n",
      " Loss: 0.000000\n",
      " Loss: 0.028173\n",
      " Loss: 0.000000\n",
      " Loss: 0.031832\n",
      " Loss: 0.000000\n",
      " Loss: 0.023357\n",
      " Loss: 0.000000\n",
      " Loss: 0.079965\n",
      " Loss: 0.000000\n",
      " Loss: 0.059153\n",
      " Loss: 0.000000\n",
      " Loss: 0.028411\n",
      "Epoch 1018 Chain 0 loss std 3.18e-03 variance 5.04e-06 smooth variance 2.55e-06 adaptive c -1.00\n",
      "Epoch 1018 Chain 1 loss std 1.93e+02 variance 1.87e+04 smooth variance 3.35e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037302\n",
      " Loss: 0.000001\n",
      " Loss: 0.081503\n",
      " Loss: 0.000000\n",
      " Loss: 0.038502\n",
      " Loss: 0.000000\n",
      " Loss: 0.027599\n",
      " Loss: 0.000000\n",
      " Loss: 0.037506\n",
      " Loss: 0.000000\n",
      " Loss: 0.027464\n",
      " Loss: 0.000000\n",
      " Loss: 0.034797\n",
      " Loss: 0.000000\n",
      " Loss: 0.044392\n",
      " Loss: 0.000000\n",
      " Loss: 0.030270\n",
      " Loss: 0.000000\n",
      " Loss: 0.085230\n",
      "Epoch 1020 Chain 0 loss std 1.70e-03 variance 1.45e-06 smooth variance 2.22e-06 adaptive c -1.00\n",
      "Epoch 1020 Chain 1 loss std 3.69e+02 variance 6.82e+04 smooth variance 4.39e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.074174\n",
      " Loss: 0.000000\n",
      " Loss: 0.043785\n",
      " Loss: 0.000000\n",
      " Loss: 0.032595\n",
      " Loss: 0.000000\n",
      " Loss: 0.048667\n",
      " Loss: 0.000001\n",
      " Loss: 0.023148\n",
      " Loss: 0.000000\n",
      " Loss: 0.051005\n",
      " Loss: 0.000000\n",
      " Loss: 0.040406\n",
      " Loss: 0.000001\n",
      " Loss: 0.022729\n",
      " Loss: 0.000000\n",
      " Loss: 0.081542\n",
      " Loss: 0.000000\n",
      " Loss: 0.026095\n",
      "Epoch 1022 Chain 0 loss std 1.46e-03 variance 1.07e-06 smooth variance 1.88e-06 adaptive c -1.00\n",
      "Epoch 1022 Chain 1 loss std 2.44e+02 variance 2.99e+04 smooth variance 3.97e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029398\n",
      " Loss: 0.000000\n",
      " Loss: 0.041550\n",
      " Loss: 0.000000\n",
      " Loss: 0.087599\n",
      " Loss: 0.000001\n",
      " Loss: 0.018461\n",
      " Loss: 0.000000\n",
      " Loss: 0.044115\n",
      " Loss: 0.000000\n",
      " Loss: 0.024615\n",
      " Loss: 0.000000\n",
      " Loss: 0.028337\n",
      " Loss: 0.000001\n",
      " Loss: 0.084055\n",
      " Loss: 0.000000\n",
      " Loss: 0.058135\n",
      " Loss: 0.000000\n",
      " Loss: 0.025632\n",
      "Epoch 1024 Chain 0 loss std 2.06e-03 variance 2.13e-06 smooth variance 1.95e-06 adaptive c -1.00\n",
      "Epoch 1024 Chain 1 loss std 2.42e+02 variance 2.93e+04 smooth variance 3.66e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.038941\n",
      " Loss: 0.000001\n",
      " Loss: 0.045691\n",
      " Loss: 0.000000\n",
      " Loss: 0.083665\n",
      " Loss: 0.000000\n",
      " Loss: 0.029270\n",
      " Loss: 0.000000\n",
      " Loss: 0.022899\n",
      " Loss: 0.000000\n",
      " Loss: 0.039128\n",
      " Loss: 0.000000\n",
      " Loss: 0.022336\n",
      " Loss: 0.000001\n",
      " Loss: 0.044353\n",
      " Loss: 0.000000\n",
      " Loss: 0.034133\n",
      " Loss: 0.000000\n",
      " Loss: 0.080353\n",
      "Epoch 1026 Chain 0 loss std 2.06e-03 variance 2.11e-06 smooth variance 2.00e-06 adaptive c -1.00\n",
      "Epoch 1026 Chain 1 loss std 1.97e+02 variance 1.94e+04 smooth variance 3.14e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.092372\n",
      " Loss: 0.000000\n",
      " Loss: 0.017077\n",
      " Loss: 0.000000\n",
      " Loss: 0.028396\n",
      " Loss: 0.000001\n",
      " Loss: 0.034887\n",
      " Loss: 0.000000\n",
      " Loss: 0.047718\n",
      " Loss: 0.000000\n",
      " Loss: 0.022705\n",
      " Loss: 0.000000\n",
      " Loss: 0.085731\n",
      " Loss: 0.000001\n",
      " Loss: 0.029826\n",
      " Loss: 0.000000\n",
      " Loss: 0.031126\n",
      " Loss: 0.000000\n",
      " Loss: 0.050263\n",
      "Epoch 1028 Chain 0 loss std 1.49e-03 variance 1.11e-06 smooth variance 1.73e-06 adaptive c -1.00\n",
      "Epoch 1028 Chain 1 loss std 2.94e+02 variance 4.31e+04 smooth variance 3.49e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022490\n",
      " Loss: 0.000000\n",
      " Loss: 0.021539\n",
      " Loss: 0.000001\n",
      " Loss: 0.042210\n",
      " Loss: 0.000000\n",
      " Loss: 0.036227\n",
      " Loss: 0.000000\n",
      " Loss: 0.096976\n",
      " Loss: 0.000000\n",
      " Loss: 0.018406\n",
      " Loss: 0.000000\n",
      " Loss: 0.026946\n",
      " Loss: 0.000001\n",
      " Loss: 0.095439\n",
      " Loss: 0.000000\n",
      " Loss: 0.049800\n",
      " Loss: 0.000000\n",
      " Loss: 0.028270\n",
      "Epoch 1030 Chain 0 loss std 1.79e-03 variance 1.60e-06 smooth variance 1.69e-06 adaptive c -1.00\n",
      "Epoch 1030 Chain 1 loss std 2.12e+02 variance 2.24e+04 smooth variance 3.12e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.031417\n",
      " Loss: 0.000000\n",
      " Loss: 0.096567\n",
      " Loss: 0.000000\n",
      " Loss: 0.028829\n",
      " Loss: 0.000000\n",
      " Loss: 0.028242\n",
      " Loss: 0.000000\n",
      " Loss: 0.033542\n",
      " Loss: 0.000000\n",
      " Loss: 0.023927\n",
      " Loss: 0.000000\n",
      " Loss: 0.031033\n",
      " Loss: 0.000000\n",
      " Loss: 0.046641\n",
      " Loss: 0.000000\n",
      " Loss: 0.027330\n",
      " Loss: 0.000001\n",
      " Loss: 0.089510\n",
      "Epoch 1032 Chain 0 loss std 1.83e-03 variance 1.67e-06 smooth variance 1.69e-06 adaptive c -1.00\n",
      "Epoch 1032 Chain 1 loss std 2.38e+02 variance 2.83e+04 smooth variance 3.03e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035472\n",
      " Loss: 0.000000\n",
      " Loss: 0.030972\n",
      " Loss: 0.000000\n",
      " Loss: 0.079392\n",
      " Loss: 0.000000\n",
      " Loss: 0.029033\n",
      " Loss: 0.000001\n",
      " Loss: 0.043240\n",
      " Loss: 0.000000\n",
      " Loss: 0.043898\n",
      " Loss: 0.000001\n",
      " Loss: 0.013743\n",
      " Loss: 0.000000\n",
      " Loss: 0.038148\n",
      " Loss: 0.000000\n",
      " Loss: 0.084531\n",
      " Loss: 0.000000\n",
      " Loss: 0.037340\n",
      "Epoch 1034 Chain 0 loss std 1.64e-03 variance 1.35e-06 smooth variance 1.59e-06 adaptive c -1.00\n",
      "Epoch 1034 Chain 1 loss std 3.08e+02 variance 4.75e+04 smooth variance 3.55e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026046\n",
      " Loss: 0.000000\n",
      " Loss: 0.073262\n",
      " Loss: 0.000000\n",
      " Loss: 0.048472\n",
      " Loss: 0.000000\n",
      " Loss: 0.041222\n",
      " Loss: 0.000000\n",
      " Loss: 0.028353\n",
      " Loss: 0.000000\n",
      " Loss: 0.032748\n",
      " Loss: 0.000000\n",
      " Loss: 0.033768\n",
      " Loss: 0.000001\n",
      " Loss: 0.074148\n",
      " Loss: 0.000000\n",
      " Loss: 0.040621\n",
      " Loss: 0.000000\n",
      " Loss: 0.035727\n",
      "Epoch 1036 Chain 0 loss std 1.66e-03 variance 1.37e-06 smooth variance 1.52e-06 adaptive c -1.00\n",
      "Epoch 1036 Chain 1 loss std 2.72e+02 variance 3.71e+04 smooth variance 3.60e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032669\n",
      " Loss: 0.000000\n",
      " Loss: 0.084212\n",
      " Loss: 0.000000\n",
      " Loss: 0.018311\n",
      " Loss: 0.000000\n",
      " Loss: 0.030600\n",
      " Loss: 0.000000\n",
      " Loss: 0.051170\n",
      " Loss: 0.000000\n",
      " Loss: 0.086196\n",
      " Loss: 0.000000\n",
      " Loss: 0.031800\n",
      " Loss: 0.000001\n",
      " Loss: 0.028088\n",
      " Loss: 0.000000\n",
      " Loss: 0.050990\n",
      " Loss: 0.000000\n",
      " Loss: 0.019375\n",
      "Epoch 1038 Chain 0 loss std 2.90e-03 variance 4.22e-06 smooth variance 2.33e-06 adaptive c -1.00\n",
      "Epoch 1038 Chain 1 loss std 1.86e+02 variance 1.72e+04 smooth variance 3.03e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029595\n",
      " Loss: 0.000000\n",
      " Loss: 0.044359\n",
      " Loss: 0.000000\n",
      " Loss: 0.034676\n",
      " Loss: 0.000000\n",
      " Loss: 0.037127\n",
      " Loss: 0.000000\n",
      " Loss: 0.070729\n",
      " Loss: 0.000000\n",
      " Loss: 0.037836\n",
      " Loss: 0.000000\n",
      " Loss: 0.025976\n",
      " Loss: 0.000000\n",
      " Loss: 0.023932\n",
      " Loss: 0.000000\n",
      " Loss: 0.077805\n",
      " Loss: 0.000000\n",
      " Loss: 0.050380\n",
      "Epoch 1040 Chain 0 loss std 2.32e-03 variance 2.68e-06 smooth variance 2.44e-06 adaptive c -1.00\n",
      "Epoch 1040 Chain 1 loss std 2.08e+02 variance 2.16e+04 smooth variance 2.77e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023089\n",
      " Loss: 0.000000\n",
      " Loss: 0.098931\n",
      " Loss: 0.000000\n",
      " Loss: 0.027384\n",
      " Loss: 0.000000\n",
      " Loss: 0.027576\n",
      " Loss: 0.000000\n",
      " Loss: 0.038452\n",
      " Loss: 0.000000\n",
      " Loss: 0.025259\n",
      " Loss: 0.000000\n",
      " Loss: 0.043556\n",
      " Loss: 0.000000\n",
      " Loss: 0.017757\n",
      " Loss: 0.000000\n",
      " Loss: 0.076564\n",
      " Loss: 0.000000\n",
      " Loss: 0.052154\n",
      "Epoch 1042 Chain 0 loss std 1.71e-03 variance 1.47e-06 smooth variance 2.14e-06 adaptive c -1.00\n",
      "Epoch 1042 Chain 1 loss std 2.29e+02 variance 2.62e+04 smooth variance 2.73e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016739\n",
      " Loss: 0.000000\n",
      " Loss: 0.038188\n",
      " Loss: 0.000000\n",
      " Loss: 0.038927\n",
      " Loss: 0.000001\n",
      " Loss: 0.084121\n",
      " Loss: 0.000000\n",
      " Loss: 0.036872\n",
      " Loss: 0.000000\n",
      " Loss: 0.028729\n",
      " Loss: 0.000000\n",
      " Loss: 0.034705\n",
      " Loss: 0.000001\n",
      " Loss: 0.082445\n",
      " Loss: 0.000000\n",
      " Loss: 0.047726\n",
      " Loss: 0.000000\n",
      " Loss: 0.021051\n",
      "Epoch 1044 Chain 0 loss std 1.47e-03 variance 1.09e-06 smooth variance 1.83e-06 adaptive c -1.00\n",
      "Epoch 1044 Chain 1 loss std 2.82e+02 variance 3.98e+04 smooth variance 3.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015895\n",
      " Loss: 0.000000\n",
      " Loss: 0.048388\n",
      " Loss: 0.000000\n",
      " Loss: 0.033225\n",
      " Loss: 0.000000\n",
      " Loss: 0.032024\n",
      " Loss: 0.000001\n",
      " Loss: 0.085015\n",
      " Loss: 0.000000\n",
      " Loss: 0.046130\n",
      " Loss: 0.000000\n",
      " Loss: 0.028439\n",
      " Loss: 0.000000\n",
      " Loss: 0.023976\n",
      " Loss: 0.000000\n",
      " Loss: 0.078358\n",
      " Loss: 0.000000\n",
      " Loss: 0.037254\n",
      "Epoch 1046 Chain 0 loss std 1.76e-03 variance 1.54e-06 smooth variance 1.74e-06 adaptive c -1.00\n",
      "Epoch 1046 Chain 1 loss std 2.91e+02 variance 4.24e+04 smooth variance 3.44e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.080129\n",
      " Loss: 0.000001\n",
      " Loss: 0.038306\n",
      " Loss: 0.000000\n",
      " Loss: 0.021081\n",
      " Loss: 0.000000\n",
      " Loss: 0.028669\n",
      " Loss: 0.000000\n",
      " Loss: 0.045962\n",
      " Loss: 0.000000\n",
      " Loss: 0.025184\n",
      " Loss: 0.000000\n",
      " Loss: 0.070320\n",
      " Loss: 0.000000\n",
      " Loss: 0.029482\n",
      " Loss: 0.000000\n",
      " Loss: 0.041729\n",
      " Loss: 0.000000\n",
      " Loss: 0.046699\n",
      "Epoch 1048 Chain 0 loss std 1.72e-03 variance 1.47e-06 smooth variance 1.66e-06 adaptive c -1.00\n",
      "Epoch 1048 Chain 1 loss std 1.84e+02 variance 1.70e+04 smooth variance 2.92e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027261\n",
      " Loss: 0.000000\n",
      " Loss: 0.017039\n",
      " Loss: 0.000000\n",
      " Loss: 0.032951\n",
      " Loss: 0.000000\n",
      " Loss: 0.096615\n",
      " Loss: 0.000000\n",
      " Loss: 0.039092\n",
      " Loss: 0.000000\n",
      " Loss: 0.041177\n",
      " Loss: 0.000000\n",
      " Loss: 0.025396\n",
      " Loss: 0.000001\n",
      " Loss: 0.043971\n",
      " Loss: 0.000000\n",
      " Loss: 0.023055\n",
      " Loss: 0.000000\n",
      " Loss: 0.079274\n",
      "Epoch 1050 Chain 0 loss std 1.82e-03 variance 1.65e-06 smooth variance 1.66e-06 adaptive c -1.00\n",
      "Epoch 1050 Chain 1 loss std 2.06e+02 variance 2.13e+04 smooth variance 2.68e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027612\n",
      " Loss: 0.000000\n",
      " Loss: 0.012883\n",
      " Loss: 0.000000\n",
      " Loss: 0.081733\n",
      " Loss: 0.000000\n",
      " Loss: 0.049592\n",
      " Loss: 0.000001\n",
      " Loss: 0.040732\n",
      " Loss: 0.000000\n",
      " Loss: 0.075740\n",
      " Loss: 0.000000\n",
      " Loss: 0.030488\n",
      " Loss: 0.000000\n",
      " Loss: 0.049138\n",
      " Loss: 0.000000\n",
      " Loss: 0.016772\n",
      " Loss: 0.000000\n",
      " Loss: 0.040134\n",
      "Epoch 1052 Chain 0 loss std 1.95e-03 variance 1.89e-06 smooth variance 1.73e-06 adaptive c -1.00\n",
      "Epoch 1052 Chain 1 loss std 1.89e+02 variance 1.78e+04 smooth variance 2.41e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021914\n",
      " Loss: 0.000000\n",
      " Loss: 0.019610\n",
      " Loss: 0.000000\n",
      " Loss: 0.026833\n",
      " Loss: 0.000000\n",
      " Loss: 0.078393\n",
      " Loss: 0.000000\n",
      " Loss: 0.064972\n",
      " Loss: 0.000000\n",
      " Loss: 0.075935\n",
      " Loss: 0.000000\n",
      " Loss: 0.031418\n",
      " Loss: 0.000000\n",
      " Loss: 0.041115\n",
      " Loss: 0.000000\n",
      " Loss: 0.024615\n",
      " Loss: 0.000000\n",
      " Loss: 0.038474\n",
      "Epoch 1054 Chain 0 loss std 1.25e-03 variance 7.78e-07 smooth variance 1.44e-06 adaptive c -1.00\n",
      "Epoch 1054 Chain 1 loss std 2.24e+02 variance 2.50e+04 smooth variance 2.44e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.042298\n",
      " Loss: 0.000000\n",
      " Loss: 0.025231\n",
      " Loss: 0.000000\n",
      " Loss: 0.039808\n",
      " Loss: 0.000000\n",
      " Loss: 0.027859\n",
      " Loss: 0.000000\n",
      " Loss: 0.076199\n",
      " Loss: 0.000000\n",
      " Loss: 0.023117\n",
      " Loss: 0.000000\n",
      " Loss: 0.076734\n",
      " Loss: 0.000000\n",
      " Loss: 0.038654\n",
      " Loss: 0.000000\n",
      " Loss: 0.025162\n",
      " Loss: 0.000000\n",
      " Loss: 0.047589\n",
      "Epoch 1056 Chain 0 loss std 1.69e-03 variance 1.43e-06 smooth variance 1.44e-06 adaptive c -1.00\n",
      "Epoch 1056 Chain 1 loss std 3.51e+02 variance 6.17e+04 smooth variance 3.56e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.049044\n",
      " Loss: 0.000000\n",
      " Loss: 0.019173\n",
      " Loss: 0.000000\n",
      " Loss: 0.076709\n",
      " Loss: 0.000000\n",
      " Loss: 0.035515\n",
      " Loss: 0.000001\n",
      " Loss: 0.030237\n",
      " Loss: 0.000000\n",
      " Loss: 0.035805\n",
      " Loss: 0.000000\n",
      " Loss: 0.031023\n",
      " Loss: 0.000000\n",
      " Loss: 0.022307\n",
      " Loss: 0.000000\n",
      " Loss: 0.042541\n",
      " Loss: 0.000000\n",
      " Loss: 0.078890\n",
      "Epoch 1058 Chain 0 loss std 1.40e-03 variance 9.84e-07 smooth variance 1.30e-06 adaptive c -1.00\n",
      "Epoch 1058 Chain 1 loss std 2.64e+02 variance 3.49e+04 smooth variance 3.54e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026855\n",
      " Loss: 0.000000\n",
      " Loss: 0.024402\n",
      " Loss: 0.000000\n",
      " Loss: 0.023269\n",
      " Loss: 0.000000\n",
      " Loss: 0.036262\n",
      " Loss: 0.000000\n",
      " Loss: 0.099132\n",
      " Loss: 0.000000\n",
      " Loss: 0.037865\n",
      " Loss: 0.000000\n",
      " Loss: 0.082868\n",
      " Loss: 0.000000\n",
      " Loss: 0.030922\n",
      " Loss: 0.000000\n",
      " Loss: 0.041310\n",
      " Loss: 0.000000\n",
      " Loss: 0.016736\n",
      "Epoch 1060 Chain 0 loss std 2.03e-03 variance 2.06e-06 smooth variance 1.53e-06 adaptive c -1.00\n",
      "Epoch 1060 Chain 1 loss std 2.12e+02 variance 2.24e+04 smooth variance 3.15e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027939\n",
      " Loss: 0.000000\n",
      " Loss: 0.034933\n",
      " Loss: 0.000000\n",
      " Loss: 0.036881\n",
      " Loss: 0.000001\n",
      " Loss: 0.018756\n",
      " Loss: 0.000000\n",
      " Loss: 0.091022\n",
      " Loss: 0.000001\n",
      " Loss: 0.075840\n",
      " Loss: 0.000000\n",
      " Loss: 0.024386\n",
      " Loss: 0.000000\n",
      " Loss: 0.042785\n",
      " Loss: 0.000000\n",
      " Loss: 0.036831\n",
      " Loss: 0.000000\n",
      " Loss: 0.029435\n",
      "Epoch 1062 Chain 0 loss std 2.45e-03 variance 2.99e-06 smooth variance 1.97e-06 adaptive c -1.00\n",
      "Epoch 1062 Chain 1 loss std 2.51e+02 variance 3.16e+04 smooth variance 3.15e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.051900\n",
      " Loss: 0.000000\n",
      " Loss: 0.014449\n",
      " Loss: 0.000000\n",
      " Loss: 0.036580\n",
      " Loss: 0.000001\n",
      " Loss: 0.078357\n",
      " Loss: 0.000000\n",
      " Loss: 0.027559\n",
      " Loss: 0.000000\n",
      " Loss: 0.025699\n",
      " Loss: 0.000000\n",
      " Loss: 0.059478\n",
      " Loss: 0.000000\n",
      " Loss: 0.022779\n",
      " Loss: 0.000000\n",
      " Loss: 0.073889\n",
      " Loss: 0.000001\n",
      " Loss: 0.026670\n",
      "Epoch 1064 Chain 0 loss std 1.47e-03 variance 1.08e-06 smooth variance 1.70e-06 adaptive c -1.00\n",
      "Epoch 1064 Chain 1 loss std 2.22e+02 variance 2.46e+04 smooth variance 2.94e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.078705\n",
      " Loss: 0.000000\n",
      " Loss: 0.039927\n",
      " Loss: 0.000000\n",
      " Loss: 0.027473\n",
      " Loss: 0.000000\n",
      " Loss: 0.025112\n",
      " Loss: 0.000000\n",
      " Loss: 0.037117\n",
      " Loss: 0.000000\n",
      " Loss: 0.036072\n",
      " Loss: 0.000000\n",
      " Loss: 0.075252\n",
      " Loss: 0.000000\n",
      " Loss: 0.043781\n",
      " Loss: 0.000000\n",
      " Loss: 0.023008\n",
      " Loss: 0.000000\n",
      " Loss: 0.029859\n",
      "Epoch 1066 Chain 0 loss std 1.42e-03 variance 1.01e-06 smooth variance 1.49e-06 adaptive c -1.00\n",
      "Epoch 1066 Chain 1 loss std 2.94e+02 variance 4.32e+04 smooth variance 3.36e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017415\n",
      " Loss: 0.000000\n",
      " Loss: 0.084071\n",
      " Loss: 0.000000\n",
      " Loss: 0.045909\n",
      " Loss: 0.000000\n",
      " Loss: 0.018616\n",
      " Loss: 0.000000\n",
      " Loss: 0.041661\n",
      " Loss: 0.000000\n",
      " Loss: 0.022224\n",
      " Loss: 0.000000\n",
      " Loss: 0.048134\n",
      " Loss: 0.000000\n",
      " Loss: 0.028932\n",
      " Loss: 0.000000\n",
      " Loss: 0.088293\n",
      " Loss: 0.000000\n",
      " Loss: 0.019907\n",
      "Epoch 1068 Chain 0 loss std 1.69e-03 variance 1.44e-06 smooth variance 1.48e-06 adaptive c -1.00\n",
      "Epoch 1068 Chain 1 loss std 1.75e+02 variance 1.54e+04 smooth variance 2.81e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.078276\n",
      " Loss: 0.000000\n",
      " Loss: 0.031810\n",
      " Loss: 0.000000\n",
      " Loss: 0.034082\n",
      " Loss: 0.000000\n",
      " Loss: 0.021253\n",
      " Loss: 0.000000\n",
      " Loss: 0.041863\n",
      " Loss: 0.000000\n",
      " Loss: 0.029392\n",
      " Loss: 0.000000\n",
      " Loss: 0.021696\n",
      " Loss: 0.000000\n",
      " Loss: 0.026142\n",
      " Loss: 0.000000\n",
      " Loss: 0.076423\n",
      " Loss: 0.000000\n",
      " Loss: 0.053124\n",
      "Epoch 1070 Chain 0 loss std 1.40e-03 variance 9.84e-07 smooth variance 1.33e-06 adaptive c -1.00\n",
      "Epoch 1070 Chain 1 loss std 2.46e+02 variance 3.02e+04 smooth variance 2.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036647\n",
      " Loss: 0.000000\n",
      " Loss: 0.049430\n",
      " Loss: 0.000000\n",
      " Loss: 0.025720\n",
      " Loss: 0.000000\n",
      " Loss: 0.069429\n",
      " Loss: 0.000000\n",
      " Loss: 0.025308\n",
      " Loss: 0.000000\n",
      " Loss: 0.082614\n",
      " Loss: 0.000000\n",
      " Loss: 0.019223\n",
      " Loss: 0.000000\n",
      " Loss: 0.040787\n",
      " Loss: 0.000000\n",
      " Loss: 0.025362\n",
      " Loss: 0.000000\n",
      " Loss: 0.038263\n",
      "Epoch 1072 Chain 0 loss std 1.41e-03 variance 1.00e-06 smooth variance 1.23e-06 adaptive c -1.00\n",
      "Epoch 1072 Chain 1 loss std 3.27e+02 variance 5.35e+04 smooth variance 3.62e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027248\n",
      " Loss: 0.000000\n",
      " Loss: 0.052870\n",
      " Loss: 0.000000\n",
      " Loss: 0.071735\n",
      " Loss: 0.000000\n",
      " Loss: 0.025229\n",
      " Loss: 0.000000\n",
      " Loss: 0.028873\n",
      " Loss: 0.000000\n",
      " Loss: 0.097703\n",
      " Loss: 0.000000\n",
      " Loss: 0.030106\n",
      " Loss: 0.000001\n",
      " Loss: 0.032034\n",
      " Loss: 0.000000\n",
      " Loss: 0.025977\n",
      " Loss: 0.000000\n",
      " Loss: 0.019716\n",
      "Epoch 1074 Chain 0 loss std 1.46e-03 variance 1.06e-06 smooth variance 1.18e-06 adaptive c -1.00\n",
      "Epoch 1074 Chain 1 loss std 2.40e+02 variance 2.88e+04 smooth variance 3.40e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.054462\n",
      " Loss: 0.000000\n",
      " Loss: 0.022591\n",
      " Loss: 0.000000\n",
      " Loss: 0.026859\n",
      " Loss: 0.000000\n",
      " Loss: 0.070690\n",
      " Loss: 0.000000\n",
      " Loss: 0.030852\n",
      " Loss: 0.000000\n",
      " Loss: 0.031313\n",
      " Loss: 0.000000\n",
      " Loss: 0.027190\n",
      " Loss: 0.000000\n",
      " Loss: 0.036701\n",
      " Loss: 0.000001\n",
      " Loss: 0.076465\n",
      " Loss: 0.000000\n",
      " Loss: 0.033374\n",
      "Epoch 1076 Chain 0 loss std 1.39e-03 variance 9.66e-07 smooth variance 1.12e-06 adaptive c -1.00\n",
      "Epoch 1076 Chain 1 loss std 2.21e+02 variance 2.43e+04 smooth variance 3.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.039673\n",
      " Loss: 0.000000\n",
      " Loss: 0.041785\n",
      " Loss: 0.000000\n",
      " Loss: 0.071126\n",
      " Loss: 0.000001\n",
      " Loss: 0.019824\n",
      " Loss: 0.000000\n",
      " Loss: 0.032411\n",
      " Loss: 0.000000\n",
      " Loss: 0.039659\n",
      " Loss: 0.000000\n",
      " Loss: 0.023309\n",
      " Loss: 0.000001\n",
      " Loss: 0.067157\n",
      " Loss: 0.000000\n",
      " Loss: 0.018259\n",
      " Loss: 0.000000\n",
      " Loss: 0.056123\n",
      "Epoch 1078 Chain 0 loss std 1.10e-03 variance 6.05e-07 smooth variance 9.62e-07 adaptive c -1.00\n",
      "Epoch 1078 Chain 1 loss std 2.26e+02 variance 2.56e+04 smooth variance 2.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033889\n",
      " Loss: 0.000001\n",
      " Loss: 0.022732\n",
      " Loss: 0.000000\n",
      " Loss: 0.014579\n",
      " Loss: 0.000000\n",
      " Loss: 0.078851\n",
      " Loss: 0.000000\n",
      " Loss: 0.054117\n",
      " Loss: 0.000001\n",
      " Loss: 0.024065\n",
      " Loss: 0.000000\n",
      " Loss: 0.023975\n",
      " Loss: 0.000000\n",
      " Loss: 0.045086\n",
      " Loss: 0.000000\n",
      " Loss: 0.083343\n",
      " Loss: 0.000000\n",
      " Loss: 0.027517\n",
      "Epoch 1080 Chain 0 loss std 1.98e-03 variance 1.96e-06 smooth variance 1.26e-06 adaptive c -1.00\n",
      "Epoch 1080 Chain 1 loss std 2.37e+02 variance 2.81e+04 smooth variance 2.90e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015976\n",
      " Loss: 0.000000\n",
      " Loss: 0.073304\n",
      " Loss: 0.000000\n",
      " Loss: 0.025041\n",
      " Loss: 0.000000\n",
      " Loss: 0.050308\n",
      " Loss: 0.000000\n",
      " Loss: 0.039058\n",
      " Loss: 0.000000\n",
      " Loss: 0.029427\n",
      " Loss: 0.000000\n",
      " Loss: 0.084349\n",
      " Loss: 0.000000\n",
      " Loss: 0.042966\n",
      " Loss: 0.000000\n",
      " Loss: 0.017603\n",
      " Loss: 0.000000\n",
      " Loss: 0.029008\n",
      "Epoch 1082 Chain 0 loss std 1.42e-03 variance 1.01e-06 smooth variance 1.18e-06 adaptive c -1.00\n",
      "Epoch 1082 Chain 1 loss std 2.57e+02 variance 3.31e+04 smooth variance 3.02e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023389\n",
      " Loss: 0.000000\n",
      " Loss: 0.077626\n",
      " Loss: 0.000000\n",
      " Loss: 0.028444\n",
      " Loss: 0.000000\n",
      " Loss: 0.036260\n",
      " Loss: 0.000000\n",
      " Loss: 0.037466\n",
      " Loss: 0.000000\n",
      " Loss: 0.045684\n",
      " Loss: 0.000001\n",
      " Loss: 0.079871\n",
      " Loss: 0.000000\n",
      " Loss: 0.036800\n",
      " Loss: 0.000000\n",
      " Loss: 0.022426\n",
      " Loss: 0.000000\n",
      " Loss: 0.018086\n",
      "Epoch 1084 Chain 0 loss std 1.79e-03 variance 1.61e-06 smooth variance 1.31e-06 adaptive c -1.00\n",
      "Epoch 1084 Chain 1 loss std 3.33e+02 variance 5.53e+04 smooth variance 3.78e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.052376\n",
      " Loss: 0.000000\n",
      " Loss: 0.027994\n",
      " Loss: 0.000000\n",
      " Loss: 0.068276\n",
      " Loss: 0.000000\n",
      " Loss: 0.032760\n",
      " Loss: 0.000000\n",
      " Loss: 0.021439\n",
      " Loss: 0.000000\n",
      " Loss: 0.020325\n",
      " Loss: 0.000000\n",
      " Loss: 0.067703\n",
      " Loss: 0.000000\n",
      " Loss: 0.047384\n",
      " Loss: 0.000000\n",
      " Loss: 0.029391\n",
      " Loss: 0.000000\n",
      " Loss: 0.037442\n",
      "Epoch 1086 Chain 0 loss std 2.59e-03 variance 3.36e-06 smooth variance 1.93e-06 adaptive c -1.00\n",
      "Epoch 1086 Chain 1 loss std 2.06e+02 variance 2.12e+04 smooth variance 3.28e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019322\n",
      " Loss: 0.000000\n",
      " Loss: 0.079328\n",
      " Loss: 0.000000\n",
      " Loss: 0.023510\n",
      " Loss: 0.000000\n",
      " Loss: 0.032793\n",
      " Loss: 0.000000\n",
      " Loss: 0.047433\n",
      " Loss: 0.000001\n",
      " Loss: 0.014078\n",
      " Loss: 0.000000\n",
      " Loss: 0.024289\n",
      " Loss: 0.000000\n",
      " Loss: 0.025647\n",
      " Loss: 0.000000\n",
      " Loss: 0.108998\n",
      " Loss: 0.000000\n",
      " Loss: 0.028542\n",
      "Epoch 1088 Chain 0 loss std 1.29e-03 variance 8.26e-07 smooth variance 1.60e-06 adaptive c -1.00\n",
      "Epoch 1088 Chain 1 loss std 2.72e+02 variance 3.69e+04 smooth variance 3.40e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026653\n",
      " Loss: 0.000000\n",
      " Loss: 0.046089\n",
      " Loss: 0.000000\n",
      " Loss: 0.031342\n",
      " Loss: 0.000000\n",
      " Loss: 0.075652\n",
      " Loss: 0.000000\n",
      " Loss: 0.021732\n",
      " Loss: 0.000000\n",
      " Loss: 0.023739\n",
      " Loss: 0.000000\n",
      " Loss: 0.031883\n",
      " Loss: 0.000000\n",
      " Loss: 0.031255\n",
      " Loss: 0.000000\n",
      " Loss: 0.089750\n",
      " Loss: 0.000000\n",
      " Loss: 0.024399\n",
      "Epoch 1090 Chain 0 loss std 1.11e-03 variance 6.14e-07 smooth variance 1.30e-06 adaptive c -1.00\n",
      "Epoch 1090 Chain 1 loss std 2.24e+02 variance 2.51e+04 smooth variance 3.13e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029018\n",
      " Loss: 0.000000\n",
      " Loss: 0.080254\n",
      " Loss: 0.000000\n",
      " Loss: 0.041108\n",
      " Loss: 0.000000\n",
      " Loss: 0.015915\n",
      " Loss: 0.000000\n",
      " Loss: 0.034564\n",
      " Loss: 0.000000\n",
      " Loss: 0.017785\n",
      " Loss: 0.000000\n",
      " Loss: 0.022765\n",
      " Loss: 0.000000\n",
      " Loss: 0.038165\n",
      " Loss: 0.000000\n",
      " Loss: 0.092354\n",
      " Loss: 0.000000\n",
      " Loss: 0.029409\n",
      "Epoch 1092 Chain 0 loss std 1.72e-03 variance 1.47e-06 smooth variance 1.35e-06 adaptive c -1.00\n",
      "Epoch 1092 Chain 1 loss std 1.88e+02 variance 1.77e+04 smooth variance 2.72e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.057226\n",
      " Loss: 0.000000\n",
      " Loss: 0.077455\n",
      " Loss: 0.000000\n",
      " Loss: 0.023863\n",
      " Loss: 0.000000\n",
      " Loss: 0.022730\n",
      " Loss: 0.000000\n",
      " Loss: 0.018955\n",
      " Loss: 0.000000\n",
      " Loss: 0.026111\n",
      " Loss: 0.000000\n",
      " Loss: 0.023307\n",
      " Loss: 0.000000\n",
      " Loss: 0.073682\n",
      " Loss: 0.000000\n",
      " Loss: 0.045438\n",
      " Loss: 0.000000\n",
      " Loss: 0.031418\n",
      "Epoch 1094 Chain 0 loss std 1.74e-03 variance 1.52e-06 smooth variance 1.40e-06 adaptive c -1.00\n",
      "Epoch 1094 Chain 1 loss std 2.37e+02 variance 2.81e+04 smooth variance 2.75e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027355\n",
      " Loss: 0.000000\n",
      " Loss: 0.025994\n",
      " Loss: 0.000000\n",
      " Loss: 0.095131\n",
      " Loss: 0.000000\n",
      " Loss: 0.025330\n",
      " Loss: 0.000000\n",
      " Loss: 0.025848\n",
      " Loss: 0.000000\n",
      " Loss: 0.062451\n",
      " Loss: 0.000001\n",
      " Loss: 0.024976\n",
      " Loss: 0.000000\n",
      " Loss: 0.018553\n",
      " Loss: 0.000000\n",
      " Loss: 0.023695\n",
      " Loss: 0.000000\n",
      " Loss: 0.069907\n",
      "Epoch 1096 Chain 0 loss std 1.10e-03 variance 6.03e-07 smooth variance 1.16e-06 adaptive c -1.00\n",
      "Epoch 1096 Chain 1 loss std 2.83e+02 variance 4.01e+04 smooth variance 3.13e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.038545\n",
      " Loss: 0.000000\n",
      " Loss: 0.076556\n",
      " Loss: 0.000000\n",
      " Loss: 0.024431\n",
      " Loss: 0.000001\n",
      " Loss: 0.038696\n",
      " Loss: 0.000000\n",
      " Loss: 0.021234\n",
      " Loss: 0.000000\n",
      " Loss: 0.057152\n",
      " Loss: 0.000000\n",
      " Loss: 0.015982\n",
      " Loss: 0.000001\n",
      " Loss: 0.014286\n",
      " Loss: 0.000000\n",
      " Loss: 0.029974\n",
      " Loss: 0.000000\n",
      " Loss: 0.081646\n",
      "Epoch 1098 Chain 0 loss std 1.37e-03 variance 9.35e-07 smooth variance 1.09e-06 adaptive c -1.00\n",
      "Epoch 1098 Chain 1 loss std 2.22e+02 variance 2.47e+04 smooth variance 2.93e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.073829\n",
      " Loss: 0.000000\n",
      " Loss: 0.020126\n",
      " Loss: 0.000000\n",
      " Loss: 0.038320\n",
      " Loss: 0.000000\n",
      " Loss: 0.032381\n",
      " Loss: 0.000000\n",
      " Loss: 0.034064\n",
      " Loss: 0.000000\n",
      " Loss: 0.029112\n",
      " Loss: 0.000000\n",
      " Loss: 0.081089\n",
      " Loss: 0.000000\n",
      " Loss: 0.028272\n",
      " Loss: 0.000000\n",
      " Loss: 0.027164\n",
      " Loss: 0.000000\n",
      " Loss: 0.032663\n",
      "Epoch 1100 Chain 0 loss std 1.36e-03 variance 9.21e-07 smooth variance 1.04e-06 adaptive c -1.00\n",
      "Epoch 1100 Chain 1 loss std 2.10e+02 variance 2.21e+04 smooth variance 2.72e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025252\n",
      " Loss: 0.000000\n",
      " Loss: 0.048436\n",
      " Loss: 0.000000\n",
      " Loss: 0.027192\n",
      " Loss: 0.000000\n",
      " Loss: 0.014247\n",
      " Loss: 0.000000\n",
      " Loss: 0.083219\n",
      " Loss: 0.000000\n",
      " Loss: 0.027177\n",
      " Loss: 0.000000\n",
      " Loss: 0.021281\n",
      " Loss: 0.000000\n",
      " Loss: 0.040854\n",
      " Loss: 0.000000\n",
      " Loss: 0.078197\n",
      " Loss: 0.000000\n",
      " Loss: 0.030303\n",
      "Epoch 1102 Chain 0 loss std 1.21e-03 variance 7.35e-07 smooth variance 9.50e-07 adaptive c -1.00\n",
      "Epoch 1102 Chain 1 loss std 2.00e+02 variance 2.00e+04 smooth variance 2.50e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035071\n",
      " Loss: 0.000000\n",
      " Loss: 0.025940\n",
      " Loss: 0.000000\n",
      " Loss: 0.070744\n",
      " Loss: 0.000000\n",
      " Loss: 0.033682\n",
      " Loss: 0.000000\n",
      " Loss: 0.032102\n",
      " Loss: 0.000000\n",
      " Loss: 0.033195\n",
      " Loss: 0.000000\n",
      " Loss: 0.025536\n",
      " Loss: 0.000000\n",
      " Loss: 0.076543\n",
      " Loss: 0.000000\n",
      " Loss: 0.016241\n",
      " Loss: 0.000000\n",
      " Loss: 0.046084\n",
      "Epoch 1104 Chain 0 loss std 1.47e-03 variance 1.08e-06 smooth variance 9.89e-07 adaptive c -1.00\n",
      "Epoch 1104 Chain 1 loss std 2.73e+02 variance 3.73e+04 smooth variance 2.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028283\n",
      " Loss: 0.000000\n",
      " Loss: 0.030107\n",
      " Loss: 0.000000\n",
      " Loss: 0.031836\n",
      " Loss: 0.000001\n",
      " Loss: 0.076690\n",
      " Loss: 0.000000\n",
      " Loss: 0.030068\n",
      " Loss: 0.000000\n",
      " Loss: 0.046955\n",
      " Loss: 0.000000\n",
      " Loss: 0.022448\n",
      " Loss: 0.000000\n",
      " Loss: 0.086643\n",
      " Loss: 0.000000\n",
      " Loss: 0.023760\n",
      " Loss: 0.000000\n",
      " Loss: 0.016961\n",
      "Epoch 1106 Chain 0 loss std 8.69e-04 variance 3.77e-07 smooth variance 8.06e-07 adaptive c -1.00\n",
      "Epoch 1106 Chain 1 loss std 2.33e+02 variance 2.72e+04 smooth variance 2.82e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025177\n",
      " Loss: 0.000000\n",
      " Loss: 0.049550\n",
      " Loss: 0.000000\n",
      " Loss: 0.018624\n",
      " Loss: 0.000000\n",
      " Loss: 0.074056\n",
      " Loss: 0.000000\n",
      " Loss: 0.029048\n",
      " Loss: 0.000000\n",
      " Loss: 0.044647\n",
      " Loss: 0.000000\n",
      " Loss: 0.070814\n",
      " Loss: 0.000000\n",
      " Loss: 0.022350\n",
      " Loss: 0.000000\n",
      " Loss: 0.044069\n",
      " Loss: 0.000000\n",
      " Loss: 0.014279\n",
      "Epoch 1108 Chain 0 loss std 1.89e-03 variance 1.79e-06 smooth variance 1.10e-06 adaptive c -1.00\n",
      "Epoch 1108 Chain 1 loss std 1.85e+02 variance 1.72e+04 smooth variance 2.49e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015033\n",
      " Loss: 0.000000\n",
      " Loss: 0.043268\n",
      " Loss: 0.000000\n",
      " Loss: 0.070109\n",
      " Loss: 0.000000\n",
      " Loss: 0.037043\n",
      " Loss: 0.000000\n",
      " Loss: 0.030420\n",
      " Loss: 0.000000\n",
      " Loss: 0.022035\n",
      " Loss: 0.000000\n",
      " Loss: 0.034219\n",
      " Loss: 0.000000\n",
      " Loss: 0.014747\n",
      " Loss: 0.000000\n",
      " Loss: 0.087242\n",
      " Loss: 0.000000\n",
      " Loss: 0.037482\n",
      "Epoch 1110 Chain 0 loss std 1.18e-03 variance 6.94e-07 smooth variance 9.79e-07 adaptive c -1.00\n",
      "Epoch 1110 Chain 1 loss std 2.41e+02 variance 2.91e+04 smooth variance 2.62e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032946\n",
      " Loss: 0.000000\n",
      " Loss: 0.020115\n",
      " Loss: 0.000000\n",
      " Loss: 0.024614\n",
      " Loss: 0.000000\n",
      " Loss: 0.077599\n",
      " Loss: 0.000000\n",
      " Loss: 0.040112\n",
      " Loss: 0.000000\n",
      " Loss: 0.032866\n",
      " Loss: 0.000000\n",
      " Loss: 0.039250\n",
      " Loss: 0.000000\n",
      " Loss: 0.023999\n",
      " Loss: 0.000000\n",
      " Loss: 0.028024\n",
      " Loss: 0.000000\n",
      " Loss: 0.071182\n",
      "Epoch 1112 Chain 0 loss std 1.54e-03 variance 1.19e-06 smooth variance 1.04e-06 adaptive c -1.00\n",
      "Epoch 1112 Chain 1 loss std 1.90e+02 variance 1.81e+04 smooth variance 2.38e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019960\n",
      " Loss: 0.000000\n",
      " Loss: 0.036975\n",
      " Loss: 0.000000\n",
      " Loss: 0.024869\n",
      " Loss: 0.000000\n",
      " Loss: 0.044243\n",
      " Loss: 0.000000\n",
      " Loss: 0.068887\n",
      " Loss: 0.000000\n",
      " Loss: 0.083132\n",
      " Loss: 0.000000\n",
      " Loss: 0.015765\n",
      " Loss: 0.000000\n",
      " Loss: 0.031086\n",
      " Loss: 0.000000\n",
      " Loss: 0.032958\n",
      " Loss: 0.000000\n",
      " Loss: 0.031731\n",
      "Epoch 1114 Chain 0 loss std 1.00e-03 variance 5.05e-07 smooth variance 8.80e-07 adaptive c -1.00\n",
      "Epoch 1114 Chain 1 loss std 2.21e+02 variance 2.44e+04 smooth variance 2.40e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.039442\n",
      " Loss: 0.000000\n",
      " Loss: 0.018615\n",
      " Loss: 0.000000\n",
      " Loss: 0.021522\n",
      " Loss: 0.000000\n",
      " Loss: 0.065748\n",
      " Loss: 0.000000\n",
      " Loss: 0.049140\n",
      " Loss: 0.000000\n",
      " Loss: 0.027203\n",
      " Loss: 0.000000\n",
      " Loss: 0.024365\n",
      " Loss: 0.000000\n",
      " Loss: 0.016970\n",
      " Loss: 0.000000\n",
      " Loss: 0.019413\n",
      " Loss: 0.000000\n",
      " Loss: 0.106192\n",
      "Epoch 1116 Chain 0 loss std 1.46e-03 variance 1.07e-06 smooth variance 9.36e-07 adaptive c -1.00\n",
      "Epoch 1116 Chain 1 loss std 2.20e+02 variance 2.43e+04 smooth variance 2.41e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028972\n",
      " Loss: 0.000000\n",
      " Loss: 0.085575\n",
      " Loss: 0.000000\n",
      " Loss: 0.027993\n",
      " Loss: 0.000000\n",
      " Loss: 0.035754\n",
      " Loss: 0.000000\n",
      " Loss: 0.015496\n",
      " Loss: 0.000000\n",
      " Loss: 0.035656\n",
      " Loss: 0.000000\n",
      " Loss: 0.036188\n",
      " Loss: 0.000000\n",
      " Loss: 0.081503\n",
      " Loss: 0.000000\n",
      " Loss: 0.017088\n",
      " Loss: 0.000000\n",
      " Loss: 0.023085\n",
      "Epoch 1118 Chain 0 loss std 1.25e-03 variance 7.85e-07 smooth variance 8.90e-07 adaptive c -1.00\n",
      "Epoch 1118 Chain 1 loss std 1.89e+02 variance 1.79e+04 smooth variance 2.22e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028620\n",
      " Loss: 0.000000\n",
      " Loss: 0.025689\n",
      " Loss: 0.000000\n",
      " Loss: 0.068698\n",
      " Loss: 0.000000\n",
      " Loss: 0.027049\n",
      " Loss: 0.000000\n",
      " Loss: 0.043281\n",
      " Loss: 0.000000\n",
      " Loss: 0.026747\n",
      " Loss: 0.000000\n",
      " Loss: 0.027320\n",
      " Loss: 0.000000\n",
      " Loss: 0.077570\n",
      " Loss: 0.000000\n",
      " Loss: 0.038312\n",
      " Loss: 0.000000\n",
      " Loss: 0.023055\n",
      "Epoch 1120 Chain 0 loss std 1.70e-03 variance 1.44e-06 smooth variance 1.06e-06 adaptive c -1.00\n",
      "Epoch 1120 Chain 1 loss std 2.44e+02 variance 2.98e+04 smooth variance 2.45e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023698\n",
      " Loss: 0.000000\n",
      " Loss: 0.067603\n",
      " Loss: 0.000000\n",
      " Loss: 0.030258\n",
      " Loss: 0.000000\n",
      " Loss: 0.047623\n",
      " Loss: 0.000000\n",
      " Loss: 0.023561\n",
      " Loss: 0.000000\n",
      " Loss: 0.050614\n",
      " Loss: 0.000000\n",
      " Loss: 0.018114\n",
      " Loss: 0.000000\n",
      " Loss: 0.067810\n",
      " Loss: 0.000000\n",
      " Loss: 0.028230\n",
      " Loss: 0.000000\n",
      " Loss: 0.027800\n",
      "Epoch 1122 Chain 0 loss std 8.59e-04 variance 3.69e-07 smooth variance 8.50e-07 adaptive c -1.00\n",
      "Epoch 1122 Chain 1 loss std 2.10e+02 variance 2.20e+04 smooth variance 2.38e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.042014\n",
      " Loss: 0.000000\n",
      " Loss: 0.035920\n",
      " Loss: 0.000000\n",
      " Loss: 0.066061\n",
      " Loss: 0.000000\n",
      " Loss: 0.025018\n",
      " Loss: 0.000000\n",
      " Loss: 0.023577\n",
      " Loss: 0.000000\n",
      " Loss: 0.033994\n",
      " Loss: 0.000000\n",
      " Loss: 0.023617\n",
      " Loss: 0.000000\n",
      " Loss: 0.015739\n",
      " Loss: 0.000000\n",
      " Loss: 0.050888\n",
      " Loss: 0.000001\n",
      " Loss: 0.067767\n",
      "Epoch 1124 Chain 0 loss std 1.08e-03 variance 5.87e-07 smooth variance 7.71e-07 adaptive c -1.00\n",
      "Epoch 1124 Chain 1 loss std 2.17e+02 variance 2.34e+04 smooth variance 2.37e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.034104\n",
      " Loss: 0.000000\n",
      " Loss: 0.071794\n",
      " Loss: 0.000000\n",
      " Loss: 0.043314\n",
      " Loss: 0.000000\n",
      " Loss: 0.024951\n",
      " Loss: 0.000000\n",
      " Loss: 0.017526\n",
      " Loss: 0.000000\n",
      " Loss: 0.028609\n",
      " Loss: 0.000000\n",
      " Loss: 0.032495\n",
      " Loss: 0.000000\n",
      " Loss: 0.076816\n",
      " Loss: 0.000000\n",
      " Loss: 0.030746\n",
      " Loss: 0.000000\n",
      " Loss: 0.022804\n",
      "Epoch 1126 Chain 0 loss std 1.27e-03 variance 8.04e-07 smooth variance 7.81e-07 adaptive c -1.00\n",
      "Epoch 1126 Chain 1 loss std 2.12e+02 variance 2.25e+04 smooth variance 2.33e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017223\n",
      " Loss: 0.000000\n",
      " Loss: 0.034437\n",
      " Loss: 0.000000\n",
      " Loss: 0.088298\n",
      " Loss: 0.000000\n",
      " Loss: 0.025624\n",
      " Loss: 0.000000\n",
      " Loss: 0.025562\n",
      " Loss: 0.000000\n",
      " Loss: 0.033550\n",
      " Loss: 0.000000\n",
      " Loss: 0.023648\n",
      " Loss: 0.000000\n",
      " Loss: 0.074277\n",
      " Loss: 0.000000\n",
      " Loss: 0.045393\n",
      " Loss: 0.000000\n",
      " Loss: 0.014175\n",
      "Epoch 1128 Chain 0 loss std 1.59e-03 variance 1.27e-06 smooth variance 9.28e-07 adaptive c -1.00\n",
      "Epoch 1128 Chain 1 loss std 2.63e+02 variance 3.45e+04 smooth variance 2.67e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.052833\n",
      " Loss: 0.000000\n",
      " Loss: 0.069275\n",
      " Loss: 0.000000\n",
      " Loss: 0.014911\n",
      " Loss: 0.000000\n",
      " Loss: 0.028885\n",
      " Loss: 0.000000\n",
      " Loss: 0.024764\n",
      " Loss: 0.000000\n",
      " Loss: 0.018287\n",
      " Loss: 0.000000\n",
      " Loss: 0.089209\n",
      " Loss: 0.000000\n",
      " Loss: 0.028946\n",
      " Loss: 0.000000\n",
      " Loss: 0.024797\n",
      " Loss: 0.000000\n",
      " Loss: 0.029097\n",
      "Epoch 1130 Chain 0 loss std 1.61e-03 variance 1.30e-06 smooth variance 1.04e-06 adaptive c -1.00\n",
      "Epoch 1130 Chain 1 loss std 2.22e+02 variance 2.46e+04 smooth variance 2.61e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028695\n",
      " Loss: 0.000000\n",
      " Loss: 0.031362\n",
      " Loss: 0.000000\n",
      " Loss: 0.061243\n",
      " Loss: 0.000000\n",
      " Loss: 0.017454\n",
      " Loss: 0.000000\n",
      " Loss: 0.051535\n",
      " Loss: 0.000000\n",
      " Loss: 0.028673\n",
      " Loss: 0.000000\n",
      " Loss: 0.095649\n",
      " Loss: 0.000000\n",
      " Loss: 0.027499\n",
      " Loss: 0.000000\n",
      " Loss: 0.019339\n",
      " Loss: 0.000000\n",
      " Loss: 0.018743\n",
      "Epoch 1132 Chain 0 loss std 1.24e-03 variance 7.70e-07 smooth variance 9.58e-07 adaptive c -1.00\n",
      "Epoch 1132 Chain 1 loss std 2.73e+02 variance 3.73e+04 smooth variance 2.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.070453\n",
      " Loss: 0.000000\n",
      " Loss: 0.021144\n",
      " Loss: 0.000000\n",
      " Loss: 0.016778\n",
      " Loss: 0.000000\n",
      " Loss: 0.025436\n",
      " Loss: 0.000000\n",
      " Loss: 0.055990\n",
      " Loss: 0.000000\n",
      " Loss: 0.016198\n",
      " Loss: 0.000000\n",
      " Loss: 0.039516\n",
      " Loss: 0.000000\n",
      " Loss: 0.020665\n",
      " Loss: 0.000000\n",
      " Loss: 0.026449\n",
      " Loss: 0.000000\n",
      " Loss: 0.086929\n",
      "Epoch 1134 Chain 0 loss std 9.30e-04 variance 4.32e-07 smooth variance 8.00e-07 adaptive c -1.00\n",
      "Epoch 1134 Chain 1 loss std 1.91e+02 variance 1.83e+04 smooth variance 2.61e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025233\n",
      " Loss: 0.000000\n",
      " Loss: 0.021950\n",
      " Loss: 0.000000\n",
      " Loss: 0.024443\n",
      " Loss: 0.000000\n",
      " Loss: 0.047085\n",
      " Loss: 0.000000\n",
      " Loss: 0.070549\n",
      " Loss: 0.000000\n",
      " Loss: 0.063662\n",
      " Loss: 0.000000\n",
      " Loss: 0.044449\n",
      " Loss: 0.000000\n",
      " Loss: 0.029657\n",
      " Loss: 0.000000\n",
      " Loss: 0.024492\n",
      " Loss: 0.000000\n",
      " Loss: 0.026832\n",
      "Epoch 1136 Chain 0 loss std 1.39e-03 variance 9.71e-07 smooth variance 8.51e-07 adaptive c -1.00\n",
      "Epoch 1136 Chain 1 loss std 1.79e+02 variance 1.60e+04 smooth variance 2.31e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.031886\n",
      " Loss: 0.000000\n",
      " Loss: 0.013104\n",
      " Loss: 0.000000\n",
      " Loss: 0.082381\n",
      " Loss: 0.000000\n",
      " Loss: 0.034774\n",
      " Loss: 0.000000\n",
      " Loss: 0.026595\n",
      " Loss: 0.000000\n",
      " Loss: 0.026540\n",
      " Loss: 0.000000\n",
      " Loss: 0.017469\n",
      " Loss: 0.000000\n",
      " Loss: 0.033992\n",
      " Loss: 0.000000\n",
      " Loss: 0.025167\n",
      " Loss: 0.000000\n",
      " Loss: 0.085242\n",
      "Epoch 1138 Chain 0 loss std 1.26e-03 variance 7.90e-07 smooth variance 8.33e-07 adaptive c -1.00\n",
      "Epoch 1138 Chain 1 loss std 2.04e+02 variance 2.08e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.041489\n",
      " Loss: 0.000000\n",
      " Loss: 0.045459\n",
      " Loss: 0.000000\n",
      " Loss: 0.018579\n",
      " Loss: 0.000000\n",
      " Loss: 0.018359\n",
      " Loss: 0.000000\n",
      " Loss: 0.064499\n",
      " Loss: 0.000000\n",
      " Loss: 0.015485\n",
      " Loss: 0.000000\n",
      " Loss: 0.085942\n",
      " Loss: 0.000000\n",
      " Loss: 0.023740\n",
      " Loss: 0.000000\n",
      " Loss: 0.031161\n",
      " Loss: 0.000000\n",
      " Loss: 0.032020\n",
      "Epoch 1140 Chain 0 loss std 1.60e-03 variance 1.29e-06 smooth variance 9.69e-07 adaptive c -1.00\n",
      "Epoch 1140 Chain 1 loss std 2.96e+02 variance 4.38e+04 smooth variance 2.88e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.086874\n",
      " Loss: 0.000000\n",
      " Loss: 0.030083\n",
      " Loss: 0.000000\n",
      " Loss: 0.016911\n",
      " Loss: 0.000000\n",
      " Loss: 0.034290\n",
      " Loss: 0.000000\n",
      " Loss: 0.019543\n",
      " Loss: 0.000000\n",
      " Loss: 0.016491\n",
      " Loss: 0.000000\n",
      " Loss: 0.031182\n",
      " Loss: 0.000000\n",
      " Loss: 0.029959\n",
      " Loss: 0.000000\n",
      " Loss: 0.085023\n",
      " Loss: 0.000000\n",
      " Loss: 0.024786\n",
      "Epoch 1142 Chain 0 loss std 8.89e-04 variance 3.95e-07 smooth variance 7.97e-07 adaptive c -1.00\n",
      "Epoch 1142 Chain 1 loss std 1.84e+02 variance 1.69e+04 smooth variance 2.52e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.044312\n",
      " Loss: 0.000000\n",
      " Loss: 0.034489\n",
      " Loss: 0.000000\n",
      " Loss: 0.070342\n",
      " Loss: 0.000000\n",
      " Loss: 0.021968\n",
      " Loss: 0.000000\n",
      " Loss: 0.016268\n",
      " Loss: 0.000000\n",
      " Loss: 0.022258\n",
      " Loss: 0.000000\n",
      " Loss: 0.017928\n",
      " Loss: 0.000000\n",
      " Loss: 0.037593\n",
      " Loss: 0.000000\n",
      " Loss: 0.087448\n",
      " Loss: 0.000000\n",
      " Loss: 0.021698\n",
      "Epoch 1144 Chain 0 loss std 1.18e-03 variance 6.95e-07 smooth variance 7.66e-07 adaptive c -1.00\n",
      "Epoch 1144 Chain 1 loss std 1.50e+02 variance 1.12e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.043653\n",
      " Loss: 0.000000\n",
      " Loss: 0.072750\n",
      " Loss: 0.000000\n",
      " Loss: 0.024284\n",
      " Loss: 0.000000\n",
      " Loss: 0.024995\n",
      " Loss: 0.000000\n",
      " Loss: 0.021136\n",
      " Loss: 0.000000\n",
      " Loss: 0.062374\n",
      " Loss: 0.000000\n",
      " Loss: 0.032653\n",
      " Loss: 0.000000\n",
      " Loss: 0.030188\n",
      " Loss: 0.000000\n",
      " Loss: 0.022420\n",
      " Loss: 0.000000\n",
      " Loss: 0.039058\n",
      "Epoch 1146 Chain 0 loss std 1.14e-03 variance 6.53e-07 smooth variance 7.32e-07 adaptive c -1.00\n",
      "Epoch 1146 Chain 1 loss std 1.99e+02 variance 1.98e+04 smooth variance 2.07e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.068180\n",
      " Loss: 0.000000\n",
      " Loss: 0.039270\n",
      " Loss: 0.000000\n",
      " Loss: 0.023574\n",
      " Loss: 0.000000\n",
      " Loss: 0.029590\n",
      " Loss: 0.000000\n",
      " Loss: 0.025667\n",
      " Loss: 0.000000\n",
      " Loss: 0.073677\n",
      " Loss: 0.000000\n",
      " Loss: 0.029307\n",
      " Loss: 0.000000\n",
      " Loss: 0.017477\n",
      " Loss: 0.000000\n",
      " Loss: 0.042696\n",
      " Loss: 0.000000\n",
      " Loss: 0.023063\n",
      "Epoch 1148 Chain 0 loss std 7.80e-04 variance 3.05e-07 smooth variance 6.04e-07 adaptive c -1.00\n",
      "Epoch 1148 Chain 1 loss std 1.89e+02 variance 1.79e+04 smooth variance 1.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.073361\n",
      " Loss: 0.000000\n",
      " Loss: 0.044265\n",
      " Loss: 0.000000\n",
      " Loss: 0.019025\n",
      " Loss: 0.000000\n",
      " Loss: 0.024636\n",
      " Loss: 0.000000\n",
      " Loss: 0.024587\n",
      " Loss: 0.000000\n",
      " Loss: 0.038894\n",
      " Loss: 0.000000\n",
      " Loss: 0.060424\n",
      " Loss: 0.000000\n",
      " Loss: 0.028484\n",
      " Loss: 0.000000\n",
      " Loss: 0.023875\n",
      " Loss: 0.000000\n",
      " Loss: 0.033940\n",
      "Epoch 1150 Chain 0 loss std 1.21e-03 variance 7.36e-07 smooth variance 6.44e-07 adaptive c -1.00\n",
      "Epoch 1150 Chain 1 loss std 2.43e+02 variance 2.95e+04 smooth variance 2.27e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.048045\n",
      " Loss: 0.000000\n",
      " Loss: 0.061953\n",
      " Loss: 0.000000\n",
      " Loss: 0.024074\n",
      " Loss: 0.000000\n",
      " Loss: 0.018374\n",
      " Loss: 0.000000\n",
      " Loss: 0.032871\n",
      " Loss: 0.000000\n",
      " Loss: 0.036461\n",
      " Loss: 0.000000\n",
      " Loss: 0.071870\n",
      " Loss: 0.000000\n",
      " Loss: 0.018140\n",
      " Loss: 0.000000\n",
      " Loss: 0.038534\n",
      " Loss: 0.000000\n",
      " Loss: 0.020095\n",
      "Epoch 1152 Chain 0 loss std 1.06e-03 variance 5.62e-07 smooth variance 6.19e-07 adaptive c -1.00\n",
      "Epoch 1152 Chain 1 loss std 2.80e+02 variance 3.91e+04 smooth variance 2.76e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032106\n",
      " Loss: 0.000000\n",
      " Loss: 0.024464\n",
      " Loss: 0.000000\n",
      " Loss: 0.076682\n",
      " Loss: 0.000000\n",
      " Loss: 0.022302\n",
      " Loss: 0.000000\n",
      " Loss: 0.029316\n",
      " Loss: 0.000000\n",
      " Loss: 0.080262\n",
      " Loss: 0.000000\n",
      " Loss: 0.038426\n",
      " Loss: 0.000000\n",
      " Loss: 0.025151\n",
      " Loss: 0.000000\n",
      " Loss: 0.019297\n",
      " Loss: 0.000000\n",
      " Loss: 0.021518\n",
      "Epoch 1154 Chain 0 loss std 9.91e-04 variance 4.91e-07 smooth variance 5.81e-07 adaptive c -1.00\n",
      "Epoch 1154 Chain 1 loss std 1.96e+02 variance 1.91e+04 smooth variance 2.51e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017191\n",
      " Loss: 0.000000\n",
      " Loss: 0.037145\n",
      " Loss: 0.000000\n",
      " Loss: 0.076459\n",
      " Loss: 0.000000\n",
      " Loss: 0.025003\n",
      " Loss: 0.000000\n",
      " Loss: 0.028583\n",
      " Loss: 0.000000\n",
      " Loss: 0.038786\n",
      " Loss: 0.000000\n",
      " Loss: 0.030900\n",
      " Loss: 0.000000\n",
      " Loss: 0.072433\n",
      " Loss: 0.000000\n",
      " Loss: 0.028492\n",
      " Loss: 0.000000\n",
      " Loss: 0.013711\n",
      "Epoch 1156 Chain 0 loss std 1.50e-03 variance 1.13e-06 smooth variance 7.45e-07 adaptive c -1.00\n",
      "Epoch 1156 Chain 1 loss std 2.98e+02 variance 4.43e+04 smooth variance 3.08e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025549\n",
      " Loss: 0.000000\n",
      " Loss: 0.076571\n",
      " Loss: 0.000000\n",
      " Loss: 0.036303\n",
      " Loss: 0.000000\n",
      " Loss: 0.025899\n",
      " Loss: 0.000000\n",
      " Loss: 0.019717\n",
      " Loss: 0.000000\n",
      " Loss: 0.019362\n",
      " Loss: 0.000000\n",
      " Loss: 0.051009\n",
      " Loss: 0.000000\n",
      " Loss: 0.021741\n",
      " Loss: 0.000000\n",
      " Loss: 0.023921\n",
      " Loss: 0.000000\n",
      " Loss: 0.067834\n",
      "Epoch 1158 Chain 0 loss std 1.08e-03 variance 5.84e-07 smooth variance 6.97e-07 adaptive c -1.00\n",
      "Epoch 1158 Chain 1 loss std 1.64e+02 variance 1.34e+04 smooth variance 2.56e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.045726\n",
      " Loss: 0.000000\n",
      " Loss: 0.022511\n",
      " Loss: 0.000000\n",
      " Loss: 0.018542\n",
      " Loss: 0.000000\n",
      " Loss: 0.067679\n",
      " Loss: 0.000000\n",
      " Loss: 0.029009\n",
      " Loss: 0.000000\n",
      " Loss: 0.028279\n",
      " Loss: 0.000000\n",
      " Loss: 0.035623\n",
      " Loss: 0.000000\n",
      " Loss: 0.031244\n",
      " Loss: 0.000000\n",
      " Loss: 0.069682\n",
      " Loss: 0.000000\n",
      " Loss: 0.018380\n",
      "Epoch 1160 Chain 0 loss std 1.45e-03 variance 1.05e-06 smooth variance 8.03e-07 adaptive c -1.00\n",
      "Epoch 1160 Chain 1 loss std 2.60e+02 variance 3.38e+04 smooth variance 2.81e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035023\n",
      " Loss: 0.000000\n",
      " Loss: 0.041409\n",
      " Loss: 0.000000\n",
      " Loss: 0.018001\n",
      " Loss: 0.000000\n",
      " Loss: 0.024577\n",
      " Loss: 0.000000\n",
      " Loss: 0.064081\n",
      " Loss: 0.000000\n",
      " Loss: 0.031550\n",
      " Loss: 0.000000\n",
      " Loss: 0.031580\n",
      " Loss: 0.000000\n",
      " Loss: 0.026461\n",
      " Loss: 0.000000\n",
      " Loss: 0.061015\n",
      " Loss: 0.000000\n",
      " Loss: 0.032323\n",
      "Epoch 1162 Chain 0 loss std 1.09e-03 variance 5.96e-07 smooth variance 7.41e-07 adaptive c -1.00\n",
      "Epoch 1162 Chain 1 loss std 2.30e+02 variance 2.65e+04 smooth variance 2.76e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.045753\n",
      " Loss: 0.000000\n",
      " Loss: 0.015691\n",
      " Loss: 0.000000\n",
      " Loss: 0.016227\n",
      " Loss: 0.000000\n",
      " Loss: 0.026437\n",
      " Loss: 0.000000\n",
      " Loss: 0.078511\n",
      " Loss: 0.000000\n",
      " Loss: 0.027176\n",
      " Loss: 0.000000\n",
      " Loss: 0.063998\n",
      " Loss: 0.000000\n",
      " Loss: 0.043360\n",
      " Loss: 0.000000\n",
      " Loss: 0.022076\n",
      " Loss: 0.000000\n",
      " Loss: 0.025757\n",
      "Epoch 1164 Chain 0 loss std 1.55e-03 variance 1.20e-06 smooth variance 8.79e-07 adaptive c -1.00\n",
      "Epoch 1164 Chain 1 loss std 2.05e+02 variance 2.11e+04 smooth variance 2.56e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.042537\n",
      " Loss: 0.000001\n",
      " Loss: 0.067933\n",
      " Loss: 0.000000\n",
      " Loss: 0.024156\n",
      " Loss: 0.000000\n",
      " Loss: 0.029694\n",
      " Loss: 0.000000\n",
      " Loss: 0.017766\n",
      " Loss: 0.000000\n",
      " Loss: 0.022163\n",
      " Loss: 0.000000\n",
      " Loss: 0.038312\n",
      " Loss: 0.000000\n",
      " Loss: 0.022918\n",
      " Loss: 0.000000\n",
      " Loss: 0.036660\n",
      " Loss: 0.000000\n",
      " Loss: 0.061991\n",
      "Epoch 1166 Chain 0 loss std 1.34e-03 variance 8.97e-07 smooth variance 8.84e-07 adaptive c -1.00\n",
      "Epoch 1166 Chain 1 loss std 2.25e+02 variance 2.53e+04 smooth variance 2.55e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.067003\n",
      " Loss: 0.000000\n",
      " Loss: 0.022590\n",
      " Loss: 0.000000\n",
      " Loss: 0.034596\n",
      " Loss: 0.000000\n",
      " Loss: 0.037385\n",
      " Loss: 0.000000\n",
      " Loss: 0.020105\n",
      " Loss: 0.000000\n",
      " Loss: 0.017966\n",
      " Loss: 0.000000\n",
      " Loss: 0.084024\n",
      " Loss: 0.000000\n",
      " Loss: 0.029528\n",
      " Loss: 0.000000\n",
      " Loss: 0.023142\n",
      " Loss: 0.000000\n",
      " Loss: 0.026757\n",
      "Epoch 1168 Chain 0 loss std 8.33e-04 variance 3.47e-07 smooth variance 7.23e-07 adaptive c -1.00\n",
      "Epoch 1168 Chain 1 loss std 2.90e+02 variance 4.20e+04 smooth variance 3.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019789\n",
      " Loss: 0.000000\n",
      " Loss: 0.019471\n",
      " Loss: 0.000000\n",
      " Loss: 0.091698\n",
      " Loss: 0.000000\n",
      " Loss: 0.020524\n",
      " Loss: 0.000000\n",
      " Loss: 0.029632\n",
      " Loss: 0.000000\n",
      " Loss: 0.032019\n",
      " Loss: 0.000000\n",
      " Loss: 0.024832\n",
      " Loss: 0.000000\n",
      " Loss: 0.022062\n",
      " Loss: 0.000000\n",
      " Loss: 0.086250\n",
      " Loss: 0.000000\n",
      " Loss: 0.015757\n",
      "Epoch 1170 Chain 0 loss std 1.42e-03 variance 1.01e-06 smooth variance 8.10e-07 adaptive c -1.00\n",
      "Epoch 1170 Chain 1 loss std 2.14e+02 variance 2.29e+04 smooth variance 2.82e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023438\n",
      " Loss: 0.000000\n",
      " Loss: 0.065051\n",
      " Loss: 0.000000\n",
      " Loss: 0.032027\n",
      " Loss: 0.000000\n",
      " Loss: 0.036877\n",
      " Loss: 0.000000\n",
      " Loss: 0.023499\n",
      " Loss: 0.000000\n",
      " Loss: 0.069706\n",
      " Loss: 0.000000\n",
      " Loss: 0.022135\n",
      " Loss: 0.000000\n",
      " Loss: 0.017951\n",
      " Loss: 0.000000\n",
      " Loss: 0.031590\n",
      " Loss: 0.000000\n",
      " Loss: 0.039166\n",
      "Epoch 1172 Chain 0 loss std 8.98e-04 variance 4.03e-07 smooth variance 6.88e-07 adaptive c -1.00\n",
      "Epoch 1172 Chain 1 loss std 1.88e+02 variance 1.76e+04 smooth variance 2.50e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024435\n",
      " Loss: 0.000000\n",
      " Loss: 0.017115\n",
      " Loss: 0.000000\n",
      " Loss: 0.043905\n",
      " Loss: 0.000000\n",
      " Loss: 0.017690\n",
      " Loss: 0.000000\n",
      " Loss: 0.077415\n",
      " Loss: 0.000000\n",
      " Loss: 0.036095\n",
      " Loss: 0.000000\n",
      " Loss: 0.081938\n",
      " Loss: 0.000000\n",
      " Loss: 0.019327\n",
      " Loss: 0.000000\n",
      " Loss: 0.023202\n",
      " Loss: 0.000000\n",
      " Loss: 0.019550\n",
      "Epoch 1174 Chain 0 loss std 1.36e-03 variance 9.21e-07 smooth variance 7.58e-07 adaptive c -1.00\n",
      "Epoch 1174 Chain 1 loss std 1.92e+02 variance 1.84e+04 smooth variance 2.30e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.071101\n",
      " Loss: 0.000000\n",
      " Loss: 0.019409\n",
      " Loss: 0.000000\n",
      " Loss: 0.021686\n",
      " Loss: 0.000000\n",
      " Loss: 0.037731\n",
      " Loss: 0.000000\n",
      " Loss: 0.030074\n",
      " Loss: 0.000000\n",
      " Loss: 0.065928\n",
      " Loss: 0.000000\n",
      " Loss: 0.033310\n",
      " Loss: 0.000000\n",
      " Loss: 0.036424\n",
      " Loss: 0.000000\n",
      " Loss: 0.021653\n",
      " Loss: 0.000000\n",
      " Loss: 0.022358\n",
      "Epoch 1176 Chain 0 loss std 1.41e-03 variance 9.99e-07 smooth variance 8.30e-07 adaptive c -1.00\n",
      "Epoch 1176 Chain 1 loss std 2.02e+02 variance 2.05e+04 smooth variance 2.23e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033510\n",
      " Loss: 0.000000\n",
      " Loss: 0.027936\n",
      " Loss: 0.000000\n",
      " Loss: 0.034149\n",
      " Loss: 0.000000\n",
      " Loss: 0.071287\n",
      " Loss: 0.000000\n",
      " Loss: 0.012508\n",
      " Loss: 0.000000\n",
      " Loss: 0.020342\n",
      " Loss: 0.000001\n",
      " Loss: 0.061786\n",
      " Loss: 0.000000\n",
      " Loss: 0.023419\n",
      " Loss: 0.000000\n",
      " Loss: 0.051200\n",
      " Loss: 0.000000\n",
      " Loss: 0.022470\n",
      "Epoch 1178 Chain 0 loss std 1.08e-03 variance 5.84e-07 smooth variance 7.56e-07 adaptive c -1.00\n",
      "Epoch 1178 Chain 1 loss std 2.29e+02 variance 2.62e+04 smooth variance 2.34e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061324\n",
      " Loss: 0.000000\n",
      " Loss: 0.024562\n",
      " Loss: 0.000000\n",
      " Loss: 0.014909\n",
      " Loss: 0.000000\n",
      " Loss: 0.049511\n",
      " Loss: 0.000000\n",
      " Loss: 0.028703\n",
      " Loss: 0.000000\n",
      " Loss: 0.024338\n",
      " Loss: 0.000000\n",
      " Loss: 0.031946\n",
      " Loss: 0.000000\n",
      " Loss: 0.085193\n",
      " Loss: 0.000000\n",
      " Loss: 0.015004\n",
      " Loss: 0.000000\n",
      " Loss: 0.022186\n",
      "Epoch 1180 Chain 0 loss std 1.63e-03 variance 1.33e-06 smooth variance 9.28e-07 adaptive c -1.00\n",
      "Epoch 1180 Chain 1 loss std 1.82e+02 variance 1.66e+04 smooth variance 2.14e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.074699\n",
      " Loss: 0.000000\n",
      " Loss: 0.025283\n",
      " Loss: 0.000000\n",
      " Loss: 0.038679\n",
      " Loss: 0.000000\n",
      " Loss: 0.017991\n",
      " Loss: 0.000000\n",
      " Loss: 0.021965\n",
      " Loss: 0.000001\n",
      " Loss: 0.060430\n",
      " Loss: 0.000000\n",
      " Loss: 0.042764\n",
      " Loss: 0.000000\n",
      " Loss: 0.030588\n",
      " Loss: 0.000000\n",
      " Loss: 0.018727\n",
      " Loss: 0.000000\n",
      " Loss: 0.025727\n",
      "Epoch 1182 Chain 0 loss std 7.82e-04 variance 3.06e-07 smooth variance 7.41e-07 adaptive c -1.00\n",
      "Epoch 1182 Chain 1 loss std 2.63e+02 variance 3.47e+04 smooth variance 2.54e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015460\n",
      " Loss: 0.000000\n",
      " Loss: 0.034424\n",
      " Loss: 0.000000\n",
      " Loss: 0.025283\n",
      " Loss: 0.000000\n",
      " Loss: 0.065957\n",
      " Loss: 0.000000\n",
      " Loss: 0.036886\n",
      " Loss: 0.000000\n",
      " Loss: 0.034361\n",
      " Loss: 0.000000\n",
      " Loss: 0.041116\n",
      " Loss: 0.000000\n",
      " Loss: 0.017463\n",
      " Loss: 0.000000\n",
      " Loss: 0.015017\n",
      " Loss: 0.000000\n",
      " Loss: 0.069936\n",
      "Epoch 1184 Chain 0 loss std 8.42e-04 variance 3.55e-07 smooth variance 6.25e-07 adaptive c -1.00\n",
      "Epoch 1184 Chain 1 loss std 1.87e+02 variance 1.76e+04 smooth variance 2.30e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.068105\n",
      " Loss: 0.000000\n",
      " Loss: 0.030884\n",
      " Loss: 0.000000\n",
      " Loss: 0.033316\n",
      " Loss: 0.000000\n",
      " Loss: 0.017802\n",
      " Loss: 0.000000\n",
      " Loss: 0.027732\n",
      " Loss: 0.000000\n",
      " Loss: 0.024562\n",
      " Loss: 0.000000\n",
      " Loss: 0.022235\n",
      " Loss: 0.000000\n",
      " Loss: 0.047078\n",
      " Loss: 0.000000\n",
      " Loss: 0.067583\n",
      " Loss: 0.000000\n",
      " Loss: 0.015951\n",
      "Epoch 1186 Chain 0 loss std 1.29e-03 variance 8.30e-07 smooth variance 6.87e-07 adaptive c -1.00\n",
      "Epoch 1186 Chain 1 loss std 2.21e+02 variance 2.44e+04 smooth variance 2.34e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.031603\n",
      " Loss: 0.000000\n",
      " Loss: 0.036828\n",
      " Loss: 0.000000\n",
      " Loss: 0.017647\n",
      " Loss: 0.000000\n",
      " Loss: 0.074192\n",
      " Loss: 0.000000\n",
      " Loss: 0.016938\n",
      " Loss: 0.000000\n",
      " Loss: 0.018562\n",
      " Loss: 0.000000\n",
      " Loss: 0.038606\n",
      " Loss: 0.000000\n",
      " Loss: 0.022009\n",
      " Loss: 0.000000\n",
      " Loss: 0.066689\n",
      " Loss: 0.000000\n",
      " Loss: 0.031093\n",
      "Epoch 1188 Chain 0 loss std 1.14e-03 variance 6.45e-07 smooth variance 6.74e-07 adaptive c -1.00\n",
      "Epoch 1188 Chain 1 loss std 1.30e+02 variance 8.51e+03 smooth variance 1.90e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.068721\n",
      " Loss: 0.000000\n",
      " Loss: 0.027018\n",
      " Loss: 0.000000\n",
      " Loss: 0.019926\n",
      " Loss: 0.000000\n",
      " Loss: 0.019557\n",
      " Loss: 0.000000\n",
      " Loss: 0.041927\n",
      " Loss: 0.000000\n",
      " Loss: 0.023636\n",
      " Loss: 0.000000\n",
      " Loss: 0.028756\n",
      " Loss: 0.000000\n",
      " Loss: 0.059514\n",
      " Loss: 0.000000\n",
      " Loss: 0.022339\n",
      " Loss: 0.000000\n",
      " Loss: 0.042412\n",
      "Epoch 1190 Chain 0 loss std 8.03e-04 variance 3.22e-07 smooth variance 5.69e-07 adaptive c -1.00\n",
      "Epoch 1190 Chain 1 loss std 3.10e+02 variance 4.82e+04 smooth variance 2.77e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020121\n",
      " Loss: 0.000000\n",
      " Loss: 0.025546\n",
      " Loss: 0.000000\n",
      " Loss: 0.010679\n",
      " Loss: 0.000000\n",
      " Loss: 0.027977\n",
      " Loss: 0.000000\n",
      " Loss: 0.091955\n",
      " Loss: 0.000000\n",
      " Loss: 0.069532\n",
      " Loss: 0.000000\n",
      " Loss: 0.037320\n",
      " Loss: 0.000000\n",
      " Loss: 0.021168\n",
      " Loss: 0.000000\n",
      " Loss: 0.027200\n",
      " Loss: 0.000000\n",
      " Loss: 0.020953\n",
      "Epoch 1192 Chain 0 loss std 1.26e-03 variance 7.98e-07 smooth variance 6.38e-07 adaptive c -1.00\n",
      "Epoch 1192 Chain 1 loss std 1.87e+02 variance 1.75e+04 smooth variance 2.47e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.034221\n",
      " Loss: 0.000000\n",
      " Loss: 0.022503\n",
      " Loss: 0.000000\n",
      " Loss: 0.025449\n",
      " Loss: 0.000000\n",
      " Loss: 0.023753\n",
      " Loss: 0.000000\n",
      " Loss: 0.070360\n",
      " Loss: 0.000000\n",
      " Loss: 0.034535\n",
      " Loss: 0.000000\n",
      " Loss: 0.064009\n",
      " Loss: 0.000000\n",
      " Loss: 0.023057\n",
      " Loss: 0.000000\n",
      " Loss: 0.026681\n",
      " Loss: 0.000000\n",
      " Loss: 0.027439\n",
      "Epoch 1194 Chain 0 loss std 1.09e-03 variance 5.94e-07 smooth variance 6.24e-07 adaptive c -1.00\n",
      "Epoch 1194 Chain 1 loss std 1.89e+02 variance 1.79e+04 smooth variance 2.26e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.038238\n",
      " Loss: 0.000000\n",
      " Loss: 0.027934\n",
      " Loss: 0.000000\n",
      " Loss: 0.066132\n",
      " Loss: 0.000000\n",
      " Loss: 0.026415\n",
      " Loss: 0.000000\n",
      " Loss: 0.016755\n",
      " Loss: 0.000000\n",
      " Loss: 0.012941\n",
      " Loss: 0.000000\n",
      " Loss: 0.084502\n",
      " Loss: 0.000000\n",
      " Loss: 0.025837\n",
      " Loss: 0.000000\n",
      " Loss: 0.022952\n",
      " Loss: 0.000000\n",
      " Loss: 0.028955\n",
      "Epoch 1196 Chain 0 loss std 1.22e-03 variance 7.47e-07 smooth variance 6.61e-07 adaptive c -1.00\n",
      "Epoch 1196 Chain 1 loss std 2.42e+02 variance 2.93e+04 smooth variance 2.46e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.083229\n",
      " Loss: 0.000000\n",
      " Loss: 0.027751\n",
      " Loss: 0.000000\n",
      " Loss: 0.017186\n",
      " Loss: 0.000000\n",
      " Loss: 0.025144\n",
      " Loss: 0.000000\n",
      " Loss: 0.021642\n",
      " Loss: 0.000000\n",
      " Loss: 0.019162\n",
      " Loss: 0.000000\n",
      " Loss: 0.014962\n",
      " Loss: 0.000000\n",
      " Loss: 0.083311\n",
      " Loss: 0.000000\n",
      " Loss: 0.034780\n",
      " Loss: 0.000000\n",
      " Loss: 0.022538\n",
      "Epoch 1198 Chain 0 loss std 1.10e-03 variance 6.06e-07 smooth variance 6.44e-07 adaptive c -1.00\n",
      "Epoch 1198 Chain 1 loss std 1.47e+02 variance 1.09e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015425\n",
      " Loss: 0.000000\n",
      " Loss: 0.019493\n",
      " Loss: 0.000000\n",
      " Loss: 0.025575\n",
      " Loss: 0.000000\n",
      " Loss: 0.075007\n",
      " Loss: 0.000000\n",
      " Loss: 0.039053\n",
      " Loss: 0.000000\n",
      " Loss: 0.035453\n",
      " Loss: 0.000000\n",
      " Loss: 0.015842\n",
      " Loss: 0.000000\n",
      " Loss: 0.021780\n",
      " Loss: 0.000000\n",
      " Loss: 0.023740\n",
      " Loss: 0.000000\n",
      " Loss: 0.077509\n",
      "Epoch 1200 Chain 0 loss std 1.35e-03 variance 9.12e-07 smooth variance 7.25e-07 adaptive c -1.00\n",
      "Epoch 1200 Chain 1 loss std 2.32e+02 variance 2.68e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.077902\n",
      " Loss: 0.000000\n",
      " Loss: 0.017647\n",
      " Loss: 0.000000\n",
      " Loss: 0.027469\n",
      " Loss: 0.000000\n",
      " Loss: 0.024666\n",
      " Loss: 0.000000\n",
      " Loss: 0.026412\n",
      " Loss: 0.000000\n",
      " Loss: 0.043948\n",
      " Loss: 0.000000\n",
      " Loss: 0.069130\n",
      " Loss: 0.000000\n",
      " Loss: 0.029646\n",
      " Loss: 0.000000\n",
      " Loss: 0.015588\n",
      " Loss: 0.000000\n",
      " Loss: 0.015650\n",
      "Epoch 1202 Chain 0 loss std 1.27e-03 variance 8.13e-07 smooth variance 7.51e-07 adaptive c -1.00\n",
      "Epoch 1202 Chain 1 loss std 2.57e+02 variance 3.30e+04 smooth variance 2.56e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021910\n",
      " Loss: 0.000000\n",
      " Loss: 0.044227\n",
      " Loss: 0.000000\n",
      " Loss: 0.069604\n",
      " Loss: 0.000000\n",
      " Loss: 0.017828\n",
      " Loss: 0.000000\n",
      " Loss: 0.020169\n",
      " Loss: 0.000000\n",
      " Loss: 0.012081\n",
      " Loss: 0.000000\n",
      " Loss: 0.093005\n",
      " Loss: 0.000000\n",
      " Loss: 0.029203\n",
      " Loss: 0.000000\n",
      " Loss: 0.020603\n",
      " Loss: 0.000000\n",
      " Loss: 0.018567\n",
      "Epoch 1204 Chain 0 loss std 9.69e-04 variance 4.70e-07 smooth variance 6.67e-07 adaptive c -1.00\n",
      "Epoch 1204 Chain 1 loss std 1.72e+02 variance 1.47e+04 smooth variance 2.23e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.011301\n",
      " Loss: 0.000000\n",
      " Loss: 0.026670\n",
      " Loss: 0.000000\n",
      " Loss: 0.069344\n",
      " Loss: 0.000000\n",
      " Loss: 0.041289\n",
      " Loss: 0.000000\n",
      " Loss: 0.024682\n",
      " Loss: 0.000000\n",
      " Loss: 0.013988\n",
      " Loss: 0.000000\n",
      " Loss: 0.086024\n",
      " Loss: 0.000000\n",
      " Loss: 0.017475\n",
      " Loss: 0.000000\n",
      " Loss: 0.025028\n",
      " Loss: 0.000000\n",
      " Loss: 0.030567\n",
      "Epoch 1206 Chain 0 loss std 1.33e-03 variance 8.88e-07 smooth variance 7.33e-07 adaptive c -1.00\n",
      "Epoch 1206 Chain 1 loss std 1.89e+02 variance 1.79e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.046460\n",
      " Loss: 0.000000\n",
      " Loss: 0.020109\n",
      " Loss: 0.000000\n",
      " Loss: 0.016476\n",
      " Loss: 0.000000\n",
      " Loss: 0.058390\n",
      " Loss: 0.000000\n",
      " Loss: 0.031501\n",
      " Loss: 0.000000\n",
      " Loss: 0.019824\n",
      " Loss: 0.000000\n",
      " Loss: 0.020989\n",
      " Loss: 0.000000\n",
      " Loss: 0.026084\n",
      " Loss: 0.000000\n",
      " Loss: 0.041485\n",
      " Loss: 0.000000\n",
      " Loss: 0.064342\n",
      "Epoch 1208 Chain 0 loss std 9.10e-04 variance 4.14e-07 smooth variance 6.37e-07 adaptive c -1.00\n",
      "Epoch 1208 Chain 1 loss std 2.03e+02 variance 2.06e+04 smooth variance 2.09e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021260\n",
      " Loss: 0.000000\n",
      " Loss: 0.021195\n",
      " Loss: 0.000000\n",
      " Loss: 0.041753\n",
      " Loss: 0.000000\n",
      " Loss: 0.065453\n",
      " Loss: 0.000000\n",
      " Loss: 0.022863\n",
      " Loss: 0.000000\n",
      " Loss: 0.075522\n",
      " Loss: 0.000000\n",
      " Loss: 0.018539\n",
      " Loss: 0.000000\n",
      " Loss: 0.028405\n",
      " Loss: 0.000000\n",
      " Loss: 0.016659\n",
      " Loss: 0.000000\n",
      " Loss: 0.033091\n",
      "Epoch 1210 Chain 0 loss std 1.19e-03 variance 7.08e-07 smooth variance 6.58e-07 adaptive c -1.00\n",
      "Epoch 1210 Chain 1 loss std 1.60e+02 variance 1.28e+04 smooth variance 1.85e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.030545\n",
      " Loss: 0.000000\n",
      " Loss: 0.018846\n",
      " Loss: 0.000000\n",
      " Loss: 0.019532\n",
      " Loss: 0.000000\n",
      " Loss: 0.075842\n",
      " Loss: 0.000000\n",
      " Loss: 0.027261\n",
      " Loss: 0.000000\n",
      " Loss: 0.065767\n",
      " Loss: 0.000000\n",
      " Loss: 0.014880\n",
      " Loss: 0.000000\n",
      " Loss: 0.017246\n",
      " Loss: 0.000000\n",
      " Loss: 0.043947\n",
      " Loss: 0.000000\n",
      " Loss: 0.030218\n",
      "Epoch 1212 Chain 0 loss std 1.20e-03 variance 7.18e-07 smooth variance 6.76e-07 adaptive c -1.00\n",
      "Epoch 1212 Chain 1 loss std 1.92e+02 variance 1.85e+04 smooth variance 1.85e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014469\n",
      " Loss: 0.000000\n",
      " Loss: 0.023444\n",
      " Loss: 0.000000\n",
      " Loss: 0.050478\n",
      " Loss: 0.000000\n",
      " Loss: 0.016451\n",
      " Loss: 0.000000\n",
      " Loss: 0.067032\n",
      " Loss: 0.000000\n",
      " Loss: 0.021626\n",
      " Loss: 0.000000\n",
      " Loss: 0.076045\n",
      " Loss: 0.000000\n",
      " Loss: 0.010306\n",
      " Loss: 0.000000\n",
      " Loss: 0.022268\n",
      " Loss: 0.000000\n",
      " Loss: 0.041419\n",
      "Epoch 1214 Chain 0 loss std 8.40e-04 variance 3.52e-07 smooth variance 5.79e-07 adaptive c -1.00\n",
      "Epoch 1214 Chain 1 loss std 2.54e+02 variance 3.22e+04 smooth variance 2.26e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024199\n",
      " Loss: 0.000000\n",
      " Loss: 0.018561\n",
      " Loss: 0.000000\n",
      " Loss: 0.031122\n",
      " Loss: 0.000000\n",
      " Loss: 0.083547\n",
      " Loss: 0.000000\n",
      " Loss: 0.013892\n",
      " Loss: 0.000000\n",
      " Loss: 0.036586\n",
      " Loss: 0.000000\n",
      " Loss: 0.015182\n",
      " Loss: 0.000000\n",
      " Loss: 0.030289\n",
      " Loss: 0.000000\n",
      " Loss: 0.071511\n",
      " Loss: 0.000000\n",
      " Loss: 0.017766\n",
      "Epoch 1216 Chain 0 loss std 1.41e-03 variance 9.91e-07 smooth variance 7.03e-07 adaptive c -1.00\n",
      "Epoch 1216 Chain 1 loss std 2.26e+02 variance 2.55e+04 smooth variance 2.34e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032414\n",
      " Loss: 0.000000\n",
      " Loss: 0.027896\n",
      " Loss: 0.000000\n",
      " Loss: 0.025659\n",
      " Loss: 0.000000\n",
      " Loss: 0.022049\n",
      " Loss: 0.000000\n",
      " Loss: 0.063058\n",
      " Loss: 0.000000\n",
      " Loss: 0.038138\n",
      " Loss: 0.000000\n",
      " Loss: 0.021340\n",
      " Loss: 0.000000\n",
      " Loss: 0.028104\n",
      " Loss: 0.000000\n",
      " Loss: 0.067280\n",
      " Loss: 0.000000\n",
      " Loss: 0.016041\n",
      "Epoch 1218 Chain 0 loss std 1.37e-03 variance 9.37e-07 smooth variance 7.73e-07 adaptive c -1.00\n",
      "Epoch 1218 Chain 1 loss std 1.40e+02 variance 9.84e+03 smooth variance 1.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036344\n",
      " Loss: 0.000000\n",
      " Loss: 0.036395\n",
      " Loss: 0.000000\n",
      " Loss: 0.024609\n",
      " Loss: 0.000000\n",
      " Loss: 0.056664\n",
      " Loss: 0.000000\n",
      " Loss: 0.016665\n",
      " Loss: 0.000000\n",
      " Loss: 0.022356\n",
      " Loss: 0.000000\n",
      " Loss: 0.019693\n",
      " Loss: 0.000000\n",
      " Loss: 0.063966\n",
      " Loss: 0.000000\n",
      " Loss: 0.046495\n",
      " Loss: 0.000000\n",
      " Loss: 0.018098\n",
      "Epoch 1220 Chain 0 loss std 7.37e-04 variance 2.71e-07 smooth variance 6.22e-07 adaptive c -1.00\n",
      "Epoch 1220 Chain 1 loss std 1.71e+02 variance 1.46e+04 smooth variance 1.79e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028845\n",
      " Loss: 0.000000\n",
      " Loss: 0.067480\n",
      " Loss: 0.000000\n",
      " Loss: 0.030693\n",
      " Loss: 0.000000\n",
      " Loss: 0.021350\n",
      " Loss: 0.000000\n",
      " Loss: 0.021956\n",
      " Loss: 0.000000\n",
      " Loss: 0.011700\n",
      " Loss: 0.000000\n",
      " Loss: 0.017084\n",
      " Loss: 0.000000\n",
      " Loss: 0.032985\n",
      " Loss: 0.000000\n",
      " Loss: 0.046208\n",
      " Loss: 0.000000\n",
      " Loss: 0.062226\n",
      "Epoch 1222 Chain 0 loss std 1.72e-03 variance 1.48e-06 smooth variance 8.79e-07 adaptive c -1.00\n",
      "Epoch 1222 Chain 1 loss std 1.87e+02 variance 1.75e+04 smooth variance 1.78e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.095644\n",
      " Loss: 0.000000\n",
      " Loss: 0.029171\n",
      " Loss: 0.000000\n",
      " Loss: 0.018491\n",
      " Loss: 0.000000\n",
      " Loss: 0.016399\n",
      " Loss: 0.000000\n",
      " Loss: 0.010305\n",
      " Loss: 0.000000\n",
      " Loss: 0.040362\n",
      " Loss: 0.000000\n",
      " Loss: 0.019575\n",
      " Loss: 0.000000\n",
      " Loss: 0.030136\n",
      " Loss: 0.000000\n",
      " Loss: 0.017350\n",
      " Loss: 0.000000\n",
      " Loss: 0.062550\n",
      "Epoch 1224 Chain 0 loss std 1.10e-03 variance 6.06e-07 smooth variance 7.97e-07 adaptive c -1.00\n",
      "Epoch 1224 Chain 1 loss std 1.90e+02 variance 1.81e+04 smooth variance 1.79e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.058541\n",
      " Loss: 0.000000\n",
      " Loss: 0.025571\n",
      " Loss: 0.000000\n",
      " Loss: 0.020801\n",
      " Loss: 0.000000\n",
      " Loss: 0.026020\n",
      " Loss: 0.000000\n",
      " Loss: 0.039048\n",
      " Loss: 0.000000\n",
      " Loss: 0.062148\n",
      " Loss: 0.000000\n",
      " Loss: 0.035096\n",
      " Loss: 0.000000\n",
      " Loss: 0.031295\n",
      " Loss: 0.000000\n",
      " Loss: 0.017257\n",
      " Loss: 0.000000\n",
      " Loss: 0.023795\n",
      "Epoch 1226 Chain 0 loss std 1.33e-03 variance 8.85e-07 smooth variance 8.24e-07 adaptive c -1.00\n",
      "Epoch 1226 Chain 1 loss std 2.98e+02 variance 4.44e+04 smooth variance 2.59e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.060902\n",
      " Loss: 0.000000\n",
      " Loss: 0.026028\n",
      " Loss: 0.000000\n",
      " Loss: 0.037873\n",
      " Loss: 0.000000\n",
      " Loss: 0.019844\n",
      " Loss: 0.000000\n",
      " Loss: 0.024857\n",
      " Loss: 0.000000\n",
      " Loss: 0.063615\n",
      " Loss: 0.000000\n",
      " Loss: 0.022051\n",
      " Loss: 0.000000\n",
      " Loss: 0.030797\n",
      " Loss: 0.000000\n",
      " Loss: 0.039145\n",
      " Loss: 0.000000\n",
      " Loss: 0.013641\n",
      "Epoch 1228 Chain 0 loss std 1.35e-03 variance 9.08e-07 smooth variance 8.49e-07 adaptive c -1.00\n",
      "Epoch 1228 Chain 1 loss std 3.41e+02 variance 5.81e+04 smooth variance 3.55e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020682\n",
      " Loss: 0.000000\n",
      " Loss: 0.087042\n",
      " Loss: 0.000000\n",
      " Loss: 0.017995\n",
      " Loss: 0.000000\n",
      " Loss: 0.027294\n",
      " Loss: 0.000000\n",
      " Loss: 0.016086\n",
      " Loss: 0.000000\n",
      " Loss: 0.065515\n",
      " Loss: 0.000000\n",
      " Loss: 0.029525\n",
      " Loss: 0.000000\n",
      " Loss: 0.021043\n",
      " Loss: 0.000000\n",
      " Loss: 0.024487\n",
      " Loss: 0.000000\n",
      " Loss: 0.028507\n",
      "Epoch 1230 Chain 0 loss std 8.79e-04 variance 3.86e-07 smooth variance 7.10e-07 adaptive c -1.00\n",
      "Epoch 1230 Chain 1 loss std 2.16e+02 variance 2.33e+04 smooth variance 3.19e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036828\n",
      " Loss: 0.000000\n",
      " Loss: 0.015968\n",
      " Loss: 0.000000\n",
      " Loss: 0.055902\n",
      " Loss: 0.000000\n",
      " Loss: 0.022002\n",
      " Loss: 0.000000\n",
      " Loss: 0.038198\n",
      " Loss: 0.000000\n",
      " Loss: 0.062425\n",
      " Loss: 0.000000\n",
      " Loss: 0.033827\n",
      " Loss: 0.000000\n",
      " Loss: 0.027218\n",
      " Loss: 0.000000\n",
      " Loss: 0.015671\n",
      " Loss: 0.000000\n",
      " Loss: 0.029644\n",
      "Epoch 1232 Chain 0 loss std 8.17e-04 variance 3.34e-07 smooth variance 5.97e-07 adaptive c -1.00\n",
      "Epoch 1232 Chain 1 loss std 2.81e+02 variance 3.96e+04 smooth variance 3.42e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025451\n",
      " Loss: 0.000000\n",
      " Loss: 0.014823\n",
      " Loss: 0.000000\n",
      " Loss: 0.049570\n",
      " Loss: 0.000000\n",
      " Loss: 0.017992\n",
      " Loss: 0.000000\n",
      " Loss: 0.060887\n",
      " Loss: 0.000000\n",
      " Loss: 0.009790\n",
      " Loss: 0.000000\n",
      " Loss: 0.028734\n",
      " Loss: 0.000000\n",
      " Loss: 0.022906\n",
      " Loss: 0.000000\n",
      " Loss: 0.090411\n",
      " Loss: 0.000000\n",
      " Loss: 0.016597\n",
      "Epoch 1234 Chain 0 loss std 9.18e-04 variance 4.22e-07 smooth variance 5.45e-07 adaptive c -1.00\n",
      "Epoch 1234 Chain 1 loss std 2.94e+02 variance 4.32e+04 smooth variance 3.69e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022036\n",
      " Loss: 0.000000\n",
      " Loss: 0.027109\n",
      " Loss: 0.000000\n",
      " Loss: 0.022977\n",
      " Loss: 0.000000\n",
      " Loss: 0.061321\n",
      " Loss: 0.000000\n",
      " Loss: 0.034938\n",
      " Loss: 0.000000\n",
      " Loss: 0.017079\n",
      " Loss: 0.000000\n",
      " Loss: 0.079304\n",
      " Loss: 0.000000\n",
      " Loss: 0.017536\n",
      " Loss: 0.000000\n",
      " Loss: 0.018674\n",
      " Loss: 0.000000\n",
      " Loss: 0.035614\n",
      "Epoch 1236 Chain 0 loss std 1.12e-03 variance 6.24e-07 smooth variance 5.68e-07 adaptive c -1.00\n",
      "Epoch 1236 Chain 1 loss std 2.39e+02 variance 2.86e+04 smooth variance 3.44e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022048\n",
      " Loss: 0.000000\n",
      " Loss: 0.010074\n",
      " Loss: 0.000000\n",
      " Loss: 0.026620\n",
      " Loss: 0.000000\n",
      " Loss: 0.042958\n",
      " Loss: 0.000000\n",
      " Loss: 0.066402\n",
      " Loss: 0.000000\n",
      " Loss: 0.021858\n",
      " Loss: 0.000000\n",
      " Loss: 0.028687\n",
      " Loss: 0.000000\n",
      " Loss: 0.022883\n",
      " Loss: 0.000000\n",
      " Loss: 0.060333\n",
      " Loss: 0.000000\n",
      " Loss: 0.034237\n",
      "Epoch 1238 Chain 0 loss std 1.15e-03 variance 6.65e-07 smooth variance 5.97e-07 adaptive c -1.00\n",
      "Epoch 1238 Chain 1 loss std 2.20e+02 variance 2.41e+04 smooth variance 3.13e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.070384\n",
      " Loss: 0.000000\n",
      " Loss: 0.042214\n",
      " Loss: 0.000000\n",
      " Loss: 0.018487\n",
      " Loss: 0.000000\n",
      " Loss: 0.019069\n",
      " Loss: 0.000000\n",
      " Loss: 0.017720\n",
      " Loss: 0.000000\n",
      " Loss: 0.031182\n",
      " Loss: 0.000000\n",
      " Loss: 0.028351\n",
      " Loss: 0.000000\n",
      " Loss: 0.070124\n",
      " Loss: 0.000000\n",
      " Loss: 0.022175\n",
      " Loss: 0.000000\n",
      " Loss: 0.015938\n",
      "Epoch 1240 Chain 0 loss std 1.14e-03 variance 6.55e-07 smooth variance 6.15e-07 adaptive c -1.00\n",
      "Epoch 1240 Chain 1 loss std 2.17e+02 variance 2.36e+04 smooth variance 2.90e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016310\n",
      " Loss: 0.000000\n",
      " Loss: 0.032146\n",
      " Loss: 0.000000\n",
      " Loss: 0.029355\n",
      " Loss: 0.000000\n",
      " Loss: 0.027533\n",
      " Loss: 0.000000\n",
      " Loss: 0.062398\n",
      " Loss: 0.000000\n",
      " Loss: 0.066521\n",
      " Loss: 0.000000\n",
      " Loss: 0.042519\n",
      " Loss: 0.000000\n",
      " Loss: 0.015854\n",
      " Loss: 0.000000\n",
      " Loss: 0.011607\n",
      " Loss: 0.000000\n",
      " Loss: 0.031062\n",
      "Epoch 1242 Chain 0 loss std 7.13e-04 variance 2.54e-07 smooth variance 5.07e-07 adaptive c -1.00\n",
      "Epoch 1242 Chain 1 loss std 1.98e+02 variance 1.96e+04 smooth variance 2.62e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036030\n",
      " Loss: 0.000000\n",
      " Loss: 0.032638\n",
      " Loss: 0.000000\n",
      " Loss: 0.014757\n",
      " Loss: 0.000000\n",
      " Loss: 0.068039\n",
      " Loss: 0.000000\n",
      " Loss: 0.015984\n",
      " Loss: 0.000000\n",
      " Loss: 0.013506\n",
      " Loss: 0.000000\n",
      " Loss: 0.077674\n",
      " Loss: 0.000000\n",
      " Loss: 0.029528\n",
      " Loss: 0.000000\n",
      " Loss: 0.025936\n",
      " Loss: 0.000000\n",
      " Loss: 0.020632\n",
      "Epoch 1244 Chain 0 loss std 1.73e-03 variance 1.50e-06 smooth variance 8.06e-07 adaptive c -1.00\n",
      "Epoch 1244 Chain 1 loss std 2.07e+02 variance 2.15e+04 smooth variance 2.48e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024255\n",
      " Loss: 0.000000\n",
      " Loss: 0.062695\n",
      " Loss: 0.000000\n",
      " Loss: 0.025218\n",
      " Loss: 0.000000\n",
      " Loss: 0.022210\n",
      " Loss: 0.000000\n",
      " Loss: 0.032913\n",
      " Loss: 0.000000\n",
      " Loss: 0.017730\n",
      " Loss: 0.000000\n",
      " Loss: 0.059034\n",
      " Loss: 0.000000\n",
      " Loss: 0.030902\n",
      " Loss: 0.000000\n",
      " Loss: 0.018027\n",
      " Loss: 0.000000\n",
      " Loss: 0.041434\n",
      "Epoch 1246 Chain 0 loss std 5.79e-04 variance 1.68e-07 smooth variance 6.14e-07 adaptive c -1.00\n",
      "Epoch 1246 Chain 1 loss std 1.87e+02 variance 1.75e+04 smooth variance 2.26e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.063448\n",
      " Loss: 0.000000\n",
      " Loss: 0.030803\n",
      " Loss: 0.000000\n",
      " Loss: 0.018032\n",
      " Loss: 0.000000\n",
      " Loss: 0.022147\n",
      " Loss: 0.000000\n",
      " Loss: 0.032629\n",
      " Loss: 0.000000\n",
      " Loss: 0.016782\n",
      " Loss: 0.000000\n",
      " Loss: 0.026481\n",
      " Loss: 0.000000\n",
      " Loss: 0.036139\n",
      " Loss: 0.000000\n",
      " Loss: 0.025323\n",
      " Loss: 0.000000\n",
      " Loss: 0.062249\n",
      "Epoch 1248 Chain 0 loss std 1.32e-03 variance 8.66e-07 smooth variance 6.90e-07 adaptive c -1.00\n",
      "Epoch 1248 Chain 1 loss std 1.39e+02 variance 9.69e+03 smooth variance 1.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.059790\n",
      " Loss: 0.000000\n",
      " Loss: 0.018098\n",
      " Loss: 0.000000\n",
      " Loss: 0.019605\n",
      " Loss: 0.000000\n",
      " Loss: 0.044597\n",
      " Loss: 0.000000\n",
      " Loss: 0.024730\n",
      " Loss: 0.000000\n",
      " Loss: 0.010135\n",
      " Loss: 0.000000\n",
      " Loss: 0.019363\n",
      " Loss: 0.000000\n",
      " Loss: 0.037880\n",
      " Loss: 0.000000\n",
      " Loss: 0.072593\n",
      " Loss: 0.000000\n",
      " Loss: 0.026758\n",
      "Epoch 1250 Chain 0 loss std 7.43e-04 variance 2.76e-07 smooth variance 5.66e-07 adaptive c -1.00\n",
      "Epoch 1250 Chain 1 loss std 2.39e+02 variance 2.87e+04 smooth variance 2.17e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.031283\n",
      " Loss: 0.000000\n",
      " Loss: 0.019858\n",
      " Loss: 0.000000\n",
      " Loss: 0.060818\n",
      " Loss: 0.000000\n",
      " Loss: 0.022273\n",
      " Loss: 0.000000\n",
      " Loss: 0.032422\n",
      " Loss: 0.000000\n",
      " Loss: 0.017766\n",
      " Loss: 0.000000\n",
      " Loss: 0.031420\n",
      " Loss: 0.000000\n",
      " Loss: 0.056785\n",
      " Loss: 0.000000\n",
      " Loss: 0.041695\n",
      " Loss: 0.000000\n",
      " Loss: 0.018819\n",
      "Epoch 1252 Chain 0 loss std 1.52e-03 variance 1.15e-06 smooth variance 7.40e-07 adaptive c -1.00\n",
      "Epoch 1252 Chain 1 loss std 1.67e+02 variance 1.40e+04 smooth variance 1.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018139\n",
      " Loss: 0.000000\n",
      " Loss: 0.023255\n",
      " Loss: 0.000000\n",
      " Loss: 0.030404\n",
      " Loss: 0.000000\n",
      " Loss: 0.076667\n",
      " Loss: 0.000000\n",
      " Loss: 0.017949\n",
      " Loss: 0.000000\n",
      " Loss: 0.011938\n",
      " Loss: 0.000000\n",
      " Loss: 0.028087\n",
      " Loss: 0.000000\n",
      " Loss: 0.032468\n",
      " Loss: 0.000000\n",
      " Loss: 0.019856\n",
      " Loss: 0.000000\n",
      " Loss: 0.074048\n",
      "Epoch 1254 Chain 0 loss std 7.83e-04 variance 3.07e-07 smooth variance 6.10e-07 adaptive c -1.00\n",
      "Epoch 1254 Chain 1 loss std 1.61e+02 variance 1.29e+04 smooth variance 1.75e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.042028\n",
      " Loss: 0.000000\n",
      " Loss: 0.062158\n",
      " Loss: 0.000000\n",
      " Loss: 0.015220\n",
      " Loss: 0.000000\n",
      " Loss: 0.024349\n",
      " Loss: 0.000000\n",
      " Loss: 0.022485\n",
      " Loss: 0.000000\n",
      " Loss: 0.020288\n",
      " Loss: 0.000000\n",
      " Loss: 0.022558\n",
      " Loss: 0.000000\n",
      " Loss: 0.082653\n",
      " Loss: 0.000000\n",
      " Loss: 0.024844\n",
      " Loss: 0.000000\n",
      " Loss: 0.015758\n",
      "Epoch 1256 Chain 0 loss std 1.87e-03 variance 1.75e-06 smooth variance 9.51e-07 adaptive c -1.00\n",
      "Epoch 1256 Chain 1 loss std 1.57e+02 variance 1.23e+04 smooth variance 1.59e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.013179\n",
      " Loss: 0.000000\n",
      " Loss: 0.035020\n",
      " Loss: 0.000000\n",
      " Loss: 0.024776\n",
      " Loss: 0.000000\n",
      " Loss: 0.058882\n",
      " Loss: 0.000000\n",
      " Loss: 0.034192\n",
      " Loss: 0.000000\n",
      " Loss: 0.020983\n",
      " Loss: 0.000000\n",
      " Loss: 0.071384\n",
      " Loss: 0.000000\n",
      " Loss: 0.015710\n",
      " Loss: 0.000000\n",
      " Loss: 0.035027\n",
      " Loss: 0.000000\n",
      " Loss: 0.022863\n",
      "Epoch 1258 Chain 0 loss std 1.06e-03 variance 5.66e-07 smooth variance 8.35e-07 adaptive c -1.00\n",
      "Epoch 1258 Chain 1 loss std 2.06e+02 variance 2.13e+04 smooth variance 1.75e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061770\n",
      " Loss: 0.000000\n",
      " Loss: 0.025399\n",
      " Loss: 0.000000\n",
      " Loss: 0.018878\n",
      " Loss: 0.000000\n",
      " Loss: 0.015333\n",
      " Loss: 0.000000\n",
      " Loss: 0.044510\n",
      " Loss: 0.000000\n",
      " Loss: 0.035916\n",
      " Loss: 0.000000\n",
      " Loss: 0.015632\n",
      " Loss: 0.000000\n",
      " Loss: 0.068972\n",
      " Loss: 0.000000\n",
      " Loss: 0.030031\n",
      " Loss: 0.000000\n",
      " Loss: 0.015345\n",
      "Epoch 1260 Chain 0 loss std 1.20e-03 variance 7.26e-07 smooth variance 8.03e-07 adaptive c -1.00\n",
      "Epoch 1260 Chain 1 loss std 2.62e+02 variance 3.43e+04 smooth variance 2.26e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021458\n",
      " Loss: 0.000000\n",
      " Loss: 0.038131\n",
      " Loss: 0.000000\n",
      " Loss: 0.020257\n",
      " Loss: 0.000000\n",
      " Loss: 0.068153\n",
      " Loss: 0.000000\n",
      " Loss: 0.017761\n",
      " Loss: 0.000000\n",
      " Loss: 0.020834\n",
      " Loss: 0.000000\n",
      " Loss: 0.021928\n",
      " Loss: 0.000000\n",
      " Loss: 0.026741\n",
      " Loss: 0.000000\n",
      " Loss: 0.064665\n",
      " Loss: 0.000000\n",
      " Loss: 0.031491\n",
      "Epoch 1262 Chain 0 loss std 1.00e-03 variance 5.04e-07 smooth variance 7.13e-07 adaptive c -1.00\n",
      "Epoch 1262 Chain 1 loss std 2.00e+02 variance 2.01e+04 smooth variance 2.18e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026070\n",
      " Loss: 0.000000\n",
      " Loss: 0.036377\n",
      " Loss: 0.000000\n",
      " Loss: 0.022192\n",
      " Loss: 0.000000\n",
      " Loss: 0.023034\n",
      " Loss: 0.000000\n",
      " Loss: 0.057936\n",
      " Loss: 0.000000\n",
      " Loss: 0.084062\n",
      " Loss: 0.000000\n",
      " Loss: 0.015259\n",
      " Loss: 0.000000\n",
      " Loss: 0.024450\n",
      " Loss: 0.000000\n",
      " Loss: 0.028472\n",
      " Loss: 0.000000\n",
      " Loss: 0.013213\n",
      "Epoch 1264 Chain 0 loss std 6.71e-04 variance 2.25e-07 smooth variance 5.67e-07 adaptive c -1.00\n",
      "Epoch 1264 Chain 1 loss std 2.16e+02 variance 2.33e+04 smooth variance 2.23e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.065807\n",
      " Loss: 0.000000\n",
      " Loss: 0.019206\n",
      " Loss: 0.000000\n",
      " Loss: 0.043993\n",
      " Loss: 0.000000\n",
      " Loss: 0.011586\n",
      " Loss: 0.000000\n",
      " Loss: 0.024861\n",
      " Loss: 0.000000\n",
      " Loss: 0.044641\n",
      " Loss: 0.000000\n",
      " Loss: 0.026082\n",
      " Loss: 0.000000\n",
      " Loss: 0.025510\n",
      " Loss: 0.000000\n",
      " Loss: 0.011616\n",
      " Loss: 0.000000\n",
      " Loss: 0.057531\n",
      "Epoch 1266 Chain 0 loss std 1.01e-03 variance 5.15e-07 smooth variance 5.51e-07 adaptive c -1.00\n",
      "Epoch 1266 Chain 1 loss std 1.54e+02 variance 1.18e+04 smooth variance 1.91e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016767\n",
      " Loss: 0.000000\n",
      " Loss: 0.079005\n",
      " Loss: 0.000000\n",
      " Loss: 0.023052\n",
      " Loss: 0.000000\n",
      " Loss: 0.017731\n",
      " Loss: 0.000000\n",
      " Loss: 0.028664\n",
      " Loss: 0.000000\n",
      " Loss: 0.016656\n",
      " Loss: 0.000000\n",
      " Loss: 0.020423\n",
      " Loss: 0.000000\n",
      " Loss: 0.018732\n",
      " Loss: 0.000000\n",
      " Loss: 0.070212\n",
      " Loss: 0.000000\n",
      " Loss: 0.039173\n",
      "Epoch 1268 Chain 0 loss std 1.38e-03 variance 9.50e-07 smooth variance 6.71e-07 adaptive c -1.00\n",
      "Epoch 1268 Chain 1 loss std 2.73e+02 variance 3.73e+04 smooth variance 2.46e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024797\n",
      " Loss: 0.000000\n",
      " Loss: 0.022534\n",
      " Loss: 0.000000\n",
      " Loss: 0.032851\n",
      " Loss: 0.000000\n",
      " Loss: 0.071954\n",
      " Loss: 0.000000\n",
      " Loss: 0.012967\n",
      " Loss: 0.000000\n",
      " Loss: 0.063827\n",
      " Loss: 0.000000\n",
      " Loss: 0.038167\n",
      " Loss: 0.000000\n",
      " Loss: 0.028670\n",
      " Loss: 0.000000\n",
      " Loss: 0.012471\n",
      " Loss: 0.000000\n",
      " Loss: 0.021911\n",
      "Epoch 1270 Chain 0 loss std 1.05e-03 variance 5.48e-07 smooth variance 6.34e-07 adaptive c -1.00\n",
      "Epoch 1270 Chain 1 loss std 1.88e+02 variance 1.77e+04 smooth variance 2.25e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.031086\n",
      " Loss: 0.000000\n",
      " Loss: 0.028003\n",
      " Loss: 0.000000\n",
      " Loss: 0.017768\n",
      " Loss: 0.000001\n",
      " Loss: 0.063495\n",
      " Loss: 0.000000\n",
      " Loss: 0.024659\n",
      " Loss: 0.000000\n",
      " Loss: 0.014788\n",
      " Loss: 0.000000\n",
      " Loss: 0.033962\n",
      " Loss: 0.000000\n",
      " Loss: 0.036683\n",
      " Loss: 0.000000\n",
      " Loss: 0.020540\n",
      " Loss: 0.000000\n",
      " Loss: 0.058934\n",
      "Epoch 1272 Chain 0 loss std 1.30e-03 variance 8.46e-07 smooth variance 6.98e-07 adaptive c -1.00\n",
      "Epoch 1272 Chain 1 loss std 2.71e+02 variance 3.67e+04 smooth variance 2.68e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032208\n",
      " Loss: 0.000000\n",
      " Loss: 0.030541\n",
      " Loss: 0.000000\n",
      " Loss: 0.019626\n",
      " Loss: 0.000000\n",
      " Loss: 0.063350\n",
      " Loss: 0.000000\n",
      " Loss: 0.019112\n",
      " Loss: 0.000000\n",
      " Loss: 0.013758\n",
      " Loss: 0.000000\n",
      " Loss: 0.067186\n",
      " Loss: 0.000000\n",
      " Loss: 0.036464\n",
      " Loss: 0.000000\n",
      " Loss: 0.025044\n",
      " Loss: 0.000000\n",
      " Loss: 0.022363\n",
      "Epoch 1274 Chain 0 loss std 4.60e-04 variance 1.06e-07 smooth variance 5.20e-07 adaptive c -1.00\n",
      "Epoch 1274 Chain 1 loss std 1.72e+02 variance 1.49e+04 smooth variance 2.32e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.034255\n",
      " Loss: 0.000000\n",
      " Loss: 0.019949\n",
      " Loss: 0.000000\n",
      " Loss: 0.029248\n",
      " Loss: 0.000000\n",
      " Loss: 0.018902\n",
      " Loss: 0.000000\n",
      " Loss: 0.062384\n",
      " Loss: 0.000000\n",
      " Loss: 0.020701\n",
      " Loss: 0.000000\n",
      " Loss: 0.061771\n",
      " Loss: 0.000000\n",
      " Loss: 0.023634\n",
      " Loss: 0.000000\n",
      " Loss: 0.028544\n",
      " Loss: 0.000000\n",
      " Loss: 0.030054\n",
      "Epoch 1276 Chain 0 loss std 1.39e-03 variance 9.65e-07 smooth variance 6.54e-07 adaptive c -1.00\n",
      "Epoch 1276 Chain 1 loss std 1.60e+02 variance 1.28e+04 smooth variance 2.01e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.063443\n",
      " Loss: 0.000000\n",
      " Loss: 0.022582\n",
      " Loss: 0.000000\n",
      " Loss: 0.027960\n",
      " Loss: 0.000000\n",
      " Loss: 0.021235\n",
      " Loss: 0.000000\n",
      " Loss: 0.029421\n",
      " Loss: 0.000000\n",
      " Loss: 0.073752\n",
      " Loss: 0.000000\n",
      " Loss: 0.018702\n",
      " Loss: 0.000000\n",
      " Loss: 0.038454\n",
      " Loss: 0.000000\n",
      " Loss: 0.019291\n",
      " Loss: 0.000000\n",
      " Loss: 0.014329\n",
      "Epoch 1278 Chain 0 loss std 8.05e-04 variance 3.24e-07 smooth variance 5.55e-07 adaptive c -1.00\n",
      "Epoch 1278 Chain 1 loss std 2.08e+02 variance 2.17e+04 smooth variance 2.06e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016894\n",
      " Loss: 0.000000\n",
      " Loss: 0.025283\n",
      " Loss: 0.000000\n",
      " Loss: 0.057838\n",
      " Loss: 0.000000\n",
      " Loss: 0.043416\n",
      " Loss: 0.000000\n",
      " Loss: 0.020997\n",
      " Loss: 0.000000\n",
      " Loss: 0.067707\n",
      " Loss: 0.000000\n",
      " Loss: 0.038398\n",
      " Loss: 0.000000\n",
      " Loss: 0.024629\n",
      " Loss: 0.000000\n",
      " Loss: 0.018407\n",
      " Loss: 0.000000\n",
      " Loss: 0.015245\n",
      "Epoch 1280 Chain 0 loss std 8.71e-04 variance 3.79e-07 smooth variance 5.02e-07 adaptive c -1.00\n",
      "Epoch 1280 Chain 1 loss std 1.69e+02 variance 1.43e+04 smooth variance 1.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.063889\n",
      " Loss: 0.000000\n",
      " Loss: 0.018369\n",
      " Loss: 0.000000\n",
      " Loss: 0.025878\n",
      " Loss: 0.000000\n",
      " Loss: 0.020038\n",
      " Loss: 0.000000\n",
      " Loss: 0.036187\n",
      " Loss: 0.000000\n",
      " Loss: 0.039767\n",
      " Loss: 0.000000\n",
      " Loss: 0.060744\n",
      " Loss: 0.000000\n",
      " Loss: 0.019035\n",
      " Loss: 0.000000\n",
      " Loss: 0.017299\n",
      " Loss: 0.000000\n",
      " Loss: 0.027440\n",
      "Epoch 1282 Chain 0 loss std 1.08e-03 variance 5.81e-07 smooth variance 5.26e-07 adaptive c -1.00\n",
      "Epoch 1282 Chain 1 loss std 2.89e+02 variance 4.17e+04 smooth variance 2.56e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028356\n",
      " Loss: 0.000000\n",
      " Loss: 0.014413\n",
      " Loss: 0.000000\n",
      " Loss: 0.012291\n",
      " Loss: 0.000000\n",
      " Loss: 0.064255\n",
      " Loss: 0.000000\n",
      " Loss: 0.044897\n",
      " Loss: 0.000000\n",
      " Loss: 0.033216\n",
      " Loss: 0.000000\n",
      " Loss: 0.021329\n",
      " Loss: 0.000000\n",
      " Loss: 0.019034\n",
      " Loss: 0.000000\n",
      " Loss: 0.030647\n",
      " Loss: 0.000000\n",
      " Loss: 0.060020\n",
      "Epoch 1284 Chain 0 loss std 1.32e-03 variance 8.66e-07 smooth variance 6.28e-07 adaptive c -1.00\n",
      "Epoch 1284 Chain 1 loss std 1.99e+02 variance 1.98e+04 smooth variance 2.39e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015486\n",
      " Loss: 0.000000\n",
      " Loss: 0.015643\n",
      " Loss: 0.000000\n",
      " Loss: 0.024573\n",
      " Loss: 0.000000\n",
      " Loss: 0.069143\n",
      " Loss: 0.000000\n",
      " Loss: 0.039271\n",
      " Loss: 0.000000\n",
      " Loss: 0.013250\n",
      " Loss: 0.000000\n",
      " Loss: 0.022236\n",
      " Loss: 0.000000\n",
      " Loss: 0.021193\n",
      " Loss: 0.000000\n",
      " Loss: 0.071284\n",
      " Loss: 0.000000\n",
      " Loss: 0.036096\n",
      "Epoch 1286 Chain 0 loss std 7.52e-04 variance 2.83e-07 smooth variance 5.24e-07 adaptive c -1.00\n",
      "Epoch 1286 Chain 1 loss std 2.20e+02 variance 2.42e+04 smooth variance 2.40e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027707\n",
      " Loss: 0.000000\n",
      " Loss: 0.026122\n",
      " Loss: 0.000000\n",
      " Loss: 0.059650\n",
      " Loss: 0.000000\n",
      " Loss: 0.025874\n",
      " Loss: 0.000000\n",
      " Loss: 0.024667\n",
      " Loss: 0.000000\n",
      " Loss: 0.012416\n",
      " Loss: 0.000000\n",
      " Loss: 0.018404\n",
      " Loss: 0.000000\n",
      " Loss: 0.038049\n",
      " Loss: 0.000000\n",
      " Loss: 0.067265\n",
      " Loss: 0.000000\n",
      " Loss: 0.027820\n",
      "Epoch 1288 Chain 0 loss std 8.57e-04 variance 3.67e-07 smooth variance 4.77e-07 adaptive c -1.00\n",
      "Epoch 1288 Chain 1 loss std 1.66e+02 variance 1.37e+04 smooth variance 2.09e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037900\n",
      " Loss: 0.000000\n",
      " Loss: 0.030802\n",
      " Loss: 0.000000\n",
      " Loss: 0.054961\n",
      " Loss: 0.000000\n",
      " Loss: 0.024586\n",
      " Loss: 0.000000\n",
      " Loss: 0.015659\n",
      " Loss: 0.000000\n",
      " Loss: 0.022609\n",
      " Loss: 0.000000\n",
      " Loss: 0.015925\n",
      " Loss: 0.000000\n",
      " Loss: 0.077233\n",
      " Loss: 0.000000\n",
      " Loss: 0.017680\n",
      " Loss: 0.000000\n",
      " Loss: 0.030394\n",
      "Epoch 1290 Chain 0 loss std 1.20e-03 variance 7.17e-07 smooth variance 5.49e-07 adaptive c -1.00\n",
      "Epoch 1290 Chain 1 loss std 2.60e+02 variance 3.38e+04 smooth variance 2.48e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028822\n",
      " Loss: 0.000000\n",
      " Loss: 0.015637\n",
      " Loss: 0.000000\n",
      " Loss: 0.028335\n",
      " Loss: 0.000000\n",
      " Loss: 0.067127\n",
      " Loss: 0.000000\n",
      " Loss: 0.023902\n",
      " Loss: 0.000000\n",
      " Loss: 0.029827\n",
      " Loss: 0.000000\n",
      " Loss: 0.057252\n",
      " Loss: 0.000000\n",
      " Loss: 0.029733\n",
      " Loss: 0.000000\n",
      " Loss: 0.026625\n",
      " Loss: 0.000000\n",
      " Loss: 0.020337\n",
      "Epoch 1292 Chain 0 loss std 8.43e-04 variance 3.56e-07 smooth variance 4.91e-07 adaptive c -1.00\n",
      "Epoch 1292 Chain 1 loss std 3.22e+02 variance 5.18e+04 smooth variance 3.29e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.039859\n",
      " Loss: 0.000000\n",
      " Loss: 0.024123\n",
      " Loss: 0.000000\n",
      " Loss: 0.018915\n",
      " Loss: 0.000000\n",
      " Loss: 0.054424\n",
      " Loss: 0.000000\n",
      " Loss: 0.026398\n",
      " Loss: 0.000000\n",
      " Loss: 0.040813\n",
      " Loss: 0.000000\n",
      " Loss: 0.015326\n",
      " Loss: 0.000000\n",
      " Loss: 0.016058\n",
      " Loss: 0.000000\n",
      " Loss: 0.026670\n",
      " Loss: 0.000000\n",
      " Loss: 0.064838\n",
      "Epoch 1294 Chain 0 loss std 1.08e-03 variance 5.86e-07 smooth variance 5.20e-07 adaptive c -1.00\n",
      "Epoch 1294 Chain 1 loss std 1.83e+02 variance 1.68e+04 smooth variance 2.80e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.062369\n",
      " Loss: 0.000000\n",
      " Loss: 0.031714\n",
      " Loss: 0.000000\n",
      " Loss: 0.029140\n",
      " Loss: 0.000000\n",
      " Loss: 0.019529\n",
      " Loss: 0.000000\n",
      " Loss: 0.020893\n",
      " Loss: 0.000000\n",
      " Loss: 0.058233\n",
      " Loss: 0.000000\n",
      " Loss: 0.022675\n",
      " Loss: 0.000000\n",
      " Loss: 0.025554\n",
      " Loss: 0.000000\n",
      " Loss: 0.037132\n",
      " Loss: 0.000000\n",
      " Loss: 0.020004\n",
      "Epoch 1296 Chain 0 loss std 1.58e-03 variance 1.25e-06 smooth variance 7.40e-07 adaptive c -1.00\n",
      "Epoch 1296 Chain 1 loss std 1.87e+02 variance 1.75e+04 smooth variance 2.49e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025506\n",
      " Loss: 0.000000\n",
      " Loss: 0.037351\n",
      " Loss: 0.000000\n",
      " Loss: 0.018493\n",
      " Loss: 0.000000\n",
      " Loss: 0.025390\n",
      " Loss: 0.000000\n",
      " Loss: 0.056845\n",
      " Loss: 0.000000\n",
      " Loss: 0.032778\n",
      " Loss: 0.000000\n",
      " Loss: 0.018395\n",
      " Loss: 0.000000\n",
      " Loss: 0.040486\n",
      " Loss: 0.000000\n",
      " Loss: 0.015003\n",
      " Loss: 0.000000\n",
      " Loss: 0.056837\n",
      "Epoch 1298 Chain 0 loss std 8.81e-04 variance 3.88e-07 smooth variance 6.35e-07 adaptive c -1.00\n",
      "Epoch 1298 Chain 1 loss std 2.89e+02 variance 4.16e+04 smooth variance 2.99e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.031265\n",
      " Loss: 0.000000\n",
      " Loss: 0.019515\n",
      " Loss: 0.000000\n",
      " Loss: 0.012255\n",
      " Loss: 0.000000\n",
      " Loss: 0.016355\n",
      " Loss: 0.000000\n",
      " Loss: 0.084043\n",
      " Loss: 0.000000\n",
      " Loss: 0.012518\n",
      " Loss: 0.000000\n",
      " Loss: 0.044116\n",
      " Loss: 0.000000\n",
      " Loss: 0.020914\n",
      " Loss: 0.000000\n",
      " Loss: 0.060595\n",
      " Loss: 0.000000\n",
      " Loss: 0.025276\n",
      "Epoch 1300 Chain 0 loss std 1.50e-03 variance 1.12e-06 smooth variance 7.81e-07 adaptive c -1.00\n",
      "Epoch 1300 Chain 1 loss std 2.09e+02 variance 2.18e+04 smooth variance 2.75e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033496\n",
      " Loss: 0.000000\n",
      " Loss: 0.014498\n",
      " Loss: 0.000000\n",
      " Loss: 0.021189\n",
      " Loss: 0.000000\n",
      " Loss: 0.061724\n",
      " Loss: 0.000000\n",
      " Loss: 0.032449\n",
      " Loss: 0.000000\n",
      " Loss: 0.056670\n",
      " Loss: 0.000000\n",
      " Loss: 0.013513\n",
      " Loss: 0.000000\n",
      " Loss: 0.042612\n",
      " Loss: 0.000000\n",
      " Loss: 0.033209\n",
      " Loss: 0.000000\n",
      " Loss: 0.017348\n",
      "Epoch 1302 Chain 0 loss std 7.38e-04 variance 2.72e-07 smooth variance 6.28e-07 adaptive c -1.00\n",
      "Epoch 1302 Chain 1 loss std 1.79e+02 variance 1.59e+04 smooth variance 2.40e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018995\n",
      " Loss: 0.000000\n",
      " Loss: 0.046162\n",
      " Loss: 0.000000\n",
      " Loss: 0.013668\n",
      " Loss: 0.000000\n",
      " Loss: 0.073229\n",
      " Loss: 0.000000\n",
      " Loss: 0.011256\n",
      " Loss: 0.000000\n",
      " Loss: 0.016037\n",
      " Loss: 0.000000\n",
      " Loss: 0.029201\n",
      " Loss: 0.000000\n",
      " Loss: 0.018022\n",
      " Loss: 0.000000\n",
      " Loss: 0.085275\n",
      " Loss: 0.000000\n",
      " Loss: 0.014695\n",
      "Epoch 1304 Chain 0 loss std 1.70e-03 variance 1.44e-06 smooth variance 8.73e-07 adaptive c -1.00\n",
      "Epoch 1304 Chain 1 loss std 2.06e+02 variance 2.12e+04 smooth variance 2.32e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.066505\n",
      " Loss: 0.000000\n",
      " Loss: 0.022142\n",
      " Loss: 0.000000\n",
      " Loss: 0.035064\n",
      " Loss: 0.000000\n",
      " Loss: 0.013473\n",
      " Loss: 0.000000\n",
      " Loss: 0.026028\n",
      " Loss: 0.000000\n",
      " Loss: 0.021022\n",
      " Loss: 0.000000\n",
      " Loss: 0.066895\n",
      " Loss: 0.000000\n",
      " Loss: 0.011261\n",
      " Loss: 0.000000\n",
      " Loss: 0.022703\n",
      " Loss: 0.000000\n",
      " Loss: 0.041304\n",
      "Epoch 1306 Chain 0 loss std 1.23e-03 variance 7.60e-07 smooth variance 8.39e-07 adaptive c -1.00\n",
      "Epoch 1306 Chain 1 loss std 2.54e+02 variance 3.22e+04 smooth variance 2.59e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026270\n",
      " Loss: 0.000000\n",
      " Loss: 0.025562\n",
      " Loss: 0.000000\n",
      " Loss: 0.035360\n",
      " Loss: 0.000000\n",
      " Loss: 0.056710\n",
      " Loss: 0.000000\n",
      " Loss: 0.019229\n",
      " Loss: 0.000000\n",
      " Loss: 0.071728\n",
      " Loss: 0.000000\n",
      " Loss: 0.020869\n",
      " Loss: 0.000000\n",
      " Loss: 0.023047\n",
      " Loss: 0.000000\n",
      " Loss: 0.029093\n",
      " Loss: 0.000000\n",
      " Loss: 0.018364\n",
      "Epoch 1308 Chain 0 loss std 1.33e-03 variance 8.90e-07 smooth variance 8.55e-07 adaptive c -1.00\n",
      "Epoch 1308 Chain 1 loss std 2.26e+02 variance 2.55e+04 smooth variance 2.58e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016618\n",
      " Loss: 0.000000\n",
      " Loss: 0.013672\n",
      " Loss: 0.000000\n",
      " Loss: 0.079694\n",
      " Loss: 0.000000\n",
      " Loss: 0.017408\n",
      " Loss: 0.000000\n",
      " Loss: 0.035634\n",
      " Loss: 0.000000\n",
      " Loss: 0.020463\n",
      " Loss: 0.000000\n",
      " Loss: 0.067990\n",
      " Loss: 0.000000\n",
      " Loss: 0.016955\n",
      " Loss: 0.000000\n",
      " Loss: 0.015537\n",
      " Loss: 0.000000\n",
      " Loss: 0.042090\n",
      "Epoch 1310 Chain 0 loss std 1.31e-03 variance 8.65e-07 smooth variance 8.58e-07 adaptive c -1.00\n",
      "Epoch 1310 Chain 1 loss std 2.66e+02 variance 3.54e+04 smooth variance 2.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016021\n",
      " Loss: 0.000000\n",
      " Loss: 0.032103\n",
      " Loss: 0.000000\n",
      " Loss: 0.016173\n",
      " Loss: 0.000000\n",
      " Loss: 0.061962\n",
      " Loss: 0.000000\n",
      " Loss: 0.036702\n",
      " Loss: 0.000000\n",
      " Loss: 0.017203\n",
      " Loss: 0.000000\n",
      " Loss: 0.041198\n",
      " Loss: 0.000000\n",
      " Loss: 0.063956\n",
      " Loss: 0.000000\n",
      " Loss: 0.027215\n",
      " Loss: 0.000000\n",
      " Loss: 0.013362\n",
      "Epoch 1312 Chain 0 loss std 8.46e-04 variance 3.58e-07 smooth variance 7.08e-07 adaptive c -1.00\n",
      "Epoch 1312 Chain 1 loss std 2.28e+02 variance 2.60e+04 smooth variance 2.79e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023729\n",
      " Loss: 0.000000\n",
      " Loss: 0.036620\n",
      " Loss: 0.000000\n",
      " Loss: 0.058533\n",
      " Loss: 0.000000\n",
      " Loss: 0.028916\n",
      " Loss: 0.000000\n",
      " Loss: 0.015125\n",
      " Loss: 0.000000\n",
      " Loss: 0.025924\n",
      " Loss: 0.000000\n",
      " Loss: 0.018909\n",
      " Loss: 0.000000\n",
      " Loss: 0.041120\n",
      " Loss: 0.000000\n",
      " Loss: 0.018526\n",
      " Loss: 0.000000\n",
      " Loss: 0.058414\n",
      "Epoch 1314 Chain 0 loss std 9.32e-04 variance 4.34e-07 smooth variance 6.26e-07 adaptive c -1.00\n",
      "Epoch 1314 Chain 1 loss std 2.98e+02 variance 4.43e+04 smooth variance 3.28e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033817\n",
      " Loss: 0.000000\n",
      " Loss: 0.026950\n",
      " Loss: 0.000000\n",
      " Loss: 0.023414\n",
      " Loss: 0.000000\n",
      " Loss: 0.017514\n",
      " Loss: 0.000000\n",
      " Loss: 0.061169\n",
      " Loss: 0.000000\n",
      " Loss: 0.069639\n",
      " Loss: 0.000000\n",
      " Loss: 0.028073\n",
      " Loss: 0.000000\n",
      " Loss: 0.028007\n",
      " Loss: 0.000000\n",
      " Loss: 0.021749\n",
      " Loss: 0.000000\n",
      " Loss: 0.015350\n",
      "Epoch 1316 Chain 0 loss std 8.04e-04 variance 3.23e-07 smooth variance 5.35e-07 adaptive c -1.00\n",
      "Epoch 1316 Chain 1 loss std 1.81e+02 variance 1.63e+04 smooth variance 2.79e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.013304\n",
      " Loss: 0.000000\n",
      " Loss: 0.062512\n",
      " Loss: 0.000000\n",
      " Loss: 0.044607\n",
      " Loss: 0.000000\n",
      " Loss: 0.022063\n",
      " Loss: 0.000000\n",
      " Loss: 0.020293\n",
      " Loss: 0.000000\n",
      " Loss: 0.059307\n",
      " Loss: 0.000000\n",
      " Loss: 0.020074\n",
      " Loss: 0.000000\n",
      " Loss: 0.023878\n",
      " Loss: 0.000000\n",
      " Loss: 0.029726\n",
      " Loss: 0.000000\n",
      " Loss: 0.029812\n",
      "Epoch 1318 Chain 0 loss std 8.12e-04 variance 3.29e-07 smooth variance 4.73e-07 adaptive c -1.00\n",
      "Epoch 1318 Chain 1 loss std 1.74e+02 variance 1.51e+04 smooth variance 2.40e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015594\n",
      " Loss: 0.000000\n",
      " Loss: 0.036432\n",
      " Loss: 0.000000\n",
      " Loss: 0.025506\n",
      " Loss: 0.000000\n",
      " Loss: 0.019047\n",
      " Loss: 0.000000\n",
      " Loss: 0.066178\n",
      " Loss: 0.000000\n",
      " Loss: 0.025474\n",
      " Loss: 0.000000\n",
      " Loss: 0.019160\n",
      " Loss: 0.000000\n",
      " Loss: 0.083232\n",
      " Loss: 0.000000\n",
      " Loss: 0.020074\n",
      " Loss: 0.000000\n",
      " Loss: 0.014739\n",
      "Epoch 1320 Chain 0 loss std 1.31e-03 variance 8.63e-07 smooth variance 5.90e-07 adaptive c -1.00\n",
      "Epoch 1320 Chain 1 loss std 1.51e+02 variance 1.14e+04 smooth variance 2.02e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036894\n",
      " Loss: 0.000000\n",
      " Loss: 0.022122\n",
      " Loss: 0.000000\n",
      " Loss: 0.017484\n",
      " Loss: 0.000000\n",
      " Loss: 0.065197\n",
      " Loss: 0.000000\n",
      " Loss: 0.020979\n",
      " Loss: 0.000000\n",
      " Loss: 0.018707\n",
      " Loss: 0.000000\n",
      " Loss: 0.035975\n",
      " Loss: 0.000000\n",
      " Loss: 0.017945\n",
      " Loss: 0.000000\n",
      " Loss: 0.032663\n",
      " Loss: 0.000000\n",
      " Loss: 0.057325\n",
      "Epoch 1322 Chain 0 loss std 8.77e-04 variance 3.85e-07 smooth variance 5.29e-07 adaptive c -1.00\n",
      "Epoch 1322 Chain 1 loss std 2.40e+02 variance 2.87e+04 smooth variance 2.28e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.031757\n",
      " Loss: 0.000000\n",
      " Loss: 0.061826\n",
      " Loss: 0.000000\n",
      " Loss: 0.032381\n",
      " Loss: 0.000000\n",
      " Loss: 0.020888\n",
      " Loss: 0.000000\n",
      " Loss: 0.015742\n",
      " Loss: 0.000000\n",
      " Loss: 0.021143\n",
      " Loss: 0.000000\n",
      " Loss: 0.017945\n",
      " Loss: 0.000000\n",
      " Loss: 0.033007\n",
      " Loss: 0.000000\n",
      " Loss: 0.023612\n",
      " Loss: 0.000000\n",
      " Loss: 0.066869\n",
      "Epoch 1324 Chain 0 loss std 1.04e-03 variance 5.43e-07 smooth variance 5.33e-07 adaptive c -1.00\n",
      "Epoch 1324 Chain 1 loss std 2.34e+02 variance 2.75e+04 smooth variance 2.42e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036872\n",
      " Loss: 0.000000\n",
      " Loss: 0.019630\n",
      " Loss: 0.000000\n",
      " Loss: 0.058465\n",
      " Loss: 0.000000\n",
      " Loss: 0.028461\n",
      " Loss: 0.000000\n",
      " Loss: 0.019107\n",
      " Loss: 0.000000\n",
      " Loss: 0.036974\n",
      " Loss: 0.000000\n",
      " Loss: 0.060770\n",
      " Loss: 0.000000\n",
      " Loss: 0.013677\n",
      " Loss: 0.000000\n",
      " Loss: 0.018231\n",
      " Loss: 0.000000\n",
      " Loss: 0.032850\n",
      "Epoch 1326 Chain 0 loss std 9.76e-04 variance 4.76e-07 smooth variance 5.16e-07 adaptive c -1.00\n",
      "Epoch 1326 Chain 1 loss std 1.97e+02 variance 1.93e+04 smooth variance 2.27e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.013939\n",
      " Loss: 0.000000\n",
      " Loss: 0.047495\n",
      " Loss: 0.000000\n",
      " Loss: 0.018039\n",
      " Loss: 0.000000\n",
      " Loss: 0.060220\n",
      " Loss: 0.000000\n",
      " Loss: 0.022788\n",
      " Loss: 0.000000\n",
      " Loss: 0.021176\n",
      " Loss: 0.000000\n",
      " Loss: 0.019775\n",
      " Loss: 0.000000\n",
      " Loss: 0.025908\n",
      " Loss: 0.000000\n",
      " Loss: 0.017160\n",
      " Loss: 0.000000\n",
      " Loss: 0.078426\n",
      "Epoch 1328 Chain 0 loss std 7.36e-04 variance 2.71e-07 smooth variance 4.42e-07 adaptive c -1.00\n",
      "Epoch 1328 Chain 1 loss std 2.08e+02 variance 2.16e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.062875\n",
      " Loss: 0.000000\n",
      " Loss: 0.039733\n",
      " Loss: 0.000000\n",
      " Loss: 0.019116\n",
      " Loss: 0.000000\n",
      " Loss: 0.018295\n",
      " Loss: 0.000000\n",
      " Loss: 0.022409\n",
      " Loss: 0.000000\n",
      " Loss: 0.026102\n",
      " Loss: 0.000000\n",
      " Loss: 0.020892\n",
      " Loss: 0.000000\n",
      " Loss: 0.060476\n",
      " Loss: 0.000000\n",
      " Loss: 0.023150\n",
      " Loss: 0.000000\n",
      " Loss: 0.031786\n",
      "Epoch 1330 Chain 0 loss std 6.07e-04 variance 1.84e-07 smooth variance 3.65e-07 adaptive c -1.00\n",
      "Epoch 1330 Chain 1 loss std 2.30e+02 variance 2.65e+04 smooth variance 2.36e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018506\n",
      " Loss: 0.000000\n",
      " Loss: 0.063194\n",
      " Loss: 0.000000\n",
      " Loss: 0.015594\n",
      " Loss: 0.000000\n",
      " Loss: 0.042319\n",
      " Loss: 0.000000\n",
      " Loss: 0.022768\n",
      " Loss: 0.000000\n",
      " Loss: 0.038417\n",
      " Loss: 0.000000\n",
      " Loss: 0.065139\n",
      " Loss: 0.000000\n",
      " Loss: 0.016051\n",
      " Loss: 0.000000\n",
      " Loss: 0.024231\n",
      " Loss: 0.000000\n",
      " Loss: 0.018520\n",
      "Epoch 1332 Chain 0 loss std 9.73e-04 variance 4.73e-07 smooth variance 3.98e-07 adaptive c -1.00\n",
      "Epoch 1332 Chain 1 loss std 2.64e+02 variance 3.48e+04 smooth variance 2.70e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028835\n",
      " Loss: 0.000000\n",
      " Loss: 0.027678\n",
      " Loss: 0.000000\n",
      " Loss: 0.070632\n",
      " Loss: 0.000000\n",
      " Loss: 0.018282\n",
      " Loss: 0.000000\n",
      " Loss: 0.016916\n",
      " Loss: 0.000000\n",
      " Loss: 0.033186\n",
      " Loss: 0.000000\n",
      " Loss: 0.021263\n",
      " Loss: 0.000000\n",
      " Loss: 0.061216\n",
      " Loss: 0.000000\n",
      " Loss: 0.023689\n",
      " Loss: 0.000000\n",
      " Loss: 0.022949\n",
      "Epoch 1334 Chain 0 loss std 7.68e-04 variance 2.95e-07 smooth variance 3.67e-07 adaptive c -1.00\n",
      "Epoch 1334 Chain 1 loss std 2.08e+02 variance 2.17e+04 smooth variance 2.54e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.062536\n",
      " Loss: 0.000000\n",
      " Loss: 0.028251\n",
      " Loss: 0.000000\n",
      " Loss: 0.035042\n",
      " Loss: 0.000000\n",
      " Loss: 0.022798\n",
      " Loss: 0.000000\n",
      " Loss: 0.013662\n",
      " Loss: 0.000000\n",
      " Loss: 0.018644\n",
      " Loss: 0.000000\n",
      " Loss: 0.025781\n",
      " Loss: 0.000000\n",
      " Loss: 0.014711\n",
      " Loss: 0.000000\n",
      " Loss: 0.023569\n",
      " Loss: 0.000000\n",
      " Loss: 0.079541\n",
      "Epoch 1336 Chain 0 loss std 1.37e-03 variance 9.35e-07 smooth variance 5.37e-07 adaptive c -1.00\n",
      "Epoch 1336 Chain 1 loss std 1.49e+02 variance 1.12e+04 smooth variance 2.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027202\n",
      " Loss: 0.000000\n",
      " Loss: 0.022827\n",
      " Loss: 0.000000\n",
      " Loss: 0.036688\n",
      " Loss: 0.000000\n",
      " Loss: 0.013494\n",
      " Loss: 0.000000\n",
      " Loss: 0.062027\n",
      " Loss: 0.000000\n",
      " Loss: 0.016947\n",
      " Loss: 0.000000\n",
      " Loss: 0.015046\n",
      " Loss: 0.000000\n",
      " Loss: 0.018823\n",
      " Loss: 0.000000\n",
      " Loss: 0.042085\n",
      " Loss: 0.000000\n",
      " Loss: 0.069306\n",
      "Epoch 1338 Chain 0 loss std 1.52e-03 variance 1.16e-06 smooth variance 7.23e-07 adaptive c -1.00\n",
      "Epoch 1338 Chain 1 loss std 2.05e+02 variance 2.10e+04 smooth variance 2.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016140\n",
      " Loss: 0.000000\n",
      " Loss: 0.064905\n",
      " Loss: 0.000000\n",
      " Loss: 0.033744\n",
      " Loss: 0.000000\n",
      " Loss: 0.027545\n",
      " Loss: 0.000000\n",
      " Loss: 0.019856\n",
      " Loss: 0.000000\n",
      " Loss: 0.069641\n",
      " Loss: 0.000000\n",
      " Loss: 0.012895\n",
      " Loss: 0.000000\n",
      " Loss: 0.046011\n",
      " Loss: 0.000000\n",
      " Loss: 0.009529\n",
      " Loss: 0.000000\n",
      " Loss: 0.024111\n",
      "Epoch 1340 Chain 0 loss std 9.37e-04 variance 4.39e-07 smooth variance 6.38e-07 adaptive c -1.00\n",
      "Epoch 1340 Chain 1 loss std 1.55e+02 variance 1.21e+04 smooth variance 1.84e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.064466\n",
      " Loss: 0.000000\n",
      " Loss: 0.040952\n",
      " Loss: 0.000000\n",
      " Loss: 0.013066\n",
      " Loss: 0.000000\n",
      " Loss: 0.027327\n",
      " Loss: 0.000000\n",
      " Loss: 0.016335\n",
      " Loss: 0.000000\n",
      " Loss: 0.028152\n",
      " Loss: 0.000000\n",
      " Loss: 0.024328\n",
      " Loss: 0.000000\n",
      " Loss: 0.024031\n",
      " Loss: 0.000000\n",
      " Loss: 0.024122\n",
      " Loss: 0.000000\n",
      " Loss: 0.061518\n",
      "Epoch 1342 Chain 0 loss std 1.33e-03 variance 8.88e-07 smooth variance 7.13e-07 adaptive c -1.00\n",
      "Epoch 1342 Chain 1 loss std 1.98e+02 variance 1.95e+04 smooth variance 1.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.066101\n",
      " Loss: 0.000000\n",
      " Loss: 0.023412\n",
      " Loss: 0.000000\n",
      " Loss: 0.030613\n",
      " Loss: 0.000000\n",
      " Loss: 0.024590\n",
      " Loss: 0.000000\n",
      " Loss: 0.017397\n",
      " Loss: 0.000000\n",
      " Loss: 0.026524\n",
      " Loss: 0.000000\n",
      " Loss: 0.015396\n",
      " Loss: 0.000000\n",
      " Loss: 0.037054\n",
      " Loss: 0.000000\n",
      " Loss: 0.026982\n",
      " Loss: 0.000001\n",
      " Loss: 0.056134\n",
      "Epoch 1344 Chain 0 loss std 7.92e-04 variance 3.14e-07 smooth variance 5.93e-07 adaptive c -1.00\n",
      "Epoch 1344 Chain 1 loss std 2.99e+02 variance 4.48e+04 smooth variance 2.65e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.038475\n",
      " Loss: 0.000000\n",
      " Loss: 0.064335\n",
      " Loss: 0.000000\n",
      " Loss: 0.017435\n",
      " Loss: 0.000000\n",
      " Loss: 0.013316\n",
      " Loss: 0.000000\n",
      " Loss: 0.028499\n",
      " Loss: 0.000000\n",
      " Loss: 0.021012\n",
      " Loss: 0.000000\n",
      " Loss: 0.019703\n",
      " Loss: 0.000000\n",
      " Loss: 0.028610\n",
      " Loss: 0.000000\n",
      " Loss: 0.071019\n",
      " Loss: 0.000000\n",
      " Loss: 0.021697\n",
      "Epoch 1346 Chain 0 loss std 9.94e-04 variance 4.94e-07 smooth variance 5.63e-07 adaptive c -1.00\n",
      "Epoch 1346 Chain 1 loss std 1.90e+02 variance 1.81e+04 smooth variance 2.40e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.085336\n",
      " Loss: 0.000000\n",
      " Loss: 0.032145\n",
      " Loss: 0.000000\n",
      " Loss: 0.014022\n",
      " Loss: 0.000000\n",
      " Loss: 0.015112\n",
      " Loss: 0.000000\n",
      " Loss: 0.015398\n",
      " Loss: 0.000000\n",
      " Loss: 0.041607\n",
      " Loss: 0.000000\n",
      " Loss: 0.063819\n",
      " Loss: 0.000000\n",
      " Loss: 0.013011\n",
      " Loss: 0.000000\n",
      " Loss: 0.021192\n",
      " Loss: 0.000000\n",
      " Loss: 0.022377\n",
      "Epoch 1348 Chain 0 loss std 8.21e-04 variance 3.37e-07 smooth variance 4.95e-07 adaptive c -1.00\n",
      "Epoch 1348 Chain 1 loss std 1.66e+02 variance 1.37e+04 smooth variance 2.09e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022339\n",
      " Loss: 0.000000\n",
      " Loss: 0.013835\n",
      " Loss: 0.000000\n",
      " Loss: 0.035882\n",
      " Loss: 0.000000\n",
      " Loss: 0.070950\n",
      " Loss: 0.000000\n",
      " Loss: 0.018974\n",
      " Loss: 0.000000\n",
      " Loss: 0.016130\n",
      " Loss: 0.000000\n",
      " Loss: 0.026839\n",
      " Loss: 0.000000\n",
      " Loss: 0.017470\n",
      " Loss: 0.000000\n",
      " Loss: 0.063648\n",
      " Loss: 0.000000\n",
      " Loss: 0.037875\n",
      "Epoch 1350 Chain 0 loss std 7.40e-04 variance 2.74e-07 smooth variance 4.29e-07 adaptive c -1.00\n",
      "Epoch 1350 Chain 1 loss std 1.93e+02 variance 1.86e+04 smooth variance 2.02e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.076589\n",
      " Loss: 0.000000\n",
      " Loss: 0.014337\n",
      " Loss: 0.000000\n",
      " Loss: 0.016743\n",
      " Loss: 0.000000\n",
      " Loss: 0.019248\n",
      " Loss: 0.000000\n",
      " Loss: 0.035050\n",
      " Loss: 0.000000\n",
      " Loss: 0.034292\n",
      " Loss: 0.000000\n",
      " Loss: 0.015639\n",
      " Loss: 0.000000\n",
      " Loss: 0.031762\n",
      " Loss: 0.000000\n",
      " Loss: 0.024568\n",
      " Loss: 0.000000\n",
      " Loss: 0.055685\n",
      "Epoch 1352 Chain 0 loss std 8.16e-04 variance 3.33e-07 smooth variance 4.00e-07 adaptive c -1.00\n",
      "Epoch 1352 Chain 1 loss std 1.64e+02 variance 1.34e+04 smooth variance 1.82e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.038274\n",
      " Loss: 0.000000\n",
      " Loss: 0.022513\n",
      " Loss: 0.000000\n",
      " Loss: 0.020385\n",
      " Loss: 0.000000\n",
      " Loss: 0.016172\n",
      " Loss: 0.000000\n",
      " Loss: 0.064570\n",
      " Loss: 0.000000\n",
      " Loss: 0.027993\n",
      " Loss: 0.000000\n",
      " Loss: 0.022546\n",
      " Loss: 0.000000\n",
      " Loss: 0.031516\n",
      " Loss: 0.000000\n",
      " Loss: 0.060644\n",
      " Loss: 0.000000\n",
      " Loss: 0.019188\n",
      "Epoch 1354 Chain 0 loss std 8.43e-04 variance 3.56e-07 smooth variance 3.87e-07 adaptive c -1.00\n",
      "Epoch 1354 Chain 1 loss std 2.15e+02 variance 2.32e+04 smooth variance 1.97e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032479\n",
      " Loss: 0.000000\n",
      " Loss: 0.057528\n",
      " Loss: 0.000000\n",
      " Loss: 0.012366\n",
      " Loss: 0.000000\n",
      " Loss: 0.031966\n",
      " Loss: 0.000000\n",
      " Loss: 0.027532\n",
      " Loss: 0.000000\n",
      " Loss: 0.022633\n",
      " Loss: 0.000000\n",
      " Loss: 0.059208\n",
      " Loss: 0.000000\n",
      " Loss: 0.020086\n",
      " Loss: 0.000000\n",
      " Loss: 0.031223\n",
      " Loss: 0.000000\n",
      " Loss: 0.028716\n",
      "Epoch 1356 Chain 0 loss std 1.17e-03 variance 6.85e-07 smooth variance 4.76e-07 adaptive c -1.00\n",
      "Epoch 1356 Chain 1 loss std 1.89e+02 variance 1.79e+04 smooth variance 1.92e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022630\n",
      " Loss: 0.000000\n",
      " Loss: 0.060412\n",
      " Loss: 0.000000\n",
      " Loss: 0.019221\n",
      " Loss: 0.000000\n",
      " Loss: 0.015502\n",
      " Loss: 0.000000\n",
      " Loss: 0.044084\n",
      " Loss: 0.000000\n",
      " Loss: 0.019032\n",
      " Loss: 0.000000\n",
      " Loss: 0.039351\n",
      " Loss: 0.000000\n",
      " Loss: 0.018093\n",
      " Loss: 0.000000\n",
      " Loss: 0.057949\n",
      " Loss: 0.000000\n",
      " Loss: 0.027417\n",
      "Epoch 1358 Chain 0 loss std 1.02e-03 variance 5.22e-07 smooth variance 4.90e-07 adaptive c -1.00\n",
      "Epoch 1358 Chain 1 loss std 2.45e+02 variance 2.99e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.080460\n",
      " Loss: 0.000000\n",
      " Loss: 0.022197\n",
      " Loss: 0.000000\n",
      " Loss: 0.026989\n",
      " Loss: 0.000000\n",
      " Loss: 0.013204\n",
      " Loss: 0.000000\n",
      " Loss: 0.018954\n",
      " Loss: 0.000000\n",
      " Loss: 0.027439\n",
      " Loss: 0.000001\n",
      " Loss: 0.060619\n",
      " Loss: 0.000000\n",
      " Loss: 0.022593\n",
      " Loss: 0.000000\n",
      " Loss: 0.033977\n",
      " Loss: 0.000000\n",
      " Loss: 0.017162\n",
      "Epoch 1360 Chain 0 loss std 1.18e-03 variance 6.99e-07 smooth variance 5.53e-07 adaptive c -1.00\n",
      "Epoch 1360 Chain 1 loss std 2.08e+02 variance 2.17e+04 smooth variance 2.22e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021442\n",
      " Loss: 0.000000\n",
      " Loss: 0.019116\n",
      " Loss: 0.000000\n",
      " Loss: 0.018854\n",
      " Loss: 0.000000\n",
      " Loss: 0.085442\n",
      " Loss: 0.000000\n",
      " Loss: 0.016916\n",
      " Loss: 0.000000\n",
      " Loss: 0.064221\n",
      " Loss: 0.000000\n",
      " Loss: 0.041288\n",
      " Loss: 0.000000\n",
      " Loss: 0.019485\n",
      " Loss: 0.000000\n",
      " Loss: 0.021208\n",
      " Loss: 0.000000\n",
      " Loss: 0.015558\n",
      "Epoch 1362 Chain 0 loss std 1.00e-03 variance 5.04e-07 smooth variance 5.38e-07 adaptive c -1.00\n",
      "Epoch 1362 Chain 1 loss std 1.64e+02 variance 1.35e+04 smooth variance 1.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.058295\n",
      " Loss: 0.000000\n",
      " Loss: 0.038312\n",
      " Loss: 0.000000\n",
      " Loss: 0.024603\n",
      " Loss: 0.000000\n",
      " Loss: 0.021752\n",
      " Loss: 0.000000\n",
      " Loss: 0.018782\n",
      " Loss: 0.000000\n",
      " Loss: 0.024300\n",
      " Loss: 0.000000\n",
      " Loss: 0.041104\n",
      " Loss: 0.000001\n",
      " Loss: 0.060166\n",
      " Loss: 0.000000\n",
      " Loss: 0.021923\n",
      " Loss: 0.000000\n",
      " Loss: 0.014239\n",
      "Epoch 1364 Chain 0 loss std 1.50e-03 variance 1.12e-06 smooth variance 7.13e-07 adaptive c -1.00\n",
      "Epoch 1364 Chain 1 loss std 1.68e+02 variance 1.40e+04 smooth variance 1.79e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.065247\n",
      " Loss: 0.000000\n",
      " Loss: 0.020851\n",
      " Loss: 0.000000\n",
      " Loss: 0.022183\n",
      " Loss: 0.000000\n",
      " Loss: 0.029895\n",
      " Loss: 0.000000\n",
      " Loss: 0.023546\n",
      " Loss: 0.000000\n",
      " Loss: 0.015718\n",
      " Loss: 0.000000\n",
      " Loss: 0.017944\n",
      " Loss: 0.000000\n",
      " Loss: 0.044166\n",
      " Loss: 0.000001\n",
      " Loss: 0.066151\n",
      " Loss: 0.000000\n",
      " Loss: 0.017731\n",
      "Epoch 1366 Chain 0 loss std 1.01e-03 variance 5.10e-07 smooth variance 6.52e-07 adaptive c -1.00\n",
      "Epoch 1366 Chain 1 loss std 1.77e+02 variance 1.56e+04 smooth variance 1.72e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032165\n",
      " Loss: 0.000000\n",
      " Loss: 0.021692\n",
      " Loss: 0.000000\n",
      " Loss: 0.014375\n",
      " Loss: 0.000000\n",
      " Loss: 0.059265\n",
      " Loss: 0.000000\n",
      " Loss: 0.034190\n",
      " Loss: 0.000000\n",
      " Loss: 0.019664\n",
      " Loss: 0.000000\n",
      " Loss: 0.020809\n",
      " Loss: 0.000000\n",
      " Loss: 0.024272\n",
      " Loss: 0.000000\n",
      " Loss: 0.059325\n",
      " Loss: 0.000000\n",
      " Loss: 0.037599\n",
      "Epoch 1368 Chain 0 loss std 1.16e-03 variance 6.68e-07 smooth variance 6.57e-07 adaptive c -1.00\n",
      "Epoch 1368 Chain 1 loss std 1.66e+02 variance 1.37e+04 smooth variance 1.62e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035557\n",
      " Loss: 0.000000\n",
      " Loss: 0.021305\n",
      " Loss: 0.000000\n",
      " Loss: 0.012740\n",
      " Loss: 0.000000\n",
      " Loss: 0.077686\n",
      " Loss: 0.000000\n",
      " Loss: 0.014368\n",
      " Loss: 0.000000\n",
      " Loss: 0.060574\n",
      " Loss: 0.000000\n",
      " Loss: 0.041523\n",
      " Loss: 0.000000\n",
      " Loss: 0.024579\n",
      " Loss: 0.000000\n",
      " Loss: 0.017632\n",
      " Loss: 0.000000\n",
      " Loss: 0.017341\n",
      "Epoch 1370 Chain 0 loss std 1.16e-03 variance 6.68e-07 smooth variance 6.60e-07 adaptive c -1.00\n",
      "Epoch 1370 Chain 1 loss std 2.11e+02 variance 2.22e+04 smooth variance 1.80e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018236\n",
      " Loss: 0.000000\n",
      " Loss: 0.058762\n",
      " Loss: 0.000000\n",
      " Loss: 0.028247\n",
      " Loss: 0.000000\n",
      " Loss: 0.042517\n",
      " Loss: 0.000000\n",
      " Loss: 0.013873\n",
      " Loss: 0.000000\n",
      " Loss: 0.017505\n",
      " Loss: 0.000000\n",
      " Loss: 0.025496\n",
      " Loss: 0.000000\n",
      " Loss: 0.036857\n",
      " Loss: 0.000000\n",
      " Loss: 0.061853\n",
      " Loss: 0.000000\n",
      " Loss: 0.019909\n",
      "Epoch 1372 Chain 0 loss std 7.94e-04 variance 3.15e-07 smooth variance 5.56e-07 adaptive c -1.00\n",
      "Epoch 1372 Chain 1 loss std 1.91e+02 variance 1.82e+04 smooth variance 1.80e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037855\n",
      " Loss: 0.000000\n",
      " Loss: 0.058994\n",
      " Loss: 0.000000\n",
      " Loss: 0.020007\n",
      " Loss: 0.000000\n",
      " Loss: 0.020904\n",
      " Loss: 0.000000\n",
      " Loss: 0.023848\n",
      " Loss: 0.000000\n",
      " Loss: 0.024533\n",
      " Loss: 0.000000\n",
      " Loss: 0.030970\n",
      " Loss: 0.000000\n",
      " Loss: 0.015071\n",
      " Loss: 0.000000\n",
      " Loss: 0.077365\n",
      " Loss: 0.000000\n",
      " Loss: 0.013651\n",
      "Epoch 1374 Chain 0 loss std 1.46e-03 variance 1.06e-06 smooth variance 7.08e-07 adaptive c -1.00\n",
      "Epoch 1374 Chain 1 loss std 1.65e+02 variance 1.36e+04 smooth variance 1.67e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.059341\n",
      " Loss: 0.000000\n",
      " Loss: 0.044147\n",
      " Loss: 0.000000\n",
      " Loss: 0.017327\n",
      " Loss: 0.000000\n",
      " Loss: 0.018910\n",
      " Loss: 0.000000\n",
      " Loss: 0.021864\n",
      " Loss: 0.000000\n",
      " Loss: 0.033700\n",
      " Loss: 0.000000\n",
      " Loss: 0.027930\n",
      " Loss: 0.000000\n",
      " Loss: 0.014264\n",
      " Loss: 0.000000\n",
      " Loss: 0.030897\n",
      " Loss: 0.000000\n",
      " Loss: 0.054787\n",
      "Epoch 1376 Chain 0 loss std 1.18e-03 variance 6.93e-07 smooth variance 7.04e-07 adaptive c -1.00\n",
      "Epoch 1376 Chain 1 loss std 3.01e+02 variance 4.52e+04 smooth variance 2.53e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015483\n",
      " Loss: 0.000000\n",
      " Loss: 0.019232\n",
      " Loss: 0.000000\n",
      " Loss: 0.037148\n",
      " Loss: 0.000000\n",
      " Loss: 0.019319\n",
      " Loss: 0.000000\n",
      " Loss: 0.070379\n",
      " Loss: 0.000000\n",
      " Loss: 0.038130\n",
      " Loss: 0.000000\n",
      " Loss: 0.025425\n",
      " Loss: 0.000000\n",
      " Loss: 0.056604\n",
      " Loss: 0.000000\n",
      " Loss: 0.021874\n",
      " Loss: 0.000000\n",
      " Loss: 0.019515\n",
      "Epoch 1378 Chain 0 loss std 9.26e-04 variance 4.29e-07 smooth variance 6.21e-07 adaptive c -1.00\n",
      "Epoch 1378 Chain 1 loss std 1.83e+02 variance 1.67e+04 smooth variance 2.27e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.071097\n",
      " Loss: 0.000000\n",
      " Loss: 0.024679\n",
      " Loss: 0.000000\n",
      " Loss: 0.014879\n",
      " Loss: 0.000000\n",
      " Loss: 0.020299\n",
      " Loss: 0.000000\n",
      " Loss: 0.030577\n",
      " Loss: 0.000000\n",
      " Loss: 0.014353\n",
      " Loss: 0.000000\n",
      " Loss: 0.021381\n",
      " Loss: 0.000000\n",
      " Loss: 0.022092\n",
      " Loss: 0.000000\n",
      " Loss: 0.077694\n",
      " Loss: 0.000000\n",
      " Loss: 0.026009\n",
      "Epoch 1380 Chain 0 loss std 9.50e-04 variance 4.51e-07 smooth variance 5.70e-07 adaptive c -1.00\n",
      "Epoch 1380 Chain 1 loss std 1.85e+02 variance 1.72e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017702\n",
      " Loss: 0.000000\n",
      " Loss: 0.021517\n",
      " Loss: 0.000000\n",
      " Loss: 0.028817\n",
      " Loss: 0.000000\n",
      " Loss: 0.068728\n",
      " Loss: 0.000000\n",
      " Loss: 0.024747\n",
      " Loss: 0.000000\n",
      " Loss: 0.020507\n",
      " Loss: 0.000000\n",
      " Loss: 0.065142\n",
      " Loss: 0.000000\n",
      " Loss: 0.016723\n",
      " Loss: 0.000000\n",
      " Loss: 0.041030\n",
      " Loss: 0.000000\n",
      " Loss: 0.018099\n",
      "Epoch 1382 Chain 0 loss std 7.77e-04 variance 3.02e-07 smooth variance 4.90e-07 adaptive c -1.00\n",
      "Epoch 1382 Chain 1 loss std 1.68e+02 variance 1.42e+04 smooth variance 1.90e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.042636\n",
      " Loss: 0.000000\n",
      " Loss: 0.017409\n",
      " Loss: 0.000000\n",
      " Loss: 0.060682\n",
      " Loss: 0.000000\n",
      " Loss: 0.022819\n",
      " Loss: 0.000000\n",
      " Loss: 0.017951\n",
      " Loss: 0.000000\n",
      " Loss: 0.016992\n",
      " Loss: 0.000000\n",
      " Loss: 0.033843\n",
      " Loss: 0.000000\n",
      " Loss: 0.029211\n",
      " Loss: 0.000000\n",
      " Loss: 0.062650\n",
      " Loss: 0.000000\n",
      " Loss: 0.018785\n",
      "Epoch 1384 Chain 0 loss std 1.04e-03 variance 5.40e-07 smooth variance 5.05e-07 adaptive c -1.00\n",
      "Epoch 1384 Chain 1 loss std 1.63e+02 variance 1.33e+04 smooth variance 1.73e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.068548\n",
      " Loss: 0.000000\n",
      " Loss: 0.019299\n",
      " Loss: 0.000000\n",
      " Loss: 0.013391\n",
      " Loss: 0.000000\n",
      " Loss: 0.035361\n",
      " Loss: 0.000000\n",
      " Loss: 0.024887\n",
      " Loss: 0.000000\n",
      " Loss: 0.015853\n",
      " Loss: 0.000000\n",
      " Loss: 0.042666\n",
      " Loss: 0.000000\n",
      " Loss: 0.022604\n",
      " Loss: 0.000000\n",
      " Loss: 0.066007\n",
      " Loss: 0.000000\n",
      " Loss: 0.014331\n",
      "Epoch 1386 Chain 0 loss std 9.02e-04 variance 4.07e-07 smooth variance 4.75e-07 adaptive c -1.00\n",
      "Epoch 1386 Chain 1 loss std 2.41e+02 variance 2.90e+04 smooth variance 2.08e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016186\n",
      " Loss: 0.000000\n",
      " Loss: 0.042597\n",
      " Loss: 0.000000\n",
      " Loss: 0.019590\n",
      " Loss: 0.000000\n",
      " Loss: 0.061480\n",
      " Loss: 0.000000\n",
      " Loss: 0.021601\n",
      " Loss: 0.000000\n",
      " Loss: 0.036605\n",
      " Loss: 0.000000\n",
      " Loss: 0.013709\n",
      " Loss: 0.000000\n",
      " Loss: 0.021855\n",
      " Loss: 0.000000\n",
      " Loss: 0.024484\n",
      " Loss: 0.000000\n",
      " Loss: 0.064791\n",
      "Epoch 1388 Chain 0 loss std 9.44e-04 variance 4.45e-07 smooth variance 4.66e-07 adaptive c -1.00\n",
      "Epoch 1388 Chain 1 loss std 1.94e+02 variance 1.89e+04 smooth variance 2.02e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023946\n",
      " Loss: 0.000000\n",
      " Loss: 0.020837\n",
      " Loss: 0.000000\n",
      " Loss: 0.058759\n",
      " Loss: 0.000000\n",
      " Loss: 0.019401\n",
      " Loss: 0.000000\n",
      " Loss: 0.038488\n",
      " Loss: 0.000000\n",
      " Loss: 0.059011\n",
      " Loss: 0.000000\n",
      " Loss: 0.029578\n",
      " Loss: 0.000000\n",
      " Loss: 0.015766\n",
      " Loss: 0.000000\n",
      " Loss: 0.033880\n",
      " Loss: 0.000000\n",
      " Loss: 0.023187\n",
      "Epoch 1390 Chain 0 loss std 8.61e-04 variance 3.70e-07 smooth variance 4.38e-07 adaptive c -1.00\n",
      "Epoch 1390 Chain 1 loss std 2.00e+02 variance 2.00e+04 smooth variance 2.02e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026421\n",
      " Loss: 0.000000\n",
      " Loss: 0.030371\n",
      " Loss: 0.000000\n",
      " Loss: 0.027748\n",
      " Loss: 0.000000\n",
      " Loss: 0.015214\n",
      " Loss: 0.000000\n",
      " Loss: 0.061661\n",
      " Loss: 0.000000\n",
      " Loss: 0.018507\n",
      " Loss: 0.000000\n",
      " Loss: 0.024379\n",
      " Loss: 0.000000\n",
      " Loss: 0.032218\n",
      " Loss: 0.000000\n",
      " Loss: 0.021277\n",
      " Loss: 0.000000\n",
      " Loss: 0.065023\n",
      "Epoch 1392 Chain 0 loss std 9.25e-04 variance 4.28e-07 smooth variance 4.35e-07 adaptive c -1.00\n",
      "Epoch 1392 Chain 1 loss std 1.85e+02 variance 1.72e+04 smooth variance 1.93e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018944\n",
      " Loss: 0.000000\n",
      " Loss: 0.046535\n",
      " Loss: 0.000000\n",
      " Loss: 0.061761\n",
      " Loss: 0.000000\n",
      " Loss: 0.024463\n",
      " Loss: 0.000000\n",
      " Loss: 0.009684\n",
      " Loss: 0.000000\n",
      " Loss: 0.015776\n",
      " Loss: 0.000000\n",
      " Loss: 0.067114\n",
      " Loss: 0.000000\n",
      " Loss: 0.032726\n",
      " Loss: 0.000000\n",
      " Loss: 0.015542\n",
      " Loss: 0.000000\n",
      " Loss: 0.030234\n",
      "Epoch 1394 Chain 0 loss std 1.33e-03 variance 8.83e-07 smooth variance 5.69e-07 adaptive c -1.00\n",
      "Epoch 1394 Chain 1 loss std 2.16e+02 variance 2.34e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.031253\n",
      " Loss: 0.000000\n",
      " Loss: 0.021427\n",
      " Loss: 0.000000\n",
      " Loss: 0.020677\n",
      " Loss: 0.000000\n",
      " Loss: 0.052941\n",
      " Loss: 0.000000\n",
      " Loss: 0.035075\n",
      " Loss: 0.000000\n",
      " Loss: 0.022549\n",
      " Loss: 0.000000\n",
      " Loss: 0.021937\n",
      " Loss: 0.000000\n",
      " Loss: 0.044232\n",
      " Loss: 0.000000\n",
      " Loss: 0.059282\n",
      " Loss: 0.000000\n",
      " Loss: 0.013363\n",
      "Epoch 1396 Chain 0 loss std 9.26e-04 variance 4.29e-07 smooth variance 5.27e-07 adaptive c -1.00\n",
      "Epoch 1396 Chain 1 loss std 1.64e+02 variance 1.34e+04 smooth variance 1.84e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.073023\n",
      " Loss: 0.000000\n",
      " Loss: 0.021806\n",
      " Loss: 0.000000\n",
      " Loss: 0.010141\n",
      " Loss: 0.000000\n",
      " Loss: 0.037491\n",
      " Loss: 0.000000\n",
      " Loss: 0.018899\n",
      " Loss: 0.000000\n",
      " Loss: 0.036123\n",
      " Loss: 0.000000\n",
      " Loss: 0.017064\n",
      " Loss: 0.000000\n",
      " Loss: 0.018859\n",
      " Loss: 0.000000\n",
      " Loss: 0.057902\n",
      " Loss: 0.000000\n",
      " Loss: 0.031407\n",
      "Epoch 1398 Chain 0 loss std 1.17e-03 variance 6.86e-07 smooth variance 5.75e-07 adaptive c -1.00\n",
      "Epoch 1398 Chain 1 loss std 2.52e+02 variance 3.17e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036025\n",
      " Loss: 0.000000\n",
      " Loss: 0.015210\n",
      " Loss: 0.000000\n",
      " Loss: 0.060920\n",
      " Loss: 0.000000\n",
      " Loss: 0.031836\n",
      " Loss: 0.000000\n",
      " Loss: 0.017354\n",
      " Loss: 0.000000\n",
      " Loss: 0.044114\n",
      " Loss: 0.000000\n",
      " Loss: 0.017789\n",
      " Loss: 0.000000\n",
      " Loss: 0.021409\n",
      " Loss: 0.000000\n",
      " Loss: 0.060611\n",
      " Loss: 0.000000\n",
      " Loss: 0.017409\n",
      "Epoch 1400 Chain 0 loss std 1.15e-03 variance 6.60e-07 smooth variance 6.00e-07 adaptive c -1.00\n",
      "Epoch 1400 Chain 1 loss std 2.51e+02 variance 3.16e+04 smooth variance 2.51e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024427\n",
      " Loss: 0.000000\n",
      " Loss: 0.021141\n",
      " Loss: 0.000000\n",
      " Loss: 0.014492\n",
      " Loss: 0.000000\n",
      " Loss: 0.035554\n",
      " Loss: 0.000001\n",
      " Loss: 0.065704\n",
      " Loss: 0.000000\n",
      " Loss: 0.063038\n",
      " Loss: 0.000000\n",
      " Loss: 0.024449\n",
      " Loss: 0.000000\n",
      " Loss: 0.033232\n",
      " Loss: 0.000000\n",
      " Loss: 0.024070\n",
      " Loss: 0.000000\n",
      " Loss: 0.016531\n",
      "Epoch 1402 Chain 0 loss std 7.78e-04 variance 3.03e-07 smooth variance 5.11e-07 adaptive c -1.00\n",
      "Epoch 1402 Chain 1 loss std 1.55e+02 variance 1.21e+04 smooth variance 2.12e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019859\n",
      " Loss: 0.000000\n",
      " Loss: 0.037772\n",
      " Loss: 0.000000\n",
      " Loss: 0.017674\n",
      " Loss: 0.000000\n",
      " Loss: 0.061097\n",
      " Loss: 0.000000\n",
      " Loss: 0.024905\n",
      " Loss: 0.000000\n",
      " Loss: 0.016024\n",
      " Loss: 0.000000\n",
      " Loss: 0.021104\n",
      " Loss: 0.000000\n",
      " Loss: 0.019652\n",
      " Loss: 0.000000\n",
      " Loss: 0.024370\n",
      " Loss: 0.000000\n",
      " Loss: 0.080143\n",
      "Epoch 1404 Chain 0 loss std 1.41e-03 variance 9.89e-07 smooth variance 6.54e-07 adaptive c -1.00\n",
      "Epoch 1404 Chain 1 loss std 2.57e+02 variance 3.29e+04 smooth variance 2.47e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017694\n",
      " Loss: 0.000000\n",
      " Loss: 0.058190\n",
      " Loss: 0.000000\n",
      " Loss: 0.033260\n",
      " Loss: 0.000000\n",
      " Loss: 0.018330\n",
      " Loss: 0.000000\n",
      " Loss: 0.033821\n",
      " Loss: 0.000000\n",
      " Loss: 0.065538\n",
      " Loss: 0.000000\n",
      " Loss: 0.015724\n",
      " Loss: 0.000000\n",
      " Loss: 0.012971\n",
      " Loss: 0.000000\n",
      " Loss: 0.045734\n",
      " Loss: 0.000000\n",
      " Loss: 0.021317\n",
      "Epoch 1406 Chain 0 loss std 1.10e-03 variance 6.09e-07 smooth variance 6.41e-07 adaptive c -1.00\n",
      "Epoch 1406 Chain 1 loss std 1.97e+02 variance 1.93e+04 smooth variance 2.31e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018880\n",
      " Loss: 0.000000\n",
      " Loss: 0.031752\n",
      " Loss: 0.000000\n",
      " Loss: 0.016274\n",
      " Loss: 0.000000\n",
      " Loss: 0.070057\n",
      " Loss: 0.000000\n",
      " Loss: 0.024314\n",
      " Loss: 0.000000\n",
      " Loss: 0.018111\n",
      " Loss: 0.000000\n",
      " Loss: 0.021316\n",
      " Loss: 0.000000\n",
      " Loss: 0.024505\n",
      " Loss: 0.000000\n",
      " Loss: 0.036276\n",
      " Loss: 0.000000\n",
      " Loss: 0.061058\n",
      "Epoch 1408 Chain 0 loss std 1.56e-03 variance 1.21e-06 smooth variance 8.12e-07 adaptive c -1.00\n",
      "Epoch 1408 Chain 1 loss std 1.96e+02 variance 1.92e+04 smooth variance 2.19e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061996\n",
      " Loss: 0.000000\n",
      " Loss: 0.017323\n",
      " Loss: 0.000000\n",
      " Loss: 0.030577\n",
      " Loss: 0.000000\n",
      " Loss: 0.016593\n",
      " Loss: 0.000000\n",
      " Loss: 0.034774\n",
      " Loss: 0.000000\n",
      " Loss: 0.023915\n",
      " Loss: 0.000000\n",
      " Loss: 0.024037\n",
      " Loss: 0.000000\n",
      " Loss: 0.025609\n",
      " Loss: 0.000000\n",
      " Loss: 0.057172\n",
      " Loss: 0.000000\n",
      " Loss: 0.030521\n",
      "Epoch 1410 Chain 0 loss std 1.30e-03 variance 8.50e-07 smooth variance 8.24e-07 adaptive c -1.00\n",
      "Epoch 1410 Chain 1 loss std 1.70e+02 variance 1.45e+04 smooth variance 1.97e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.055039\n",
      " Loss: 0.000000\n",
      " Loss: 0.044630\n",
      " Loss: 0.000000\n",
      " Loss: 0.019665\n",
      " Loss: 0.000000\n",
      " Loss: 0.018405\n",
      " Loss: 0.000000\n",
      " Loss: 0.023507\n",
      " Loss: 0.000000\n",
      " Loss: 0.015859\n",
      " Loss: 0.000000\n",
      " Loss: 0.019509\n",
      " Loss: 0.000000\n",
      " Loss: 0.038731\n",
      " Loss: 0.000000\n",
      " Loss: 0.066237\n",
      " Loss: 0.000000\n",
      " Loss: 0.020904\n",
      "Epoch 1412 Chain 0 loss std 8.84e-04 variance 3.91e-07 smooth variance 6.94e-07 adaptive c -1.00\n",
      "Epoch 1412 Chain 1 loss std 2.13e+02 variance 2.28e+04 smooth variance 2.06e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026617\n",
      " Loss: 0.000000\n",
      " Loss: 0.016864\n",
      " Loss: 0.000000\n",
      " Loss: 0.073230\n",
      " Loss: 0.000000\n",
      " Loss: 0.019508\n",
      " Loss: 0.000000\n",
      " Loss: 0.025011\n",
      " Loss: 0.000000\n",
      " Loss: 0.017681\n",
      " Loss: 0.000000\n",
      " Loss: 0.071109\n",
      " Loss: 0.000000\n",
      " Loss: 0.020227\n",
      " Loss: 0.000000\n",
      " Loss: 0.016950\n",
      " Loss: 0.000000\n",
      " Loss: 0.035262\n",
      "Epoch 1414 Chain 0 loss std 6.98e-04 variance 2.44e-07 smooth variance 5.59e-07 adaptive c -1.00\n",
      "Epoch 1414 Chain 1 loss std 2.00e+02 variance 1.99e+04 smooth variance 2.04e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.039997\n",
      " Loss: 0.000000\n",
      " Loss: 0.017925\n",
      " Loss: 0.000000\n",
      " Loss: 0.025738\n",
      " Loss: 0.000000\n",
      " Loss: 0.062609\n",
      " Loss: 0.000000\n",
      " Loss: 0.014956\n",
      " Loss: 0.000000\n",
      " Loss: 0.030219\n",
      " Loss: 0.000000\n",
      " Loss: 0.056558\n",
      " Loss: 0.000000\n",
      " Loss: 0.017678\n",
      " Loss: 0.000000\n",
      " Loss: 0.017396\n",
      " Loss: 0.000000\n",
      " Loss: 0.039370\n",
      "Epoch 1416 Chain 0 loss std 1.88e-03 variance 1.77e-06 smooth variance 9.23e-07 adaptive c -1.00\n",
      "Epoch 1416 Chain 1 loss std 2.31e+02 variance 2.68e+04 smooth variance 2.23e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.045940\n",
      " Loss: 0.000000\n",
      " Loss: 0.021184\n",
      " Loss: 0.000000\n",
      " Loss: 0.053222\n",
      " Loss: 0.000000\n",
      " Loss: 0.023597\n",
      " Loss: 0.000000\n",
      " Loss: 0.017265\n",
      " Loss: 0.000000\n",
      " Loss: 0.024068\n",
      " Loss: 0.000000\n",
      " Loss: 0.015729\n",
      " Loss: 0.000000\n",
      " Loss: 0.037225\n",
      " Loss: 0.000000\n",
      " Loss: 0.020425\n",
      " Loss: 0.000000\n",
      " Loss: 0.063755\n",
      "Epoch 1418 Chain 0 loss std 9.39e-04 variance 4.40e-07 smooth variance 7.78e-07 adaptive c -1.00\n",
      "Epoch 1418 Chain 1 loss std 2.09e+02 variance 2.19e+04 smooth variance 2.22e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033461\n",
      " Loss: 0.000000\n",
      " Loss: 0.022889\n",
      " Loss: 0.000000\n",
      " Loss: 0.017524\n",
      " Loss: 0.000000\n",
      " Loss: 0.056925\n",
      " Loss: 0.000000\n",
      " Loss: 0.030406\n",
      " Loss: 0.000000\n",
      " Loss: 0.031124\n",
      " Loss: 0.000000\n",
      " Loss: 0.061680\n",
      " Loss: 0.000000\n",
      " Loss: 0.030845\n",
      " Loss: 0.000000\n",
      " Loss: 0.017832\n",
      " Loss: 0.000000\n",
      " Loss: 0.019707\n",
      "Epoch 1420 Chain 0 loss std 1.09e-03 variance 5.89e-07 smooth variance 7.21e-07 adaptive c -1.00\n",
      "Epoch 1420 Chain 1 loss std 2.03e+02 variance 2.05e+04 smooth variance 2.17e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017682\n",
      " Loss: 0.000000\n",
      " Loss: 0.018178\n",
      " Loss: 0.000000\n",
      " Loss: 0.041428\n",
      " Loss: 0.000000\n",
      " Loss: 0.021850\n",
      " Loss: 0.000000\n",
      " Loss: 0.062046\n",
      " Loss: 0.000000\n",
      " Loss: 0.030275\n",
      " Loss: 0.000000\n",
      " Loss: 0.064036\n",
      " Loss: 0.000000\n",
      " Loss: 0.034178\n",
      " Loss: 0.000000\n",
      " Loss: 0.016065\n",
      " Loss: 0.000000\n",
      " Loss: 0.016626\n",
      "Epoch 1422 Chain 0 loss std 7.45e-04 variance 2.77e-07 smooth variance 5.88e-07 adaptive c -1.00\n",
      "Epoch 1422 Chain 1 loss std 2.15e+02 variance 2.31e+04 smooth variance 2.21e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024678\n",
      " Loss: 0.000000\n",
      " Loss: 0.023814\n",
      " Loss: 0.000000\n",
      " Loss: 0.018535\n",
      " Loss: 0.000000\n",
      " Loss: 0.059475\n",
      " Loss: 0.000000\n",
      " Loss: 0.034670\n",
      " Loss: 0.000000\n",
      " Loss: 0.024717\n",
      " Loss: 0.000000\n",
      " Loss: 0.030437\n",
      " Loss: 0.000000\n",
      " Loss: 0.063906\n",
      " Loss: 0.000000\n",
      " Loss: 0.020281\n",
      " Loss: 0.000000\n",
      " Loss: 0.021825\n",
      "Epoch 1424 Chain 0 loss std 1.31e-03 variance 8.60e-07 smooth variance 6.70e-07 adaptive c -1.00\n",
      "Epoch 1424 Chain 1 loss std 2.03e+02 variance 2.05e+04 smooth variance 2.16e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024619\n",
      " Loss: 0.000000\n",
      " Loss: 0.021691\n",
      " Loss: 0.000000\n",
      " Loss: 0.063228\n",
      " Loss: 0.000000\n",
      " Loss: 0.034147\n",
      " Loss: 0.000000\n",
      " Loss: 0.017475\n",
      " Loss: 0.000000\n",
      " Loss: 0.020875\n",
      " Loss: 0.000000\n",
      " Loss: 0.020264\n",
      " Loss: 0.000000\n",
      " Loss: 0.011810\n",
      " Loss: 0.000000\n",
      " Loss: 0.071602\n",
      " Loss: 0.000000\n",
      " Loss: 0.036602\n",
      "Epoch 1426 Chain 0 loss std 1.48e-03 variance 1.10e-06 smooth variance 7.99e-07 adaptive c -1.00\n",
      "Epoch 1426 Chain 1 loss std 2.51e+02 variance 3.14e+04 smooth variance 2.46e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.034722\n",
      " Loss: 0.000000\n",
      " Loss: 0.026902\n",
      " Loss: 0.000000\n",
      " Loss: 0.060540\n",
      " Loss: 0.000000\n",
      " Loss: 0.015212\n",
      " Loss: 0.000000\n",
      " Loss: 0.023773\n",
      " Loss: 0.000000\n",
      " Loss: 0.021184\n",
      " Loss: 0.000000\n",
      " Loss: 0.018614\n",
      " Loss: 0.000000\n",
      " Loss: 0.014077\n",
      " Loss: 0.000000\n",
      " Loss: 0.035424\n",
      " Loss: 0.000000\n",
      " Loss: 0.071846\n",
      "Epoch 1428 Chain 0 loss std 1.04e-03 variance 5.43e-07 smooth variance 7.22e-07 adaptive c -1.00\n",
      "Epoch 1428 Chain 1 loss std 1.97e+02 variance 1.94e+04 smooth variance 2.30e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018153\n",
      " Loss: 0.000000\n",
      " Loss: 0.023486\n",
      " Loss: 0.000000\n",
      " Loss: 0.024345\n",
      " Loss: 0.000000\n",
      " Loss: 0.076781\n",
      " Loss: 0.000000\n",
      " Loss: 0.018373\n",
      " Loss: 0.000000\n",
      " Loss: 0.019558\n",
      " Loss: 0.000000\n",
      " Loss: 0.056932\n",
      " Loss: 0.000000\n",
      " Loss: 0.041777\n",
      " Loss: 0.000000\n",
      " Loss: 0.029780\n",
      " Loss: 0.000000\n",
      " Loss: 0.013085\n",
      "Epoch 1430 Chain 0 loss std 7.57e-04 variance 2.86e-07 smooth variance 5.91e-07 adaptive c -1.00\n",
      "Epoch 1430 Chain 1 loss std 2.02e+02 variance 2.04e+04 smooth variance 2.22e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017860\n",
      " Loss: 0.000000\n",
      " Loss: 0.025840\n",
      " Loss: 0.000000\n",
      " Loss: 0.065480\n",
      " Loss: 0.000000\n",
      " Loss: 0.021865\n",
      " Loss: 0.000000\n",
      " Loss: 0.030083\n",
      " Loss: 0.000000\n",
      " Loss: 0.022251\n",
      " Loss: 0.000000\n",
      " Loss: 0.021260\n",
      " Loss: 0.000000\n",
      " Loss: 0.019921\n",
      " Loss: 0.000000\n",
      " Loss: 0.057525\n",
      " Loss: 0.000000\n",
      " Loss: 0.040167\n",
      "Epoch 1432 Chain 0 loss std 1.10e-03 variance 6.06e-07 smooth variance 5.96e-07 adaptive c -1.00\n",
      "Epoch 1432 Chain 1 loss std 1.98e+02 variance 1.97e+04 smooth variance 2.15e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014883\n",
      " Loss: 0.000000\n",
      " Loss: 0.020069\n",
      " Loss: 0.000000\n",
      " Loss: 0.075005\n",
      " Loss: 0.000000\n",
      " Loss: 0.024838\n",
      " Loss: 0.000000\n",
      " Loss: 0.026321\n",
      " Loss: 0.000000\n",
      " Loss: 0.033287\n",
      " Loss: 0.000000\n",
      " Loss: 0.024206\n",
      " Loss: 0.000000\n",
      " Loss: 0.021301\n",
      " Loss: 0.000000\n",
      " Loss: 0.068565\n",
      " Loss: 0.000000\n",
      " Loss: 0.013757\n",
      "Epoch 1434 Chain 0 loss std 8.75e-04 variance 3.83e-07 smooth variance 5.32e-07 adaptive c -1.00\n",
      "Epoch 1434 Chain 1 loss std 2.67e+02 variance 3.55e+04 smooth variance 2.57e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024818\n",
      " Loss: 0.000000\n",
      " Loss: 0.021787\n",
      " Loss: 0.000000\n",
      " Loss: 0.060763\n",
      " Loss: 0.000000\n",
      " Loss: 0.037996\n",
      " Loss: 0.000000\n",
      " Loss: 0.015746\n",
      " Loss: 0.000000\n",
      " Loss: 0.014386\n",
      " Loss: 0.000000\n",
      " Loss: 0.019418\n",
      " Loss: 0.000000\n",
      " Loss: 0.075488\n",
      " Loss: 0.000000\n",
      " Loss: 0.030383\n",
      " Loss: 0.000000\n",
      " Loss: 0.021428\n",
      "Epoch 1436 Chain 0 loss std 9.62e-04 variance 4.63e-07 smooth variance 5.11e-07 adaptive c -1.00\n",
      "Epoch 1436 Chain 1 loss std 1.90e+02 variance 1.81e+04 smooth variance 2.34e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018621\n",
      " Loss: 0.000000\n",
      " Loss: 0.023093\n",
      " Loss: 0.000000\n",
      " Loss: 0.044010\n",
      " Loss: 0.000000\n",
      " Loss: 0.012930\n",
      " Loss: 0.000000\n",
      " Loss: 0.062447\n",
      " Loss: 0.000000\n",
      " Loss: 0.019167\n",
      " Loss: 0.000000\n",
      " Loss: 0.022296\n",
      " Loss: 0.000000\n",
      " Loss: 0.023515\n",
      " Loss: 0.000000\n",
      " Loss: 0.037167\n",
      " Loss: 0.000000\n",
      " Loss: 0.058950\n",
      "Epoch 1438 Chain 0 loss std 9.15e-04 variance 4.19e-07 smooth variance 4.83e-07 adaptive c -1.00\n",
      "Epoch 1438 Chain 1 loss std 2.74e+02 variance 3.76e+04 smooth variance 2.77e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019880\n",
      " Loss: 0.000000\n",
      " Loss: 0.023795\n",
      " Loss: 0.000000\n",
      " Loss: 0.020720\n",
      " Loss: 0.000000\n",
      " Loss: 0.074362\n",
      " Loss: 0.000000\n",
      " Loss: 0.022331\n",
      " Loss: 0.000000\n",
      " Loss: 0.016629\n",
      " Loss: 0.000000\n",
      " Loss: 0.015388\n",
      " Loss: 0.000000\n",
      " Loss: 0.027758\n",
      " Loss: 0.000000\n",
      " Loss: 0.079330\n",
      " Loss: 0.000000\n",
      " Loss: 0.021979\n",
      "Epoch 1440 Chain 0 loss std 6.15e-04 variance 1.89e-07 smooth variance 3.95e-07 adaptive c -1.00\n",
      "Epoch 1440 Chain 1 loss std 1.94e+02 variance 1.89e+04 smooth variance 2.50e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015589\n",
      " Loss: 0.000000\n",
      " Loss: 0.018770\n",
      " Loss: 0.000000\n",
      " Loss: 0.028195\n",
      " Loss: 0.000000\n",
      " Loss: 0.076762\n",
      " Loss: 0.000000\n",
      " Loss: 0.021766\n",
      " Loss: 0.000000\n",
      " Loss: 0.057813\n",
      " Loss: 0.000000\n",
      " Loss: 0.033422\n",
      " Loss: 0.000000\n",
      " Loss: 0.018384\n",
      " Loss: 0.000000\n",
      " Loss: 0.019460\n",
      " Loss: 0.000000\n",
      " Loss: 0.032004\n",
      "Epoch 1442 Chain 0 loss std 1.06e-03 variance 5.63e-07 smooth variance 4.46e-07 adaptive c -1.00\n",
      "Epoch 1442 Chain 1 loss std 2.04e+02 variance 2.07e+04 smooth variance 2.37e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022060\n",
      " Loss: 0.000000\n",
      " Loss: 0.067466\n",
      " Loss: 0.000000\n",
      " Loss: 0.016582\n",
      " Loss: 0.000000\n",
      " Loss: 0.021737\n",
      " Loss: 0.000000\n",
      " Loss: 0.033231\n",
      " Loss: 0.000000\n",
      " Loss: 0.011310\n",
      " Loss: 0.000000\n",
      " Loss: 0.018646\n",
      " Loss: 0.000000\n",
      " Loss: 0.027203\n",
      " Loss: 0.000000\n",
      " Loss: 0.040214\n",
      " Loss: 0.000000\n",
      " Loss: 0.063698\n",
      "Epoch 1444 Chain 0 loss std 1.27e-03 variance 8.01e-07 smooth variance 5.52e-07 adaptive c -1.00\n",
      "Epoch 1444 Chain 1 loss std 1.25e+02 variance 7.75e+03 smooth variance 1.89e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023149\n",
      " Loss: 0.000000\n",
      " Loss: 0.012921\n",
      " Loss: 0.000000\n",
      " Loss: 0.086078\n",
      " Loss: 0.000000\n",
      " Loss: 0.025770\n",
      " Loss: 0.000000\n",
      " Loss: 0.013148\n",
      " Loss: 0.000000\n",
      " Loss: 0.032469\n",
      " Loss: 0.000000\n",
      " Loss: 0.014739\n",
      " Loss: 0.000000\n",
      " Loss: 0.022438\n",
      " Loss: 0.000000\n",
      " Loss: 0.035205\n",
      " Loss: 0.000000\n",
      " Loss: 0.056213\n",
      "Epoch 1446 Chain 0 loss std 7.32e-04 variance 2.68e-07 smooth variance 4.67e-07 adaptive c -1.00\n",
      "Epoch 1446 Chain 1 loss std 1.74e+02 variance 1.52e+04 smooth variance 1.78e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.057155\n",
      " Loss: 0.000000\n",
      " Loss: 0.013545\n",
      " Loss: 0.000000\n",
      " Loss: 0.027824\n",
      " Loss: 0.000000\n",
      " Loss: 0.027509\n",
      " Loss: 0.000000\n",
      " Loss: 0.035030\n",
      " Loss: 0.000000\n",
      " Loss: 0.027930\n",
      " Loss: 0.000000\n",
      " Loss: 0.022135\n",
      " Loss: 0.000000\n",
      " Loss: 0.016577\n",
      " Loss: 0.000000\n",
      " Loss: 0.074948\n",
      " Loss: 0.000000\n",
      " Loss: 0.019464\n",
      "Epoch 1448 Chain 0 loss std 1.07e-03 variance 5.68e-07 smooth variance 4.97e-07 adaptive c -1.00\n",
      "Epoch 1448 Chain 1 loss std 1.93e+02 variance 1.85e+04 smooth variance 1.80e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026701\n",
      " Loss: 0.000000\n",
      " Loss: 0.023610\n",
      " Loss: 0.000000\n",
      " Loss: 0.023038\n",
      " Loss: 0.000000\n",
      " Loss: 0.016060\n",
      " Loss: 0.000000\n",
      " Loss: 0.071641\n",
      " Loss: 0.000000\n",
      " Loss: 0.022324\n",
      " Loss: 0.000000\n",
      " Loss: 0.024511\n",
      " Loss: 0.000000\n",
      " Loss: 0.016127\n",
      " Loss: 0.000000\n",
      " Loss: 0.037569\n",
      " Loss: 0.000000\n",
      " Loss: 0.060516\n",
      "Epoch 1450 Chain 0 loss std 1.01e-03 variance 5.08e-07 smooth variance 5.01e-07 adaptive c -1.00\n",
      "Epoch 1450 Chain 1 loss std 2.14e+02 variance 2.29e+04 smooth variance 1.95e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019284\n",
      " Loss: 0.000000\n",
      " Loss: 0.018462\n",
      " Loss: 0.000000\n",
      " Loss: 0.063363\n",
      " Loss: 0.000000\n",
      " Loss: 0.038805\n",
      " Loss: 0.000000\n",
      " Loss: 0.021132\n",
      " Loss: 0.000000\n",
      " Loss: 0.019392\n",
      " Loss: 0.000000\n",
      " Loss: 0.024797\n",
      " Loss: 0.000000\n",
      " Loss: 0.014149\n",
      " Loss: 0.000000\n",
      " Loss: 0.023329\n",
      " Loss: 0.000000\n",
      " Loss: 0.079372\n",
      "Epoch 1452 Chain 0 loss std 6.18e-04 variance 1.91e-07 smooth variance 4.08e-07 adaptive c -1.00\n",
      "Epoch 1452 Chain 1 loss std 1.92e+02 variance 1.84e+04 smooth variance 1.92e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020214\n",
      " Loss: 0.000000\n",
      " Loss: 0.040450\n",
      " Loss: 0.000000\n",
      " Loss: 0.020691\n",
      " Loss: 0.000000\n",
      " Loss: 0.022187\n",
      " Loss: 0.000000\n",
      " Loss: 0.057498\n",
      " Loss: 0.000000\n",
      " Loss: 0.045184\n",
      " Loss: 0.000000\n",
      " Loss: 0.019107\n",
      " Loss: 0.000000\n",
      " Loss: 0.063415\n",
      " Loss: 0.000000\n",
      " Loss: 0.014774\n",
      " Loss: 0.000000\n",
      " Loss: 0.018555\n",
      "Epoch 1454 Chain 0 loss std 4.69e-04 variance 1.10e-07 smooth variance 3.18e-07 adaptive c -1.00\n",
      "Epoch 1454 Chain 1 loss std 2.72e+02 variance 3.71e+04 smooth variance 2.45e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020220\n",
      " Loss: 0.000000\n",
      " Loss: 0.012509\n",
      " Loss: 0.000000\n",
      " Loss: 0.065871\n",
      " Loss: 0.000000\n",
      " Loss: 0.020102\n",
      " Loss: 0.000000\n",
      " Loss: 0.042329\n",
      " Loss: 0.000000\n",
      " Loss: 0.038309\n",
      " Loss: 0.000000\n",
      " Loss: 0.023349\n",
      " Loss: 0.000000\n",
      " Loss: 0.012902\n",
      " Loss: 0.000000\n",
      " Loss: 0.061907\n",
      " Loss: 0.000000\n",
      " Loss: 0.024564\n",
      "Epoch 1456 Chain 0 loss std 5.69e-04 variance 1.62e-07 smooth variance 2.71e-07 adaptive c -1.00\n",
      "Epoch 1456 Chain 1 loss std 1.35e+02 variance 9.12e+03 smooth variance 1.99e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029947\n",
      " Loss: 0.000000\n",
      " Loss: 0.040558\n",
      " Loss: 0.000000\n",
      " Loss: 0.021929\n",
      " Loss: 0.000000\n",
      " Loss: 0.015510\n",
      " Loss: 0.000000\n",
      " Loss: 0.053081\n",
      " Loss: 0.000000\n",
      " Loss: 0.016931\n",
      " Loss: 0.000000\n",
      " Loss: 0.062992\n",
      " Loss: 0.000000\n",
      " Loss: 0.037641\n",
      " Loss: 0.000000\n",
      " Loss: 0.026424\n",
      " Loss: 0.000000\n",
      " Loss: 0.017033\n",
      "Epoch 1458 Chain 0 loss std 6.92e-04 variance 2.40e-07 smooth variance 2.62e-07 adaptive c -1.00\n",
      "Epoch 1458 Chain 1 loss std 2.10e+02 variance 2.20e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016556\n",
      " Loss: 0.000000\n",
      " Loss: 0.058177\n",
      " Loss: 0.000000\n",
      " Loss: 0.031581\n",
      " Loss: 0.000000\n",
      " Loss: 0.035373\n",
      " Loss: 0.000000\n",
      " Loss: 0.019331\n",
      " Loss: 0.000000\n",
      " Loss: 0.039285\n",
      " Loss: 0.000000\n",
      " Loss: 0.067809\n",
      " Loss: 0.000000\n",
      " Loss: 0.026787\n",
      " Loss: 0.000000\n",
      " Loss: 0.015093\n",
      " Loss: 0.000000\n",
      " Loss: 0.012040\n",
      "Epoch 1460 Chain 0 loss std 6.83e-04 variance 2.33e-07 smooth variance 2.53e-07 adaptive c -1.00\n",
      "Epoch 1460 Chain 1 loss std 2.67e+02 variance 3.58e+04 smooth variance 2.51e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.069317\n",
      " Loss: 0.000000\n",
      " Loss: 0.015067\n",
      " Loss: 0.000000\n",
      " Loss: 0.011743\n",
      " Loss: 0.000000\n",
      " Loss: 0.039250\n",
      " Loss: 0.000000\n",
      " Loss: 0.025637\n",
      " Loss: 0.000000\n",
      " Loss: 0.035069\n",
      " Loss: 0.000000\n",
      " Loss: 0.027131\n",
      " Loss: 0.000000\n",
      " Loss: 0.018630\n",
      " Loss: 0.000000\n",
      " Loss: 0.020974\n",
      " Loss: 0.000000\n",
      " Loss: 0.059207\n",
      "Epoch 1462 Chain 0 loss std 1.39e-03 variance 9.61e-07 smooth variance 4.65e-07 adaptive c -1.00\n",
      "Epoch 1462 Chain 1 loss std 2.00e+02 variance 2.00e+04 smooth variance 2.36e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015657\n",
      " Loss: 0.000000\n",
      " Loss: 0.022191\n",
      " Loss: 0.000000\n",
      " Loss: 0.044834\n",
      " Loss: 0.000000\n",
      " Loss: 0.013628\n",
      " Loss: 0.000000\n",
      " Loss: 0.064697\n",
      " Loss: 0.000000\n",
      " Loss: 0.018140\n",
      " Loss: 0.000000\n",
      " Loss: 0.090088\n",
      " Loss: 0.000000\n",
      " Loss: 0.020332\n",
      " Loss: 0.000000\n",
      " Loss: 0.015069\n",
      " Loss: 0.000000\n",
      " Loss: 0.017374\n",
      "Epoch 1464 Chain 0 loss std 7.52e-04 variance 2.83e-07 smooth variance 4.11e-07 adaptive c -1.00\n",
      "Epoch 1464 Chain 1 loss std 2.14e+02 variance 2.29e+04 smooth variance 2.33e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.042055\n",
      " Loss: 0.000000\n",
      " Loss: 0.011903\n",
      " Loss: 0.000000\n",
      " Loss: 0.069589\n",
      " Loss: 0.000000\n",
      " Loss: 0.019789\n",
      " Loss: 0.000000\n",
      " Loss: 0.017663\n",
      " Loss: 0.000000\n",
      " Loss: 0.026548\n",
      " Loss: 0.000000\n",
      " Loss: 0.020181\n",
      " Loss: 0.000000\n",
      " Loss: 0.031387\n",
      " Loss: 0.000000\n",
      " Loss: 0.013625\n",
      " Loss: 0.000000\n",
      " Loss: 0.069254\n",
      "Epoch 1466 Chain 0 loss std 1.21e-03 variance 7.36e-07 smooth variance 5.08e-07 adaptive c -1.00\n",
      "Epoch 1466 Chain 1 loss std 1.98e+02 variance 1.95e+04 smooth variance 2.22e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024007\n",
      " Loss: 0.000000\n",
      " Loss: 0.013508\n",
      " Loss: 0.000000\n",
      " Loss: 0.023388\n",
      " Loss: 0.000000\n",
      " Loss: 0.019376\n",
      " Loss: 0.000000\n",
      " Loss: 0.080713\n",
      " Loss: 0.000000\n",
      " Loss: 0.030677\n",
      " Loss: 0.000000\n",
      " Loss: 0.015501\n",
      " Loss: 0.000000\n",
      " Loss: 0.080869\n",
      " Loss: 0.000000\n",
      " Loss: 0.015736\n",
      " Loss: 0.000000\n",
      " Loss: 0.018207\n",
      "Epoch 1468 Chain 0 loss std 1.53e-03 variance 1.16e-06 smooth variance 7.05e-07 adaptive c -1.00\n",
      "Epoch 1468 Chain 1 loss std 2.73e+02 variance 3.73e+04 smooth variance 2.67e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020851\n",
      " Loss: 0.000000\n",
      " Loss: 0.064762\n",
      " Loss: 0.000000\n",
      " Loss: 0.021220\n",
      " Loss: 0.000000\n",
      " Loss: 0.025314\n",
      " Loss: 0.000000\n",
      " Loss: 0.028841\n",
      " Loss: 0.000000\n",
      " Loss: 0.009789\n",
      " Loss: 0.000000\n",
      " Loss: 0.060339\n",
      " Loss: 0.000000\n",
      " Loss: 0.025532\n",
      " Loss: 0.000000\n",
      " Loss: 0.024208\n",
      " Loss: 0.000000\n",
      " Loss: 0.041120\n",
      "Epoch 1470 Chain 0 loss std 1.06e-03 variance 5.57e-07 smooth variance 6.60e-07 adaptive c -1.00\n",
      "Epoch 1470 Chain 1 loss std 2.15e+02 variance 2.32e+04 smooth variance 2.57e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014177\n",
      " Loss: 0.000000\n",
      " Loss: 0.018556\n",
      " Loss: 0.000000\n",
      " Loss: 0.028889\n",
      " Loss: 0.000000\n",
      " Loss: 0.062181\n",
      " Loss: 0.000000\n",
      " Loss: 0.037179\n",
      " Loss: 0.000000\n",
      " Loss: 0.026073\n",
      " Loss: 0.000000\n",
      " Loss: 0.012782\n",
      " Loss: 0.000000\n",
      " Loss: 0.020022\n",
      " Loss: 0.000000\n",
      " Loss: 0.037618\n",
      " Loss: 0.000000\n",
      " Loss: 0.064486\n",
      "Epoch 1472 Chain 0 loss std 9.26e-04 variance 4.29e-07 smooth variance 5.91e-07 adaptive c -1.00\n",
      "Epoch 1472 Chain 1 loss std 1.87e+02 variance 1.75e+04 smooth variance 2.32e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037274\n",
      " Loss: 0.000000\n",
      " Loss: 0.019009\n",
      " Loss: 0.000000\n",
      " Loss: 0.020178\n",
      " Loss: 0.000000\n",
      " Loss: 0.068896\n",
      " Loss: 0.000000\n",
      " Loss: 0.015622\n",
      " Loss: 0.000000\n",
      " Loss: 0.030224\n",
      " Loss: 0.000000\n",
      " Loss: 0.022290\n",
      " Loss: 0.000000\n",
      " Loss: 0.059573\n",
      " Loss: 0.000000\n",
      " Loss: 0.020478\n",
      " Loss: 0.000000\n",
      " Loss: 0.028411\n",
      "Epoch 1474 Chain 0 loss std 1.14e-03 variance 6.44e-07 smooth variance 6.07e-07 adaptive c -1.00\n",
      "Epoch 1474 Chain 1 loss std 3.17e+02 variance 5.04e+04 smooth variance 3.14e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023003\n",
      " Loss: 0.000000\n",
      " Loss: 0.026522\n",
      " Loss: 0.000000\n",
      " Loss: 0.021102\n",
      " Loss: 0.000000\n",
      " Loss: 0.076753\n",
      " Loss: 0.000000\n",
      " Loss: 0.013591\n",
      " Loss: 0.000000\n",
      " Loss: 0.030821\n",
      " Loss: 0.000000\n",
      " Loss: 0.015415\n",
      " Loss: 0.000000\n",
      " Loss: 0.019074\n",
      " Loss: 0.000000\n",
      " Loss: 0.031396\n",
      " Loss: 0.000000\n",
      " Loss: 0.064265\n",
      "Epoch 1476 Chain 0 loss std 5.47e-04 variance 1.50e-07 smooth variance 4.70e-07 adaptive c -1.00\n",
      "Epoch 1476 Chain 1 loss std 2.28e+02 variance 2.61e+04 smooth variance 2.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025160\n",
      " Loss: 0.000000\n",
      " Loss: 0.015102\n",
      " Loss: 0.000000\n",
      " Loss: 0.065590\n",
      " Loss: 0.000000\n",
      " Loss: 0.044289\n",
      " Loss: 0.000000\n",
      " Loss: 0.010825\n",
      " Loss: 0.000000\n",
      " Loss: 0.022184\n",
      " Loss: 0.000000\n",
      " Loss: 0.013640\n",
      " Loss: 0.000000\n",
      " Loss: 0.033508\n",
      " Loss: 0.000000\n",
      " Loss: 0.076407\n",
      " Loss: 0.000000\n",
      " Loss: 0.015225\n",
      "Epoch 1478 Chain 0 loss std 1.07e-03 variance 5.72e-07 smooth variance 5.01e-07 adaptive c -1.00\n",
      "Epoch 1478 Chain 1 loss std 1.68e+02 variance 1.41e+04 smooth variance 2.51e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020203\n",
      " Loss: 0.000000\n",
      " Loss: 0.035407\n",
      " Loss: 0.000000\n",
      " Loss: 0.030850\n",
      " Loss: 0.000000\n",
      " Loss: 0.008609\n",
      " Loss: 0.000000\n",
      " Loss: 0.065895\n",
      " Loss: 0.000000\n",
      " Loss: 0.058077\n",
      " Loss: 0.000000\n",
      " Loss: 0.013621\n",
      " Loss: 0.000000\n",
      " Loss: 0.027730\n",
      " Loss: 0.000000\n",
      " Loss: 0.023492\n",
      " Loss: 0.000000\n",
      " Loss: 0.038044\n",
      "Epoch 1480 Chain 0 loss std 1.22e-03 variance 7.49e-07 smooth variance 5.75e-07 adaptive c -1.00\n",
      "Epoch 1480 Chain 1 loss std 1.67e+02 variance 1.40e+04 smooth variance 2.18e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019022\n",
      " Loss: 0.000000\n",
      " Loss: 0.027005\n",
      " Loss: 0.000000\n",
      " Loss: 0.076673\n",
      " Loss: 0.000000\n",
      " Loss: 0.014113\n",
      " Loss: 0.000000\n",
      " Loss: 0.024145\n",
      " Loss: 0.000000\n",
      " Loss: 0.012690\n",
      " Loss: 0.000000\n",
      " Loss: 0.018135\n",
      " Loss: 0.000000\n",
      " Loss: 0.043328\n",
      " Loss: 0.000000\n",
      " Loss: 0.023882\n",
      " Loss: 0.000000\n",
      " Loss: 0.062923\n",
      "Epoch 1482 Chain 0 loss std 1.10e-03 variance 6.02e-07 smooth variance 5.83e-07 adaptive c -1.00\n",
      "Epoch 1482 Chain 1 loss std 1.45e+02 variance 1.05e+04 smooth variance 1.84e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.013886\n",
      " Loss: 0.000000\n",
      " Loss: 0.032442\n",
      " Loss: 0.000000\n",
      " Loss: 0.032658\n",
      " Loss: 0.000000\n",
      " Loss: 0.014788\n",
      " Loss: 0.000000\n",
      " Loss: 0.067180\n",
      " Loss: 0.000000\n",
      " Loss: 0.020109\n",
      " Loss: 0.000000\n",
      " Loss: 0.033247\n",
      " Loss: 0.000000\n",
      " Loss: 0.063271\n",
      " Loss: 0.000000\n",
      " Loss: 0.022460\n",
      " Loss: 0.000000\n",
      " Loss: 0.021864\n",
      "Epoch 1484 Chain 0 loss std 6.65e-04 variance 2.21e-07 smooth variance 4.75e-07 adaptive c -1.00\n",
      "Epoch 1484 Chain 1 loss std 2.72e+02 variance 3.70e+04 smooth variance 2.40e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019301\n",
      " Loss: 0.000000\n",
      " Loss: 0.035582\n",
      " Loss: 0.000000\n",
      " Loss: 0.079510\n",
      " Loss: 0.000000\n",
      " Loss: 0.011799\n",
      " Loss: 0.000000\n",
      " Loss: 0.014757\n",
      " Loss: 0.000000\n",
      " Loss: 0.063490\n",
      " Loss: 0.000000\n",
      " Loss: 0.023552\n",
      " Loss: 0.000000\n",
      " Loss: 0.040779\n",
      " Loss: 0.000000\n",
      " Loss: 0.022876\n",
      " Loss: 0.000000\n",
      " Loss: 0.010252\n",
      "Epoch 1486 Chain 0 loss std 1.16e-03 variance 6.70e-07 smooth variance 5.33e-07 adaptive c -1.00\n",
      "Epoch 1486 Chain 1 loss std 1.84e+02 variance 1.70e+04 smooth variance 2.19e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033117\n",
      " Loss: 0.000000\n",
      " Loss: 0.022099\n",
      " Loss: 0.000000\n",
      " Loss: 0.057060\n",
      " Loss: 0.000000\n",
      " Loss: 0.021561\n",
      " Loss: 0.000000\n",
      " Loss: 0.027110\n",
      " Loss: 0.000000\n",
      " Loss: 0.017338\n",
      " Loss: 0.000000\n",
      " Loss: 0.086943\n",
      " Loss: 0.000000\n",
      " Loss: 0.025100\n",
      " Loss: 0.000000\n",
      " Loss: 0.023796\n",
      " Loss: 0.000000\n",
      " Loss: 0.007765\n",
      "Epoch 1488 Chain 0 loss std 1.17e-03 variance 6.90e-07 smooth variance 5.80e-07 adaptive c -1.00\n",
      "Epoch 1488 Chain 1 loss std 2.30e+02 variance 2.63e+04 smooth variance 2.32e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014356\n",
      " Loss: 0.000000\n",
      " Loss: 0.038971\n",
      " Loss: 0.000000\n",
      " Loss: 0.022672\n",
      " Loss: 0.000000\n",
      " Loss: 0.018698\n",
      " Loss: 0.000000\n",
      " Loss: 0.066245\n",
      " Loss: 0.000000\n",
      " Loss: 0.018018\n",
      " Loss: 0.000000\n",
      " Loss: 0.020929\n",
      " Loss: 0.000000\n",
      " Loss: 0.019176\n",
      " Loss: 0.000000\n",
      " Loss: 0.016079\n",
      " Loss: 0.000000\n",
      " Loss: 0.086737\n",
      "Epoch 1490 Chain 0 loss std 1.12e-03 variance 6.29e-07 smooth variance 5.95e-07 adaptive c -1.00\n",
      "Epoch 1490 Chain 1 loss std 1.58e+02 variance 1.25e+04 smooth variance 2.00e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.085017\n",
      " Loss: 0.000000\n",
      " Loss: 0.021767\n",
      " Loss: 0.000000\n",
      " Loss: 0.020564\n",
      " Loss: 0.000000\n",
      " Loss: 0.017689\n",
      " Loss: 0.000000\n",
      " Loss: 0.015901\n",
      " Loss: 0.000000\n",
      " Loss: 0.030706\n",
      " Loss: 0.000000\n",
      " Loss: 0.059637\n",
      " Loss: 0.000000\n",
      " Loss: 0.014983\n",
      " Loss: 0.000000\n",
      " Loss: 0.036583\n",
      " Loss: 0.000000\n",
      " Loss: 0.019027\n",
      "Epoch 1492 Chain 0 loss std 9.59e-04 variance 4.60e-07 smooth variance 5.54e-07 adaptive c -1.00\n",
      "Epoch 1492 Chain 1 loss std 1.82e+02 variance 1.66e+04 smooth variance 1.90e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028774\n",
      " Loss: 0.000000\n",
      " Loss: 0.060283\n",
      " Loss: 0.000000\n",
      " Loss: 0.037269\n",
      " Loss: 0.000000\n",
      " Loss: 0.012533\n",
      " Loss: 0.000000\n",
      " Loss: 0.022074\n",
      " Loss: 0.000000\n",
      " Loss: 0.034947\n",
      " Loss: 0.000000\n",
      " Loss: 0.052331\n",
      " Loss: 0.000000\n",
      " Loss: 0.024237\n",
      " Loss: 0.000000\n",
      " Loss: 0.017515\n",
      " Loss: 0.000000\n",
      " Loss: 0.031903\n",
      "Epoch 1494 Chain 0 loss std 6.50e-04 variance 2.11e-07 smooth variance 4.51e-07 adaptive c -1.00\n",
      "Epoch 1494 Chain 1 loss std 1.79e+02 variance 1.60e+04 smooth variance 1.81e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026273\n",
      " Loss: 0.000000\n",
      " Loss: 0.040796\n",
      " Loss: 0.000000\n",
      " Loss: 0.020119\n",
      " Loss: 0.000000\n",
      " Loss: 0.017862\n",
      " Loss: 0.000000\n",
      " Loss: 0.055882\n",
      " Loss: 0.000000\n",
      " Loss: 0.071703\n",
      " Loss: 0.000000\n",
      " Loss: 0.030468\n",
      " Loss: 0.000000\n",
      " Loss: 0.021428\n",
      " Loss: 0.000000\n",
      " Loss: 0.021695\n",
      " Loss: 0.000000\n",
      " Loss: 0.015635\n",
      "Epoch 1496 Chain 0 loss std 7.23e-04 variance 2.61e-07 smooth variance 3.94e-07 adaptive c -1.00\n",
      "Epoch 1496 Chain 1 loss std 1.99e+02 variance 1.99e+04 smooth variance 1.86e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.046759\n",
      " Loss: 0.000000\n",
      " Loss: 0.057446\n",
      " Loss: 0.000000\n",
      " Loss: 0.013450\n",
      " Loss: 0.000000\n",
      " Loss: 0.019602\n",
      " Loss: 0.000000\n",
      " Loss: 0.023670\n",
      " Loss: 0.000000\n",
      " Loss: 0.065325\n",
      " Loss: 0.000000\n",
      " Loss: 0.042020\n",
      " Loss: 0.000000\n",
      " Loss: 0.023222\n",
      " Loss: 0.000000\n",
      " Loss: 0.018969\n",
      " Loss: 0.000000\n",
      " Loss: 0.011389\n",
      "Epoch 1498 Chain 0 loss std 8.05e-04 variance 3.24e-07 smooth variance 3.73e-07 adaptive c -1.00\n",
      "Epoch 1498 Chain 1 loss std 1.94e+02 variance 1.87e+04 smooth variance 1.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.011907\n",
      " Loss: 0.000000\n",
      " Loss: 0.015656\n",
      " Loss: 0.000000\n",
      " Loss: 0.068533\n",
      " Loss: 0.000000\n",
      " Loss: 0.039345\n",
      " Loss: 0.000000\n",
      " Loss: 0.025483\n",
      " Loss: 0.000000\n",
      " Loss: 0.065455\n",
      " Loss: 0.000000\n",
      " Loss: 0.031426\n",
      " Loss: 0.000000\n",
      " Loss: 0.023361\n",
      " Loss: 0.000000\n",
      " Loss: 0.022688\n",
      " Loss: 0.000000\n",
      " Loss: 0.017992\n",
      "Epoch 1500 Chain 0 loss std 8.42e-04 variance 3.55e-07 smooth variance 3.68e-07 adaptive c -1.00\n",
      "Epoch 1500 Chain 1 loss std 2.48e+02 variance 3.07e+04 smooth variance 2.23e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020496\n",
      " Loss: 0.000000\n",
      " Loss: 0.010572\n",
      " Loss: 0.000000\n",
      " Loss: 0.036928\n",
      " Loss: 0.000000\n",
      " Loss: 0.019221\n",
      " Loss: 0.000000\n",
      " Loss: 0.073705\n",
      " Loss: 0.000000\n",
      " Loss: 0.014991\n",
      " Loss: 0.000000\n",
      " Loss: 0.019068\n",
      " Loss: 0.000000\n",
      " Loss: 0.021711\n",
      " Loss: 0.000000\n",
      " Loss: 0.063960\n",
      " Loss: 0.000000\n",
      " Loss: 0.041189\n",
      "Epoch 1502 Chain 0 loss std 1.07e-03 variance 5.74e-07 smooth variance 4.29e-07 adaptive c -1.00\n",
      "Epoch 1502 Chain 1 loss std 1.80e+02 variance 1.61e+04 smooth variance 2.04e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014622\n",
      " Loss: 0.000000\n",
      " Loss: 0.079170\n",
      " Loss: 0.000000\n",
      " Loss: 0.015653\n",
      " Loss: 0.000000\n",
      " Loss: 0.032557\n",
      " Loss: 0.000000\n",
      " Loss: 0.018915\n",
      " Loss: 0.000000\n",
      " Loss: 0.021793\n",
      " Loss: 0.000000\n",
      " Loss: 0.010314\n",
      " Loss: 0.000000\n",
      " Loss: 0.092283\n",
      " Loss: 0.000000\n",
      " Loss: 0.023019\n",
      " Loss: 0.000000\n",
      " Loss: 0.013506\n",
      "Epoch 1504 Chain 0 loss std 8.56e-04 variance 3.66e-07 smooth variance 4.10e-07 adaptive c -1.00\n",
      "Epoch 1504 Chain 1 loss std 2.05e+02 variance 2.10e+04 smooth variance 2.06e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.039065\n",
      " Loss: 0.000000\n",
      " Loss: 0.020730\n",
      " Loss: 0.000000\n",
      " Loss: 0.059978\n",
      " Loss: 0.000000\n",
      " Loss: 0.021868\n",
      " Loss: 0.000000\n",
      " Loss: 0.019275\n",
      " Loss: 0.000000\n",
      " Loss: 0.014378\n",
      " Loss: 0.000000\n",
      " Loss: 0.032931\n",
      " Loss: 0.000000\n",
      " Loss: 0.016712\n",
      " Loss: 0.000000\n",
      " Loss: 0.036758\n",
      " Loss: 0.000000\n",
      " Loss: 0.060134\n",
      "Epoch 1506 Chain 0 loss std 6.52e-04 variance 2.12e-07 smooth variance 3.51e-07 adaptive c -1.00\n",
      "Epoch 1506 Chain 1 loss std 2.05e+02 variance 2.10e+04 smooth variance 2.07e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.078753\n",
      " Loss: 0.000000\n",
      " Loss: 0.025498\n",
      " Loss: 0.000000\n",
      " Loss: 0.019385\n",
      " Loss: 0.000000\n",
      " Loss: 0.015686\n",
      " Loss: 0.000000\n",
      " Loss: 0.021590\n",
      " Loss: 0.000000\n",
      " Loss: 0.054420\n",
      " Loss: 0.000000\n",
      " Loss: 0.019630\n",
      " Loss: 0.000000\n",
      " Loss: 0.039663\n",
      " Loss: 0.000000\n",
      " Loss: 0.017938\n",
      " Loss: 0.000000\n",
      " Loss: 0.029259\n",
      "Epoch 1508 Chain 0 loss std 1.02e-03 variance 5.21e-07 smooth variance 4.02e-07 adaptive c -1.00\n",
      "Epoch 1508 Chain 1 loss std 2.09e+02 variance 2.19e+04 smooth variance 2.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.046028\n",
      " Loss: 0.000000\n",
      " Loss: 0.020222\n",
      " Loss: 0.000000\n",
      " Loss: 0.017767\n",
      " Loss: 0.000000\n",
      " Loss: 0.057567\n",
      " Loss: 0.000000\n",
      " Loss: 0.019325\n",
      " Loss: 0.000000\n",
      " Loss: 0.060309\n",
      " Loss: 0.000000\n",
      " Loss: 0.028825\n",
      " Loss: 0.000000\n",
      " Loss: 0.017917\n",
      " Loss: 0.000000\n",
      " Loss: 0.023320\n",
      " Loss: 0.000000\n",
      " Loss: 0.030538\n",
      "Epoch 1510 Chain 0 loss std 1.02e-03 variance 5.20e-07 smooth variance 4.37e-07 adaptive c -1.00\n",
      "Epoch 1510 Chain 1 loss std 2.30e+02 variance 2.64e+04 smooth variance 2.27e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024759\n",
      " Loss: 0.000000\n",
      " Loss: 0.013739\n",
      " Loss: 0.000000\n",
      " Loss: 0.021402\n",
      " Loss: 0.000000\n",
      " Loss: 0.070534\n",
      " Loss: 0.000000\n",
      " Loss: 0.030471\n",
      " Loss: 0.000000\n",
      " Loss: 0.023042\n",
      " Loss: 0.000000\n",
      " Loss: 0.036601\n",
      " Loss: 0.000000\n",
      " Loss: 0.023754\n",
      " Loss: 0.000000\n",
      " Loss: 0.060228\n",
      " Loss: 0.000000\n",
      " Loss: 0.017281\n",
      "Epoch 1512 Chain 0 loss std 1.42e-03 variance 1.01e-06 smooth variance 6.10e-07 adaptive c -1.00\n",
      "Epoch 1512 Chain 1 loss std 1.45e+02 variance 1.05e+04 smooth variance 1.90e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018684\n",
      " Loss: 0.000000\n",
      " Loss: 0.018609\n",
      " Loss: 0.000000\n",
      " Loss: 0.053689\n",
      " Loss: 0.000000\n",
      " Loss: 0.032058\n",
      " Loss: 0.000000\n",
      " Loss: 0.037864\n",
      " Loss: 0.000000\n",
      " Loss: 0.033921\n",
      " Loss: 0.000000\n",
      " Loss: 0.023392\n",
      " Loss: 0.000000\n",
      " Loss: 0.029842\n",
      " Loss: 0.000000\n",
      " Loss: 0.055231\n",
      " Loss: 0.000000\n",
      " Loss: 0.018518\n",
      "Epoch 1514 Chain 0 loss std 8.58e-04 variance 3.68e-07 smooth variance 5.37e-07 adaptive c -1.00\n",
      "Epoch 1514 Chain 1 loss std 1.65e+02 variance 1.37e+04 smooth variance 1.74e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.011504\n",
      " Loss: 0.000000\n",
      " Loss: 0.077724\n",
      " Loss: 0.000000\n",
      " Loss: 0.026308\n",
      " Loss: 0.000000\n",
      " Loss: 0.029436\n",
      " Loss: 0.000000\n",
      " Loss: 0.015930\n",
      " Loss: 0.000000\n",
      " Loss: 0.038601\n",
      " Loss: 0.000000\n",
      " Loss: 0.013946\n",
      " Loss: 0.000000\n",
      " Loss: 0.027234\n",
      " Loss: 0.000000\n",
      " Loss: 0.022321\n",
      " Loss: 0.000000\n",
      " Loss: 0.058797\n",
      "Epoch 1516 Chain 0 loss std 8.61e-04 variance 3.70e-07 smooth variance 4.87e-07 adaptive c -1.00\n",
      "Epoch 1516 Chain 1 loss std 2.83e+02 variance 3.99e+04 smooth variance 2.42e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.059726\n",
      " Loss: 0.000000\n",
      " Loss: 0.026957\n",
      " Loss: 0.000000\n",
      " Loss: 0.012127\n",
      " Loss: 0.000000\n",
      " Loss: 0.020502\n",
      " Loss: 0.000000\n",
      " Loss: 0.041588\n",
      " Loss: 0.000000\n",
      " Loss: 0.058966\n",
      " Loss: 0.000000\n",
      " Loss: 0.019473\n",
      " Loss: 0.000000\n",
      " Loss: 0.040828\n",
      " Loss: 0.000000\n",
      " Loss: 0.027591\n",
      " Loss: 0.000000\n",
      " Loss: 0.014039\n",
      "Epoch 1518 Chain 0 loss std 6.77e-04 variance 2.29e-07 smooth variance 4.10e-07 adaptive c -1.00\n",
      "Epoch 1518 Chain 1 loss std 1.90e+02 variance 1.80e+04 smooth variance 2.23e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.040273\n",
      " Loss: 0.000000\n",
      " Loss: 0.020001\n",
      " Loss: 0.000000\n",
      " Loss: 0.022933\n",
      " Loss: 0.000000\n",
      " Loss: 0.058730\n",
      " Loss: 0.000000\n",
      " Loss: 0.018959\n",
      " Loss: 0.000000\n",
      " Loss: 0.021357\n",
      " Loss: 0.000000\n",
      " Loss: 0.018780\n",
      " Loss: 0.000000\n",
      " Loss: 0.041956\n",
      " Loss: 0.000000\n",
      " Loss: 0.015891\n",
      " Loss: 0.000000\n",
      " Loss: 0.062912\n",
      "Epoch 1520 Chain 0 loss std 8.97e-04 variance 4.03e-07 smooth variance 4.08e-07 adaptive c -1.00\n",
      "Epoch 1520 Chain 1 loss std 2.70e+02 variance 3.66e+04 smooth variance 2.66e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022582\n",
      " Loss: 0.000000\n",
      " Loss: 0.037764\n",
      " Loss: 0.000000\n",
      " Loss: 0.062980\n",
      " Loss: 0.000000\n",
      " Loss: 0.024855\n",
      " Loss: 0.000000\n",
      " Loss: 0.012712\n",
      " Loss: 0.000000\n",
      " Loss: 0.022128\n",
      " Loss: 0.000000\n",
      " Loss: 0.064556\n",
      " Loss: 0.000000\n",
      " Loss: 0.026777\n",
      " Loss: 0.000000\n",
      " Loss: 0.018003\n",
      " Loss: 0.000000\n",
      " Loss: 0.029428\n",
      "Epoch 1522 Chain 0 loss std 1.40e-03 variance 9.78e-07 smooth variance 5.79e-07 adaptive c -1.00\n",
      "Epoch 1522 Chain 1 loss std 2.24e+02 variance 2.50e+04 smooth variance 2.61e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033002\n",
      " Loss: 0.000000\n",
      " Loss: 0.067437\n",
      " Loss: 0.000000\n",
      " Loss: 0.028560\n",
      " Loss: 0.000000\n",
      " Loss: 0.014055\n",
      " Loss: 0.000000\n",
      " Loss: 0.017836\n",
      " Loss: 0.000000\n",
      " Loss: 0.019804\n",
      " Loss: 0.000000\n",
      " Loss: 0.011084\n",
      " Loss: 0.000000\n",
      " Loss: 0.038991\n",
      " Loss: 0.000000\n",
      " Loss: 0.022199\n",
      " Loss: 0.000000\n",
      " Loss: 0.068813\n",
      "Epoch 1524 Chain 0 loss std 8.42e-04 variance 3.55e-07 smooth variance 5.11e-07 adaptive c -1.00\n",
      "Epoch 1524 Chain 1 loss std 2.28e+02 variance 2.59e+04 smooth variance 2.60e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.031938\n",
      " Loss: 0.000000\n",
      " Loss: 0.055029\n",
      " Loss: 0.000000\n",
      " Loss: 0.025383\n",
      " Loss: 0.000000\n",
      " Loss: 0.021562\n",
      " Loss: 0.000000\n",
      " Loss: 0.026978\n",
      " Loss: 0.000000\n",
      " Loss: 0.021463\n",
      " Loss: 0.000000\n",
      " Loss: 0.018277\n",
      " Loss: 0.000000\n",
      " Loss: 0.025517\n",
      " Loss: 0.000000\n",
      " Loss: 0.056640\n",
      " Loss: 0.000000\n",
      " Loss: 0.038991\n",
      "Epoch 1526 Chain 0 loss std 1.04e-03 variance 5.43e-07 smooth variance 5.21e-07 adaptive c -1.00\n",
      "Epoch 1526 Chain 1 loss std 1.73e+02 variance 1.50e+04 smooth variance 2.27e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017208\n",
      " Loss: 0.000000\n",
      " Loss: 0.022104\n",
      " Loss: 0.000000\n",
      " Loss: 0.067540\n",
      " Loss: 0.000000\n",
      " Loss: 0.035143\n",
      " Loss: 0.000000\n",
      " Loss: 0.018892\n",
      " Loss: 0.000000\n",
      " Loss: 0.014622\n",
      " Loss: 0.000000\n",
      " Loss: 0.040191\n",
      " Loss: 0.000000\n",
      " Loss: 0.053930\n",
      " Loss: 0.000000\n",
      " Loss: 0.028800\n",
      " Loss: 0.000000\n",
      " Loss: 0.023342\n",
      "Epoch 1528 Chain 0 loss std 7.52e-04 variance 2.83e-07 smooth variance 4.49e-07 adaptive c -1.00\n",
      "Epoch 1528 Chain 1 loss std 1.84e+02 variance 1.69e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.080766\n",
      " Loss: 0.000000\n",
      " Loss: 0.014679\n",
      " Loss: 0.000000\n",
      " Loss: 0.014412\n",
      " Loss: 0.000000\n",
      " Loss: 0.018759\n",
      " Loss: 0.000000\n",
      " Loss: 0.032269\n",
      " Loss: 0.000000\n",
      " Loss: 0.015021\n",
      " Loss: 0.000000\n",
      " Loss: 0.019774\n",
      " Loss: 0.000000\n",
      " Loss: 0.061542\n",
      " Loss: 0.000000\n",
      " Loss: 0.022266\n",
      " Loss: 0.000000\n",
      " Loss: 0.042281\n",
      "Epoch 1530 Chain 0 loss std 9.91e-04 variance 4.91e-07 smooth variance 4.62e-07 adaptive c -1.00\n",
      "Epoch 1530 Chain 1 loss std 2.79e+02 variance 3.89e+04 smooth variance 2.64e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023739\n",
      " Loss: 0.000000\n",
      " Loss: 0.069684\n",
      " Loss: 0.000000\n",
      " Loss: 0.018987\n",
      " Loss: 0.000000\n",
      " Loss: 0.009375\n",
      " Loss: 0.000000\n",
      " Loss: 0.039099\n",
      " Loss: 0.000000\n",
      " Loss: 0.087608\n",
      " Loss: 0.000000\n",
      " Loss: 0.018727\n",
      " Loss: 0.000000\n",
      " Loss: 0.019531\n",
      " Loss: 0.000000\n",
      " Loss: 0.021966\n",
      " Loss: 0.000000\n",
      " Loss: 0.013050\n",
      "Epoch 1532 Chain 0 loss std 1.66e-03 variance 1.37e-06 smooth variance 7.35e-07 adaptive c -1.00\n",
      "Epoch 1532 Chain 1 loss std 1.87e+02 variance 1.75e+04 smooth variance 2.37e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016923\n",
      " Loss: 0.000000\n",
      " Loss: 0.066281\n",
      " Loss: 0.000000\n",
      " Loss: 0.024454\n",
      " Loss: 0.000000\n",
      " Loss: 0.039482\n",
      " Loss: 0.000000\n",
      " Loss: 0.013741\n",
      " Loss: 0.000000\n",
      " Loss: 0.042170\n",
      " Loss: 0.000000\n",
      " Loss: 0.014366\n",
      " Loss: 0.000000\n",
      " Loss: 0.063904\n",
      " Loss: 0.000000\n",
      " Loss: 0.024147\n",
      " Loss: 0.000000\n",
      " Loss: 0.016293\n",
      "Epoch 1534 Chain 0 loss std 8.15e-04 variance 3.32e-07 smooth variance 6.14e-07 adaptive c -1.00\n",
      "Epoch 1534 Chain 1 loss std 2.51e+02 variance 3.16e+04 smooth variance 2.61e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026335\n",
      " Loss: 0.000000\n",
      " Loss: 0.059349\n",
      " Loss: 0.000000\n",
      " Loss: 0.036811\n",
      " Loss: 0.000000\n",
      " Loss: 0.018070\n",
      " Loss: 0.000000\n",
      " Loss: 0.020314\n",
      " Loss: 0.000000\n",
      " Loss: 0.016191\n",
      " Loss: 0.000000\n",
      " Loss: 0.015466\n",
      " Loss: 0.000000\n",
      " Loss: 0.022155\n",
      " Loss: 0.000000\n",
      " Loss: 0.043527\n",
      " Loss: 0.000000\n",
      " Loss: 0.063540\n",
      "Epoch 1536 Chain 0 loss std 8.19e-04 variance 3.36e-07 smooth variance 5.31e-07 adaptive c -1.00\n",
      "Epoch 1536 Chain 1 loss std 1.89e+02 variance 1.78e+04 smooth variance 2.36e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.040772\n",
      " Loss: 0.000000\n",
      " Loss: 0.058110\n",
      " Loss: 0.000000\n",
      " Loss: 0.016988\n",
      " Loss: 0.000000\n",
      " Loss: 0.020953\n",
      " Loss: 0.000000\n",
      " Loss: 0.024053\n",
      " Loss: 0.000000\n",
      " Loss: 0.016399\n",
      " Loss: 0.000000\n",
      " Loss: 0.034562\n",
      " Loss: 0.000000\n",
      " Loss: 0.017122\n",
      " Loss: 0.000000\n",
      " Loss: 0.065159\n",
      " Loss: 0.000000\n",
      " Loss: 0.027634\n",
      "Epoch 1538 Chain 0 loss std 9.47e-04 variance 4.48e-07 smooth variance 5.06e-07 adaptive c -1.00\n",
      "Epoch 1538 Chain 1 loss std 1.75e+02 variance 1.53e+04 smooth variance 2.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020993\n",
      " Loss: 0.000000\n",
      " Loss: 0.064902\n",
      " Loss: 0.000000\n",
      " Loss: 0.015715\n",
      " Loss: 0.000000\n",
      " Loss: 0.017982\n",
      " Loss: 0.000000\n",
      " Loss: 0.041283\n",
      " Loss: 0.000000\n",
      " Loss: 0.017005\n",
      " Loss: 0.000000\n",
      " Loss: 0.034943\n",
      " Loss: 0.000000\n",
      " Loss: 0.022337\n",
      " Loss: 0.000000\n",
      " Loss: 0.013956\n",
      " Loss: 0.000000\n",
      " Loss: 0.072634\n",
      "Epoch 1540 Chain 0 loss std 8.79e-04 variance 3.87e-07 smooth variance 4.70e-07 adaptive c -1.00\n",
      "Epoch 1540 Chain 1 loss std 1.62e+02 variance 1.31e+04 smooth variance 1.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022867\n",
      " Loss: 0.000000\n",
      " Loss: 0.081307\n",
      " Loss: 0.000000\n",
      " Loss: 0.025745\n",
      " Loss: 0.000000\n",
      " Loss: 0.014437\n",
      " Loss: 0.000000\n",
      " Loss: 0.016518\n",
      " Loss: 0.000000\n",
      " Loss: 0.017448\n",
      " Loss: 0.000000\n",
      " Loss: 0.023059\n",
      " Loss: 0.000000\n",
      " Loss: 0.027765\n",
      " Loss: 0.000000\n",
      " Loss: 0.025125\n",
      " Loss: 0.000000\n",
      " Loss: 0.067477\n",
      "Epoch 1542 Chain 0 loss std 1.22e-03 variance 7.47e-07 smooth variance 5.53e-07 adaptive c -1.00\n",
      "Epoch 1542 Chain 1 loss std 2.41e+02 variance 2.90e+04 smooth variance 2.18e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014287\n",
      " Loss: 0.000000\n",
      " Loss: 0.058426\n",
      " Loss: 0.000000\n",
      " Loss: 0.031563\n",
      " Loss: 0.000000\n",
      " Loss: 0.028358\n",
      " Loss: 0.000000\n",
      " Loss: 0.028238\n",
      " Loss: 0.000000\n",
      " Loss: 0.033874\n",
      " Loss: 0.000000\n",
      " Loss: 0.015073\n",
      " Loss: 0.000000\n",
      " Loss: 0.062372\n",
      " Loss: 0.000000\n",
      " Loss: 0.021658\n",
      " Loss: 0.000000\n",
      " Loss: 0.027894\n",
      "Epoch 1544 Chain 0 loss std 9.04e-04 variance 4.08e-07 smooth variance 5.10e-07 adaptive c -1.00\n",
      "Epoch 1544 Chain 1 loss std 1.95e+02 variance 1.90e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025931\n",
      " Loss: 0.000000\n",
      " Loss: 0.019566\n",
      " Loss: 0.000000\n",
      " Loss: 0.022869\n",
      " Loss: 0.000000\n",
      " Loss: 0.054509\n",
      " Loss: 0.000000\n",
      " Loss: 0.037997\n",
      " Loss: 0.000000\n",
      " Loss: 0.016915\n",
      " Loss: 0.000000\n",
      " Loss: 0.012300\n",
      " Loss: 0.000000\n",
      " Loss: 0.044050\n",
      " Loss: 0.000000\n",
      " Loss: 0.025779\n",
      " Loss: 0.000000\n",
      " Loss: 0.061826\n",
      "Epoch 1546 Chain 0 loss std 1.18e-03 variance 6.99e-07 smooth variance 5.66e-07 adaptive c -1.00\n",
      "Epoch 1546 Chain 1 loss std 2.14e+02 variance 2.28e+04 smooth variance 2.15e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.087493\n",
      " Loss: 0.000000\n",
      " Loss: 0.028056\n",
      " Loss: 0.000000\n",
      " Loss: 0.015783\n",
      " Loss: 0.000000\n",
      " Loss: 0.015630\n",
      " Loss: 0.000000\n",
      " Loss: 0.013907\n",
      " Loss: 0.000000\n",
      " Loss: 0.020611\n",
      " Loss: 0.000000\n",
      " Loss: 0.024264\n",
      " Loss: 0.000000\n",
      " Loss: 0.020253\n",
      " Loss: 0.000000\n",
      " Loss: 0.034263\n",
      " Loss: 0.000000\n",
      " Loss: 0.061477\n",
      "Epoch 1548 Chain 0 loss std 1.06e-03 variance 5.64e-07 smooth variance 5.66e-07 adaptive c -1.00\n",
      "Epoch 1548 Chain 1 loss std 1.90e+02 variance 1.81e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.013844\n",
      " Loss: 0.000000\n",
      " Loss: 0.028703\n",
      " Loss: 0.000000\n",
      " Loss: 0.015825\n",
      " Loss: 0.000000\n",
      " Loss: 0.056869\n",
      " Loss: 0.000000\n",
      " Loss: 0.045627\n",
      " Loss: 0.000000\n",
      " Loss: 0.036910\n",
      " Loss: 0.000000\n",
      " Loss: 0.018140\n",
      " Loss: 0.000000\n",
      " Loss: 0.013959\n",
      " Loss: 0.000000\n",
      " Loss: 0.062123\n",
      " Loss: 0.000000\n",
      " Loss: 0.029736\n",
      "Epoch 1550 Chain 0 loss std 8.53e-04 variance 3.64e-07 smooth variance 5.05e-07 adaptive c -1.00\n",
      "Epoch 1550 Chain 1 loss std 1.30e+02 variance 8.42e+03 smooth variance 1.69e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027434\n",
      " Loss: 0.000000\n",
      " Loss: 0.016460\n",
      " Loss: 0.000000\n",
      " Loss: 0.035149\n",
      " Loss: 0.000000\n",
      " Loss: 0.010278\n",
      " Loss: 0.000000\n",
      " Loss: 0.071547\n",
      " Loss: 0.000000\n",
      " Loss: 0.022745\n",
      " Loss: 0.000000\n",
      " Loss: 0.033553\n",
      " Loss: 0.000000\n",
      " Loss: 0.061824\n",
      " Loss: 0.000000\n",
      " Loss: 0.015635\n",
      " Loss: 0.000000\n",
      " Loss: 0.027110\n",
      "Epoch 1552 Chain 0 loss std 1.08e-03 variance 5.86e-07 smooth variance 5.29e-07 adaptive c -1.00\n",
      "Epoch 1552 Chain 1 loss std 2.22e+02 variance 2.46e+04 smooth variance 1.92e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014226\n",
      " Loss: 0.000000\n",
      " Loss: 0.079773\n",
      " Loss: 0.000000\n",
      " Loss: 0.021639\n",
      " Loss: 0.000000\n",
      " Loss: 0.018905\n",
      " Loss: 0.000000\n",
      " Loss: 0.026323\n",
      " Loss: 0.000000\n",
      " Loss: 0.035825\n",
      " Loss: 0.000000\n",
      " Loss: 0.016809\n",
      " Loss: 0.000000\n",
      " Loss: 0.029868\n",
      " Loss: 0.000000\n",
      " Loss: 0.065249\n",
      " Loss: 0.000000\n",
      " Loss: 0.013113\n",
      "Epoch 1554 Chain 0 loss std 1.19e-03 variance 7.12e-07 smooth variance 5.84e-07 adaptive c -1.00\n",
      "Epoch 1554 Chain 1 loss std 1.96e+02 variance 1.92e+04 smooth variance 1.92e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032634\n",
      " Loss: 0.000000\n",
      " Loss: 0.015670\n",
      " Loss: 0.000000\n",
      " Loss: 0.024494\n",
      " Loss: 0.000000\n",
      " Loss: 0.062815\n",
      " Loss: 0.000000\n",
      " Loss: 0.025251\n",
      " Loss: 0.000000\n",
      " Loss: 0.032841\n",
      " Loss: 0.000000\n",
      " Loss: 0.017918\n",
      " Loss: 0.000000\n",
      " Loss: 0.073624\n",
      " Loss: 0.000000\n",
      " Loss: 0.017662\n",
      " Loss: 0.000000\n",
      " Loss: 0.018819\n",
      "Epoch 1556 Chain 0 loss std 6.22e-04 variance 1.94e-07 smooth variance 4.67e-07 adaptive c -1.00\n",
      "Epoch 1556 Chain 1 loss std 1.47e+02 variance 1.08e+04 smooth variance 1.67e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.038836\n",
      " Loss: 0.000000\n",
      " Loss: 0.025873\n",
      " Loss: 0.000000\n",
      " Loss: 0.061791\n",
      " Loss: 0.000000\n",
      " Loss: 0.018394\n",
      " Loss: 0.000000\n",
      " Loss: 0.015969\n",
      " Loss: 0.000000\n",
      " Loss: 0.015974\n",
      " Loss: 0.000000\n",
      " Loss: 0.031841\n",
      " Loss: 0.000000\n",
      " Loss: 0.023436\n",
      " Loss: 0.000000\n",
      " Loss: 0.031933\n",
      " Loss: 0.000000\n",
      " Loss: 0.057678\n",
      "Epoch 1558 Chain 0 loss std 9.39e-04 variance 4.41e-07 smooth variance 4.59e-07 adaptive c -1.00\n",
      "Epoch 1558 Chain 1 loss std 2.35e+02 variance 2.77e+04 smooth variance 2.00e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.031832\n",
      " Loss: 0.000000\n",
      " Loss: 0.019450\n",
      " Loss: 0.000000\n",
      " Loss: 0.023051\n",
      " Loss: 0.000000\n",
      " Loss: 0.018357\n",
      " Loss: 0.000000\n",
      " Loss: 0.068172\n",
      " Loss: 0.000000\n",
      " Loss: 0.032232\n",
      " Loss: 0.000000\n",
      " Loss: 0.014526\n",
      " Loss: 0.000000\n",
      " Loss: 0.024007\n",
      " Loss: 0.000000\n",
      " Loss: 0.075796\n",
      " Loss: 0.000000\n",
      " Loss: 0.014300\n",
      "Epoch 1560 Chain 0 loss std 9.57e-04 variance 4.58e-07 smooth variance 4.59e-07 adaptive c -1.00\n",
      "Epoch 1560 Chain 1 loss std 1.85e+02 variance 1.71e+04 smooth variance 1.91e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025586\n",
      " Loss: 0.000000\n",
      " Loss: 0.015231\n",
      " Loss: 0.000000\n",
      " Loss: 0.023851\n",
      " Loss: 0.000000\n",
      " Loss: 0.061998\n",
      " Loss: 0.000000\n",
      " Loss: 0.034195\n",
      " Loss: 0.000000\n",
      " Loss: 0.019761\n",
      " Loss: 0.000000\n",
      " Loss: 0.016651\n",
      " Loss: 0.000000\n",
      " Loss: 0.022247\n",
      " Loss: 0.000000\n",
      " Loss: 0.066858\n",
      " Loss: 0.000000\n",
      " Loss: 0.035343\n",
      "Epoch 1562 Chain 0 loss std 1.25e-03 variance 7.85e-07 smooth variance 5.57e-07 adaptive c -1.00\n",
      "Epoch 1562 Chain 1 loss std 1.48e+02 variance 1.10e+04 smooth variance 1.67e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018214\n",
      " Loss: 0.000000\n",
      " Loss: 0.084752\n",
      " Loss: 0.000000\n",
      " Loss: 0.025955\n",
      " Loss: 0.000000\n",
      " Loss: 0.012573\n",
      " Loss: 0.000000\n",
      " Loss: 0.019365\n",
      " Loss: 0.000000\n",
      " Loss: 0.024885\n",
      " Loss: 0.000000\n",
      " Loss: 0.042078\n",
      " Loss: 0.000000\n",
      " Loss: 0.010817\n",
      " Loss: 0.000000\n",
      " Loss: 0.066822\n",
      " Loss: 0.000000\n",
      " Loss: 0.016257\n",
      "Epoch 1564 Chain 0 loss std 1.12e-03 variance 6.28e-07 smooth variance 5.78e-07 adaptive c -1.00\n",
      "Epoch 1564 Chain 1 loss std 1.86e+02 variance 1.73e+04 smooth variance 1.69e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018083\n",
      " Loss: 0.000000\n",
      " Loss: 0.047254\n",
      " Loss: 0.000000\n",
      " Loss: 0.021115\n",
      " Loss: 0.000000\n",
      " Loss: 0.062645\n",
      " Loss: 0.000000\n",
      " Loss: 0.011762\n",
      " Loss: 0.000000\n",
      " Loss: 0.037572\n",
      " Loss: 0.000000\n",
      " Loss: 0.066706\n",
      " Loss: 0.000000\n",
      " Loss: 0.022089\n",
      " Loss: 0.000000\n",
      " Loss: 0.020589\n",
      " Loss: 0.000000\n",
      " Loss: 0.013901\n",
      "Epoch 1566 Chain 0 loss std 1.80e-03 variance 1.63e-06 smooth variance 8.93e-07 adaptive c -1.00\n",
      "Epoch 1566 Chain 1 loss std 1.96e+02 variance 1.92e+04 smooth variance 1.76e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015734\n",
      " Loss: 0.000000\n",
      " Loss: 0.076406\n",
      " Loss: 0.000000\n",
      " Loss: 0.022877\n",
      " Loss: 0.000000\n",
      " Loss: 0.028544\n",
      " Loss: 0.000000\n",
      " Loss: 0.017296\n",
      " Loss: 0.000000\n",
      " Loss: 0.023396\n",
      " Loss: 0.000000\n",
      " Loss: 0.057541\n",
      " Loss: 0.000000\n",
      " Loss: 0.016363\n",
      " Loss: 0.000000\n",
      " Loss: 0.020688\n",
      " Loss: 0.000000\n",
      " Loss: 0.042869\n",
      "Epoch 1568 Chain 0 loss std 9.44e-04 variance 4.46e-07 smooth variance 7.59e-07 adaptive c -1.00\n",
      "Epoch 1568 Chain 1 loss std 1.72e+02 variance 1.48e+04 smooth variance 1.67e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022842\n",
      " Loss: 0.000000\n",
      " Loss: 0.019713\n",
      " Loss: 0.000000\n",
      " Loss: 0.027231\n",
      " Loss: 0.000000\n",
      " Loss: 0.059513\n",
      " Loss: 0.000000\n",
      " Loss: 0.031558\n",
      " Loss: 0.000000\n",
      " Loss: 0.036061\n",
      " Loss: 0.000000\n",
      " Loss: 0.065128\n",
      " Loss: 0.000000\n",
      " Loss: 0.022332\n",
      " Loss: 0.000000\n",
      " Loss: 0.017085\n",
      " Loss: 0.000000\n",
      " Loss: 0.020250\n",
      "Epoch 1570 Chain 0 loss std 8.16e-04 variance 3.33e-07 smooth variance 6.31e-07 adaptive c -1.00\n",
      "Epoch 1570 Chain 1 loss std 2.59e+02 variance 3.34e+04 smooth variance 2.17e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.056956\n",
      " Loss: 0.000000\n",
      " Loss: 0.016621\n",
      " Loss: 0.000000\n",
      " Loss: 0.036464\n",
      " Loss: 0.000000\n",
      " Loss: 0.031713\n",
      " Loss: 0.000000\n",
      " Loss: 0.019101\n",
      " Loss: 0.000000\n",
      " Loss: 0.016775\n",
      " Loss: 0.000000\n",
      " Loss: 0.013021\n",
      " Loss: 0.000000\n",
      " Loss: 0.043369\n",
      " Loss: 0.000000\n",
      " Loss: 0.062130\n",
      " Loss: 0.000000\n",
      " Loss: 0.025560\n",
      "Epoch 1572 Chain 0 loss std 6.26e-04 variance 1.96e-07 smooth variance 5.00e-07 adaptive c -1.00\n",
      "Epoch 1572 Chain 1 loss std 1.67e+02 variance 1.39e+04 smooth variance 1.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.051901\n",
      " Loss: 0.000000\n",
      " Loss: 0.040668\n",
      " Loss: 0.000000\n",
      " Loss: 0.026625\n",
      " Loss: 0.000000\n",
      " Loss: 0.017988\n",
      " Loss: 0.000000\n",
      " Loss: 0.023672\n",
      " Loss: 0.000000\n",
      " Loss: 0.014532\n",
      " Loss: 0.000000\n",
      " Loss: 0.012918\n",
      " Loss: 0.000000\n",
      " Loss: 0.019483\n",
      " Loss: 0.000000\n",
      " Loss: 0.029461\n",
      " Loss: 0.000000\n",
      " Loss: 0.084460\n",
      "Epoch 1574 Chain 0 loss std 8.25e-04 variance 3.40e-07 smooth variance 4.52e-07 adaptive c -1.00\n",
      "Epoch 1574 Chain 1 loss std 2.06e+02 variance 2.13e+04 smooth variance 2.00e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037411\n",
      " Loss: 0.000000\n",
      " Loss: 0.015068\n",
      " Loss: 0.000000\n",
      " Loss: 0.057408\n",
      " Loss: 0.000000\n",
      " Loss: 0.025691\n",
      " Loss: 0.000000\n",
      " Loss: 0.025277\n",
      " Loss: 0.000000\n",
      " Loss: 0.014853\n",
      " Loss: 0.000000\n",
      " Loss: 0.022809\n",
      " Loss: 0.000000\n",
      " Loss: 0.061115\n",
      " Loss: 0.000000\n",
      " Loss: 0.026119\n",
      " Loss: 0.000000\n",
      " Loss: 0.035958\n",
      "Epoch 1576 Chain 0 loss std 8.87e-04 variance 3.93e-07 smooth variance 4.35e-07 adaptive c -1.00\n",
      "Epoch 1576 Chain 1 loss std 2.48e+02 variance 3.08e+04 smooth variance 2.32e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025985\n",
      " Loss: 0.000000\n",
      " Loss: 0.015062\n",
      " Loss: 0.000000\n",
      " Loss: 0.061624\n",
      " Loss: 0.000000\n",
      " Loss: 0.033246\n",
      " Loss: 0.000000\n",
      " Loss: 0.024936\n",
      " Loss: 0.000000\n",
      " Loss: 0.022928\n",
      " Loss: 0.000000\n",
      " Loss: 0.069170\n",
      " Loss: 0.000000\n",
      " Loss: 0.015637\n",
      " Loss: 0.000000\n",
      " Loss: 0.040745\n",
      " Loss: 0.000000\n",
      " Loss: 0.012372\n",
      "Epoch 1578 Chain 0 loss std 9.08e-04 variance 4.13e-07 smooth variance 4.28e-07 adaptive c -1.00\n",
      "Epoch 1578 Chain 1 loss std 1.68e+02 variance 1.40e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021345\n",
      " Loss: 0.000000\n",
      " Loss: 0.033150\n",
      " Loss: 0.000000\n",
      " Loss: 0.012502\n",
      " Loss: 0.000000\n",
      " Loss: 0.071904\n",
      " Loss: 0.000000\n",
      " Loss: 0.021952\n",
      " Loss: 0.000000\n",
      " Loss: 0.061669\n",
      " Loss: 0.000000\n",
      " Loss: 0.021987\n",
      " Loss: 0.000000\n",
      " Loss: 0.034864\n",
      " Loss: 0.000000\n",
      " Loss: 0.031507\n",
      " Loss: 0.000000\n",
      " Loss: 0.010824\n",
      "Epoch 1580 Chain 0 loss std 7.88e-04 variance 3.11e-07 smooth variance 3.93e-07 adaptive c -1.00\n",
      "Epoch 1580 Chain 1 loss std 2.02e+02 variance 2.05e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016900\n",
      " Loss: 0.000000\n",
      " Loss: 0.018478\n",
      " Loss: 0.000000\n",
      " Loss: 0.042095\n",
      " Loss: 0.000000\n",
      " Loss: 0.055551\n",
      " Loss: 0.000000\n",
      " Loss: 0.027828\n",
      " Loss: 0.000000\n",
      " Loss: 0.019466\n",
      " Loss: 0.000000\n",
      " Loss: 0.062749\n",
      " Loss: 0.000000\n",
      " Loss: 0.027817\n",
      " Loss: 0.000000\n",
      " Loss: 0.016585\n",
      " Loss: 0.000000\n",
      " Loss: 0.034234\n",
      "Epoch 1582 Chain 0 loss std 1.28e-03 variance 8.25e-07 smooth variance 5.23e-07 adaptive c -1.00\n",
      "Epoch 1582 Chain 1 loss std 1.97e+02 variance 1.94e+04 smooth variance 2.01e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.058966\n",
      " Loss: 0.000000\n",
      " Loss: 0.020250\n",
      " Loss: 0.000000\n",
      " Loss: 0.027633\n",
      " Loss: 0.000000\n",
      " Loss: 0.025082\n",
      " Loss: 0.000000\n",
      " Loss: 0.028921\n",
      " Loss: 0.000000\n",
      " Loss: 0.027785\n",
      " Loss: 0.000000\n",
      " Loss: 0.013275\n",
      " Loss: 0.000000\n",
      " Loss: 0.020477\n",
      " Loss: 0.000000\n",
      " Loss: 0.034150\n",
      " Loss: 0.000000\n",
      " Loss: 0.065163\n",
      "Epoch 1584 Chain 0 loss std 7.56e-04 variance 2.86e-07 smooth variance 4.51e-07 adaptive c -1.00\n",
      "Epoch 1584 Chain 1 loss std 3.05e+02 variance 4.65e+04 smooth variance 2.81e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018317\n",
      " Loss: 0.000000\n",
      " Loss: 0.042030\n",
      " Loss: 0.000000\n",
      " Loss: 0.020253\n",
      " Loss: 0.000000\n",
      " Loss: 0.059546\n",
      " Loss: 0.000000\n",
      " Loss: 0.020704\n",
      " Loss: 0.000000\n",
      " Loss: 0.020358\n",
      " Loss: 0.000000\n",
      " Loss: 0.018216\n",
      " Loss: 0.000000\n",
      " Loss: 0.030832\n",
      " Loss: 0.000000\n",
      " Loss: 0.062239\n",
      " Loss: 0.000000\n",
      " Loss: 0.029205\n",
      "Epoch 1586 Chain 0 loss std 1.23e-03 variance 7.59e-07 smooth variance 5.44e-07 adaptive c -1.00\n",
      "Epoch 1586 Chain 1 loss std 2.06e+02 variance 2.12e+04 smooth variance 2.60e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035744\n",
      " Loss: 0.000000\n",
      " Loss: 0.026578\n",
      " Loss: 0.000000\n",
      " Loss: 0.065118\n",
      " Loss: 0.000000\n",
      " Loss: 0.011926\n",
      " Loss: 0.000000\n",
      " Loss: 0.021485\n",
      " Loss: 0.000000\n",
      " Loss: 0.010031\n",
      " Loss: 0.000000\n",
      " Loss: 0.058693\n",
      " Loss: 0.000000\n",
      " Loss: 0.038224\n",
      " Loss: 0.000000\n",
      " Loss: 0.020193\n",
      " Loss: 0.000000\n",
      " Loss: 0.033708\n",
      "Epoch 1588 Chain 0 loss std 1.72e-03 variance 1.48e-06 smooth variance 8.23e-07 adaptive c -1.00\n",
      "Epoch 1588 Chain 1 loss std 2.51e+02 variance 3.15e+04 smooth variance 2.76e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021837\n",
      " Loss: 0.000000\n",
      " Loss: 0.079750\n",
      " Loss: 0.000000\n",
      " Loss: 0.020308\n",
      " Loss: 0.000000\n",
      " Loss: 0.014921\n",
      " Loss: 0.000000\n",
      " Loss: 0.024034\n",
      " Loss: 0.000000\n",
      " Loss: 0.012427\n",
      " Loss: 0.000000\n",
      " Loss: 0.017720\n",
      " Loss: 0.000000\n",
      " Loss: 0.023363\n",
      " Loss: 0.000000\n",
      " Loss: 0.087522\n",
      " Loss: 0.000000\n",
      " Loss: 0.019818\n",
      "Epoch 1590 Chain 0 loss std 1.10e-03 variance 6.01e-07 smooth variance 7.57e-07 adaptive c -1.00\n",
      "Epoch 1590 Chain 1 loss std 1.54e+02 variance 1.18e+04 smooth variance 2.29e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061715\n",
      " Loss: 0.000000\n",
      " Loss: 0.016983\n",
      " Loss: 0.000000\n",
      " Loss: 0.025953\n",
      " Loss: 0.000000\n",
      " Loss: 0.023791\n",
      " Loss: 0.000000\n",
      " Loss: 0.032408\n",
      " Loss: 0.000000\n",
      " Loss: 0.021615\n",
      " Loss: 0.000000\n",
      " Loss: 0.020471\n",
      " Loss: 0.000000\n",
      " Loss: 0.023127\n",
      " Loss: 0.000000\n",
      " Loss: 0.022730\n",
      " Loss: 0.000000\n",
      " Loss: 0.072905\n",
      "Epoch 1592 Chain 0 loss std 1.04e-03 variance 5.45e-07 smooth variance 6.93e-07 adaptive c -1.00\n",
      "Epoch 1592 Chain 1 loss std 1.64e+02 variance 1.35e+04 smooth variance 2.01e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.063665\n",
      " Loss: 0.000000\n",
      " Loss: 0.029069\n",
      " Loss: 0.000000\n",
      " Loss: 0.011595\n",
      " Loss: 0.000000\n",
      " Loss: 0.037600\n",
      " Loss: 0.000000\n",
      " Loss: 0.018919\n",
      " Loss: 0.000000\n",
      " Loss: 0.025891\n",
      " Loss: 0.000000\n",
      " Loss: 0.033016\n",
      " Loss: 0.000000\n",
      " Loss: 0.059410\n",
      " Loss: 0.000000\n",
      " Loss: 0.018722\n",
      " Loss: 0.000000\n",
      " Loss: 0.023808\n",
      "Epoch 1594 Chain 0 loss std 1.10e-03 variance 6.07e-07 smooth variance 6.67e-07 adaptive c -1.00\n",
      "Epoch 1594 Chain 1 loss std 2.10e+02 variance 2.20e+04 smooth variance 2.07e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037094\n",
      " Loss: 0.000000\n",
      " Loss: 0.017788\n",
      " Loss: 0.000000\n",
      " Loss: 0.066639\n",
      " Loss: 0.000000\n",
      " Loss: 0.021511\n",
      " Loss: 0.000000\n",
      " Loss: 0.017815\n",
      " Loss: 0.000000\n",
      " Loss: 0.034756\n",
      " Loss: 0.000000\n",
      " Loss: 0.061948\n",
      " Loss: 0.000000\n",
      " Loss: 0.012576\n",
      " Loss: 0.000000\n",
      " Loss: 0.036018\n",
      " Loss: 0.000000\n",
      " Loss: 0.015550\n",
      "Epoch 1596 Chain 0 loss std 1.20e-03 variance 7.19e-07 smooth variance 6.83e-07 adaptive c -1.00\n",
      "Epoch 1596 Chain 1 loss std 1.99e+02 variance 1.97e+04 smooth variance 2.04e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020247\n",
      " Loss: 0.000000\n",
      " Loss: 0.068410\n",
      " Loss: 0.000000\n",
      " Loss: 0.017004\n",
      " Loss: 0.000000\n",
      " Loss: 0.037203\n",
      " Loss: 0.000000\n",
      " Loss: 0.017983\n",
      " Loss: 0.000000\n",
      " Loss: 0.057384\n",
      " Loss: 0.000000\n",
      " Loss: 0.021594\n",
      " Loss: 0.000000\n",
      " Loss: 0.024849\n",
      " Loss: 0.000000\n",
      " Loss: 0.021467\n",
      " Loss: 0.000000\n",
      " Loss: 0.035553\n",
      "Epoch 1598 Chain 0 loss std 6.04e-04 variance 1.82e-07 smooth variance 5.32e-07 adaptive c -1.00\n",
      "Epoch 1598 Chain 1 loss std 2.29e+02 variance 2.62e+04 smooth variance 2.21e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027126\n",
      " Loss: 0.000000\n",
      " Loss: 0.066969\n",
      " Loss: 0.000000\n",
      " Loss: 0.017952\n",
      " Loss: 0.000000\n",
      " Loss: 0.031939\n",
      " Loss: 0.000000\n",
      " Loss: 0.016861\n",
      " Loss: 0.000000\n",
      " Loss: 0.021940\n",
      " Loss: 0.000000\n",
      " Loss: 0.035811\n",
      " Loss: 0.000000\n",
      " Loss: 0.056558\n",
      " Loss: 0.000000\n",
      " Loss: 0.016407\n",
      " Loss: 0.000000\n",
      " Loss: 0.030129\n",
      "Epoch 1600 Chain 0 loss std 8.13e-04 variance 3.30e-07 smooth variance 4.72e-07 adaptive c -1.00\n",
      "Epoch 1600 Chain 1 loss std 2.10e+02 variance 2.20e+04 smooth variance 2.21e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017160\n",
      " Loss: 0.000000\n",
      " Loss: 0.016773\n",
      " Loss: 0.000000\n",
      " Loss: 0.045107\n",
      " Loss: 0.000000\n",
      " Loss: 0.058270\n",
      " Loss: 0.000000\n",
      " Loss: 0.023537\n",
      " Loss: 0.000000\n",
      " Loss: 0.017895\n",
      " Loss: 0.000000\n",
      " Loss: 0.079664\n",
      " Loss: 0.000000\n",
      " Loss: 0.031824\n",
      " Loss: 0.000000\n",
      " Loss: 0.010615\n",
      " Loss: 0.000000\n",
      " Loss: 0.020848\n",
      "Epoch 1602 Chain 0 loss std 1.41e-03 variance 1.00e-06 smooth variance 6.30e-07 adaptive c -1.00\n",
      "Epoch 1602 Chain 1 loss std 2.02e+02 variance 2.03e+04 smooth variance 2.15e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.040216\n",
      " Loss: 0.000000\n",
      " Loss: 0.018739\n",
      " Loss: 0.000000\n",
      " Loss: 0.012262\n",
      " Loss: 0.000000\n",
      " Loss: 0.022715\n",
      " Loss: 0.000000\n",
      " Loss: 0.066914\n",
      " Loss: 0.000000\n",
      " Loss: 0.012978\n",
      " Loss: 0.000000\n",
      " Loss: 0.063609\n",
      " Loss: 0.000000\n",
      " Loss: 0.019377\n",
      " Loss: 0.000000\n",
      " Loss: 0.035715\n",
      " Loss: 0.000000\n",
      " Loss: 0.029167\n",
      "Epoch 1604 Chain 0 loss std 8.90e-04 variance 3.96e-07 smooth variance 5.60e-07 adaptive c -1.00\n",
      "Epoch 1604 Chain 1 loss std 1.69e+02 variance 1.42e+04 smooth variance 1.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.042225\n",
      " Loss: 0.000000\n",
      " Loss: 0.023193\n",
      " Loss: 0.000000\n",
      " Loss: 0.014914\n",
      " Loss: 0.000000\n",
      " Loss: 0.054953\n",
      " Loss: 0.000000\n",
      " Loss: 0.025560\n",
      " Loss: 0.000000\n",
      " Loss: 0.012213\n",
      " Loss: 0.000000\n",
      " Loss: 0.022573\n",
      " Loss: 0.000000\n",
      " Loss: 0.016027\n",
      " Loss: 0.000000\n",
      " Loss: 0.066368\n",
      " Loss: 0.000000\n",
      " Loss: 0.043665\n",
      "Epoch 1606 Chain 0 loss std 9.78e-04 variance 4.78e-07 smooth variance 5.35e-07 adaptive c -1.00\n",
      "Epoch 1606 Chain 1 loss std 2.40e+02 variance 2.88e+04 smooth variance 2.22e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022449\n",
      " Loss: 0.000000\n",
      " Loss: 0.076692\n",
      " Loss: 0.000000\n",
      " Loss: 0.025118\n",
      " Loss: 0.000000\n",
      " Loss: 0.019330\n",
      " Loss: 0.000000\n",
      " Loss: 0.017255\n",
      " Loss: 0.000000\n",
      " Loss: 0.025979\n",
      " Loss: 0.000000\n",
      " Loss: 0.073490\n",
      " Loss: 0.000000\n",
      " Loss: 0.018924\n",
      " Loss: 0.000000\n",
      " Loss: 0.019688\n",
      " Loss: 0.000000\n",
      " Loss: 0.022764\n",
      "Epoch 1608 Chain 0 loss std 9.21e-04 variance 4.25e-07 smooth variance 5.02e-07 adaptive c -1.00\n",
      "Epoch 1608 Chain 1 loss std 2.35e+02 variance 2.77e+04 smooth variance 2.38e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.058255\n",
      " Loss: 0.000000\n",
      " Loss: 0.021610\n",
      " Loss: 0.000000\n",
      " Loss: 0.017366\n",
      " Loss: 0.000000\n",
      " Loss: 0.033689\n",
      " Loss: 0.000000\n",
      " Loss: 0.029924\n",
      " Loss: 0.000000\n",
      " Loss: 0.017305\n",
      " Loss: 0.000000\n",
      " Loss: 0.023793\n",
      " Loss: 0.000000\n",
      " Loss: 0.027625\n",
      " Loss: 0.000000\n",
      " Loss: 0.069017\n",
      " Loss: 0.000000\n",
      " Loss: 0.023104\n",
      "Epoch 1610 Chain 0 loss std 1.29e-03 variance 8.34e-07 smooth variance 6.02e-07 adaptive c -1.00\n",
      "Epoch 1610 Chain 1 loss std 1.77e+02 variance 1.58e+04 smooth variance 2.14e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.080873\n",
      " Loss: 0.000000\n",
      " Loss: 0.018942\n",
      " Loss: 0.000000\n",
      " Loss: 0.020648\n",
      " Loss: 0.000000\n",
      " Loss: 0.018251\n",
      " Loss: 0.000000\n",
      " Loss: 0.022130\n",
      " Loss: 0.000000\n",
      " Loss: 0.022351\n",
      " Loss: 0.000000\n",
      " Loss: 0.016110\n",
      " Loss: 0.000000\n",
      " Loss: 0.023720\n",
      " Loss: 0.000000\n",
      " Loss: 0.067539\n",
      " Loss: 0.000000\n",
      " Loss: 0.031123\n",
      "Epoch 1612 Chain 0 loss std 8.57e-04 variance 3.68e-07 smooth variance 5.31e-07 adaptive c -1.00\n",
      "Epoch 1612 Chain 1 loss std 2.23e+02 variance 2.49e+04 smooth variance 2.25e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021141\n",
      " Loss: 0.000000\n",
      " Loss: 0.074884\n",
      " Loss: 0.000000\n",
      " Loss: 0.036235\n",
      " Loss: 0.000000\n",
      " Loss: 0.010795\n",
      " Loss: 0.000000\n",
      " Loss: 0.017788\n",
      " Loss: 0.000000\n",
      " Loss: 0.065738\n",
      " Loss: 0.000000\n",
      " Loss: 0.024032\n",
      " Loss: 0.000000\n",
      " Loss: 0.020559\n",
      " Loss: 0.000000\n",
      " Loss: 0.015569\n",
      " Loss: 0.000000\n",
      " Loss: 0.034945\n",
      "Epoch 1614 Chain 0 loss std 1.39e-03 variance 9.71e-07 smooth variance 6.63e-07 adaptive c -1.00\n",
      "Epoch 1614 Chain 1 loss std 1.71e+02 variance 1.46e+04 smooth variance 2.01e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016273\n",
      " Loss: 0.000000\n",
      " Loss: 0.038215\n",
      " Loss: 0.000000\n",
      " Loss: 0.014304\n",
      " Loss: 0.000000\n",
      " Loss: 0.021302\n",
      " Loss: 0.000000\n",
      " Loss: 0.070750\n",
      " Loss: 0.000000\n",
      " Loss: 0.037390\n",
      " Loss: 0.000000\n",
      " Loss: 0.030746\n",
      " Loss: 0.000000\n",
      " Loss: 0.014316\n",
      " Loss: 0.000000\n",
      " Loss: 0.057065\n",
      " Loss: 0.000000\n",
      " Loss: 0.021326\n",
      "Epoch 1616 Chain 0 loss std 1.46e-03 variance 1.06e-06 smooth variance 7.82e-07 adaptive c -1.00\n",
      "Epoch 1616 Chain 1 loss std 1.61e+02 variance 1.29e+04 smooth variance 1.79e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.044275\n",
      " Loss: 0.000000\n",
      " Loss: 0.011565\n",
      " Loss: 0.000000\n",
      " Loss: 0.025817\n",
      " Loss: 0.000000\n",
      " Loss: 0.020542\n",
      " Loss: 0.000000\n",
      " Loss: 0.058644\n",
      " Loss: 0.000000\n",
      " Loss: 0.021606\n",
      " Loss: 0.000000\n",
      " Loss: 0.028194\n",
      " Loss: 0.000000\n",
      " Loss: 0.071651\n",
      " Loss: 0.000000\n",
      " Loss: 0.022676\n",
      " Loss: 0.000000\n",
      " Loss: 0.016715\n",
      "Epoch 1618 Chain 0 loss std 6.50e-04 variance 2.11e-07 smooth variance 6.11e-07 adaptive c -1.00\n",
      "Epoch 1618 Chain 1 loss std 2.12e+02 variance 2.24e+04 smooth variance 1.93e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035255\n",
      " Loss: 0.000000\n",
      " Loss: 0.022226\n",
      " Loss: 0.000000\n",
      " Loss: 0.023936\n",
      " Loss: 0.000000\n",
      " Loss: 0.063972\n",
      " Loss: 0.000000\n",
      " Loss: 0.015453\n",
      " Loss: 0.000000\n",
      " Loss: 0.040662\n",
      " Loss: 0.000000\n",
      " Loss: 0.020563\n",
      " Loss: 0.000000\n",
      " Loss: 0.066875\n",
      " Loss: 0.000000\n",
      " Loss: 0.014328\n",
      " Loss: 0.000000\n",
      " Loss: 0.018414\n",
      "Epoch 1620 Chain 0 loss std 1.10e-03 variance 6.04e-07 smooth variance 6.09e-07 adaptive c -1.00\n",
      "Epoch 1620 Chain 1 loss std 2.51e+02 variance 3.14e+04 smooth variance 2.29e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023926\n",
      " Loss: 0.000000\n",
      " Loss: 0.020284\n",
      " Loss: 0.000000\n",
      " Loss: 0.015980\n",
      " Loss: 0.000000\n",
      " Loss: 0.081274\n",
      " Loss: 0.000000\n",
      " Loss: 0.019378\n",
      " Loss: 0.000000\n",
      " Loss: 0.023565\n",
      " Loss: 0.000000\n",
      " Loss: 0.017904\n",
      " Loss: 0.000000\n",
      " Loss: 0.021014\n",
      " Loss: 0.000000\n",
      " Loss: 0.033514\n",
      " Loss: 0.000000\n",
      " Loss: 0.064845\n",
      "Epoch 1622 Chain 0 loss std 4.28e-04 variance 9.16e-08 smooth variance 4.54e-07 adaptive c -1.00\n",
      "Epoch 1622 Chain 1 loss std 1.98e+02 variance 1.97e+04 smooth variance 2.19e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021515\n",
      " Loss: 0.000000\n",
      " Loss: 0.023006\n",
      " Loss: 0.000000\n",
      " Loss: 0.058259\n",
      " Loss: 0.000000\n",
      " Loss: 0.038660\n",
      " Loss: 0.000000\n",
      " Loss: 0.019403\n",
      " Loss: 0.000000\n",
      " Loss: 0.086037\n",
      " Loss: 0.000000\n",
      " Loss: 0.014812\n",
      " Loss: 0.000000\n",
      " Loss: 0.019455\n",
      " Loss: 0.000000\n",
      " Loss: 0.023929\n",
      " Loss: 0.000000\n",
      " Loss: 0.016609\n",
      "Epoch 1624 Chain 0 loss std 1.54e-03 variance 1.18e-06 smooth variance 6.71e-07 adaptive c -1.00\n",
      "Epoch 1624 Chain 1 loss std 1.90e+02 variance 1.80e+04 smooth variance 2.08e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016497\n",
      " Loss: 0.000000\n",
      " Loss: 0.067368\n",
      " Loss: 0.000000\n",
      " Loss: 0.023827\n",
      " Loss: 0.000000\n",
      " Loss: 0.017751\n",
      " Loss: 0.000000\n",
      " Loss: 0.035398\n",
      " Loss: 0.000000\n",
      " Loss: 0.011246\n",
      " Loss: 0.000000\n",
      " Loss: 0.044863\n",
      " Loss: 0.000000\n",
      " Loss: 0.029856\n",
      " Loss: 0.000000\n",
      " Loss: 0.061858\n",
      " Loss: 0.000000\n",
      " Loss: 0.013018\n",
      "Epoch 1626 Chain 0 loss std 1.01e-03 variance 5.13e-07 smooth variance 6.24e-07 adaptive c -1.00\n",
      "Epoch 1626 Chain 1 loss std 2.13e+02 variance 2.26e+04 smooth variance 2.13e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021247\n",
      " Loss: 0.000000\n",
      " Loss: 0.017656\n",
      " Loss: 0.000000\n",
      " Loss: 0.032536\n",
      " Loss: 0.000000\n",
      " Loss: 0.063532\n",
      " Loss: 0.000000\n",
      " Loss: 0.025871\n",
      " Loss: 0.000000\n",
      " Loss: 0.020200\n",
      " Loss: 0.000000\n",
      " Loss: 0.057361\n",
      " Loss: 0.000000\n",
      " Loss: 0.030747\n",
      " Loss: 0.000000\n",
      " Loss: 0.017885\n",
      " Loss: 0.000000\n",
      " Loss: 0.034648\n",
      "Epoch 1628 Chain 0 loss std 1.50e-03 variance 1.13e-06 smooth variance 7.76e-07 adaptive c -1.00\n",
      "Epoch 1628 Chain 1 loss std 1.90e+02 variance 1.81e+04 smooth variance 2.04e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020892\n",
      " Loss: 0.000000\n",
      " Loss: 0.015846\n",
      " Loss: 0.000000\n",
      " Loss: 0.024264\n",
      " Loss: 0.000000\n",
      " Loss: 0.031004\n",
      " Loss: 0.000000\n",
      " Loss: 0.068835\n",
      " Loss: 0.000000\n",
      " Loss: 0.076568\n",
      " Loss: 0.000000\n",
      " Loss: 0.016649\n",
      " Loss: 0.000000\n",
      " Loss: 0.017245\n",
      " Loss: 0.000000\n",
      " Loss: 0.036158\n",
      " Loss: 0.000000\n",
      " Loss: 0.014221\n",
      "Epoch 1630 Chain 0 loss std 6.16e-04 variance 1.90e-07 smooth variance 6.00e-07 adaptive c -1.00\n",
      "Epoch 1630 Chain 1 loss std 1.56e+02 variance 1.21e+04 smooth variance 1.79e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028540\n",
      " Loss: 0.000000\n",
      " Loss: 0.045977\n",
      " Loss: 0.000000\n",
      " Loss: 0.011565\n",
      " Loss: 0.000000\n",
      " Loss: 0.059743\n",
      " Loss: 0.000000\n",
      " Loss: 0.015016\n",
      " Loss: 0.000000\n",
      " Loss: 0.024441\n",
      " Loss: 0.000000\n",
      " Loss: 0.031820\n",
      " Loss: 0.000000\n",
      " Loss: 0.025481\n",
      " Loss: 0.000000\n",
      " Loss: 0.066077\n",
      " Loss: 0.000000\n",
      " Loss: 0.013023\n",
      "Epoch 1632 Chain 0 loss std 5.61e-04 variance 1.57e-07 smooth variance 4.67e-07 adaptive c -1.00\n",
      "Epoch 1632 Chain 1 loss std 1.36e+02 variance 9.19e+03 smooth variance 1.53e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027086\n",
      " Loss: 0.000000\n",
      " Loss: 0.024960\n",
      " Loss: 0.000000\n",
      " Loss: 0.062662\n",
      " Loss: 0.000000\n",
      " Loss: 0.029020\n",
      " Loss: 0.000000\n",
      " Loss: 0.017113\n",
      " Loss: 0.000000\n",
      " Loss: 0.016511\n",
      " Loss: 0.000000\n",
      " Loss: 0.038946\n",
      " Loss: 0.000000\n",
      " Loss: 0.057018\n",
      " Loss: 0.000000\n",
      " Loss: 0.029397\n",
      " Loss: 0.000000\n",
      " Loss: 0.018969\n",
      "Epoch 1634 Chain 0 loss std 7.45e-04 variance 2.78e-07 smooth variance 4.10e-07 adaptive c -1.00\n",
      "Epoch 1634 Chain 1 loss std 1.68e+02 variance 1.42e+04 smooth variance 1.49e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019579\n",
      " Loss: 0.000000\n",
      " Loss: 0.010573\n",
      " Loss: 0.000000\n",
      " Loss: 0.037983\n",
      " Loss: 0.000000\n",
      " Loss: 0.066039\n",
      " Loss: 0.000000\n",
      " Loss: 0.026667\n",
      " Loss: 0.000000\n",
      " Loss: 0.021552\n",
      " Loss: 0.000000\n",
      " Loss: 0.016502\n",
      " Loss: 0.000000\n",
      " Loss: 0.038908\n",
      " Loss: 0.000000\n",
      " Loss: 0.019742\n",
      " Loss: 0.000000\n",
      " Loss: 0.064136\n",
      "Epoch 1636 Chain 0 loss std 7.69e-04 variance 2.96e-07 smooth variance 3.76e-07 adaptive c -1.00\n",
      "Epoch 1636 Chain 1 loss std 2.01e+02 variance 2.01e+04 smooth variance 1.65e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.041157\n",
      " Loss: 0.000000\n",
      " Loss: 0.061940\n",
      " Loss: 0.000000\n",
      " Loss: 0.016808\n",
      " Loss: 0.000000\n",
      " Loss: 0.022812\n",
      " Loss: 0.000000\n",
      " Loss: 0.018123\n",
      " Loss: 0.000000\n",
      " Loss: 0.072829\n",
      " Loss: 0.000000\n",
      " Loss: 0.028773\n",
      " Loss: 0.000000\n",
      " Loss: 0.015452\n",
      " Loss: 0.000000\n",
      " Loss: 0.015026\n",
      " Loss: 0.000000\n",
      " Loss: 0.028761\n",
      "Epoch 1638 Chain 0 loss std 9.73e-04 variance 4.73e-07 smooth variance 4.05e-07 adaptive c -1.00\n",
      "Epoch 1638 Chain 1 loss std 2.72e+02 variance 3.71e+04 smooth variance 2.27e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015415\n",
      " Loss: 0.000000\n",
      " Loss: 0.064174\n",
      " Loss: 0.000000\n",
      " Loss: 0.028337\n",
      " Loss: 0.000000\n",
      " Loss: 0.037107\n",
      " Loss: 0.000000\n",
      " Loss: 0.015808\n",
      " Loss: 0.000000\n",
      " Loss: 0.021864\n",
      " Loss: 0.000000\n",
      " Loss: 0.037579\n",
      " Loss: 0.000000\n",
      " Loss: 0.020892\n",
      " Loss: 0.000000\n",
      " Loss: 0.024056\n",
      " Loss: 0.000000\n",
      " Loss: 0.056448\n",
      "Epoch 1640 Chain 0 loss std 1.03e-03 variance 5.33e-07 smooth variance 4.44e-07 adaptive c -1.00\n",
      "Epoch 1640 Chain 1 loss std 1.89e+02 variance 1.79e+04 smooth variance 2.12e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015861\n",
      " Loss: 0.000000\n",
      " Loss: 0.024929\n",
      " Loss: 0.000000\n",
      " Loss: 0.066259\n",
      " Loss: 0.000000\n",
      " Loss: 0.040159\n",
      " Loss: 0.000000\n",
      " Loss: 0.013632\n",
      " Loss: 0.000000\n",
      " Loss: 0.018039\n",
      " Loss: 0.000000\n",
      " Loss: 0.014448\n",
      " Loss: 0.000000\n",
      " Loss: 0.021623\n",
      " Loss: 0.000000\n",
      " Loss: 0.027239\n",
      " Loss: 0.000000\n",
      " Loss: 0.079491\n",
      "Epoch 1642 Chain 0 loss std 7.10e-04 variance 2.52e-07 smooth variance 3.86e-07 adaptive c -1.00\n",
      "Epoch 1642 Chain 1 loss std 2.14e+02 variance 2.30e+04 smooth variance 2.18e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.040181\n",
      " Loss: 0.000000\n",
      " Loss: 0.063039\n",
      " Loss: 0.000000\n",
      " Loss: 0.025313\n",
      " Loss: 0.000000\n",
      " Loss: 0.012736\n",
      " Loss: 0.000000\n",
      " Loss: 0.019571\n",
      " Loss: 0.000000\n",
      " Loss: 0.058736\n",
      " Loss: 0.000000\n",
      " Loss: 0.039697\n",
      " Loss: 0.000000\n",
      " Loss: 0.026434\n",
      " Loss: 0.000000\n",
      " Loss: 0.023252\n",
      " Loss: 0.000000\n",
      " Loss: 0.012721\n",
      "Epoch 1644 Chain 0 loss std 7.28e-04 variance 2.65e-07 smooth variance 3.50e-07 adaptive c -1.00\n",
      "Epoch 1644 Chain 1 loss std 1.95e+02 variance 1.90e+04 smooth variance 2.09e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.011895\n",
      " Loss: 0.000000\n",
      " Loss: 0.023313\n",
      " Loss: 0.000000\n",
      " Loss: 0.016208\n",
      " Loss: 0.000000\n",
      " Loss: 0.019414\n",
      " Loss: 0.000000\n",
      " Loss: 0.090009\n",
      " Loss: 0.000000\n",
      " Loss: 0.019889\n",
      " Loss: 0.000000\n",
      " Loss: 0.031033\n",
      " Loss: 0.000000\n",
      " Loss: 0.038402\n",
      " Loss: 0.000000\n",
      " Loss: 0.015208\n",
      " Loss: 0.000000\n",
      " Loss: 0.056309\n",
      "Epoch 1646 Chain 0 loss std 6.11e-04 variance 1.86e-07 smooth variance 3.01e-07 adaptive c -1.00\n",
      "Epoch 1646 Chain 1 loss std 1.85e+02 variance 1.70e+04 smooth variance 1.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014082\n",
      " Loss: 0.000000\n",
      " Loss: 0.019137\n",
      " Loss: 0.000000\n",
      " Loss: 0.021182\n",
      " Loss: 0.000000\n",
      " Loss: 0.087991\n",
      " Loss: 0.000000\n",
      " Loss: 0.018447\n",
      " Loss: 0.000000\n",
      " Loss: 0.024464\n",
      " Loss: 0.000000\n",
      " Loss: 0.014588\n",
      " Loss: 0.000000\n",
      " Loss: 0.022356\n",
      " Loss: 0.000000\n",
      " Loss: 0.085355\n",
      " Loss: 0.000000\n",
      " Loss: 0.014077\n",
      "Epoch 1648 Chain 0 loss std 1.24e-03 variance 7.63e-07 smooth variance 4.39e-07 adaptive c -1.00\n",
      "Epoch 1648 Chain 1 loss std 2.03e+02 variance 2.07e+04 smooth variance 2.00e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.041046\n",
      " Loss: 0.000000\n",
      " Loss: 0.024175\n",
      " Loss: 0.000000\n",
      " Loss: 0.059985\n",
      " Loss: 0.000000\n",
      " Loss: 0.021411\n",
      " Loss: 0.000000\n",
      " Loss: 0.014222\n",
      " Loss: 0.000000\n",
      " Loss: 0.036992\n",
      " Loss: 0.000000\n",
      " Loss: 0.023370\n",
      " Loss: 0.000000\n",
      " Loss: 0.013438\n",
      " Loss: 0.000000\n",
      " Loss: 0.060103\n",
      " Loss: 0.000000\n",
      " Loss: 0.026937\n",
      "Epoch 1650 Chain 0 loss std 1.06e-03 variance 5.62e-07 smooth variance 4.76e-07 adaptive c -1.00\n",
      "Epoch 1650 Chain 1 loss std 2.25e+02 variance 2.54e+04 smooth variance 2.16e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.044853\n",
      " Loss: 0.000000\n",
      " Loss: 0.025270\n",
      " Loss: 0.000000\n",
      " Loss: 0.015160\n",
      " Loss: 0.000000\n",
      " Loss: 0.064190\n",
      " Loss: 0.000000\n",
      " Loss: 0.011366\n",
      " Loss: 0.000000\n",
      " Loss: 0.018959\n",
      " Loss: 0.000000\n",
      " Loss: 0.015204\n",
      " Loss: 0.000000\n",
      " Loss: 0.070927\n",
      " Loss: 0.000000\n",
      " Loss: 0.038546\n",
      " Loss: 0.000000\n",
      " Loss: 0.017202\n",
      "Epoch 1652 Chain 0 loss std 9.96e-04 variance 4.96e-07 smooth variance 4.82e-07 adaptive c -1.00\n",
      "Epoch 1652 Chain 1 loss std 2.76e+02 variance 3.80e+04 smooth variance 2.65e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.030096\n",
      " Loss: 0.000000\n",
      " Loss: 0.023584\n",
      " Loss: 0.000000\n",
      " Loss: 0.061478\n",
      " Loss: 0.000000\n",
      " Loss: 0.024768\n",
      " Loss: 0.000000\n",
      " Loss: 0.020914\n",
      " Loss: 0.000000\n",
      " Loss: 0.034852\n",
      " Loss: 0.000000\n",
      " Loss: 0.027168\n",
      " Loss: 0.000000\n",
      " Loss: 0.018292\n",
      " Loss: 0.000000\n",
      " Loss: 0.021612\n",
      " Loss: 0.000000\n",
      " Loss: 0.058915\n",
      "Epoch 1654 Chain 0 loss std 8.27e-04 variance 3.42e-07 smooth variance 4.40e-07 adaptive c -1.00\n",
      "Epoch 1654 Chain 1 loss std 1.98e+02 variance 1.96e+04 smooth variance 2.44e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023621\n",
      " Loss: 0.000000\n",
      " Loss: 0.022206\n",
      " Loss: 0.000000\n",
      " Loss: 0.032507\n",
      " Loss: 0.000000\n",
      " Loss: 0.060467\n",
      " Loss: 0.000000\n",
      " Loss: 0.022038\n",
      " Loss: 0.000000\n",
      " Loss: 0.039257\n",
      " Loss: 0.000000\n",
      " Loss: 0.018214\n",
      " Loss: 0.000000\n",
      " Loss: 0.019465\n",
      " Loss: 0.000000\n",
      " Loss: 0.058994\n",
      " Loss: 0.000000\n",
      " Loss: 0.024909\n",
      "Epoch 1656 Chain 0 loss std 6.36e-04 variance 2.02e-07 smooth variance 3.69e-07 adaptive c -1.00\n",
      "Epoch 1656 Chain 1 loss std 1.38e+02 variance 9.53e+03 smooth variance 2.00e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061169\n",
      " Loss: 0.000000\n",
      " Loss: 0.021631\n",
      " Loss: 0.000000\n",
      " Loss: 0.009959\n",
      " Loss: 0.000000\n",
      " Loss: 0.031944\n",
      " Loss: 0.000000\n",
      " Loss: 0.036135\n",
      " Loss: 0.000000\n",
      " Loss: 0.043588\n",
      " Loss: 0.000000\n",
      " Loss: 0.025189\n",
      " Loss: 0.000000\n",
      " Loss: 0.012034\n",
      " Loss: 0.000000\n",
      " Loss: 0.019476\n",
      " Loss: 0.000000\n",
      " Loss: 0.060552\n",
      "Epoch 1658 Chain 0 loss std 9.67e-04 variance 4.68e-07 smooth variance 3.98e-07 adaptive c -1.00\n",
      "Epoch 1658 Chain 1 loss std 1.74e+02 variance 1.51e+04 smooth variance 1.85e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.011645\n",
      " Loss: 0.000000\n",
      " Loss: 0.059443\n",
      " Loss: 0.000000\n",
      " Loss: 0.018709\n",
      " Loss: 0.000000\n",
      " Loss: 0.032630\n",
      " Loss: 0.000000\n",
      " Loss: 0.038412\n",
      " Loss: 0.000000\n",
      " Loss: 0.053945\n",
      " Loss: 0.000000\n",
      " Loss: 0.020261\n",
      " Loss: 0.000000\n",
      " Loss: 0.024842\n",
      " Loss: 0.000000\n",
      " Loss: 0.027765\n",
      " Loss: 0.000000\n",
      " Loss: 0.034027\n",
      "Epoch 1660 Chain 0 loss std 7.47e-04 variance 2.79e-07 smooth variance 3.63e-07 adaptive c -1.00\n",
      "Epoch 1660 Chain 1 loss std 1.89e+02 variance 1.78e+04 smooth variance 1.83e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.044965\n",
      " Loss: 0.000000\n",
      " Loss: 0.062889\n",
      " Loss: 0.000000\n",
      " Loss: 0.017061\n",
      " Loss: 0.000000\n",
      " Loss: 0.017707\n",
      " Loss: 0.000000\n",
      " Loss: 0.018216\n",
      " Loss: 0.000000\n",
      " Loss: 0.019450\n",
      " Loss: 0.000000\n",
      " Loss: 0.021809\n",
      " Loss: 0.000000\n",
      " Loss: 0.057256\n",
      " Loss: 0.000000\n",
      " Loss: 0.027719\n",
      " Loss: 0.000000\n",
      " Loss: 0.034604\n",
      "Epoch 1662 Chain 0 loss std 5.90e-04 variance 1.74e-07 smooth variance 3.06e-07 adaptive c -1.00\n",
      "Epoch 1662 Chain 1 loss std 2.97e+02 variance 4.40e+04 smooth variance 2.60e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.040962\n",
      " Loss: 0.000000\n",
      " Loss: 0.013007\n",
      " Loss: 0.000000\n",
      " Loss: 0.030249\n",
      " Loss: 0.000000\n",
      " Loss: 0.019766\n",
      " Loss: 0.000000\n",
      " Loss: 0.056855\n",
      " Loss: 0.000000\n",
      " Loss: 0.024742\n",
      " Loss: 0.000000\n",
      " Loss: 0.078548\n",
      " Loss: 0.000000\n",
      " Loss: 0.021751\n",
      " Loss: 0.000000\n",
      " Loss: 0.013764\n",
      " Loss: 0.000000\n",
      " Loss: 0.022034\n",
      "Epoch 1664 Chain 0 loss std 1.08e-03 variance 5.82e-07 smooth variance 3.89e-07 adaptive c -1.00\n",
      "Epoch 1664 Chain 1 loss std 1.60e+02 variance 1.28e+04 smooth variance 2.20e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.013977\n",
      " Loss: 0.000000\n",
      " Loss: 0.021565\n",
      " Loss: 0.000000\n",
      " Loss: 0.072545\n",
      " Loss: 0.000000\n",
      " Loss: 0.021871\n",
      " Loss: 0.000000\n",
      " Loss: 0.030880\n",
      " Loss: 0.000000\n",
      " Loss: 0.015281\n",
      " Loss: 0.000000\n",
      " Loss: 0.014163\n",
      " Loss: 0.000000\n",
      " Loss: 0.024082\n",
      " Loss: 0.000000\n",
      " Loss: 0.082711\n",
      " Loss: 0.000000\n",
      " Loss: 0.024601\n",
      "Epoch 1666 Chain 0 loss std 1.08e-03 variance 5.80e-07 smooth variance 4.46e-07 adaptive c -1.00\n",
      "Epoch 1666 Chain 1 loss std 2.61e+02 variance 3.40e+04 smooth variance 2.56e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015404\n",
      " Loss: 0.000000\n",
      " Loss: 0.036202\n",
      " Loss: 0.000000\n",
      " Loss: 0.065434\n",
      " Loss: 0.000000\n",
      " Loss: 0.026067\n",
      " Loss: 0.000000\n",
      " Loss: 0.017731\n",
      " Loss: 0.000000\n",
      " Loss: 0.067769\n",
      " Loss: 0.000000\n",
      " Loss: 0.019135\n",
      " Loss: 0.000000\n",
      " Loss: 0.016872\n",
      " Loss: 0.000000\n",
      " Loss: 0.018663\n",
      " Loss: 0.000000\n",
      " Loss: 0.038399\n",
      "Epoch 1668 Chain 0 loss std 1.11e-03 variance 6.20e-07 smooth variance 4.98e-07 adaptive c -1.00\n",
      "Epoch 1668 Chain 1 loss std 3.05e+02 variance 4.65e+04 smooth variance 3.19e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024182\n",
      " Loss: 0.000000\n",
      " Loss: 0.020757\n",
      " Loss: 0.000000\n",
      " Loss: 0.021021\n",
      " Loss: 0.000000\n",
      " Loss: 0.034508\n",
      " Loss: 0.000000\n",
      " Loss: 0.060370\n",
      " Loss: 0.000000\n",
      " Loss: 0.019806\n",
      " Loss: 0.000000\n",
      " Loss: 0.058237\n",
      " Loss: 0.000000\n",
      " Loss: 0.034455\n",
      " Loss: 0.000000\n",
      " Loss: 0.029230\n",
      " Loss: 0.000000\n",
      " Loss: 0.019111\n",
      "Epoch 1670 Chain 0 loss std 1.10e-03 variance 6.03e-07 smooth variance 5.30e-07 adaptive c -1.00\n",
      "Epoch 1670 Chain 1 loss std 1.57e+02 variance 1.24e+04 smooth variance 2.60e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027380\n",
      " Loss: 0.000000\n",
      " Loss: 0.010803\n",
      " Loss: 0.000000\n",
      " Loss: 0.028790\n",
      " Loss: 0.000000\n",
      " Loss: 0.023612\n",
      " Loss: 0.000000\n",
      " Loss: 0.070253\n",
      " Loss: 0.000000\n",
      " Loss: 0.045487\n",
      " Loss: 0.000000\n",
      " Loss: 0.059691\n",
      " Loss: 0.000000\n",
      " Loss: 0.022187\n",
      " Loss: 0.000000\n",
      " Loss: 0.015490\n",
      " Loss: 0.000000\n",
      " Loss: 0.017984\n",
      "Epoch 1672 Chain 0 loss std 6.44e-04 variance 2.07e-07 smooth variance 4.33e-07 adaptive c -1.00\n",
      "Epoch 1672 Chain 1 loss std 2.56e+02 variance 3.27e+04 smooth variance 2.80e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032754\n",
      " Loss: 0.000000\n",
      " Loss: 0.027535\n",
      " Loss: 0.000000\n",
      " Loss: 0.019986\n",
      " Loss: 0.000000\n",
      " Loss: 0.062362\n",
      " Loss: 0.000000\n",
      " Loss: 0.018200\n",
      " Loss: 0.000000\n",
      " Loss: 0.038940\n",
      " Loss: 0.000000\n",
      " Loss: 0.026405\n",
      " Loss: 0.000000\n",
      " Loss: 0.066143\n",
      " Loss: 0.000000\n",
      " Loss: 0.009857\n",
      " Loss: 0.000000\n",
      " Loss: 0.019493\n",
      "Epoch 1674 Chain 0 loss std 9.32e-04 variance 4.35e-07 smooth variance 4.33e-07 adaptive c -1.00\n",
      "Epoch 1674 Chain 1 loss std 2.02e+02 variance 2.04e+04 smooth variance 2.57e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017846\n",
      " Loss: 0.000000\n",
      " Loss: 0.011958\n",
      " Loss: 0.000000\n",
      " Loss: 0.029638\n",
      " Loss: 0.000000\n",
      " Loss: 0.040762\n",
      " Loss: 0.000000\n",
      " Loss: 0.060634\n",
      " Loss: 0.000000\n",
      " Loss: 0.076676\n",
      " Loss: 0.000000\n",
      " Loss: 0.026858\n",
      " Loss: 0.000000\n",
      " Loss: 0.022756\n",
      " Loss: 0.000000\n",
      " Loss: 0.011450\n",
      " Loss: 0.000000\n",
      " Loss: 0.023099\n",
      "Epoch 1676 Chain 0 loss std 1.17e-03 variance 6.90e-07 smooth variance 5.10e-07 adaptive c -1.00\n",
      "Epoch 1676 Chain 1 loss std 1.83e+02 variance 1.67e+04 smooth variance 2.30e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.012578\n",
      " Loss: 0.000000\n",
      " Loss: 0.025171\n",
      " Loss: 0.000000\n",
      " Loss: 0.018127\n",
      " Loss: 0.000000\n",
      " Loss: 0.041736\n",
      " Loss: 0.000000\n",
      " Loss: 0.063227\n",
      " Loss: 0.000000\n",
      " Loss: 0.037801\n",
      " Loss: 0.000000\n",
      " Loss: 0.015799\n",
      " Loss: 0.000000\n",
      " Loss: 0.020285\n",
      " Loss: 0.000000\n",
      " Loss: 0.064913\n",
      " Loss: 0.000000\n",
      " Loss: 0.022041\n",
      "Epoch 1678 Chain 0 loss std 8.62e-04 variance 3.71e-07 smooth variance 4.69e-07 adaptive c -1.00\n",
      "Epoch 1678 Chain 1 loss std 2.68e+02 variance 3.59e+04 smooth variance 2.69e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022526\n",
      " Loss: 0.000000\n",
      " Loss: 0.031741\n",
      " Loss: 0.000000\n",
      " Loss: 0.035150\n",
      " Loss: 0.000000\n",
      " Loss: 0.057579\n",
      " Loss: 0.000000\n",
      " Loss: 0.013842\n",
      " Loss: 0.000000\n",
      " Loss: 0.015740\n",
      " Loss: 0.000000\n",
      " Loss: 0.082231\n",
      " Loss: 0.000000\n",
      " Loss: 0.015434\n",
      " Loss: 0.000000\n",
      " Loss: 0.029207\n",
      " Loss: 0.000000\n",
      " Loss: 0.018226\n",
      "Epoch 1680 Chain 0 loss std 1.36e-03 variance 9.27e-07 smooth variance 6.06e-07 adaptive c -1.00\n",
      "Epoch 1680 Chain 1 loss std 2.41e+02 variance 2.92e+04 smooth variance 2.76e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.080338\n",
      " Loss: 0.000000\n",
      " Loss: 0.017182\n",
      " Loss: 0.000000\n",
      " Loss: 0.021885\n",
      " Loss: 0.000000\n",
      " Loss: 0.020258\n",
      " Loss: 0.000000\n",
      " Loss: 0.021175\n",
      " Loss: 0.000000\n",
      " Loss: 0.054133\n",
      " Loss: 0.000000\n",
      " Loss: 0.023314\n",
      " Loss: 0.000000\n",
      " Loss: 0.021541\n",
      " Loss: 0.000000\n",
      " Loss: 0.013831\n",
      " Loss: 0.000000\n",
      " Loss: 0.048019\n",
      "Epoch 1682 Chain 0 loss std 9.87e-04 variance 4.87e-07 smooth variance 5.70e-07 adaptive c -1.00\n",
      "Epoch 1682 Chain 1 loss std 1.50e+02 variance 1.12e+04 smooth variance 2.27e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016590\n",
      " Loss: 0.000000\n",
      " Loss: 0.065138\n",
      " Loss: 0.000000\n",
      " Loss: 0.025852\n",
      " Loss: 0.000000\n",
      " Loss: 0.016137\n",
      " Loss: 0.000000\n",
      " Loss: 0.037121\n",
      " Loss: 0.000000\n",
      " Loss: 0.021471\n",
      " Loss: 0.000000\n",
      " Loss: 0.071697\n",
      " Loss: 0.000000\n",
      " Loss: 0.030534\n",
      " Loss: 0.000000\n",
      " Loss: 0.021143\n",
      " Loss: 0.000000\n",
      " Loss: 0.015992\n",
      "Epoch 1684 Chain 0 loss std 9.56e-04 variance 4.57e-07 smooth variance 5.36e-07 adaptive c -1.00\n",
      "Epoch 1684 Chain 1 loss std 2.14e+02 variance 2.29e+04 smooth variance 2.27e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023407\n",
      " Loss: 0.000000\n",
      " Loss: 0.020183\n",
      " Loss: 0.000000\n",
      " Loss: 0.043088\n",
      " Loss: 0.000001\n",
      " Loss: 0.054341\n",
      " Loss: 0.000000\n",
      " Loss: 0.019820\n",
      " Loss: 0.000000\n",
      " Loss: 0.014055\n",
      " Loss: 0.000000\n",
      " Loss: 0.083505\n",
      " Loss: 0.000000\n",
      " Loss: 0.023342\n",
      " Loss: 0.000000\n",
      " Loss: 0.014388\n",
      " Loss: 0.000000\n",
      " Loss: 0.025548\n",
      "Epoch 1686 Chain 0 loss std 5.25e-04 variance 1.38e-07 smooth variance 4.17e-07 adaptive c -1.00\n",
      "Epoch 1686 Chain 1 loss std 2.22e+02 variance 2.47e+04 smooth variance 2.33e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022898\n",
      " Loss: 0.000000\n",
      " Loss: 0.034265\n",
      " Loss: 0.000000\n",
      " Loss: 0.030642\n",
      " Loss: 0.000000\n",
      " Loss: 0.056545\n",
      " Loss: 0.000000\n",
      " Loss: 0.016488\n",
      " Loss: 0.000000\n",
      " Loss: 0.078044\n",
      " Loss: 0.000000\n",
      " Loss: 0.017188\n",
      " Loss: 0.000000\n",
      " Loss: 0.016825\n",
      " Loss: 0.000000\n",
      " Loss: 0.026490\n",
      " Loss: 0.000000\n",
      " Loss: 0.022290\n",
      "Epoch 1688 Chain 0 loss std 9.39e-04 variance 4.41e-07 smooth variance 4.24e-07 adaptive c -1.00\n",
      "Epoch 1688 Chain 1 loss std 2.37e+02 variance 2.81e+04 smooth variance 2.48e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016767\n",
      " Loss: 0.000000\n",
      " Loss: 0.026607\n",
      " Loss: 0.000000\n",
      " Loss: 0.029252\n",
      " Loss: 0.000000\n",
      " Loss: 0.017403\n",
      " Loss: 0.000000\n",
      " Loss: 0.070808\n",
      " Loss: 0.000000\n",
      " Loss: 0.078837\n",
      " Loss: 0.000000\n",
      " Loss: 0.024097\n",
      " Loss: 0.000000\n",
      " Loss: 0.026347\n",
      " Loss: 0.000000\n",
      " Loss: 0.011136\n",
      " Loss: 0.000000\n",
      " Loss: 0.020421\n",
      "Epoch 1690 Chain 0 loss std 4.81e-04 variance 1.16e-07 smooth variance 3.32e-07 adaptive c -1.00\n",
      "Epoch 1690 Chain 1 loss std 1.76e+02 variance 1.55e+04 smooth variance 2.20e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029467\n",
      " Loss: 0.000000\n",
      " Loss: 0.015870\n",
      " Loss: 0.000000\n",
      " Loss: 0.023398\n",
      " Loss: 0.000000\n",
      " Loss: 0.028592\n",
      " Loss: 0.000000\n",
      " Loss: 0.063511\n",
      " Loss: 0.000000\n",
      " Loss: 0.022620\n",
      " Loss: 0.000000\n",
      " Loss: 0.016407\n",
      " Loss: 0.000000\n",
      " Loss: 0.067203\n",
      " Loss: 0.000000\n",
      " Loss: 0.020809\n",
      " Loss: 0.000000\n",
      " Loss: 0.033800\n",
      "Epoch 1692 Chain 0 loss std 1.02e-03 variance 5.19e-07 smooth variance 3.88e-07 adaptive c -1.00\n",
      "Epoch 1692 Chain 1 loss std 2.29e+02 variance 2.61e+04 smooth variance 2.32e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.058160\n",
      " Loss: 0.000000\n",
      " Loss: 0.023380\n",
      " Loss: 0.000000\n",
      " Loss: 0.016219\n",
      " Loss: 0.000000\n",
      " Loss: 0.020506\n",
      " Loss: 0.000000\n",
      " Loss: 0.042573\n",
      " Loss: 0.000000\n",
      " Loss: 0.025208\n",
      " Loss: 0.000000\n",
      " Loss: 0.016185\n",
      " Loss: 0.000000\n",
      " Loss: 0.078445\n",
      " Loss: 0.000000\n",
      " Loss: 0.016031\n",
      " Loss: 0.000000\n",
      " Loss: 0.024970\n",
      "Epoch 1694 Chain 0 loss std 9.49e-04 variance 4.51e-07 smooth variance 4.07e-07 adaptive c -1.00\n",
      "Epoch 1694 Chain 1 loss std 1.48e+02 variance 1.10e+04 smooth variance 1.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014574\n",
      " Loss: 0.000000\n",
      " Loss: 0.026584\n",
      " Loss: 0.000000\n",
      " Loss: 0.066178\n",
      " Loss: 0.000000\n",
      " Loss: 0.014414\n",
      " Loss: 0.000000\n",
      " Loss: 0.039088\n",
      " Loss: 0.000000\n",
      " Loss: 0.033723\n",
      " Loss: 0.000000\n",
      " Loss: 0.019358\n",
      " Loss: 0.000000\n",
      " Loss: 0.016493\n",
      " Loss: 0.000000\n",
      " Loss: 0.022250\n",
      " Loss: 0.000000\n",
      " Loss: 0.069014\n",
      "Epoch 1696 Chain 0 loss std 8.16e-04 variance 3.33e-07 smooth variance 3.85e-07 adaptive c -1.00\n",
      "Epoch 1696 Chain 1 loss std 2.90e+02 variance 4.20e+04 smooth variance 2.63e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019071\n",
      " Loss: 0.000000\n",
      " Loss: 0.024972\n",
      " Loss: 0.000000\n",
      " Loss: 0.035081\n",
      " Loss: 0.000000\n",
      " Loss: 0.069240\n",
      " Loss: 0.000000\n",
      " Loss: 0.012474\n",
      " Loss: 0.000000\n",
      " Loss: 0.034412\n",
      " Loss: 0.000000\n",
      " Loss: 0.014983\n",
      " Loss: 0.000000\n",
      " Loss: 0.014610\n",
      " Loss: 0.000000\n",
      " Loss: 0.019985\n",
      " Loss: 0.000000\n",
      " Loss: 0.076848\n",
      "Epoch 1698 Chain 0 loss std 9.17e-04 variance 4.21e-07 smooth variance 3.95e-07 adaptive c -1.00\n",
      "Epoch 1698 Chain 1 loss std 2.22e+02 variance 2.46e+04 smooth variance 2.58e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020252\n",
      " Loss: 0.000000\n",
      " Loss: 0.014919\n",
      " Loss: 0.000000\n",
      " Loss: 0.016791\n",
      " Loss: 0.000000\n",
      " Loss: 0.035829\n",
      " Loss: 0.000000\n",
      " Loss: 0.073046\n",
      " Loss: 0.000000\n",
      " Loss: 0.032431\n",
      " Loss: 0.000000\n",
      " Loss: 0.012084\n",
      " Loss: 0.000000\n",
      " Loss: 0.029120\n",
      " Loss: 0.000000\n",
      " Loss: 0.077857\n",
      " Loss: 0.000000\n",
      " Loss: 0.009346\n",
      "Epoch 1700 Chain 0 loss std 1.33e-03 variance 8.87e-07 smooth variance 5.43e-07 adaptive c -1.00\n",
      "Epoch 1700 Chain 1 loss std 1.58e+02 variance 1.24e+04 smooth variance 2.18e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017872\n",
      " Loss: 0.000000\n",
      " Loss: 0.063051\n",
      " Loss: 0.000000\n",
      " Loss: 0.024543\n",
      " Loss: 0.000000\n",
      " Loss: 0.030421\n",
      " Loss: 0.000000\n",
      " Loss: 0.024950\n",
      " Loss: 0.000000\n",
      " Loss: 0.021609\n",
      " Loss: 0.000000\n",
      " Loss: 0.016996\n",
      " Loss: 0.000000\n",
      " Loss: 0.065315\n",
      " Loss: 0.000000\n",
      " Loss: 0.032965\n",
      " Loss: 0.000000\n",
      " Loss: 0.023952\n",
      "Epoch 1702 Chain 0 loss std 5.93e-04 variance 1.76e-07 smooth variance 4.33e-07 adaptive c -1.00\n",
      "Epoch 1702 Chain 1 loss std 1.77e+02 variance 1.56e+04 smooth variance 1.99e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019059\n",
      " Loss: 0.000000\n",
      " Loss: 0.018090\n",
      " Loss: 0.000000\n",
      " Loss: 0.018787\n",
      " Loss: 0.000000\n",
      " Loss: 0.066858\n",
      " Loss: 0.000000\n",
      " Loss: 0.038045\n",
      " Loss: 0.000000\n",
      " Loss: 0.020169\n",
      " Loss: 0.000000\n",
      " Loss: 0.021200\n",
      " Loss: 0.000000\n",
      " Loss: 0.081608\n",
      " Loss: 0.000000\n",
      " Loss: 0.021237\n",
      " Loss: 0.000000\n",
      " Loss: 0.016624\n",
      "Epoch 1704 Chain 0 loss std 1.05e-03 variance 5.49e-07 smooth variance 4.68e-07 adaptive c -1.00\n",
      "Epoch 1704 Chain 1 loss std 1.73e+02 variance 1.50e+04 smooth variance 1.84e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.012273\n",
      " Loss: 0.000000\n",
      " Loss: 0.021844\n",
      " Loss: 0.000000\n",
      " Loss: 0.058900\n",
      " Loss: 0.000000\n",
      " Loss: 0.041555\n",
      " Loss: 0.000000\n",
      " Loss: 0.026265\n",
      " Loss: 0.000000\n",
      " Loss: 0.018785\n",
      " Loss: 0.000000\n",
      " Loss: 0.026123\n",
      " Loss: 0.000000\n",
      " Loss: 0.065528\n",
      " Loss: 0.000000\n",
      " Loss: 0.013367\n",
      " Loss: 0.000000\n",
      " Loss: 0.037035\n",
      "Epoch 1706 Chain 0 loss std 1.09e-03 variance 5.95e-07 smooth variance 5.06e-07 adaptive c -1.00\n",
      "Epoch 1706 Chain 1 loss std 2.22e+02 variance 2.46e+04 smooth variance 2.03e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.062972\n",
      " Loss: 0.000000\n",
      " Loss: 0.019081\n",
      " Loss: 0.000000\n",
      " Loss: 0.025356\n",
      " Loss: 0.000000\n",
      " Loss: 0.024821\n",
      " Loss: 0.000000\n",
      " Loss: 0.028608\n",
      " Loss: 0.000000\n",
      " Loss: 0.036357\n",
      " Loss: 0.000000\n",
      " Loss: 0.059317\n",
      " Loss: 0.000000\n",
      " Loss: 0.030098\n",
      " Loss: 0.000000\n",
      " Loss: 0.019464\n",
      " Loss: 0.000000\n",
      " Loss: 0.015603\n",
      "Epoch 1708 Chain 0 loss std 1.49e-03 variance 1.12e-06 smooth variance 6.89e-07 adaptive c -1.00\n",
      "Epoch 1708 Chain 1 loss std 1.97e+02 variance 1.93e+04 smooth variance 2.00e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061857\n",
      " Loss: 0.000000\n",
      " Loss: 0.024044\n",
      " Loss: 0.000000\n",
      " Loss: 0.013601\n",
      " Loss: 0.000000\n",
      " Loss: 0.027790\n",
      " Loss: 0.000000\n",
      " Loss: 0.033546\n",
      " Loss: 0.000000\n",
      " Loss: 0.025256\n",
      " Loss: 0.000000\n",
      " Loss: 0.021946\n",
      " Loss: 0.000000\n",
      " Loss: 0.022850\n",
      " Loss: 0.000000\n",
      " Loss: 0.072235\n",
      " Loss: 0.000000\n",
      " Loss: 0.018551\n",
      "Epoch 1710 Chain 0 loss std 1.10e-03 variance 6.00e-07 smooth variance 6.62e-07 adaptive c -1.00\n",
      "Epoch 1710 Chain 1 loss std 1.95e+02 variance 1.91e+04 smooth variance 1.97e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026621\n",
      " Loss: 0.000000\n",
      " Loss: 0.021838\n",
      " Loss: 0.000000\n",
      " Loss: 0.062849\n",
      " Loss: 0.000000\n",
      " Loss: 0.029733\n",
      " Loss: 0.000000\n",
      " Loss: 0.019796\n",
      " Loss: 0.000000\n",
      " Loss: 0.015391\n",
      " Loss: 0.000000\n",
      " Loss: 0.016871\n",
      " Loss: 0.000000\n",
      " Loss: 0.024980\n",
      " Loss: 0.000000\n",
      " Loss: 0.060770\n",
      " Loss: 0.000000\n",
      " Loss: 0.042827\n",
      "Epoch 1712 Chain 0 loss std 1.04e-03 variance 5.39e-07 smooth variance 6.25e-07 adaptive c -1.00\n",
      "Epoch 1712 Chain 1 loss std 1.74e+02 variance 1.51e+04 smooth variance 1.83e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014099\n",
      " Loss: 0.000000\n",
      " Loss: 0.063382\n",
      " Loss: 0.000000\n",
      " Loss: 0.029596\n",
      " Loss: 0.000000\n",
      " Loss: 0.035296\n",
      " Loss: 0.000000\n",
      " Loss: 0.018466\n",
      " Loss: 0.000000\n",
      " Loss: 0.024712\n",
      " Loss: 0.000000\n",
      " Loss: 0.022819\n",
      " Loss: 0.000000\n",
      " Loss: 0.078411\n",
      " Loss: 0.000000\n",
      " Loss: 0.016982\n",
      " Loss: 0.000000\n",
      " Loss: 0.017913\n",
      "Epoch 1714 Chain 0 loss std 9.58e-04 variance 4.59e-07 smooth variance 5.75e-07 adaptive c -1.00\n",
      "Epoch 1714 Chain 1 loss std 1.60e+02 variance 1.28e+04 smooth variance 1.67e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.030142\n",
      " Loss: 0.000000\n",
      " Loss: 0.020746\n",
      " Loss: 0.000000\n",
      " Loss: 0.035288\n",
      " Loss: 0.000000\n",
      " Loss: 0.062375\n",
      " Loss: 0.000000\n",
      " Loss: 0.012287\n",
      " Loss: 0.000000\n",
      " Loss: 0.020754\n",
      " Loss: 0.000000\n",
      " Loss: 0.023664\n",
      " Loss: 0.000000\n",
      " Loss: 0.018956\n",
      " Loss: 0.000000\n",
      " Loss: 0.017081\n",
      " Loss: 0.000000\n",
      " Loss: 0.080383\n",
      "Epoch 1716 Chain 0 loss std 1.33e-03 variance 8.88e-07 smooth variance 6.69e-07 adaptive c -1.00\n",
      "Epoch 1716 Chain 1 loss std 2.09e+02 variance 2.18e+04 smooth variance 1.82e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035741\n",
      " Loss: 0.000000\n",
      " Loss: 0.023909\n",
      " Loss: 0.000000\n",
      " Loss: 0.013324\n",
      " Loss: 0.000000\n",
      " Loss: 0.020699\n",
      " Loss: 0.000000\n",
      " Loss: 0.067164\n",
      " Loss: 0.000000\n",
      " Loss: 0.027812\n",
      " Loss: 0.000000\n",
      " Loss: 0.021569\n",
      " Loss: 0.000000\n",
      " Loss: 0.014651\n",
      " Loss: 0.000000\n",
      " Loss: 0.014985\n",
      " Loss: 0.000000\n",
      " Loss: 0.081820\n",
      "Epoch 1718 Chain 0 loss std 8.65e-04 variance 3.74e-07 smooth variance 5.81e-07 adaptive c -1.00\n",
      "Epoch 1718 Chain 1 loss std 2.80e+02 variance 3.91e+04 smooth variance 2.45e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061502\n",
      " Loss: 0.000000\n",
      " Loss: 0.031502\n",
      " Loss: 0.000000\n",
      " Loss: 0.023637\n",
      " Loss: 0.000000\n",
      " Loss: 0.024854\n",
      " Loss: 0.000000\n",
      " Loss: 0.019341\n",
      " Loss: 0.000000\n",
      " Loss: 0.019205\n",
      " Loss: 0.000000\n",
      " Loss: 0.062211\n",
      " Loss: 0.000000\n",
      " Loss: 0.020990\n",
      " Loss: 0.000000\n",
      " Loss: 0.034120\n",
      " Loss: 0.000000\n",
      " Loss: 0.024312\n",
      "Epoch 1720 Chain 0 loss std 1.03e-03 variance 5.34e-07 smooth variance 5.67e-07 adaptive c -1.00\n",
      "Epoch 1720 Chain 1 loss std 2.18e+02 variance 2.38e+04 smooth variance 2.43e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017585\n",
      " Loss: 0.000000\n",
      " Loss: 0.028360\n",
      " Loss: 0.000000\n",
      " Loss: 0.021256\n",
      " Loss: 0.000000\n",
      " Loss: 0.063737\n",
      " Loss: 0.000000\n",
      " Loss: 0.029899\n",
      " Loss: 0.000000\n",
      " Loss: 0.038062\n",
      " Loss: 0.000000\n",
      " Loss: 0.060093\n",
      " Loss: 0.000000\n",
      " Loss: 0.023831\n",
      " Loss: 0.000000\n",
      " Loss: 0.023282\n",
      " Loss: 0.000000\n",
      " Loss: 0.015570\n",
      "Epoch 1722 Chain 0 loss std 8.97e-04 variance 4.02e-07 smooth variance 5.17e-07 adaptive c -1.00\n",
      "Epoch 1722 Chain 1 loss std 1.65e+02 variance 1.35e+04 smooth variance 2.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028046\n",
      " Loss: 0.000000\n",
      " Loss: 0.026656\n",
      " Loss: 0.000000\n",
      " Loss: 0.060520\n",
      " Loss: 0.000000\n",
      " Loss: 0.022941\n",
      " Loss: 0.000000\n",
      " Loss: 0.022675\n",
      " Loss: 0.000000\n",
      " Loss: 0.029815\n",
      " Loss: 0.000000\n",
      " Loss: 0.023806\n",
      " Loss: 0.000000\n",
      " Loss: 0.020264\n",
      " Loss: 0.000000\n",
      " Loss: 0.023241\n",
      " Loss: 0.000000\n",
      " Loss: 0.063713\n",
      "Epoch 1724 Chain 0 loss std 1.49e-03 variance 1.10e-06 smooth variance 6.94e-07 adaptive c -1.00\n",
      "Epoch 1724 Chain 1 loss std 2.36e+02 variance 2.78e+04 smooth variance 2.31e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.012890\n",
      " Loss: 0.000000\n",
      " Loss: 0.017208\n",
      " Loss: 0.000000\n",
      " Loss: 0.025978\n",
      " Loss: 0.000000\n",
      " Loss: 0.067115\n",
      " Loss: 0.000000\n",
      " Loss: 0.037647\n",
      " Loss: 0.000000\n",
      " Loss: 0.030549\n",
      " Loss: 0.000000\n",
      " Loss: 0.016016\n",
      " Loss: 0.000000\n",
      " Loss: 0.027508\n",
      " Loss: 0.000000\n",
      " Loss: 0.061107\n",
      " Loss: 0.000000\n",
      " Loss: 0.025657\n",
      "Epoch 1726 Chain 0 loss std 1.29e-03 variance 8.28e-07 smooth variance 7.34e-07 adaptive c -1.00\n",
      "Epoch 1726 Chain 1 loss std 1.69e+02 variance 1.42e+04 smooth variance 2.04e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.031831\n",
      " Loss: 0.000000\n",
      " Loss: 0.020782\n",
      " Loss: 0.000000\n",
      " Loss: 0.061714\n",
      " Loss: 0.000000\n",
      " Loss: 0.031088\n",
      " Loss: 0.000000\n",
      " Loss: 0.015422\n",
      " Loss: 0.000000\n",
      " Loss: 0.012905\n",
      " Loss: 0.000000\n",
      " Loss: 0.026676\n",
      " Loss: 0.000000\n",
      " Loss: 0.066385\n",
      " Loss: 0.000000\n",
      " Loss: 0.011914\n",
      " Loss: 0.000000\n",
      " Loss: 0.042958\n",
      "Epoch 1728 Chain 0 loss std 6.30e-04 variance 1.98e-07 smooth variance 5.73e-07 adaptive c -1.00\n",
      "Epoch 1728 Chain 1 loss std 1.90e+02 variance 1.81e+04 smooth variance 1.97e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018150\n",
      " Loss: 0.000000\n",
      " Loss: 0.010379\n",
      " Loss: 0.000000\n",
      " Loss: 0.034816\n",
      " Loss: 0.000000\n",
      " Loss: 0.068150\n",
      " Loss: 0.000000\n",
      " Loss: 0.029342\n",
      " Loss: 0.000000\n",
      " Loss: 0.037580\n",
      " Loss: 0.000000\n",
      " Loss: 0.035184\n",
      " Loss: 0.000000\n",
      " Loss: 0.054291\n",
      " Loss: 0.000000\n",
      " Loss: 0.018373\n",
      " Loss: 0.000000\n",
      " Loss: 0.015409\n",
      "Epoch 1730 Chain 0 loss std 7.59e-04 variance 2.88e-07 smooth variance 4.88e-07 adaptive c -1.00\n",
      "Epoch 1730 Chain 1 loss std 2.07e+02 variance 2.15e+04 smooth variance 2.03e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016353\n",
      " Loss: 0.000000\n",
      " Loss: 0.015242\n",
      " Loss: 0.000000\n",
      " Loss: 0.038025\n",
      " Loss: 0.000000\n",
      " Loss: 0.059813\n",
      " Loss: 0.000000\n",
      " Loss: 0.031405\n",
      " Loss: 0.000000\n",
      " Loss: 0.031240\n",
      " Loss: 0.000000\n",
      " Loss: 0.023319\n",
      " Loss: 0.000000\n",
      " Loss: 0.010168\n",
      " Loss: 0.000000\n",
      " Loss: 0.079532\n",
      " Loss: 0.000000\n",
      " Loss: 0.016580\n",
      "Epoch 1732 Chain 0 loss std 1.18e-03 variance 6.93e-07 smooth variance 5.49e-07 adaptive c -1.00\n",
      "Epoch 1732 Chain 1 loss std 2.12e+02 variance 2.25e+04 smooth variance 2.09e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023485\n",
      " Loss: 0.000000\n",
      " Loss: 0.013666\n",
      " Loss: 0.000000\n",
      " Loss: 0.028195\n",
      " Loss: 0.000000\n",
      " Loss: 0.060026\n",
      " Loss: 0.000000\n",
      " Loss: 0.035466\n",
      " Loss: 0.000000\n",
      " Loss: 0.035741\n",
      " Loss: 0.000000\n",
      " Loss: 0.017742\n",
      " Loss: 0.000000\n",
      " Loss: 0.059938\n",
      " Loss: 0.000000\n",
      " Loss: 0.022185\n",
      " Loss: 0.000000\n",
      " Loss: 0.025231\n",
      "Epoch 1734 Chain 0 loss std 1.30e-03 variance 8.43e-07 smooth variance 6.37e-07 adaptive c -1.00\n",
      "Epoch 1734 Chain 1 loss std 1.65e+02 variance 1.36e+04 smooth variance 1.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.011351\n",
      " Loss: 0.000000\n",
      " Loss: 0.023708\n",
      " Loss: 0.000000\n",
      " Loss: 0.034747\n",
      " Loss: 0.000000\n",
      " Loss: 0.025303\n",
      " Loss: 0.000000\n",
      " Loss: 0.065729\n",
      " Loss: 0.000000\n",
      " Loss: 0.021971\n",
      " Loss: 0.000000\n",
      " Loss: 0.018134\n",
      " Loss: 0.000000\n",
      " Loss: 0.040302\n",
      " Loss: 0.000000\n",
      " Loss: 0.021544\n",
      " Loss: 0.000000\n",
      " Loss: 0.058887\n",
      "Epoch 1736 Chain 0 loss std 8.44e-04 variance 3.56e-07 smooth variance 5.53e-07 adaptive c -1.00\n",
      "Epoch 1736 Chain 1 loss std 1.35e+02 variance 9.13e+03 smooth variance 1.59e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016053\n",
      " Loss: 0.000000\n",
      " Loss: 0.039241\n",
      " Loss: 0.000000\n",
      " Loss: 0.070439\n",
      " Loss: 0.000000\n",
      " Loss: 0.018283\n",
      " Loss: 0.000000\n",
      " Loss: 0.016822\n",
      " Loss: 0.000000\n",
      " Loss: 0.012913\n",
      " Loss: 0.000000\n",
      " Loss: 0.064521\n",
      " Loss: 0.000000\n",
      " Loss: 0.041126\n",
      " Loss: 0.000000\n",
      " Loss: 0.021061\n",
      " Loss: 0.000000\n",
      " Loss: 0.021216\n",
      "Epoch 1738 Chain 0 loss std 9.20e-04 variance 4.23e-07 smooth variance 5.14e-07 adaptive c -1.00\n",
      "Epoch 1738 Chain 1 loss std 2.17e+02 variance 2.36e+04 smooth variance 1.82e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019497\n",
      " Loss: 0.000000\n",
      " Loss: 0.017174\n",
      " Loss: 0.000000\n",
      " Loss: 0.070704\n",
      " Loss: 0.000000\n",
      " Loss: 0.035320\n",
      " Loss: 0.000000\n",
      " Loss: 0.018143\n",
      " Loss: 0.000000\n",
      " Loss: 0.021410\n",
      " Loss: 0.000000\n",
      " Loss: 0.010305\n",
      " Loss: 0.000000\n",
      " Loss: 0.023484\n",
      " Loss: 0.000000\n",
      " Loss: 0.064624\n",
      " Loss: 0.000000\n",
      " Loss: 0.041015\n",
      "Epoch 1740 Chain 0 loss std 8.81e-04 variance 3.88e-07 smooth variance 4.76e-07 adaptive c -1.00\n",
      "Epoch 1740 Chain 1 loss std 2.37e+02 variance 2.80e+04 smooth variance 2.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.042074\n",
      " Loss: 0.000000\n",
      " Loss: 0.014987\n",
      " Loss: 0.000000\n",
      " Loss: 0.060666\n",
      " Loss: 0.000000\n",
      " Loss: 0.022393\n",
      " Loss: 0.000000\n",
      " Loss: 0.020718\n",
      " Loss: 0.000000\n",
      " Loss: 0.014749\n",
      " Loss: 0.000000\n",
      " Loss: 0.065246\n",
      " Loss: 0.000000\n",
      " Loss: 0.036228\n",
      " Loss: 0.000000\n",
      " Loss: 0.025728\n",
      " Loss: 0.000000\n",
      " Loss: 0.018886\n",
      "Epoch 1742 Chain 0 loss std 8.79e-04 variance 3.86e-07 smooth variance 4.49e-07 adaptive c -1.00\n",
      "Epoch 1742 Chain 1 loss std 2.08e+02 variance 2.17e+04 smooth variance 2.13e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024350\n",
      " Loss: 0.000000\n",
      " Loss: 0.025268\n",
      " Loss: 0.000000\n",
      " Loss: 0.056707\n",
      " Loss: 0.000000\n",
      " Loss: 0.033701\n",
      " Loss: 0.000000\n",
      " Loss: 0.020812\n",
      " Loss: 0.000000\n",
      " Loss: 0.063320\n",
      " Loss: 0.000000\n",
      " Loss: 0.031578\n",
      " Loss: 0.000000\n",
      " Loss: 0.020266\n",
      " Loss: 0.000000\n",
      " Loss: 0.030217\n",
      " Loss: 0.000000\n",
      " Loss: 0.015457\n",
      "Epoch 1744 Chain 0 loss std 8.90e-04 variance 3.96e-07 smooth variance 4.33e-07 adaptive c -1.00\n",
      "Epoch 1744 Chain 1 loss std 2.23e+02 variance 2.49e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.011891\n",
      " Loss: 0.000000\n",
      " Loss: 0.028273\n",
      " Loss: 0.000000\n",
      " Loss: 0.019042\n",
      " Loss: 0.000000\n",
      " Loss: 0.036813\n",
      " Loss: 0.000000\n",
      " Loss: 0.064819\n",
      " Loss: 0.000000\n",
      " Loss: 0.022000\n",
      " Loss: 0.000000\n",
      " Loss: 0.041932\n",
      " Loss: 0.000000\n",
      " Loss: 0.014809\n",
      " Loss: 0.000000\n",
      " Loss: 0.028425\n",
      " Loss: 0.000000\n",
      " Loss: 0.053672\n",
      "Epoch 1746 Chain 0 loss std 9.44e-04 variance 4.46e-07 smooth variance 4.37e-07 adaptive c -1.00\n",
      "Epoch 1746 Chain 1 loss std 2.84e+02 variance 4.04e+04 smooth variance 2.78e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028385\n",
      " Loss: 0.000000\n",
      " Loss: 0.023673\n",
      " Loss: 0.000000\n",
      " Loss: 0.056832\n",
      " Loss: 0.000000\n",
      " Loss: 0.020139\n",
      " Loss: 0.000000\n",
      " Loss: 0.031808\n",
      " Loss: 0.000000\n",
      " Loss: 0.020451\n",
      " Loss: 0.000000\n",
      " Loss: 0.042453\n",
      " Loss: 0.000000\n",
      " Loss: 0.063844\n",
      " Loss: 0.000000\n",
      " Loss: 0.015385\n",
      " Loss: 0.000000\n",
      " Loss: 0.018705\n",
      "Epoch 1748 Chain 0 loss std 1.09e-03 variance 5.96e-07 smooth variance 4.85e-07 adaptive c -1.00\n",
      "Epoch 1748 Chain 1 loss std 1.60e+02 variance 1.28e+04 smooth variance 2.33e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033757\n",
      " Loss: 0.000000\n",
      " Loss: 0.035931\n",
      " Loss: 0.000000\n",
      " Loss: 0.014355\n",
      " Loss: 0.000000\n",
      " Loss: 0.021174\n",
      " Loss: 0.000000\n",
      " Loss: 0.055621\n",
      " Loss: 0.000000\n",
      " Loss: 0.060661\n",
      " Loss: 0.000000\n",
      " Loss: 0.018716\n",
      " Loss: 0.000000\n",
      " Loss: 0.020179\n",
      " Loss: 0.000000\n",
      " Loss: 0.023586\n",
      " Loss: 0.000000\n",
      " Loss: 0.037695\n",
      "Epoch 1750 Chain 0 loss std 9.82e-04 variance 4.82e-07 smooth variance 4.84e-07 adaptive c -1.00\n",
      "Epoch 1750 Chain 1 loss std 1.65e+02 variance 1.37e+04 smooth variance 2.04e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019462\n",
      " Loss: 0.000000\n",
      " Loss: 0.020376\n",
      " Loss: 0.000000\n",
      " Loss: 0.026844\n",
      " Loss: 0.000000\n",
      " Loss: 0.075338\n",
      " Loss: 0.000000\n",
      " Loss: 0.018818\n",
      " Loss: 0.000000\n",
      " Loss: 0.056853\n",
      " Loss: 0.000000\n",
      " Loss: 0.013177\n",
      " Loss: 0.000000\n",
      " Loss: 0.025456\n",
      " Loss: 0.000000\n",
      " Loss: 0.023889\n",
      " Loss: 0.000000\n",
      " Loss: 0.041462\n",
      "Epoch 1752 Chain 0 loss std 1.00e-03 variance 5.04e-07 smooth variance 4.90e-07 adaptive c -1.00\n",
      "Epoch 1752 Chain 1 loss std 1.76e+02 variance 1.54e+04 smooth variance 1.89e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015800\n",
      " Loss: 0.000000\n",
      " Loss: 0.018872\n",
      " Loss: 0.000000\n",
      " Loss: 0.028554\n",
      " Loss: 0.000000\n",
      " Loss: 0.016258\n",
      " Loss: 0.000000\n",
      " Loss: 0.081353\n",
      " Loss: 0.000000\n",
      " Loss: 0.052173\n",
      " Loss: 0.000000\n",
      " Loss: 0.019132\n",
      " Loss: 0.000000\n",
      " Loss: 0.016553\n",
      " Loss: 0.000000\n",
      " Loss: 0.057549\n",
      " Loss: 0.000000\n",
      " Loss: 0.015431\n",
      "Epoch 1754 Chain 0 loss std 1.11e-03 variance 6.20e-07 smooth variance 5.29e-07 adaptive c -1.00\n",
      "Epoch 1754 Chain 1 loss std 2.64e+02 variance 3.48e+04 smooth variance 2.37e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.059413\n",
      " Loss: 0.000000\n",
      " Loss: 0.030229\n",
      " Loss: 0.000000\n",
      " Loss: 0.020767\n",
      " Loss: 0.000000\n",
      " Loss: 0.026520\n",
      " Loss: 0.000000\n",
      " Loss: 0.023909\n",
      " Loss: 0.000000\n",
      " Loss: 0.015529\n",
      " Loss: 0.000000\n",
      " Loss: 0.019316\n",
      " Loss: 0.000000\n",
      " Loss: 0.022108\n",
      " Loss: 0.000000\n",
      " Loss: 0.035698\n",
      " Loss: 0.000000\n",
      " Loss: 0.068187\n",
      "Epoch 1756 Chain 0 loss std 9.68e-04 variance 4.68e-07 smooth variance 5.11e-07 adaptive c -1.00\n",
      "Epoch 1756 Chain 1 loss std 2.58e+02 variance 3.32e+04 smooth variance 2.65e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020113\n",
      " Loss: 0.000000\n",
      " Loss: 0.023252\n",
      " Loss: 0.000000\n",
      " Loss: 0.027303\n",
      " Loss: 0.000000\n",
      " Loss: 0.057881\n",
      " Loss: 0.000000\n",
      " Loss: 0.032290\n",
      " Loss: 0.000000\n",
      " Loss: 0.014892\n",
      " Loss: 0.000000\n",
      " Loss: 0.054763\n",
      " Loss: 0.000000\n",
      " Loss: 0.017586\n",
      " Loss: 0.000000\n",
      " Loss: 0.025882\n",
      " Loss: 0.000000\n",
      " Loss: 0.047715\n",
      "Epoch 1758 Chain 0 loss std 7.66e-04 variance 2.94e-07 smooth variance 4.46e-07 adaptive c -1.00\n",
      "Epoch 1758 Chain 1 loss std 2.11e+02 variance 2.23e+04 smooth variance 2.53e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.041332\n",
      " Loss: 0.000000\n",
      " Loss: 0.021604\n",
      " Loss: 0.000000\n",
      " Loss: 0.021616\n",
      " Loss: 0.000000\n",
      " Loss: 0.054307\n",
      " Loss: 0.000000\n",
      " Loss: 0.021977\n",
      " Loss: 0.000000\n",
      " Loss: 0.023479\n",
      " Loss: 0.000000\n",
      " Loss: 0.021931\n",
      " Loss: 0.000000\n",
      " Loss: 0.065647\n",
      " Loss: 0.000000\n",
      " Loss: 0.033682\n",
      " Loss: 0.000000\n",
      " Loss: 0.016099\n",
      "Epoch 1760 Chain 0 loss std 9.32e-04 variance 4.34e-07 smooth variance 4.42e-07 adaptive c -1.00\n",
      "Epoch 1760 Chain 1 loss std 1.77e+02 variance 1.56e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.067449\n",
      " Loss: 0.000000\n",
      " Loss: 0.022412\n",
      " Loss: 0.000000\n",
      " Loss: 0.033930\n",
      " Loss: 0.000000\n",
      " Loss: 0.021687\n",
      " Loss: 0.000000\n",
      " Loss: 0.015359\n",
      " Loss: 0.000000\n",
      " Loss: 0.018093\n",
      " Loss: 0.000000\n",
      " Loss: 0.019815\n",
      " Loss: 0.000000\n",
      " Loss: 0.011033\n",
      " Loss: 0.000000\n",
      " Loss: 0.090226\n",
      " Loss: 0.000000\n",
      " Loss: 0.021671\n",
      "Epoch 1762 Chain 0 loss std 1.23e-03 variance 7.54e-07 smooth variance 5.36e-07 adaptive c -1.00\n",
      "Epoch 1762 Chain 1 loss std 1.88e+02 variance 1.77e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018613\n",
      " Loss: 0.000000\n",
      " Loss: 0.028162\n",
      " Loss: 0.000000\n",
      " Loss: 0.034999\n",
      " Loss: 0.000000\n",
      " Loss: 0.060594\n",
      " Loss: 0.000000\n",
      " Loss: 0.018470\n",
      " Loss: 0.000000\n",
      " Loss: 0.015153\n",
      " Loss: 0.000000\n",
      " Loss: 0.017151\n",
      " Loss: 0.000000\n",
      " Loss: 0.057603\n",
      " Loss: 0.000000\n",
      " Loss: 0.019801\n",
      " Loss: 0.000000\n",
      " Loss: 0.051130\n",
      "Epoch 1764 Chain 0 loss std 8.07e-04 variance 3.26e-07 smooth variance 4.73e-07 adaptive c -1.00\n",
      "Epoch 1764 Chain 1 loss std 1.99e+02 variance 1.98e+04 smooth variance 2.06e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020493\n",
      " Loss: 0.000000\n",
      " Loss: 0.034196\n",
      " Loss: 0.000000\n",
      " Loss: 0.028878\n",
      " Loss: 0.000000\n",
      " Loss: 0.057022\n",
      " Loss: 0.000000\n",
      " Loss: 0.020248\n",
      " Loss: 0.000000\n",
      " Loss: 0.024440\n",
      " Loss: 0.000000\n",
      " Loss: 0.015680\n",
      " Loss: 0.000000\n",
      " Loss: 0.034139\n",
      " Loss: 0.000000\n",
      " Loss: 0.058900\n",
      " Loss: 0.000000\n",
      " Loss: 0.027679\n",
      "Epoch 1766 Chain 0 loss std 1.17e-03 variance 6.90e-07 smooth variance 5.38e-07 adaptive c -1.00\n",
      "Epoch 1766 Chain 1 loss std 2.53e+02 variance 3.20e+04 smooth variance 2.40e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019708\n",
      " Loss: 0.000000\n",
      " Loss: 0.063131\n",
      " Loss: 0.000000\n",
      " Loss: 0.032306\n",
      " Loss: 0.000000\n",
      " Loss: 0.021656\n",
      " Loss: 0.000000\n",
      " Loss: 0.024037\n",
      " Loss: 0.000000\n",
      " Loss: 0.073696\n",
      " Loss: 0.000000\n",
      " Loss: 0.012445\n",
      " Loss: 0.000000\n",
      " Loss: 0.028141\n",
      " Loss: 0.000000\n",
      " Loss: 0.015122\n",
      " Loss: 0.000000\n",
      " Loss: 0.031434\n",
      "Epoch 1768 Chain 0 loss std 1.06e-03 variance 5.62e-07 smooth variance 5.45e-07 adaptive c -1.00\n",
      "Epoch 1768 Chain 1 loss std 1.84e+02 variance 1.69e+04 smooth variance 2.19e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024609\n",
      " Loss: 0.000000\n",
      " Loss: 0.027517\n",
      " Loss: 0.000000\n",
      " Loss: 0.012784\n",
      " Loss: 0.000000\n",
      " Loss: 0.059089\n",
      " Loss: 0.000000\n",
      " Loss: 0.036839\n",
      " Loss: 0.000000\n",
      " Loss: 0.018993\n",
      " Loss: 0.000000\n",
      " Loss: 0.023294\n",
      " Loss: 0.000000\n",
      " Loss: 0.034609\n",
      " Loss: 0.000000\n",
      " Loss: 0.019066\n",
      " Loss: 0.000000\n",
      " Loss: 0.064875\n",
      "Epoch 1770 Chain 0 loss std 1.45e-03 variance 1.05e-06 smooth variance 6.98e-07 adaptive c -1.00\n",
      "Epoch 1770 Chain 1 loss std 1.68e+02 variance 1.42e+04 smooth variance 1.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.039170\n",
      " Loss: 0.000000\n",
      " Loss: 0.021738\n",
      " Loss: 0.000000\n",
      " Loss: 0.012601\n",
      " Loss: 0.000000\n",
      " Loss: 0.062536\n",
      " Loss: 0.000000\n",
      " Loss: 0.024792\n",
      " Loss: 0.000000\n",
      " Loss: 0.011721\n",
      " Loss: 0.000000\n",
      " Loss: 0.023885\n",
      " Loss: 0.000000\n",
      " Loss: 0.058945\n",
      " Loss: 0.000000\n",
      " Loss: 0.035395\n",
      " Loss: 0.000000\n",
      " Loss: 0.030892\n",
      "Epoch 1772 Chain 0 loss std 5.62e-04 variance 1.58e-07 smooth variance 5.36e-07 adaptive c -1.00\n",
      "Epoch 1772 Chain 1 loss std 1.72e+02 variance 1.48e+04 smooth variance 1.81e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061757\n",
      " Loss: 0.000000\n",
      " Loss: 0.038211\n",
      " Loss: 0.000000\n",
      " Loss: 0.013014\n",
      " Loss: 0.000000\n",
      " Loss: 0.032309\n",
      " Loss: 0.000000\n",
      " Loss: 0.015547\n",
      " Loss: 0.000000\n",
      " Loss: 0.034810\n",
      " Loss: 0.000000\n",
      " Loss: 0.018324\n",
      " Loss: 0.000000\n",
      " Loss: 0.026299\n",
      " Loss: 0.000000\n",
      " Loss: 0.023400\n",
      " Loss: 0.000000\n",
      " Loss: 0.058005\n",
      "Epoch 1774 Chain 0 loss std 1.05e-03 variance 5.47e-07 smooth variance 5.39e-07 adaptive c -1.00\n",
      "Epoch 1774 Chain 1 loss std 2.13e+02 variance 2.28e+04 smooth variance 1.95e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017394\n",
      " Loss: 0.000000\n",
      " Loss: 0.030710\n",
      " Loss: 0.000000\n",
      " Loss: 0.015746\n",
      " Loss: 0.000000\n",
      " Loss: 0.030906\n",
      " Loss: 0.000000\n",
      " Loss: 0.066082\n",
      " Loss: 0.000000\n",
      " Loss: 0.026948\n",
      " Loss: 0.000000\n",
      " Loss: 0.075199\n",
      " Loss: 0.000000\n",
      " Loss: 0.025017\n",
      " Loss: 0.000000\n",
      " Loss: 0.018397\n",
      " Loss: 0.000000\n",
      " Loss: 0.015276\n",
      "Epoch 1776 Chain 0 loss std 1.04e-03 variance 5.45e-07 smooth variance 5.41e-07 adaptive c -1.00\n",
      "Epoch 1776 Chain 1 loss std 1.85e+02 variance 1.72e+04 smooth variance 1.88e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022218\n",
      " Loss: 0.000000\n",
      " Loss: 0.058490\n",
      " Loss: 0.000000\n",
      " Loss: 0.038650\n",
      " Loss: 0.000000\n",
      " Loss: 0.026445\n",
      " Loss: 0.000000\n",
      " Loss: 0.015035\n",
      " Loss: 0.000000\n",
      " Loss: 0.016605\n",
      " Loss: 0.000000\n",
      " Loss: 0.024964\n",
      " Loss: 0.000000\n",
      " Loss: 0.060737\n",
      " Loss: 0.000000\n",
      " Loss: 0.023981\n",
      " Loss: 0.000000\n",
      " Loss: 0.034552\n",
      "Epoch 1778 Chain 0 loss std 1.16e-03 variance 6.70e-07 smooth variance 5.80e-07 adaptive c -1.00\n",
      "Epoch 1778 Chain 1 loss std 1.67e+02 variance 1.40e+04 smooth variance 1.74e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021197\n",
      " Loss: 0.000000\n",
      " Loss: 0.070359\n",
      " Loss: 0.000000\n",
      " Loss: 0.018409\n",
      " Loss: 0.000000\n",
      " Loss: 0.016712\n",
      " Loss: 0.000000\n",
      " Loss: 0.034161\n",
      " Loss: 0.000000\n",
      " Loss: 0.027413\n",
      " Loss: 0.000000\n",
      " Loss: 0.019801\n",
      " Loss: 0.000000\n",
      " Loss: 0.060661\n",
      " Loss: 0.000000\n",
      " Loss: 0.019047\n",
      " Loss: 0.000000\n",
      " Loss: 0.033915\n",
      "Epoch 1780 Chain 0 loss std 9.82e-04 variance 4.83e-07 smooth variance 5.51e-07 adaptive c -1.00\n",
      "Epoch 1780 Chain 1 loss std 1.89e+02 variance 1.79e+04 smooth variance 1.75e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025603\n",
      " Loss: 0.000000\n",
      " Loss: 0.075995\n",
      " Loss: 0.000000\n",
      " Loss: 0.024323\n",
      " Loss: 0.000000\n",
      " Loss: 0.012170\n",
      " Loss: 0.000000\n",
      " Loss: 0.022747\n",
      " Loss: 0.000000\n",
      " Loss: 0.030008\n",
      " Loss: 0.000000\n",
      " Loss: 0.021180\n",
      " Loss: 0.000000\n",
      " Loss: 0.013508\n",
      " Loss: 0.000000\n",
      " Loss: 0.020974\n",
      " Loss: 0.000000\n",
      " Loss: 0.075168\n",
      "Epoch 1782 Chain 0 loss std 6.15e-04 variance 1.89e-07 smooth variance 4.42e-07 adaptive c -1.00\n",
      "Epoch 1782 Chain 1 loss std 1.62e+02 variance 1.31e+04 smooth variance 1.62e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.013309\n",
      " Loss: 0.000000\n",
      " Loss: 0.079854\n",
      " Loss: 0.000000\n",
      " Loss: 0.030637\n",
      " Loss: 0.000000\n",
      " Loss: 0.020830\n",
      " Loss: 0.000000\n",
      " Loss: 0.016208\n",
      " Loss: 0.000000\n",
      " Loss: 0.018940\n",
      " Loss: 0.000000\n",
      " Loss: 0.019559\n",
      " Loss: 0.000000\n",
      " Loss: 0.039245\n",
      " Loss: 0.000000\n",
      " Loss: 0.017713\n",
      " Loss: 0.000000\n",
      " Loss: 0.065381\n",
      "Epoch 1784 Chain 0 loss std 1.08e-03 variance 5.79e-07 smooth variance 4.83e-07 adaptive c -1.00\n",
      "Epoch 1784 Chain 1 loss std 1.94e+02 variance 1.88e+04 smooth variance 1.70e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023676\n",
      " Loss: 0.000000\n",
      " Loss: 0.059931\n",
      " Loss: 0.000000\n",
      " Loss: 0.014801\n",
      " Loss: 0.000000\n",
      " Loss: 0.031438\n",
      " Loss: 0.000000\n",
      " Loss: 0.030992\n",
      " Loss: 0.000000\n",
      " Loss: 0.029146\n",
      " Loss: 0.000000\n",
      " Loss: 0.021554\n",
      " Loss: 0.000000\n",
      " Loss: 0.021507\n",
      " Loss: 0.000000\n",
      " Loss: 0.014793\n",
      " Loss: 0.000000\n",
      " Loss: 0.073838\n",
      "Epoch 1786 Chain 0 loss std 1.26e-03 variance 7.95e-07 smooth variance 5.77e-07 adaptive c -1.00\n",
      "Epoch 1786 Chain 1 loss std 1.86e+02 variance 1.73e+04 smooth variance 1.71e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027412\n",
      " Loss: 0.000000\n",
      " Loss: 0.025869\n",
      " Loss: 0.000000\n",
      " Loss: 0.026949\n",
      " Loss: 0.000000\n",
      " Loss: 0.020193\n",
      " Loss: 0.000000\n",
      " Loss: 0.060415\n",
      " Loss: 0.000000\n",
      " Loss: 0.030047\n",
      " Loss: 0.000000\n",
      " Loss: 0.035676\n",
      " Loss: 0.000000\n",
      " Loss: 0.013579\n",
      " Loss: 0.000000\n",
      " Loss: 0.064325\n",
      " Loss: 0.000000\n",
      " Loss: 0.017211\n",
      "Epoch 1788 Chain 0 loss std 9.92e-04 variance 4.92e-07 smooth variance 5.51e-07 adaptive c -1.00\n",
      "Epoch 1788 Chain 1 loss std 2.74e+02 variance 3.77e+04 smooth variance 2.33e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028892\n",
      " Loss: 0.000000\n",
      " Loss: 0.016982\n",
      " Loss: 0.000000\n",
      " Loss: 0.083382\n",
      " Loss: 0.000000\n",
      " Loss: 0.013279\n",
      " Loss: 0.000000\n",
      " Loss: 0.018303\n",
      " Loss: 0.000000\n",
      " Loss: 0.075666\n",
      " Loss: 0.000000\n",
      " Loss: 0.024836\n",
      " Loss: 0.000000\n",
      " Loss: 0.027204\n",
      " Loss: 0.000000\n",
      " Loss: 0.018574\n",
      " Loss: 0.000000\n",
      " Loss: 0.014558\n",
      "Epoch 1790 Chain 0 loss std 1.23e-03 variance 7.61e-07 smooth variance 6.14e-07 adaptive c -1.00\n",
      "Epoch 1790 Chain 1 loss std 2.29e+02 variance 2.62e+04 smooth variance 2.41e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016529\n",
      " Loss: 0.000000\n",
      " Loss: 0.023409\n",
      " Loss: 0.000000\n",
      " Loss: 0.075520\n",
      " Loss: 0.000000\n",
      " Loss: 0.010863\n",
      " Loss: 0.000000\n",
      " Loss: 0.034516\n",
      " Loss: 0.000000\n",
      " Loss: 0.030274\n",
      " Loss: 0.000000\n",
      " Loss: 0.069539\n",
      " Loss: 0.000000\n",
      " Loss: 0.020967\n",
      " Loss: 0.000000\n",
      " Loss: 0.025529\n",
      " Loss: 0.000000\n",
      " Loss: 0.014529\n",
      "Epoch 1792 Chain 0 loss std 9.65e-04 variance 4.65e-07 smooth variance 5.69e-07 adaptive c -1.00\n",
      "Epoch 1792 Chain 1 loss std 1.93e+02 variance 1.87e+04 smooth variance 2.25e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018713\n",
      " Loss: 0.000000\n",
      " Loss: 0.033557\n",
      " Loss: 0.000000\n",
      " Loss: 0.067976\n",
      " Loss: 0.000000\n",
      " Loss: 0.018720\n",
      " Loss: 0.000000\n",
      " Loss: 0.021871\n",
      " Loss: 0.000000\n",
      " Loss: 0.014619\n",
      " Loss: 0.000000\n",
      " Loss: 0.020036\n",
      " Loss: 0.000000\n",
      " Loss: 0.031253\n",
      " Loss: 0.000000\n",
      " Loss: 0.022336\n",
      " Loss: 0.000000\n",
      " Loss: 0.072593\n",
      "Epoch 1794 Chain 0 loss std 1.16e-03 variance 6.77e-07 smooth variance 6.02e-07 adaptive c -1.00\n",
      "Epoch 1794 Chain 1 loss std 1.99e+02 variance 1.97e+04 smooth variance 2.17e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018273\n",
      " Loss: 0.000000\n",
      " Loss: 0.059979\n",
      " Loss: 0.000000\n",
      " Loss: 0.028809\n",
      " Loss: 0.000000\n",
      " Loss: 0.017615\n",
      " Loss: 0.000000\n",
      " Loss: 0.036161\n",
      " Loss: 0.000000\n",
      " Loss: 0.014225\n",
      " Loss: 0.000000\n",
      " Loss: 0.023478\n",
      " Loss: 0.000000\n",
      " Loss: 0.022033\n",
      " Loss: 0.000000\n",
      " Loss: 0.021660\n",
      " Loss: 0.000000\n",
      " Loss: 0.079442\n",
      "Epoch 1796 Chain 0 loss std 1.28e-03 variance 8.24e-07 smooth variance 6.68e-07 adaptive c -1.00\n",
      "Epoch 1796 Chain 1 loss std 1.75e+02 variance 1.54e+04 smooth variance 1.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037668\n",
      " Loss: 0.000000\n",
      " Loss: 0.023933\n",
      " Loss: 0.000000\n",
      " Loss: 0.021558\n",
      " Loss: 0.000000\n",
      " Loss: 0.065033\n",
      " Loss: 0.000000\n",
      " Loss: 0.012645\n",
      " Loss: 0.000000\n",
      " Loss: 0.020656\n",
      " Loss: 0.000000\n",
      " Loss: 0.033760\n",
      " Loss: 0.000000\n",
      " Loss: 0.022001\n",
      " Loss: 0.000000\n",
      " Loss: 0.056549\n",
      " Loss: 0.000000\n",
      " Loss: 0.027872\n",
      "Epoch 1798 Chain 0 loss std 5.56e-04 variance 1.54e-07 smooth variance 5.14e-07 adaptive c -1.00\n",
      "Epoch 1798 Chain 1 loss std 2.68e+02 variance 3.59e+04 smooth variance 2.46e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.064440\n",
      " Loss: 0.000000\n",
      " Loss: 0.015445\n",
      " Loss: 0.000000\n",
      " Loss: 0.022201\n",
      " Loss: 0.000000\n",
      " Loss: 0.038500\n",
      " Loss: 0.000000\n",
      " Loss: 0.020252\n",
      " Loss: 0.000000\n",
      " Loss: 0.038592\n",
      " Loss: 0.000000\n",
      " Loss: 0.019023\n",
      " Loss: 0.000000\n",
      " Loss: 0.018763\n",
      " Loss: 0.000000\n",
      " Loss: 0.058437\n",
      " Loss: 0.000000\n",
      " Loss: 0.026022\n",
      "Epoch 1800 Chain 0 loss std 6.44e-04 variance 2.07e-07 smooth variance 4.22e-07 adaptive c -1.00\n",
      "Epoch 1800 Chain 1 loss std 2.45e+02 variance 3.01e+04 smooth variance 2.63e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.054848\n",
      " Loss: 0.000000\n",
      " Loss: 0.036536\n",
      " Loss: 0.000000\n",
      " Loss: 0.026881\n",
      " Loss: 0.000000\n",
      " Loss: 0.021726\n",
      " Loss: 0.000000\n",
      " Loss: 0.020847\n",
      " Loss: 0.000000\n",
      " Loss: 0.035169\n",
      " Loss: 0.000000\n",
      " Loss: 0.063760\n",
      " Loss: 0.000000\n",
      " Loss: 0.013073\n",
      " Loss: 0.000000\n",
      " Loss: 0.020368\n",
      " Loss: 0.000000\n",
      " Loss: 0.028468\n",
      "Epoch 1802 Chain 0 loss std 1.04e-03 variance 5.41e-07 smooth variance 4.58e-07 adaptive c -1.00\n",
      "Epoch 1802 Chain 1 loss std 2.71e+02 variance 3.68e+04 smooth variance 2.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021611\n",
      " Loss: 0.000000\n",
      " Loss: 0.036680\n",
      " Loss: 0.000001\n",
      " Loss: 0.060019\n",
      " Loss: 0.000000\n",
      " Loss: 0.015990\n",
      " Loss: 0.000000\n",
      " Loss: 0.026537\n",
      " Loss: 0.000000\n",
      " Loss: 0.063856\n",
      " Loss: 0.000000\n",
      " Loss: 0.036899\n",
      " Loss: 0.000000\n",
      " Loss: 0.025862\n",
      " Loss: 0.000000\n",
      " Loss: 0.019079\n",
      " Loss: 0.000000\n",
      " Loss: 0.015142\n",
      "Epoch 1804 Chain 0 loss std 1.37e-03 variance 9.44e-07 smooth variance 6.04e-07 adaptive c -1.00\n",
      "Epoch 1804 Chain 1 loss std 1.51e+02 variance 1.14e+04 smooth variance 2.40e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023737\n",
      " Loss: 0.000000\n",
      " Loss: 0.027378\n",
      " Loss: 0.000000\n",
      " Loss: 0.032976\n",
      " Loss: 0.000000\n",
      " Loss: 0.014148\n",
      " Loss: 0.000000\n",
      " Loss: 0.062598\n",
      " Loss: 0.000000\n",
      " Loss: 0.037628\n",
      " Loss: 0.000000\n",
      " Loss: 0.054955\n",
      " Loss: 0.000000\n",
      " Loss: 0.019678\n",
      " Loss: 0.000000\n",
      " Loss: 0.013781\n",
      " Loss: 0.000000\n",
      " Loss: 0.034795\n",
      "Epoch 1806 Chain 0 loss std 1.00e-03 variance 5.01e-07 smooth variance 5.73e-07 adaptive c -1.00\n",
      "Epoch 1806 Chain 1 loss std 2.58e+02 variance 3.33e+04 smooth variance 2.68e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018324\n",
      " Loss: 0.000000\n",
      " Loss: 0.036421\n",
      " Loss: 0.000000\n",
      " Loss: 0.014018\n",
      " Loss: 0.000000\n",
      " Loss: 0.061811\n",
      " Loss: 0.000000\n",
      " Loss: 0.030265\n",
      " Loss: 0.000000\n",
      " Loss: 0.036387\n",
      " Loss: 0.000000\n",
      " Loss: 0.015533\n",
      " Loss: 0.000000\n",
      " Loss: 0.019172\n",
      " Loss: 0.000000\n",
      " Loss: 0.029875\n",
      " Loss: 0.000000\n",
      " Loss: 0.059870\n",
      "Epoch 1808 Chain 0 loss std 7.62e-04 variance 2.90e-07 smooth variance 4.88e-07 adaptive c -1.00\n",
      "Epoch 1808 Chain 1 loss std 2.12e+02 variance 2.25e+04 smooth variance 2.55e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.086045\n",
      " Loss: 0.000000\n",
      " Loss: 0.022314\n",
      " Loss: 0.000000\n",
      " Loss: 0.018881\n",
      " Loss: 0.000000\n",
      " Loss: 0.018189\n",
      " Loss: 0.000000\n",
      " Loss: 0.015408\n",
      " Loss: 0.000000\n",
      " Loss: 0.012631\n",
      " Loss: 0.000000\n",
      " Loss: 0.022009\n",
      " Loss: 0.000000\n",
      " Loss: 0.026164\n",
      " Loss: 0.000000\n",
      " Loss: 0.024153\n",
      " Loss: 0.000000\n",
      " Loss: 0.075881\n",
      "Epoch 1810 Chain 0 loss std 9.64e-04 variance 4.64e-07 smooth variance 4.81e-07 adaptive c -1.00\n",
      "Epoch 1810 Chain 1 loss std 2.17e+02 variance 2.36e+04 smooth variance 2.49e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028159\n",
      " Loss: 0.000000\n",
      " Loss: 0.023784\n",
      " Loss: 0.000000\n",
      " Loss: 0.023187\n",
      " Loss: 0.000000\n",
      " Loss: 0.066328\n",
      " Loss: 0.000000\n",
      " Loss: 0.019380\n",
      " Loss: 0.000000\n",
      " Loss: 0.041445\n",
      " Loss: 0.000000\n",
      " Loss: 0.020267\n",
      " Loss: 0.000000\n",
      " Loss: 0.015381\n",
      " Loss: 0.000000\n",
      " Loss: 0.067880\n",
      " Loss: 0.000000\n",
      " Loss: 0.015864\n",
      "Epoch 1812 Chain 0 loss std 8.16e-04 variance 3.33e-07 smooth variance 4.37e-07 adaptive c -1.00\n",
      "Epoch 1812 Chain 1 loss std 1.88e+02 variance 1.78e+04 smooth variance 2.28e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015885\n",
      " Loss: 0.000000\n",
      " Loss: 0.060484\n",
      " Loss: 0.000000\n",
      " Loss: 0.026248\n",
      " Loss: 0.000000\n",
      " Loss: 0.034653\n",
      " Loss: 0.000000\n",
      " Loss: 0.023568\n",
      " Loss: 0.000000\n",
      " Loss: 0.018422\n",
      " Loss: 0.000000\n",
      " Loss: 0.019967\n",
      " Loss: 0.000000\n",
      " Loss: 0.063103\n",
      " Loss: 0.000000\n",
      " Loss: 0.014726\n",
      " Loss: 0.000000\n",
      " Loss: 0.044619\n",
      "Epoch 1814 Chain 0 loss std 8.69e-04 variance 3.77e-07 smooth variance 4.19e-07 adaptive c -1.00\n",
      "Epoch 1814 Chain 1 loss std 1.92e+02 variance 1.85e+04 smooth variance 2.15e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018898\n",
      " Loss: 0.000000\n",
      " Loss: 0.025177\n",
      " Loss: 0.000000\n",
      " Loss: 0.021266\n",
      " Loss: 0.000000\n",
      " Loss: 0.078053\n",
      " Loss: 0.000000\n",
      " Loss: 0.017444\n",
      " Loss: 0.000000\n",
      " Loss: 0.014714\n",
      " Loss: 0.000000\n",
      " Loss: 0.017973\n",
      " Loss: 0.000000\n",
      " Loss: 0.037712\n",
      " Loss: 0.000000\n",
      " Loss: 0.059197\n",
      " Loss: 0.000000\n",
      " Loss: 0.031242\n",
      "Epoch 1816 Chain 0 loss std 7.28e-04 variance 2.65e-07 smooth variance 3.73e-07 adaptive c -1.00\n",
      "Epoch 1816 Chain 1 loss std 1.68e+02 variance 1.41e+04 smooth variance 1.93e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.062389\n",
      " Loss: 0.000000\n",
      " Loss: 0.014676\n",
      " Loss: 0.000000\n",
      " Loss: 0.027224\n",
      " Loss: 0.000000\n",
      " Loss: 0.034612\n",
      " Loss: 0.000000\n",
      " Loss: 0.021936\n",
      " Loss: 0.000000\n",
      " Loss: 0.044368\n",
      " Loss: 0.000000\n",
      " Loss: 0.061668\n",
      " Loss: 0.000000\n",
      " Loss: 0.022000\n",
      " Loss: 0.000000\n",
      " Loss: 0.014847\n",
      " Loss: 0.000000\n",
      " Loss: 0.017955\n",
      "Epoch 1818 Chain 0 loss std 7.80e-04 variance 3.04e-07 smooth variance 3.52e-07 adaptive c -1.00\n",
      "Epoch 1818 Chain 1 loss std 1.70e+02 variance 1.45e+04 smooth variance 1.78e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061527\n",
      " Loss: 0.000000\n",
      " Loss: 0.022249\n",
      " Loss: 0.000000\n",
      " Loss: 0.029227\n",
      " Loss: 0.000000\n",
      " Loss: 0.025843\n",
      " Loss: 0.000000\n",
      " Loss: 0.021991\n",
      " Loss: 0.000000\n",
      " Loss: 0.019751\n",
      " Loss: 0.000000\n",
      " Loss: 0.019992\n",
      " Loss: 0.000000\n",
      " Loss: 0.021680\n",
      " Loss: 0.000000\n",
      " Loss: 0.062283\n",
      " Loss: 0.000000\n",
      " Loss: 0.037131\n",
      "Epoch 1820 Chain 0 loss std 1.02e-03 variance 5.21e-07 smooth variance 4.03e-07 adaptive c -1.00\n",
      "Epoch 1820 Chain 1 loss std 2.43e+02 variance 2.96e+04 smooth variance 2.14e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032988\n",
      " Loss: 0.000000\n",
      " Loss: 0.037295\n",
      " Loss: 0.000000\n",
      " Loss: 0.015525\n",
      " Loss: 0.000000\n",
      " Loss: 0.020400\n",
      " Loss: 0.000000\n",
      " Loss: 0.054630\n",
      " Loss: 0.000000\n",
      " Loss: 0.022433\n",
      " Loss: 0.000000\n",
      " Loss: 0.072386\n",
      " Loss: 0.000000\n",
      " Loss: 0.028799\n",
      " Loss: 0.000000\n",
      " Loss: 0.018749\n",
      " Loss: 0.000000\n",
      " Loss: 0.018471\n",
      "Epoch 1822 Chain 0 loss std 1.27e-03 variance 8.05e-07 smooth variance 5.23e-07 adaptive c -1.00\n",
      "Epoch 1822 Chain 1 loss std 2.90e+02 variance 4.21e+04 smooth variance 2.76e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014299\n",
      " Loss: 0.000000\n",
      " Loss: 0.069588\n",
      " Loss: 0.000000\n",
      " Loss: 0.022005\n",
      " Loss: 0.000000\n",
      " Loss: 0.037757\n",
      " Loss: 0.000000\n",
      " Loss: 0.017188\n",
      " Loss: 0.000000\n",
      " Loss: 0.012160\n",
      " Loss: 0.000000\n",
      " Loss: 0.075509\n",
      " Loss: 0.000000\n",
      " Loss: 0.017840\n",
      " Loss: 0.000000\n",
      " Loss: 0.029724\n",
      " Loss: 0.000000\n",
      " Loss: 0.025604\n",
      "Epoch 1824 Chain 0 loss std 7.32e-04 variance 2.68e-07 smooth variance 4.47e-07 adaptive c -1.00\n",
      "Epoch 1824 Chain 1 loss std 2.43e+02 variance 2.96e+04 smooth variance 2.82e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015335\n",
      " Loss: 0.000000\n",
      " Loss: 0.027236\n",
      " Loss: 0.000000\n",
      " Loss: 0.031271\n",
      " Loss: 0.000000\n",
      " Loss: 0.065265\n",
      " Loss: 0.000000\n",
      " Loss: 0.021730\n",
      " Loss: 0.000000\n",
      " Loss: 0.046750\n",
      " Loss: 0.000000\n",
      " Loss: 0.019679\n",
      " Loss: 0.000000\n",
      " Loss: 0.059451\n",
      " Loss: 0.000000\n",
      " Loss: 0.024518\n",
      " Loss: 0.000000\n",
      " Loss: 0.010439\n",
      "Epoch 1826 Chain 0 loss std 1.18e-03 variance 7.00e-07 smooth variance 5.23e-07 adaptive c -1.00\n",
      "Epoch 1826 Chain 1 loss std 2.23e+02 variance 2.49e+04 smooth variance 2.72e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.007498\n",
      " Loss: 0.000000\n",
      " Loss: 0.064430\n",
      " Loss: 0.000000\n",
      " Loss: 0.039587\n",
      " Loss: 0.000000\n",
      " Loss: 0.035989\n",
      " Loss: 0.000000\n",
      " Loss: 0.013333\n",
      " Loss: 0.000000\n",
      " Loss: 0.020501\n",
      " Loss: 0.000000\n",
      " Loss: 0.045552\n",
      " Loss: 0.000000\n",
      " Loss: 0.017661\n",
      " Loss: 0.000000\n",
      " Loss: 0.019054\n",
      " Loss: 0.000000\n",
      " Loss: 0.058070\n",
      "Epoch 1828 Chain 0 loss std 1.04e-03 variance 5.39e-07 smooth variance 5.28e-07 adaptive c -1.00\n",
      "Epoch 1828 Chain 1 loss std 1.66e+02 variance 1.39e+04 smooth variance 2.32e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020615\n",
      " Loss: 0.000000\n",
      " Loss: 0.021524\n",
      " Loss: 0.000000\n",
      " Loss: 0.058305\n",
      " Loss: 0.000000\n",
      " Loss: 0.020330\n",
      " Loss: 0.000000\n",
      " Loss: 0.040065\n",
      " Loss: 0.000000\n",
      " Loss: 0.016911\n",
      " Loss: 0.000000\n",
      " Loss: 0.020407\n",
      " Loss: 0.000000\n",
      " Loss: 0.039472\n",
      " Loss: 0.000000\n",
      " Loss: 0.059462\n",
      " Loss: 0.000000\n",
      " Loss: 0.024586\n",
      "Epoch 1830 Chain 0 loss std 6.45e-04 variance 2.08e-07 smooth variance 4.32e-07 adaptive c -1.00\n",
      "Epoch 1830 Chain 1 loss std 2.50e+02 variance 3.12e+04 smooth variance 2.56e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015116\n",
      " Loss: 0.000000\n",
      " Loss: 0.029351\n",
      " Loss: 0.000000\n",
      " Loss: 0.056404\n",
      " Loss: 0.000000\n",
      " Loss: 0.030910\n",
      " Loss: 0.000000\n",
      " Loss: 0.029056\n",
      " Loss: 0.000000\n",
      " Loss: 0.023465\n",
      " Loss: 0.000000\n",
      " Loss: 0.020933\n",
      " Loss: 0.000000\n",
      " Loss: 0.044275\n",
      " Loss: 0.000000\n",
      " Loss: 0.057423\n",
      " Loss: 0.000000\n",
      " Loss: 0.014740\n",
      "Epoch 1832 Chain 0 loss std 7.43e-04 variance 2.76e-07 smooth variance 3.85e-07 adaptive c -1.00\n",
      "Epoch 1832 Chain 1 loss std 2.35e+02 variance 2.77e+04 smooth variance 2.62e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014512\n",
      " Loss: 0.000000\n",
      " Loss: 0.066325\n",
      " Loss: 0.000000\n",
      " Loss: 0.018746\n",
      " Loss: 0.000000\n",
      " Loss: 0.018848\n",
      " Loss: 0.000000\n",
      " Loss: 0.042406\n",
      " Loss: 0.000000\n",
      " Loss: 0.014614\n",
      " Loss: 0.000000\n",
      " Loss: 0.011742\n",
      " Loss: 0.000000\n",
      " Loss: 0.063112\n",
      " Loss: 0.000000\n",
      " Loss: 0.041100\n",
      " Loss: 0.000000\n",
      " Loss: 0.030269\n",
      "Epoch 1834 Chain 0 loss std 9.78e-04 variance 4.78e-07 smooth variance 4.13e-07 adaptive c -1.00\n",
      "Epoch 1834 Chain 1 loss std 2.36e+02 variance 2.78e+04 smooth variance 2.67e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025319\n",
      " Loss: 0.000000\n",
      " Loss: 0.044621\n",
      " Loss: 0.000000\n",
      " Loss: 0.059983\n",
      " Loss: 0.000000\n",
      " Loss: 0.018032\n",
      " Loss: 0.000000\n",
      " Loss: 0.012882\n",
      " Loss: 0.000000\n",
      " Loss: 0.016281\n",
      " Loss: 0.000000\n",
      " Loss: 0.062195\n",
      " Loss: 0.000000\n",
      " Loss: 0.026880\n",
      " Loss: 0.000000\n",
      " Loss: 0.020659\n",
      " Loss: 0.000000\n",
      " Loss: 0.034822\n",
      "Epoch 1836 Chain 0 loss std 9.03e-04 variance 4.08e-07 smooth variance 4.11e-07 adaptive c -1.00\n",
      "Epoch 1836 Chain 1 loss std 2.08e+02 variance 2.16e+04 smooth variance 2.52e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019520\n",
      " Loss: 0.000000\n",
      " Loss: 0.068749\n",
      " Loss: 0.000000\n",
      " Loss: 0.030613\n",
      " Loss: 0.000000\n",
      " Loss: 0.027611\n",
      " Loss: 0.000000\n",
      " Loss: 0.014346\n",
      " Loss: 0.000000\n",
      " Loss: 0.074758\n",
      " Loss: 0.000000\n",
      " Loss: 0.018912\n",
      " Loss: 0.000000\n",
      " Loss: 0.014575\n",
      " Loss: 0.000000\n",
      " Loss: 0.016898\n",
      " Loss: 0.000000\n",
      " Loss: 0.035694\n",
      "Epoch 1838 Chain 0 loss std 1.31e-03 variance 8.59e-07 smooth variance 5.46e-07 adaptive c -1.00\n",
      "Epoch 1838 Chain 1 loss std 1.83e+02 variance 1.68e+04 smooth variance 2.27e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.012828\n",
      " Loss: 0.000000\n",
      " Loss: 0.041199\n",
      " Loss: 0.000000\n",
      " Loss: 0.018029\n",
      " Loss: 0.000000\n",
      " Loss: 0.063504\n",
      " Loss: 0.000000\n",
      " Loss: 0.025277\n",
      " Loss: 0.000000\n",
      " Loss: 0.033983\n",
      " Loss: 0.000000\n",
      " Loss: 0.019635\n",
      " Loss: 0.000000\n",
      " Loss: 0.066733\n",
      " Loss: 0.000000\n",
      " Loss: 0.027441\n",
      " Loss: 0.000000\n",
      " Loss: 0.013046\n",
      "Epoch 1840 Chain 0 loss std 9.69e-04 variance 4.70e-07 smooth variance 5.23e-07 adaptive c -1.00\n",
      "Epoch 1840 Chain 1 loss std 1.75e+02 variance 1.54e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024297\n",
      " Loss: 0.000000\n",
      " Loss: 0.037085\n",
      " Loss: 0.000000\n",
      " Loss: 0.025447\n",
      " Loss: 0.000000\n",
      " Loss: 0.021596\n",
      " Loss: 0.000000\n",
      " Loss: 0.052413\n",
      " Loss: 0.000000\n",
      " Loss: 0.018356\n",
      " Loss: 0.000000\n",
      " Loss: 0.034464\n",
      " Loss: 0.000000\n",
      " Loss: 0.060930\n",
      " Loss: 0.000000\n",
      " Loss: 0.021340\n",
      " Loss: 0.000000\n",
      " Loss: 0.025748\n",
      "Epoch 1842 Chain 0 loss std 9.59e-04 variance 4.60e-07 smooth variance 5.04e-07 adaptive c -1.00\n",
      "Epoch 1842 Chain 1 loss std 1.81e+02 variance 1.63e+04 smooth variance 1.92e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.077173\n",
      " Loss: 0.000000\n",
      " Loss: 0.021357\n",
      " Loss: 0.000000\n",
      " Loss: 0.027946\n",
      " Loss: 0.000000\n",
      " Loss: 0.017947\n",
      " Loss: 0.000000\n",
      " Loss: 0.016415\n",
      " Loss: 0.000000\n",
      " Loss: 0.028156\n",
      " Loss: 0.000000\n",
      " Loss: 0.014331\n",
      " Loss: 0.000000\n",
      " Loss: 0.025372\n",
      " Loss: 0.000000\n",
      " Loss: 0.032153\n",
      " Loss: 0.000000\n",
      " Loss: 0.060826\n",
      "Epoch 1844 Chain 0 loss std 1.09e-03 variance 5.94e-07 smooth variance 5.31e-07 adaptive c -1.00\n",
      "Epoch 1844 Chain 1 loss std 2.29e+02 variance 2.62e+04 smooth variance 2.13e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.070857\n",
      " Loss: 0.000000\n",
      " Loss: 0.032164\n",
      " Loss: 0.000000\n",
      " Loss: 0.015648\n",
      " Loss: 0.000000\n",
      " Loss: 0.021991\n",
      " Loss: 0.000000\n",
      " Loss: 0.020177\n",
      " Loss: 0.000000\n",
      " Loss: 0.027186\n",
      " Loss: 0.000000\n",
      " Loss: 0.064080\n",
      " Loss: 0.000000\n",
      " Loss: 0.017175\n",
      " Loss: 0.000000\n",
      " Loss: 0.032315\n",
      " Loss: 0.000000\n",
      " Loss: 0.020082\n",
      "Epoch 1846 Chain 0 loss std 1.09e-03 variance 5.90e-07 smooth variance 5.49e-07 adaptive c -1.00\n",
      "Epoch 1846 Chain 1 loss std 1.82e+02 variance 1.65e+04 smooth variance 1.99e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.030042\n",
      " Loss: 0.000000\n",
      " Loss: 0.059733\n",
      " Loss: 0.000000\n",
      " Loss: 0.018287\n",
      " Loss: 0.000000\n",
      " Loss: 0.013766\n",
      " Loss: 0.000000\n",
      " Loss: 0.039009\n",
      " Loss: 0.000000\n",
      " Loss: 0.017511\n",
      " Loss: 0.000000\n",
      " Loss: 0.033783\n",
      " Loss: 0.000000\n",
      " Loss: 0.020031\n",
      " Loss: 0.000000\n",
      " Loss: 0.078493\n",
      " Loss: 0.000000\n",
      " Loss: 0.011018\n",
      "Epoch 1848 Chain 0 loss std 7.87e-04 variance 3.09e-07 smooth variance 4.77e-07 adaptive c -1.00\n",
      "Epoch 1848 Chain 1 loss std 2.23e+02 variance 2.50e+04 smooth variance 2.14e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014370\n",
      " Loss: 0.000000\n",
      " Loss: 0.030096\n",
      " Loss: 0.000000\n",
      " Loss: 0.063077\n",
      " Loss: 0.000000\n",
      " Loss: 0.027794\n",
      " Loss: 0.000000\n",
      " Loss: 0.025501\n",
      " Loss: 0.000000\n",
      " Loss: 0.021748\n",
      " Loss: 0.000000\n",
      " Loss: 0.071587\n",
      " Loss: 0.000000\n",
      " Loss: 0.010631\n",
      " Loss: 0.000000\n",
      " Loss: 0.017335\n",
      " Loss: 0.000000\n",
      " Loss: 0.039538\n",
      "Epoch 1850 Chain 0 loss std 1.02e-03 variance 5.24e-07 smooth variance 4.91e-07 adaptive c -1.00\n",
      "Epoch 1850 Chain 1 loss std 2.03e+02 variance 2.06e+04 smooth variance 2.12e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036036\n",
      " Loss: 0.000000\n",
      " Loss: 0.020897\n",
      " Loss: 0.000000\n",
      " Loss: 0.016617\n",
      " Loss: 0.000000\n",
      " Loss: 0.018506\n",
      " Loss: 0.000000\n",
      " Loss: 0.068782\n",
      " Loss: 0.000000\n",
      " Loss: 0.028451\n",
      " Loss: 0.000000\n",
      " Loss: 0.019917\n",
      " Loss: 0.000000\n",
      " Loss: 0.033695\n",
      " Loss: 0.000000\n",
      " Loss: 0.063819\n",
      " Loss: 0.000000\n",
      " Loss: 0.014956\n",
      "Epoch 1852 Chain 0 loss std 1.25e-03 variance 7.81e-07 smooth variance 5.78e-07 adaptive c -1.00\n",
      "Epoch 1852 Chain 1 loss std 1.78e+02 variance 1.58e+04 smooth variance 1.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.073271\n",
      " Loss: 0.000000\n",
      " Loss: 0.030615\n",
      " Loss: 0.000000\n",
      " Loss: 0.019022\n",
      " Loss: 0.000000\n",
      " Loss: 0.024075\n",
      " Loss: 0.000000\n",
      " Loss: 0.013854\n",
      " Loss: 0.000000\n",
      " Loss: 0.059868\n",
      " Loss: 0.000000\n",
      " Loss: 0.011083\n",
      " Loss: 0.000000\n",
      " Loss: 0.026006\n",
      " Loss: 0.000000\n",
      " Loss: 0.030351\n",
      " Loss: 0.000000\n",
      " Loss: 0.033530\n",
      "Epoch 1854 Chain 0 loss std 1.12e-03 variance 6.32e-07 smooth variance 5.94e-07 adaptive c -1.00\n",
      "Epoch 1854 Chain 1 loss std 2.50e+02 variance 3.11e+04 smooth variance 2.30e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022439\n",
      " Loss: 0.000000\n",
      " Loss: 0.055971\n",
      " Loss: 0.000000\n",
      " Loss: 0.036938\n",
      " Loss: 0.000000\n",
      " Loss: 0.024320\n",
      " Loss: 0.000000\n",
      " Loss: 0.021169\n",
      " Loss: 0.000000\n",
      " Loss: 0.019712\n",
      " Loss: 0.000000\n",
      " Loss: 0.018072\n",
      " Loss: 0.000000\n",
      " Loss: 0.040671\n",
      " Loss: 0.000000\n",
      " Loss: 0.018783\n",
      " Loss: 0.000000\n",
      " Loss: 0.063599\n",
      "Epoch 1856 Chain 0 loss std 8.08e-04 variance 3.27e-07 smooth variance 5.14e-07 adaptive c -1.00\n",
      "Epoch 1856 Chain 1 loss std 2.45e+02 variance 3.01e+04 smooth variance 2.52e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.062595\n",
      " Loss: 0.000000\n",
      " Loss: 0.019702\n",
      " Loss: 0.000000\n",
      " Loss: 0.023849\n",
      " Loss: 0.000000\n",
      " Loss: 0.033269\n",
      " Loss: 0.000000\n",
      " Loss: 0.021423\n",
      " Loss: 0.000000\n",
      " Loss: 0.063528\n",
      " Loss: 0.000000\n",
      " Loss: 0.031723\n",
      " Loss: 0.000000\n",
      " Loss: 0.022864\n",
      " Loss: 0.000000\n",
      " Loss: 0.020442\n",
      " Loss: 0.000000\n",
      " Loss: 0.022281\n",
      "Epoch 1858 Chain 0 loss std 1.25e-03 variance 7.79e-07 smooth variance 5.93e-07 adaptive c -1.00\n",
      "Epoch 1858 Chain 1 loss std 1.95e+02 variance 1.91e+04 smooth variance 2.33e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018403\n",
      " Loss: 0.000000\n",
      " Loss: 0.031954\n",
      " Loss: 0.000000\n",
      " Loss: 0.019918\n",
      " Loss: 0.000000\n",
      " Loss: 0.064677\n",
      " Loss: 0.000000\n",
      " Loss: 0.025885\n",
      " Loss: 0.000000\n",
      " Loss: 0.061890\n",
      " Loss: 0.000000\n",
      " Loss: 0.021036\n",
      " Loss: 0.000000\n",
      " Loss: 0.018928\n",
      " Loss: 0.000000\n",
      " Loss: 0.035506\n",
      " Loss: 0.000000\n",
      " Loss: 0.023477\n",
      "Epoch 1860 Chain 0 loss std 1.57e-03 variance 1.23e-06 smooth variance 7.86e-07 adaptive c -1.00\n",
      "Epoch 1860 Chain 1 loss std 1.97e+02 variance 1.93e+04 smooth variance 2.21e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.059742\n",
      " Loss: 0.000000\n",
      " Loss: 0.025152\n",
      " Loss: 0.000000\n",
      " Loss: 0.024574\n",
      " Loss: 0.000000\n",
      " Loss: 0.016767\n",
      " Loss: 0.000000\n",
      " Loss: 0.034602\n",
      " Loss: 0.000000\n",
      " Loss: 0.028118\n",
      " Loss: 0.000000\n",
      " Loss: 0.068105\n",
      " Loss: 0.000000\n",
      " Loss: 0.023542\n",
      " Loss: 0.000000\n",
      " Loss: 0.020466\n",
      " Loss: 0.000000\n",
      " Loss: 0.020606\n",
      "Epoch 1862 Chain 0 loss std 1.46e-03 variance 1.07e-06 smooth variance 8.70e-07 adaptive c -1.00\n",
      "Epoch 1862 Chain 1 loss std 1.48e+02 variance 1.10e+04 smooth variance 1.88e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017571\n",
      " Loss: 0.000000\n",
      " Loss: 0.068736\n",
      " Loss: 0.000000\n",
      " Loss: 0.019066\n",
      " Loss: 0.000000\n",
      " Loss: 0.040745\n",
      " Loss: 0.000000\n",
      " Loss: 0.014720\n",
      " Loss: 0.000000\n",
      " Loss: 0.063530\n",
      " Loss: 0.000000\n",
      " Loss: 0.021634\n",
      " Loss: 0.000000\n",
      " Loss: 0.019167\n",
      " Loss: 0.000000\n",
      " Loss: 0.025096\n",
      " Loss: 0.000000\n",
      " Loss: 0.031411\n",
      "Epoch 1864 Chain 0 loss std 8.96e-04 variance 4.02e-07 smooth variance 7.30e-07 adaptive c -1.00\n",
      "Epoch 1864 Chain 1 loss std 1.63e+02 variance 1.33e+04 smooth variance 1.71e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.080321\n",
      " Loss: 0.000000\n",
      " Loss: 0.017632\n",
      " Loss: 0.000000\n",
      " Loss: 0.016771\n",
      " Loss: 0.000000\n",
      " Loss: 0.022335\n",
      " Loss: 0.000000\n",
      " Loss: 0.023778\n",
      " Loss: 0.000000\n",
      " Loss: 0.016819\n",
      " Loss: 0.000000\n",
      " Loss: 0.033383\n",
      " Loss: 0.000000\n",
      " Loss: 0.019231\n",
      " Loss: 0.000000\n",
      " Loss: 0.019045\n",
      " Loss: 0.000000\n",
      " Loss: 0.072360\n",
      "Epoch 1866 Chain 0 loss std 8.43e-04 variance 3.55e-07 smooth variance 6.17e-07 adaptive c -1.00\n",
      "Epoch 1866 Chain 1 loss std 1.85e+02 variance 1.71e+04 smooth variance 1.71e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.038342\n",
      " Loss: 0.000000\n",
      " Loss: 0.022688\n",
      " Loss: 0.000000\n",
      " Loss: 0.012803\n",
      " Loss: 0.000000\n",
      " Loss: 0.068049\n",
      " Loss: 0.000000\n",
      " Loss: 0.018956\n",
      " Loss: 0.000000\n",
      " Loss: 0.026589\n",
      " Loss: 0.000000\n",
      " Loss: 0.017371\n",
      " Loss: 0.000000\n",
      " Loss: 0.069050\n",
      " Loss: 0.000000\n",
      " Loss: 0.009185\n",
      " Loss: 0.000000\n",
      " Loss: 0.038642\n",
      "Epoch 1868 Chain 0 loss std 1.05e-03 variance 5.55e-07 smooth variance 5.99e-07 adaptive c -1.00\n",
      "Epoch 1868 Chain 1 loss std 2.41e+02 variance 2.91e+04 smooth variance 2.07e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.041597\n",
      " Loss: 0.000000\n",
      " Loss: 0.060453\n",
      " Loss: 0.000000\n",
      " Loss: 0.023834\n",
      " Loss: 0.000000\n",
      " Loss: 0.020952\n",
      " Loss: 0.000000\n",
      " Loss: 0.014002\n",
      " Loss: 0.000000\n",
      " Loss: 0.015239\n",
      " Loss: 0.000000\n",
      " Loss: 0.045782\n",
      " Loss: 0.000000\n",
      " Loss: 0.019927\n",
      " Loss: 0.000000\n",
      " Loss: 0.019390\n",
      " Loss: 0.000000\n",
      " Loss: 0.060500\n",
      "Epoch 1870 Chain 0 loss std 9.36e-04 variance 4.38e-07 smooth variance 5.51e-07 adaptive c -1.00\n",
      "Epoch 1870 Chain 1 loss std 2.60e+02 variance 3.38e+04 smooth variance 2.46e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.064426\n",
      " Loss: 0.000000\n",
      " Loss: 0.017732\n",
      " Loss: 0.000000\n",
      " Loss: 0.013707\n",
      " Loss: 0.000000\n",
      " Loss: 0.041457\n",
      " Loss: 0.000000\n",
      " Loss: 0.023514\n",
      " Loss: 0.000000\n",
      " Loss: 0.026110\n",
      " Loss: 0.000000\n",
      " Loss: 0.019375\n",
      " Loss: 0.000000\n",
      " Loss: 0.063528\n",
      " Loss: 0.000000\n",
      " Loss: 0.011982\n",
      " Loss: 0.000000\n",
      " Loss: 0.039844\n",
      "Epoch 1872 Chain 0 loss std 9.00e-04 variance 4.05e-07 smooth variance 5.07e-07 adaptive c -1.00\n",
      "Epoch 1872 Chain 1 loss std 1.70e+02 variance 1.45e+04 smooth variance 2.16e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033720\n",
      " Loss: 0.000000\n",
      " Loss: 0.015520\n",
      " Loss: 0.000000\n",
      " Loss: 0.026073\n",
      " Loss: 0.000000\n",
      " Loss: 0.063392\n",
      " Loss: 0.000000\n",
      " Loss: 0.022133\n",
      " Loss: 0.000000\n",
      " Loss: 0.018537\n",
      " Loss: 0.000000\n",
      " Loss: 0.013308\n",
      " Loss: 0.000000\n",
      " Loss: 0.058079\n",
      " Loss: 0.000000\n",
      " Loss: 0.035544\n",
      " Loss: 0.000000\n",
      " Loss: 0.035370\n",
      "Epoch 1874 Chain 0 loss std 6.49e-04 variance 2.11e-07 smooth variance 4.18e-07 adaptive c -1.00\n",
      "Epoch 1874 Chain 1 loss std 2.38e+02 variance 2.84e+04 smooth variance 2.36e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.031768\n",
      " Loss: 0.000000\n",
      " Loss: 0.023529\n",
      " Loss: 0.000000\n",
      " Loss: 0.017901\n",
      " Loss: 0.000000\n",
      " Loss: 0.059479\n",
      " Loss: 0.000000\n",
      " Loss: 0.028160\n",
      " Loss: 0.000000\n",
      " Loss: 0.024305\n",
      " Loss: 0.000000\n",
      " Loss: 0.031029\n",
      " Loss: 0.000000\n",
      " Loss: 0.067087\n",
      " Loss: 0.000000\n",
      " Loss: 0.013761\n",
      " Loss: 0.000000\n",
      " Loss: 0.024656\n",
      "Epoch 1876 Chain 0 loss std 7.90e-04 variance 3.12e-07 smooth variance 3.86e-07 adaptive c -1.00\n",
      "Epoch 1876 Chain 1 loss std 2.06e+02 variance 2.13e+04 smooth variance 2.29e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018177\n",
      " Loss: 0.000000\n",
      " Loss: 0.033506\n",
      " Loss: 0.000000\n",
      " Loss: 0.023235\n",
      " Loss: 0.000000\n",
      " Loss: 0.023587\n",
      " Loss: 0.000000\n",
      " Loss: 0.062333\n",
      " Loss: 0.000000\n",
      " Loss: 0.014181\n",
      " Loss: 0.000000\n",
      " Loss: 0.034549\n",
      " Loss: 0.000000\n",
      " Loss: 0.021201\n",
      " Loss: 0.000000\n",
      " Loss: 0.022700\n",
      " Loss: 0.000000\n",
      " Loss: 0.068207\n",
      "Epoch 1878 Chain 0 loss std 9.26e-04 variance 4.29e-07 smooth variance 3.99e-07 adaptive c -1.00\n",
      "Epoch 1878 Chain 1 loss std 1.98e+02 variance 1.97e+04 smooth variance 2.20e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014108\n",
      " Loss: 0.000000\n",
      " Loss: 0.030289\n",
      " Loss: 0.000000\n",
      " Loss: 0.015797\n",
      " Loss: 0.000000\n",
      " Loss: 0.076766\n",
      " Loss: 0.000000\n",
      " Loss: 0.023877\n",
      " Loss: 0.000000\n",
      " Loss: 0.062417\n",
      " Loss: 0.000000\n",
      " Loss: 0.020882\n",
      " Loss: 0.000000\n",
      " Loss: 0.016536\n",
      " Loss: 0.000000\n",
      " Loss: 0.034118\n",
      " Loss: 0.000000\n",
      " Loss: 0.026885\n",
      "Epoch 1880 Chain 0 loss std 6.33e-04 variance 2.00e-07 smooth variance 3.39e-07 adaptive c -1.00\n",
      "Epoch 1880 Chain 1 loss std 2.68e+02 variance 3.60e+04 smooth variance 2.62e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024904\n",
      " Loss: 0.000000\n",
      " Loss: 0.013411\n",
      " Loss: 0.000000\n",
      " Loss: 0.020543\n",
      " Loss: 0.000000\n",
      " Loss: 0.055676\n",
      " Loss: 0.000000\n",
      " Loss: 0.046303\n",
      " Loss: 0.000000\n",
      " Loss: 0.023161\n",
      " Loss: 0.000000\n",
      " Loss: 0.066862\n",
      " Loss: 0.000000\n",
      " Loss: 0.042186\n",
      " Loss: 0.000000\n",
      " Loss: 0.016758\n",
      " Loss: 0.000000\n",
      " Loss: 0.011871\n",
      "Epoch 1882 Chain 0 loss std 4.77e-04 variance 1.14e-07 smooth variance 2.72e-07 adaptive c -1.00\n",
      "Epoch 1882 Chain 1 loss std 2.16e+02 variance 2.33e+04 smooth variance 2.53e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029638\n",
      " Loss: 0.000000\n",
      " Loss: 0.015518\n",
      " Loss: 0.000000\n",
      " Loss: 0.030698\n",
      " Loss: 0.000000\n",
      " Loss: 0.020748\n",
      " Loss: 0.000000\n",
      " Loss: 0.064236\n",
      " Loss: 0.000000\n",
      " Loss: 0.017561\n",
      " Loss: 0.000000\n",
      " Loss: 0.038854\n",
      " Loss: 0.000000\n",
      " Loss: 0.018755\n",
      " Loss: 0.000000\n",
      " Loss: 0.013838\n",
      " Loss: 0.000000\n",
      " Loss: 0.071830\n",
      "Epoch 1884 Chain 0 loss std 1.18e-03 variance 6.96e-07 smooth variance 3.99e-07 adaptive c -1.00\n",
      "Epoch 1884 Chain 1 loss std 2.01e+02 variance 2.02e+04 smooth variance 2.38e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.066147\n",
      " Loss: 0.000000\n",
      " Loss: 0.045242\n",
      " Loss: 0.000000\n",
      " Loss: 0.014056\n",
      " Loss: 0.000000\n",
      " Loss: 0.020873\n",
      " Loss: 0.000000\n",
      " Loss: 0.014519\n",
      " Loss: 0.000000\n",
      " Loss: 0.046147\n",
      " Loss: 0.000000\n",
      " Loss: 0.066161\n",
      " Loss: 0.000000\n",
      " Loss: 0.015955\n",
      " Loss: 0.000000\n",
      " Loss: 0.010106\n",
      " Loss: 0.000000\n",
      " Loss: 0.022468\n",
      "Epoch 1886 Chain 0 loss std 7.61e-04 variance 2.90e-07 smooth variance 3.66e-07 adaptive c -1.00\n",
      "Epoch 1886 Chain 1 loss std 1.73e+02 variance 1.49e+04 smooth variance 2.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.057242\n",
      " Loss: 0.000000\n",
      " Loss: 0.025749\n",
      " Loss: 0.000000\n",
      " Loss: 0.038244\n",
      " Loss: 0.000000\n",
      " Loss: 0.018396\n",
      " Loss: 0.000000\n",
      " Loss: 0.021207\n",
      " Loss: 0.000000\n",
      " Loss: 0.070370\n",
      " Loss: 0.000000\n",
      " Loss: 0.020604\n",
      " Loss: 0.000000\n",
      " Loss: 0.031822\n",
      " Loss: 0.000000\n",
      " Loss: 0.022483\n",
      " Loss: 0.000000\n",
      " Loss: 0.015558\n",
      "Epoch 1888 Chain 0 loss std 9.77e-04 variance 4.77e-07 smooth variance 4.00e-07 adaptive c -1.00\n",
      "Epoch 1888 Chain 1 loss std 2.15e+02 variance 2.30e+04 smooth variance 2.17e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.034915\n",
      " Loss: 0.000000\n",
      " Loss: 0.021957\n",
      " Loss: 0.000000\n",
      " Loss: 0.060836\n",
      " Loss: 0.000000\n",
      " Loss: 0.028319\n",
      " Loss: 0.000000\n",
      " Loss: 0.014811\n",
      " Loss: 0.000000\n",
      " Loss: 0.019683\n",
      " Loss: 0.000000\n",
      " Loss: 0.031048\n",
      " Loss: 0.000000\n",
      " Loss: 0.017842\n",
      " Loss: 0.000000\n",
      " Loss: 0.026183\n",
      " Loss: 0.000000\n",
      " Loss: 0.066082\n",
      "Epoch 1890 Chain 0 loss std 1.35e-03 variance 9.12e-07 smooth variance 5.53e-07 adaptive c -1.00\n",
      "Epoch 1890 Chain 1 loss std 2.36e+02 variance 2.79e+04 smooth variance 2.36e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029364\n",
      " Loss: 0.000000\n",
      " Loss: 0.020055\n",
      " Loss: 0.000000\n",
      " Loss: 0.018066\n",
      " Loss: 0.000000\n",
      " Loss: 0.031155\n",
      " Loss: 0.000000\n",
      " Loss: 0.062197\n",
      " Loss: 0.000000\n",
      " Loss: 0.016740\n",
      " Loss: 0.000000\n",
      " Loss: 0.014693\n",
      " Loss: 0.000000\n",
      " Loss: 0.018353\n",
      " Loss: 0.000000\n",
      " Loss: 0.037677\n",
      " Loss: 0.000000\n",
      " Loss: 0.073374\n",
      "Epoch 1892 Chain 0 loss std 9.75e-04 variance 4.75e-07 smooth variance 5.30e-07 adaptive c -1.00\n",
      "Epoch 1892 Chain 1 loss std 2.55e+02 variance 3.26e+04 smooth variance 2.63e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.042994\n",
      " Loss: 0.000000\n",
      " Loss: 0.064209\n",
      " Loss: 0.000000\n",
      " Loss: 0.020981\n",
      " Loss: 0.000000\n",
      " Loss: 0.011538\n",
      " Loss: 0.000000\n",
      " Loss: 0.021115\n",
      " Loss: 0.000000\n",
      " Loss: 0.029881\n",
      " Loss: 0.000000\n",
      " Loss: 0.039799\n",
      " Loss: 0.000000\n",
      " Loss: 0.020747\n",
      " Loss: 0.000000\n",
      " Loss: 0.057303\n",
      " Loss: 0.000000\n",
      " Loss: 0.013108\n",
      "Epoch 1894 Chain 0 loss std 1.32e-03 variance 8.75e-07 smooth variance 6.33e-07 adaptive c -1.00\n",
      "Epoch 1894 Chain 1 loss std 2.04e+02 variance 2.08e+04 smooth variance 2.46e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035225\n",
      " Loss: 0.000000\n",
      " Loss: 0.024515\n",
      " Loss: 0.000000\n",
      " Loss: 0.022194\n",
      " Loss: 0.000000\n",
      " Loss: 0.014896\n",
      " Loss: 0.000000\n",
      " Loss: 0.064008\n",
      " Loss: 0.000000\n",
      " Loss: 0.068780\n",
      " Loss: 0.000000\n",
      " Loss: 0.018494\n",
      " Loss: 0.000000\n",
      " Loss: 0.020292\n",
      " Loss: 0.000000\n",
      " Loss: 0.015236\n",
      " Loss: 0.000000\n",
      " Loss: 0.038035\n",
      "Epoch 1896 Chain 0 loss std 1.07e-03 variance 5.68e-07 smooth variance 6.14e-07 adaptive c -1.00\n",
      "Epoch 1896 Chain 1 loss std 2.01e+02 variance 2.02e+04 smooth variance 2.33e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032480\n",
      " Loss: 0.000000\n",
      " Loss: 0.013589\n",
      " Loss: 0.000000\n",
      " Loss: 0.033795\n",
      " Loss: 0.000000\n",
      " Loss: 0.067453\n",
      " Loss: 0.000000\n",
      " Loss: 0.013521\n",
      " Loss: 0.000000\n",
      " Loss: 0.065545\n",
      " Loss: 0.000000\n",
      " Loss: 0.023530\n",
      " Loss: 0.000000\n",
      " Loss: 0.015193\n",
      " Loss: 0.000000\n",
      " Loss: 0.032582\n",
      " Loss: 0.000000\n",
      " Loss: 0.023989\n",
      "Epoch 1898 Chain 0 loss std 1.03e-03 variance 5.34e-07 smooth variance 5.90e-07 adaptive c -1.00\n",
      "Epoch 1898 Chain 1 loss std 1.55e+02 variance 1.21e+04 smooth variance 1.99e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032884\n",
      " Loss: 0.000000\n",
      " Loss: 0.061214\n",
      " Loss: 0.000000\n",
      " Loss: 0.034013\n",
      " Loss: 0.000000\n",
      " Loss: 0.017225\n",
      " Loss: 0.000000\n",
      " Loss: 0.015502\n",
      " Loss: 0.000000\n",
      " Loss: 0.059397\n",
      " Loss: 0.000000\n",
      " Loss: 0.043844\n",
      " Loss: 0.000000\n",
      " Loss: 0.018562\n",
      " Loss: 0.000000\n",
      " Loss: 0.022256\n",
      " Loss: 0.000000\n",
      " Loss: 0.016779\n",
      "Epoch 1900 Chain 0 loss std 7.48e-04 variance 2.80e-07 smooth variance 4.97e-07 adaptive c -1.00\n",
      "Epoch 1900 Chain 1 loss std 1.90e+02 variance 1.80e+04 smooth variance 1.93e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032709\n",
      " Loss: 0.000000\n",
      " Loss: 0.015571\n",
      " Loss: 0.000000\n",
      " Loss: 0.060580\n",
      " Loss: 0.000000\n",
      " Loss: 0.027985\n",
      " Loss: 0.000000\n",
      " Loss: 0.023992\n",
      " Loss: 0.000000\n",
      " Loss: 0.067768\n",
      " Loss: 0.000000\n",
      " Loss: 0.018390\n",
      " Loss: 0.000000\n",
      " Loss: 0.025635\n",
      " Loss: 0.000000\n",
      " Loss: 0.010402\n",
      " Loss: 0.000000\n",
      " Loss: 0.038643\n",
      "Epoch 1902 Chain 0 loss std 1.23e-03 variance 7.60e-07 smooth variance 5.76e-07 adaptive c -1.00\n",
      "Epoch 1902 Chain 1 loss std 2.51e+02 variance 3.15e+04 smooth variance 2.30e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021801\n",
      " Loss: 0.000000\n",
      " Loss: 0.012451\n",
      " Loss: 0.000000\n",
      " Loss: 0.045415\n",
      " Loss: 0.000000\n",
      " Loss: 0.020836\n",
      " Loss: 0.000000\n",
      " Loss: 0.060334\n",
      " Loss: 0.000000\n",
      " Loss: 0.031991\n",
      " Loss: 0.000000\n",
      " Loss: 0.026333\n",
      " Loss: 0.000000\n",
      " Loss: 0.060228\n",
      " Loss: 0.000000\n",
      " Loss: 0.025358\n",
      " Loss: 0.000000\n",
      " Loss: 0.016928\n",
      "Epoch 1904 Chain 0 loss std 9.06e-04 variance 4.10e-07 smooth variance 5.26e-07 adaptive c -1.00\n",
      "Epoch 1904 Chain 1 loss std 1.62e+02 variance 1.31e+04 smooth variance 2.00e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018997\n",
      " Loss: 0.000000\n",
      " Loss: 0.016538\n",
      " Loss: 0.000000\n",
      " Loss: 0.084456\n",
      " Loss: 0.000000\n",
      " Loss: 0.016734\n",
      " Loss: 0.000000\n",
      " Loss: 0.024112\n",
      " Loss: 0.000000\n",
      " Loss: 0.027189\n",
      " Loss: 0.000000\n",
      " Loss: 0.015664\n",
      " Loss: 0.000000\n",
      " Loss: 0.040438\n",
      " Loss: 0.000000\n",
      " Loss: 0.062442\n",
      " Loss: 0.000000\n",
      " Loss: 0.015105\n",
      "Epoch 1906 Chain 0 loss std 1.23e-03 variance 7.58e-07 smooth variance 5.96e-07 adaptive c -1.00\n",
      "Epoch 1906 Chain 1 loss std 2.35e+02 variance 2.77e+04 smooth variance 2.23e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017360\n",
      " Loss: 0.000000\n",
      " Loss: 0.020751\n",
      " Loss: 0.000000\n",
      " Loss: 0.010230\n",
      " Loss: 0.000000\n",
      " Loss: 0.028456\n",
      " Loss: 0.000000\n",
      " Loss: 0.084040\n",
      " Loss: 0.000000\n",
      " Loss: 0.031631\n",
      " Loss: 0.000000\n",
      " Loss: 0.022791\n",
      " Loss: 0.000000\n",
      " Loss: 0.060681\n",
      " Loss: 0.000000\n",
      " Loss: 0.015087\n",
      " Loss: 0.000000\n",
      " Loss: 0.030649\n",
      "Epoch 1908 Chain 0 loss std 1.26e-03 variance 7.95e-07 smooth variance 6.56e-07 adaptive c -1.00\n",
      "Epoch 1908 Chain 1 loss std 2.02e+02 variance 2.04e+04 smooth variance 2.17e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.040437\n",
      " Loss: 0.000000\n",
      " Loss: 0.026795\n",
      " Loss: 0.000000\n",
      " Loss: 0.057760\n",
      " Loss: 0.000000\n",
      " Loss: 0.018498\n",
      " Loss: 0.000000\n",
      " Loss: 0.017347\n",
      " Loss: 0.000000\n",
      " Loss: 0.014242\n",
      " Loss: 0.000000\n",
      " Loss: 0.011084\n",
      " Loss: 0.000000\n",
      " Loss: 0.083575\n",
      " Loss: 0.000000\n",
      " Loss: 0.030712\n",
      " Loss: 0.000000\n",
      " Loss: 0.021225\n",
      "Epoch 1910 Chain 0 loss std 7.88e-04 variance 3.10e-07 smooth variance 5.52e-07 adaptive c -1.00\n",
      "Epoch 1910 Chain 1 loss std 1.74e+02 variance 1.51e+04 smooth variance 1.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.065382\n",
      " Loss: 0.000000\n",
      " Loss: 0.020961\n",
      " Loss: 0.000000\n",
      " Loss: 0.012428\n",
      " Loss: 0.000000\n",
      " Loss: 0.027503\n",
      " Loss: 0.000000\n",
      " Loss: 0.034563\n",
      " Loss: 0.000000\n",
      " Loss: 0.017148\n",
      " Loss: 0.000000\n",
      " Loss: 0.016873\n",
      " Loss: 0.000000\n",
      " Loss: 0.067509\n",
      " Loss: 0.000000\n",
      " Loss: 0.022664\n",
      " Loss: 0.000000\n",
      " Loss: 0.036643\n",
      "Epoch 1912 Chain 0 loss std 8.14e-04 variance 3.31e-07 smooth variance 4.86e-07 adaptive c -1.00\n",
      "Epoch 1912 Chain 1 loss std 1.94e+02 variance 1.89e+04 smooth variance 1.95e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.059559\n",
      " Loss: 0.000000\n",
      " Loss: 0.016597\n",
      " Loss: 0.000000\n",
      " Loss: 0.032499\n",
      " Loss: 0.000000\n",
      " Loss: 0.027587\n",
      " Loss: 0.000000\n",
      " Loss: 0.024596\n",
      " Loss: 0.000000\n",
      " Loss: 0.061924\n",
      " Loss: 0.000000\n",
      " Loss: 0.050632\n",
      " Loss: 0.000000\n",
      " Loss: 0.015790\n",
      " Loss: 0.000000\n",
      " Loss: 0.017204\n",
      " Loss: 0.000000\n",
      " Loss: 0.015288\n",
      "Epoch 1914 Chain 0 loss std 1.33e-03 variance 8.89e-07 smooth variance 6.07e-07 adaptive c -1.00\n",
      "Epoch 1914 Chain 1 loss std 2.22e+02 variance 2.46e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029003\n",
      " Loss: 0.000000\n",
      " Loss: 0.023041\n",
      " Loss: 0.000000\n",
      " Loss: 0.058037\n",
      " Loss: 0.000000\n",
      " Loss: 0.016926\n",
      " Loss: 0.000000\n",
      " Loss: 0.033831\n",
      " Loss: 0.000000\n",
      " Loss: 0.070655\n",
      " Loss: 0.000000\n",
      " Loss: 0.018287\n",
      " Loss: 0.000000\n",
      " Loss: 0.021984\n",
      " Loss: 0.000000\n",
      " Loss: 0.034055\n",
      " Loss: 0.000000\n",
      " Loss: 0.015856\n",
      "Epoch 1916 Chain 0 loss std 1.12e-03 variance 6.28e-07 smooth variance 6.13e-07 adaptive c -1.00\n",
      "Epoch 1916 Chain 1 loss std 1.78e+02 variance 1.58e+04 smooth variance 1.95e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.042282\n",
      " Loss: 0.000000\n",
      " Loss: 0.016392\n",
      " Loss: 0.000000\n",
      " Loss: 0.058224\n",
      " Loss: 0.000000\n",
      " Loss: 0.027487\n",
      " Loss: 0.000000\n",
      " Loss: 0.016452\n",
      " Loss: 0.000000\n",
      " Loss: 0.023114\n",
      " Loss: 0.000000\n",
      " Loss: 0.022181\n",
      " Loss: 0.000000\n",
      " Loss: 0.016845\n",
      " Loss: 0.000000\n",
      " Loss: 0.065824\n",
      " Loss: 0.000000\n",
      " Loss: 0.032873\n",
      "Epoch 1918 Chain 0 loss std 8.85e-04 variance 3.92e-07 smooth variance 5.47e-07 adaptive c -1.00\n",
      "Epoch 1918 Chain 1 loss std 2.17e+02 variance 2.36e+04 smooth variance 2.07e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016824\n",
      " Loss: 0.000000\n",
      " Loss: 0.021408\n",
      " Loss: 0.000000\n",
      " Loss: 0.011497\n",
      " Loss: 0.000000\n",
      " Loss: 0.063699\n",
      " Loss: 0.000000\n",
      " Loss: 0.047409\n",
      " Loss: 0.000000\n",
      " Loss: 0.011150\n",
      " Loss: 0.000000\n",
      " Loss: 0.020627\n",
      " Loss: 0.000000\n",
      " Loss: 0.019997\n",
      " Loss: 0.000000\n",
      " Loss: 0.024656\n",
      " Loss: 0.000000\n",
      " Loss: 0.084408\n",
      "Epoch 1920 Chain 0 loss std 7.94e-04 variance 3.15e-07 smooth variance 4.77e-07 adaptive c -1.00\n",
      "Epoch 1920 Chain 1 loss std 1.75e+02 variance 1.53e+04 smooth variance 1.91e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017595\n",
      " Loss: 0.000000\n",
      " Loss: 0.016768\n",
      " Loss: 0.000000\n",
      " Loss: 0.047244\n",
      " Loss: 0.000000\n",
      " Loss: 0.022768\n",
      " Loss: 0.000000\n",
      " Loss: 0.056462\n",
      " Loss: 0.000000\n",
      " Loss: 0.021027\n",
      " Loss: 0.000000\n",
      " Loss: 0.060109\n",
      " Loss: 0.000000\n",
      " Loss: 0.018913\n",
      " Loss: 0.000000\n",
      " Loss: 0.019526\n",
      " Loss: 0.000000\n",
      " Loss: 0.041263\n",
      "Epoch 1922 Chain 0 loss std 1.14e-03 variance 6.53e-07 smooth variance 5.30e-07 adaptive c -1.00\n",
      "Epoch 1922 Chain 1 loss std 1.69e+02 variance 1.43e+04 smooth variance 1.77e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036881\n",
      " Loss: 0.000000\n",
      " Loss: 0.017204\n",
      " Loss: 0.000000\n",
      " Loss: 0.010166\n",
      " Loss: 0.000000\n",
      " Loss: 0.062387\n",
      " Loss: 0.000000\n",
      " Loss: 0.034201\n",
      " Loss: 0.000000\n",
      " Loss: 0.010445\n",
      " Loss: 0.000000\n",
      " Loss: 0.060269\n",
      " Loss: 0.000000\n",
      " Loss: 0.029116\n",
      " Loss: 0.000000\n",
      " Loss: 0.039219\n",
      " Loss: 0.000000\n",
      " Loss: 0.021789\n",
      "Epoch 1924 Chain 0 loss std 1.23e-03 variance 7.54e-07 smooth variance 5.97e-07 adaptive c -1.00\n",
      "Epoch 1924 Chain 1 loss std 2.25e+02 variance 2.52e+04 smooth variance 1.99e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.010998\n",
      " Loss: 0.000000\n",
      " Loss: 0.030219\n",
      " Loss: 0.000000\n",
      " Loss: 0.065768\n",
      " Loss: 0.000000\n",
      " Loss: 0.018465\n",
      " Loss: 0.000000\n",
      " Loss: 0.035387\n",
      " Loss: 0.000000\n",
      " Loss: 0.016157\n",
      " Loss: 0.000000\n",
      " Loss: 0.059065\n",
      " Loss: 0.000000\n",
      " Loss: 0.031909\n",
      " Loss: 0.000000\n",
      " Loss: 0.020027\n",
      " Loss: 0.000000\n",
      " Loss: 0.033679\n",
      "Epoch 1926 Chain 0 loss std 9.92e-04 variance 4.92e-07 smooth variance 5.66e-07 adaptive c -1.00\n",
      "Epoch 1926 Chain 1 loss std 1.62e+02 variance 1.31e+04 smooth variance 1.79e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028242\n",
      " Loss: 0.000000\n",
      " Loss: 0.032452\n",
      " Loss: 0.000000\n",
      " Loss: 0.017418\n",
      " Loss: 0.000000\n",
      " Loss: 0.059499\n",
      " Loss: 0.000000\n",
      " Loss: 0.023227\n",
      " Loss: 0.000000\n",
      " Loss: 0.019635\n",
      " Loss: 0.000000\n",
      " Loss: 0.018629\n",
      " Loss: 0.000000\n",
      " Loss: 0.056400\n",
      " Loss: 0.000000\n",
      " Loss: 0.041009\n",
      " Loss: 0.000000\n",
      " Loss: 0.025164\n",
      "Epoch 1928 Chain 0 loss std 9.86e-04 variance 4.86e-07 smooth variance 5.42e-07 adaptive c -1.00\n",
      "Epoch 1928 Chain 1 loss std 1.91e+02 variance 1.83e+04 smooth variance 1.80e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015951\n",
      " Loss: 0.000000\n",
      " Loss: 0.016931\n",
      " Loss: 0.000000\n",
      " Loss: 0.072335\n",
      " Loss: 0.000000\n",
      " Loss: 0.016921\n",
      " Loss: 0.000000\n",
      " Loss: 0.038699\n",
      " Loss: 0.000000\n",
      " Loss: 0.023665\n",
      " Loss: 0.000000\n",
      " Loss: 0.035875\n",
      " Loss: 0.000000\n",
      " Loss: 0.023392\n",
      " Loss: 0.000000\n",
      " Loss: 0.014432\n",
      " Loss: 0.000000\n",
      " Loss: 0.063473\n",
      "Epoch 1930 Chain 0 loss std 8.85e-04 variance 3.91e-07 smooth variance 4.97e-07 adaptive c -1.00\n",
      "Epoch 1930 Chain 1 loss std 1.86e+02 variance 1.73e+04 smooth variance 1.78e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018744\n",
      " Loss: 0.000000\n",
      " Loss: 0.075242\n",
      " Loss: 0.000000\n",
      " Loss: 0.020456\n",
      " Loss: 0.000000\n",
      " Loss: 0.029199\n",
      " Loss: 0.000000\n",
      " Loss: 0.017196\n",
      " Loss: 0.000000\n",
      " Loss: 0.018278\n",
      " Loss: 0.000000\n",
      " Loss: 0.034829\n",
      " Loss: 0.000000\n",
      " Loss: 0.022288\n",
      " Loss: 0.000000\n",
      " Loss: 0.066523\n",
      " Loss: 0.000000\n",
      " Loss: 0.018920\n",
      "Epoch 1932 Chain 0 loss std 1.01e-03 variance 5.10e-07 smooth variance 5.01e-07 adaptive c -1.00\n",
      "Epoch 1932 Chain 1 loss std 1.88e+02 variance 1.77e+04 smooth variance 1.78e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027916\n",
      " Loss: 0.000000\n",
      " Loss: 0.030647\n",
      " Loss: 0.000000\n",
      " Loss: 0.016598\n",
      " Loss: 0.000000\n",
      " Loss: 0.022842\n",
      " Loss: 0.000000\n",
      " Loss: 0.062835\n",
      " Loss: 0.000000\n",
      " Loss: 0.081858\n",
      " Loss: 0.000000\n",
      " Loss: 0.019366\n",
      " Loss: 0.000000\n",
      " Loss: 0.024223\n",
      " Loss: 0.000000\n",
      " Loss: 0.011762\n",
      " Loss: 0.000000\n",
      " Loss: 0.023629\n",
      "Epoch 1934 Chain 0 loss std 8.77e-04 variance 3.84e-07 smooth variance 4.66e-07 adaptive c -1.00\n",
      "Epoch 1934 Chain 1 loss std 1.96e+02 variance 1.93e+04 smooth variance 1.82e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.062317\n",
      " Loss: 0.000000\n",
      " Loss: 0.026517\n",
      " Loss: 0.000000\n",
      " Loss: 0.018441\n",
      " Loss: 0.000000\n",
      " Loss: 0.033502\n",
      " Loss: 0.000000\n",
      " Loss: 0.020061\n",
      " Loss: 0.000000\n",
      " Loss: 0.012519\n",
      " Loss: 0.000000\n",
      " Loss: 0.022039\n",
      " Loss: 0.000000\n",
      " Loss: 0.036201\n",
      " Loss: 0.000000\n",
      " Loss: 0.016070\n",
      " Loss: 0.000000\n",
      " Loss: 0.074008\n",
      "Epoch 1936 Chain 0 loss std 7.30e-04 variance 2.67e-07 smooth variance 4.06e-07 adaptive c -1.00\n",
      "Epoch 1936 Chain 1 loss std 1.76e+02 variance 1.55e+04 smooth variance 1.74e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016759\n",
      " Loss: 0.000000\n",
      " Loss: 0.024607\n",
      " Loss: 0.000000\n",
      " Loss: 0.074337\n",
      " Loss: 0.000000\n",
      " Loss: 0.017674\n",
      " Loss: 0.000000\n",
      " Loss: 0.027460\n",
      " Loss: 0.000000\n",
      " Loss: 0.017578\n",
      " Loss: 0.000000\n",
      " Loss: 0.016410\n",
      " Loss: 0.000000\n",
      " Loss: 0.019996\n",
      " Loss: 0.000000\n",
      " Loss: 0.066680\n",
      " Loss: 0.000000\n",
      " Loss: 0.040173\n",
      "Epoch 1938 Chain 0 loss std 7.33e-04 variance 2.69e-07 smooth variance 3.65e-07 adaptive c -1.00\n",
      "Epoch 1938 Chain 1 loss std 1.41e+02 variance 1.00e+04 smooth variance 1.52e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018685\n",
      " Loss: 0.000000\n",
      " Loss: 0.020968\n",
      " Loss: 0.000000\n",
      " Loss: 0.043043\n",
      " Loss: 0.000000\n",
      " Loss: 0.026221\n",
      " Loss: 0.000000\n",
      " Loss: 0.051921\n",
      " Loss: 0.000000\n",
      " Loss: 0.017363\n",
      " Loss: 0.000000\n",
      " Loss: 0.023068\n",
      " Loss: 0.000000\n",
      " Loss: 0.070562\n",
      " Loss: 0.000000\n",
      " Loss: 0.041003\n",
      " Loss: 0.000000\n",
      " Loss: 0.008841\n",
      "Epoch 1940 Chain 0 loss std 5.67e-04 variance 1.61e-07 smooth variance 3.04e-07 adaptive c -1.00\n",
      "Epoch 1940 Chain 1 loss std 1.90e+02 variance 1.81e+04 smooth variance 1.61e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.009483\n",
      " Loss: 0.000000\n",
      " Loss: 0.036145\n",
      " Loss: 0.000000\n",
      " Loss: 0.065601\n",
      " Loss: 0.000000\n",
      " Loss: 0.016588\n",
      " Loss: 0.000000\n",
      " Loss: 0.033020\n",
      " Loss: 0.000000\n",
      " Loss: 0.018931\n",
      " Loss: 0.000000\n",
      " Loss: 0.056257\n",
      " Loss: 0.000000\n",
      " Loss: 0.027709\n",
      " Loss: 0.000000\n",
      " Loss: 0.038286\n",
      " Loss: 0.000000\n",
      " Loss: 0.019654\n",
      "Epoch 1942 Chain 0 loss std 8.63e-04 variance 3.73e-07 smooth variance 3.24e-07 adaptive c -1.00\n",
      "Epoch 1942 Chain 1 loss std 2.55e+02 variance 3.24e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020200\n",
      " Loss: 0.000000\n",
      " Loss: 0.068699\n",
      " Loss: 0.000000\n",
      " Loss: 0.015782\n",
      " Loss: 0.000000\n",
      " Loss: 0.031518\n",
      " Loss: 0.000000\n",
      " Loss: 0.024639\n",
      " Loss: 0.000000\n",
      " Loss: 0.016503\n",
      " Loss: 0.000000\n",
      " Loss: 0.023592\n",
      " Loss: 0.000000\n",
      " Loss: 0.013415\n",
      " Loss: 0.000000\n",
      " Loss: 0.066917\n",
      " Loss: 0.000000\n",
      " Loss: 0.040410\n",
      "Epoch 1944 Chain 0 loss std 1.00e-03 variance 5.02e-07 smooth variance 3.78e-07 adaptive c -1.00\n",
      "Epoch 1944 Chain 1 loss std 1.78e+02 variance 1.58e+04 smooth variance 1.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.007714\n",
      " Loss: 0.000000\n",
      " Loss: 0.020213\n",
      " Loss: 0.000000\n",
      " Loss: 0.043929\n",
      " Loss: 0.000000\n",
      " Loss: 0.061620\n",
      " Loss: 0.000000\n",
      " Loss: 0.027361\n",
      " Loss: 0.000000\n",
      " Loss: 0.071540\n",
      " Loss: 0.000000\n",
      " Loss: 0.017245\n",
      " Loss: 0.000000\n",
      " Loss: 0.016122\n",
      " Loss: 0.000000\n",
      " Loss: 0.016505\n",
      " Loss: 0.000000\n",
      " Loss: 0.039425\n",
      "Epoch 1946 Chain 0 loss std 1.40e-03 variance 9.78e-07 smooth variance 5.58e-07 adaptive c -1.00\n",
      "Epoch 1946 Chain 1 loss std 1.87e+02 variance 1.75e+04 smooth variance 1.88e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.030650\n",
      " Loss: 0.000000\n",
      " Loss: 0.023784\n",
      " Loss: 0.000000\n",
      " Loss: 0.055516\n",
      " Loss: 0.000000\n",
      " Loss: 0.017738\n",
      " Loss: 0.000000\n",
      " Loss: 0.033151\n",
      " Loss: 0.000000\n",
      " Loss: 0.060290\n",
      " Loss: 0.000000\n",
      " Loss: 0.023287\n",
      " Loss: 0.000000\n",
      " Loss: 0.023357\n",
      " Loss: 0.000000\n",
      " Loss: 0.035477\n",
      " Loss: 0.000000\n",
      " Loss: 0.018427\n",
      "Epoch 1948 Chain 0 loss std 9.62e-04 variance 4.63e-07 smooth variance 5.29e-07 adaptive c -1.00\n",
      "Epoch 1948 Chain 1 loss std 1.86e+02 variance 1.74e+04 smooth variance 1.84e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.057061\n",
      " Loss: 0.000000\n",
      " Loss: 0.038745\n",
      " Loss: 0.000000\n",
      " Loss: 0.022959\n",
      " Loss: 0.000000\n",
      " Loss: 0.023874\n",
      " Loss: 0.000000\n",
      " Loss: 0.018198\n",
      " Loss: 0.000000\n",
      " Loss: 0.022573\n",
      " Loss: 0.000000\n",
      " Loss: 0.079734\n",
      " Loss: 0.000000\n",
      " Loss: 0.027501\n",
      " Loss: 0.000000\n",
      " Loss: 0.016527\n",
      " Loss: 0.000000\n",
      " Loss: 0.014501\n",
      "Epoch 1950 Chain 0 loss std 7.53e-04 variance 2.84e-07 smooth variance 4.56e-07 adaptive c -1.00\n",
      "Epoch 1950 Chain 1 loss std 1.87e+02 variance 1.76e+04 smooth variance 1.82e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021748\n",
      " Loss: 0.000000\n",
      " Loss: 0.040851\n",
      " Loss: 0.000000\n",
      " Loss: 0.058215\n",
      " Loss: 0.000000\n",
      " Loss: 0.025203\n",
      " Loss: 0.000000\n",
      " Loss: 0.014821\n",
      " Loss: 0.000000\n",
      " Loss: 0.070852\n",
      " Loss: 0.000000\n",
      " Loss: 0.017015\n",
      " Loss: 0.000000\n",
      " Loss: 0.025533\n",
      " Loss: 0.000000\n",
      " Loss: 0.030927\n",
      " Loss: 0.000000\n",
      " Loss: 0.016509\n",
      "Epoch 1952 Chain 0 loss std 6.96e-04 variance 2.42e-07 smooth variance 3.92e-07 adaptive c -1.00\n",
      "Epoch 1952 Chain 1 loss std 2.53e+02 variance 3.20e+04 smooth variance 2.23e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036003\n",
      " Loss: 0.000000\n",
      " Loss: 0.018400\n",
      " Loss: 0.000000\n",
      " Loss: 0.017865\n",
      " Loss: 0.000000\n",
      " Loss: 0.027931\n",
      " Loss: 0.000000\n",
      " Loss: 0.060639\n",
      " Loss: 0.000000\n",
      " Loss: 0.055793\n",
      " Loss: 0.000000\n",
      " Loss: 0.029170\n",
      " Loss: 0.000000\n",
      " Loss: 0.018870\n",
      " Loss: 0.000000\n",
      " Loss: 0.023682\n",
      " Loss: 0.000000\n",
      " Loss: 0.033322\n",
      "Epoch 1954 Chain 0 loss std 6.82e-04 variance 2.32e-07 smooth variance 3.44e-07 adaptive c -1.00\n",
      "Epoch 1954 Chain 1 loss std 2.13e+02 variance 2.28e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016852\n",
      " Loss: 0.000000\n",
      " Loss: 0.021541\n",
      " Loss: 0.000000\n",
      " Loss: 0.045714\n",
      " Loss: 0.000000\n",
      " Loss: 0.019921\n",
      " Loss: 0.000000\n",
      " Loss: 0.056810\n",
      " Loss: 0.000000\n",
      " Loss: 0.024536\n",
      " Loss: 0.000000\n",
      " Loss: 0.015049\n",
      " Loss: 0.000000\n",
      " Loss: 0.075210\n",
      " Loss: 0.000000\n",
      " Loss: 0.030077\n",
      " Loss: 0.000000\n",
      " Loss: 0.015965\n",
      "Epoch 1956 Chain 0 loss std 1.15e-03 variance 6.63e-07 smooth variance 4.40e-07 adaptive c -1.00\n",
      "Epoch 1956 Chain 1 loss std 1.50e+02 variance 1.13e+04 smooth variance 1.91e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015461\n",
      " Loss: 0.000000\n",
      " Loss: 0.080355\n",
      " Loss: 0.000000\n",
      " Loss: 0.019778\n",
      " Loss: 0.000000\n",
      " Loss: 0.016810\n",
      " Loss: 0.000000\n",
      " Loss: 0.028433\n",
      " Loss: 0.000000\n",
      " Loss: 0.032718\n",
      " Loss: 0.000000\n",
      " Loss: 0.020361\n",
      " Loss: 0.000000\n",
      " Loss: 0.075328\n",
      " Loss: 0.000000\n",
      " Loss: 0.009639\n",
      " Loss: 0.000000\n",
      " Loss: 0.022792\n",
      "Epoch 1958 Chain 0 loss std 1.20e-03 variance 7.15e-07 smooth variance 5.22e-07 adaptive c -1.00\n",
      "Epoch 1958 Chain 1 loss std 1.60e+02 variance 1.28e+04 smooth variance 1.72e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019028\n",
      " Loss: 0.000000\n",
      " Loss: 0.025640\n",
      " Loss: 0.000000\n",
      " Loss: 0.021840\n",
      " Loss: 0.000000\n",
      " Loss: 0.078957\n",
      " Loss: 0.000000\n",
      " Loss: 0.015373\n",
      " Loss: 0.000000\n",
      " Loss: 0.017529\n",
      " Loss: 0.000000\n",
      " Loss: 0.021936\n",
      " Loss: 0.000000\n",
      " Loss: 0.039903\n",
      " Loss: 0.000000\n",
      " Loss: 0.056135\n",
      " Loss: 0.000000\n",
      " Loss: 0.025334\n",
      "Epoch 1960 Chain 0 loss std 1.14e-03 variance 6.51e-07 smooth variance 5.61e-07 adaptive c -1.00\n",
      "Epoch 1960 Chain 1 loss std 1.92e+02 variance 1.85e+04 smooth variance 1.76e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.062505\n",
      " Loss: 0.000000\n",
      " Loss: 0.020222\n",
      " Loss: 0.000000\n",
      " Loss: 0.029237\n",
      " Loss: 0.000000\n",
      " Loss: 0.038106\n",
      " Loss: 0.000000\n",
      " Loss: 0.010768\n",
      " Loss: 0.000000\n",
      " Loss: 0.028949\n",
      " Loss: 0.000000\n",
      " Loss: 0.064333\n",
      " Loss: 0.000000\n",
      " Loss: 0.017357\n",
      " Loss: 0.000000\n",
      " Loss: 0.009529\n",
      " Loss: 0.000000\n",
      " Loss: 0.040669\n",
      "Epoch 1962 Chain 0 loss std 1.49e-03 variance 1.11e-06 smooth variance 7.27e-07 adaptive c -1.00\n",
      "Epoch 1962 Chain 1 loss std 2.22e+02 variance 2.48e+04 smooth variance 1.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023384\n",
      " Loss: 0.000000\n",
      " Loss: 0.065053\n",
      " Loss: 0.000000\n",
      " Loss: 0.027941\n",
      " Loss: 0.000000\n",
      " Loss: 0.025601\n",
      " Loss: 0.000000\n",
      " Loss: 0.018859\n",
      " Loss: 0.000000\n",
      " Loss: 0.020414\n",
      " Loss: 0.000000\n",
      " Loss: 0.037065\n",
      " Loss: 0.000000\n",
      " Loss: 0.068478\n",
      " Loss: 0.000000\n",
      " Loss: 0.019257\n",
      " Loss: 0.000000\n",
      " Loss: 0.015624\n",
      "Epoch 1964 Chain 0 loss std 7.49e-04 variance 2.81e-07 smooth variance 5.93e-07 adaptive c -1.00\n",
      "Epoch 1964 Chain 1 loss std 2.15e+02 variance 2.32e+04 smooth variance 2.08e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020771\n",
      " Loss: 0.000000\n",
      " Loss: 0.077921\n",
      " Loss: 0.000000\n",
      " Loss: 0.023570\n",
      " Loss: 0.000000\n",
      " Loss: 0.017614\n",
      " Loss: 0.000000\n",
      " Loss: 0.020961\n",
      " Loss: 0.000000\n",
      " Loss: 0.044523\n",
      " Loss: 0.000000\n",
      " Loss: 0.019732\n",
      " Loss: 0.000000\n",
      " Loss: 0.013659\n",
      " Loss: 0.000000\n",
      " Loss: 0.062293\n",
      " Loss: 0.000000\n",
      " Loss: 0.020631\n",
      "Epoch 1966 Chain 0 loss std 1.39e-03 variance 9.66e-07 smooth variance 7.05e-07 adaptive c -1.00\n",
      "Epoch 1966 Chain 1 loss std 1.94e+02 variance 1.88e+04 smooth variance 2.02e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026578\n",
      " Loss: 0.000000\n",
      " Loss: 0.015876\n",
      " Loss: 0.000000\n",
      " Loss: 0.039792\n",
      " Loss: 0.000000\n",
      " Loss: 0.015374\n",
      " Loss: 0.000000\n",
      " Loss: 0.063217\n",
      " Loss: 0.000000\n",
      " Loss: 0.040746\n",
      " Loss: 0.000000\n",
      " Loss: 0.013282\n",
      " Loss: 0.000000\n",
      " Loss: 0.024215\n",
      " Loss: 0.000000\n",
      " Loss: 0.061891\n",
      " Loss: 0.000000\n",
      " Loss: 0.020704\n",
      "Epoch 1968 Chain 0 loss std 1.01e-03 variance 5.13e-07 smooth variance 6.47e-07 adaptive c -1.00\n",
      "Epoch 1968 Chain 1 loss std 1.60e+02 variance 1.29e+04 smooth variance 1.80e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036153\n",
      " Loss: 0.000000\n",
      " Loss: 0.021689\n",
      " Loss: 0.000000\n",
      " Loss: 0.033810\n",
      " Loss: 0.000000\n",
      " Loss: 0.013882\n",
      " Loss: 0.000000\n",
      " Loss: 0.055305\n",
      " Loss: 0.000000\n",
      " Loss: 0.020236\n",
      " Loss: 0.000000\n",
      " Loss: 0.027887\n",
      " Loss: 0.000000\n",
      " Loss: 0.021332\n",
      " Loss: 0.000000\n",
      " Loss: 0.069102\n",
      " Loss: 0.000000\n",
      " Loss: 0.022280\n",
      "Epoch 1970 Chain 0 loss std 9.27e-04 variance 4.30e-07 smooth variance 5.82e-07 adaptive c -1.00\n",
      "Epoch 1970 Chain 1 loss std 1.72e+02 variance 1.48e+04 smooth variance 1.70e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015073\n",
      " Loss: 0.000000\n",
      " Loss: 0.025534\n",
      " Loss: 0.000000\n",
      " Loss: 0.017335\n",
      " Loss: 0.000000\n",
      " Loss: 0.081851\n",
      " Loss: 0.000000\n",
      " Loss: 0.021045\n",
      " Loss: 0.000000\n",
      " Loss: 0.060226\n",
      " Loss: 0.000000\n",
      " Loss: 0.019167\n",
      " Loss: 0.000000\n",
      " Loss: 0.011574\n",
      " Loss: 0.000000\n",
      " Loss: 0.051357\n",
      " Loss: 0.000000\n",
      " Loss: 0.018514\n",
      "Epoch 1972 Chain 0 loss std 9.64e-04 variance 4.65e-07 smooth variance 5.47e-07 adaptive c -1.00\n",
      "Epoch 1972 Chain 1 loss std 1.75e+02 variance 1.52e+04 smooth variance 1.65e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061087\n",
      " Loss: 0.000000\n",
      " Loss: 0.022393\n",
      " Loss: 0.000000\n",
      " Loss: 0.022996\n",
      " Loss: 0.000000\n",
      " Loss: 0.031763\n",
      " Loss: 0.000000\n",
      " Loss: 0.022598\n",
      " Loss: 0.000000\n",
      " Loss: 0.059880\n",
      " Loss: 0.000000\n",
      " Loss: 0.023314\n",
      " Loss: 0.000000\n",
      " Loss: 0.043715\n",
      " Loss: 0.000000\n",
      " Loss: 0.022246\n",
      " Loss: 0.000000\n",
      " Loss: 0.011683\n",
      "Epoch 1974 Chain 0 loss std 1.02e-03 variance 5.22e-07 smooth variance 5.40e-07 adaptive c -1.00\n",
      "Epoch 1974 Chain 1 loss std 1.58e+02 variance 1.25e+04 smooth variance 1.53e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.040571\n",
      " Loss: 0.000000\n",
      " Loss: 0.022918\n",
      " Loss: 0.000000\n",
      " Loss: 0.013933\n",
      " Loss: 0.000000\n",
      " Loss: 0.065721\n",
      " Loss: 0.000000\n",
      " Loss: 0.017694\n",
      " Loss: 0.000000\n",
      " Loss: 0.064896\n",
      " Loss: 0.000000\n",
      " Loss: 0.026889\n",
      " Loss: 0.000000\n",
      " Loss: 0.018783\n",
      " Loss: 0.000000\n",
      " Loss: 0.017752\n",
      " Loss: 0.000000\n",
      " Loss: 0.032517\n",
      "Epoch 1976 Chain 0 loss std 1.27e-03 variance 8.12e-07 smooth variance 6.21e-07 adaptive c -1.00\n",
      "Epoch 1976 Chain 1 loss std 2.49e+02 variance 3.09e+04 smooth variance 2.00e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020572\n",
      " Loss: 0.000000\n",
      " Loss: 0.061892\n",
      " Loss: 0.000000\n",
      " Loss: 0.025212\n",
      " Loss: 0.000000\n",
      " Loss: 0.037429\n",
      " Loss: 0.000000\n",
      " Loss: 0.015733\n",
      " Loss: 0.000000\n",
      " Loss: 0.017566\n",
      " Loss: 0.000000\n",
      " Loss: 0.044036\n",
      " Loss: 0.000000\n",
      " Loss: 0.012714\n",
      " Loss: 0.000000\n",
      " Loss: 0.021494\n",
      " Loss: 0.000000\n",
      " Loss: 0.065028\n",
      "Epoch 1978 Chain 0 loss std 9.04e-04 variance 4.08e-07 smooth variance 5.57e-07 adaptive c -1.00\n",
      "Epoch 1978 Chain 1 loss std 1.78e+02 variance 1.59e+04 smooth variance 1.88e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019052\n",
      " Loss: 0.000000\n",
      " Loss: 0.022254\n",
      " Loss: 0.000000\n",
      " Loss: 0.067151\n",
      " Loss: 0.000000\n",
      " Loss: 0.032017\n",
      " Loss: 0.000000\n",
      " Loss: 0.020364\n",
      " Loss: 0.000000\n",
      " Loss: 0.013158\n",
      " Loss: 0.000000\n",
      " Loss: 0.013290\n",
      " Loss: 0.000000\n",
      " Loss: 0.049430\n",
      " Loss: 0.000000\n",
      " Loss: 0.062626\n",
      " Loss: 0.000000\n",
      " Loss: 0.022334\n",
      "Epoch 1980 Chain 0 loss std 1.04e-03 variance 5.44e-07 smooth variance 5.53e-07 adaptive c -1.00\n",
      "Epoch 1980 Chain 1 loss std 2.00e+02 variance 2.01e+04 smooth variance 1.92e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022889\n",
      " Loss: 0.000000\n",
      " Loss: 0.017418\n",
      " Loss: 0.000000\n",
      " Loss: 0.063631\n",
      " Loss: 0.000000\n",
      " Loss: 0.027671\n",
      " Loss: 0.000000\n",
      " Loss: 0.029229\n",
      " Loss: 0.000000\n",
      " Loss: 0.031067\n",
      " Loss: 0.000000\n",
      " Loss: 0.024258\n",
      " Loss: 0.000000\n",
      " Loss: 0.032994\n",
      " Loss: 0.000000\n",
      " Loss: 0.012298\n",
      " Loss: 0.000000\n",
      " Loss: 0.060221\n",
      "Epoch 1982 Chain 0 loss std 1.76e-03 variance 1.55e-06 smooth variance 8.53e-07 adaptive c -1.00\n",
      "Epoch 1982 Chain 1 loss std 2.00e+02 variance 1.99e+04 smooth variance 1.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.076957\n",
      " Loss: 0.000000\n",
      " Loss: 0.015593\n",
      " Loss: 0.000000\n",
      " Loss: 0.022924\n",
      " Loss: 0.000000\n",
      " Loss: 0.022474\n",
      " Loss: 0.000000\n",
      " Loss: 0.022889\n",
      " Loss: 0.000000\n",
      " Loss: 0.068767\n",
      " Loss: 0.000000\n",
      " Loss: 0.039130\n",
      " Loss: 0.000000\n",
      " Loss: 0.022784\n",
      " Loss: 0.000000\n",
      " Loss: 0.018391\n",
      " Loss: 0.000000\n",
      " Loss: 0.011765\n",
      "Epoch 1984 Chain 0 loss std 5.68e-04 variance 1.61e-07 smooth variance 6.46e-07 adaptive c -1.00\n",
      "Epoch 1984 Chain 1 loss std 1.65e+02 variance 1.36e+04 smooth variance 1.77e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029485\n",
      " Loss: 0.000000\n",
      " Loss: 0.029676\n",
      " Loss: 0.000000\n",
      " Loss: 0.023680\n",
      " Loss: 0.000000\n",
      " Loss: 0.064835\n",
      " Loss: 0.000000\n",
      " Loss: 0.013162\n",
      " Loss: 0.000000\n",
      " Loss: 0.024088\n",
      " Loss: 0.000000\n",
      " Loss: 0.019529\n",
      " Loss: 0.000000\n",
      " Loss: 0.072255\n",
      " Loss: 0.000000\n",
      " Loss: 0.027266\n",
      " Loss: 0.000000\n",
      " Loss: 0.017699\n",
      "Epoch 1986 Chain 0 loss std 9.59e-04 variance 4.60e-07 smooth variance 5.90e-07 adaptive c -1.00\n",
      "Epoch 1986 Chain 1 loss std 2.62e+02 variance 3.43e+04 smooth variance 2.27e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021293\n",
      " Loss: 0.000000\n",
      " Loss: 0.016315\n",
      " Loss: 0.000000\n",
      " Loss: 0.034923\n",
      " Loss: 0.000000\n",
      " Loss: 0.061940\n",
      " Loss: 0.000000\n",
      " Loss: 0.026367\n",
      " Loss: 0.000000\n",
      " Loss: 0.017444\n",
      " Loss: 0.000000\n",
      " Loss: 0.027906\n",
      " Loss: 0.000000\n",
      " Loss: 0.030864\n",
      " Loss: 0.000000\n",
      " Loss: 0.015203\n",
      " Loss: 0.000000\n",
      " Loss: 0.069420\n",
      "Epoch 1988 Chain 0 loss std 1.35e-03 variance 9.10e-07 smooth variance 6.86e-07 adaptive c -1.00\n",
      "Epoch 1988 Chain 1 loss std 1.85e+02 variance 1.71e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019103\n",
      " Loss: 0.000000\n",
      " Loss: 0.073657\n",
      " Loss: 0.000000\n",
      " Loss: 0.016971\n",
      " Loss: 0.000000\n",
      " Loss: 0.024103\n",
      " Loss: 0.000000\n",
      " Loss: 0.027004\n",
      " Loss: 0.000000\n",
      " Loss: 0.019303\n",
      " Loss: 0.000000\n",
      " Loss: 0.017841\n",
      " Loss: 0.000000\n",
      " Loss: 0.013655\n",
      " Loss: 0.000000\n",
      " Loss: 0.067360\n",
      " Loss: 0.000000\n",
      " Loss: 0.042677\n",
      "Epoch 1990 Chain 0 loss std 8.75e-04 variance 3.83e-07 smooth variance 5.95e-07 adaptive c -1.00\n",
      "Epoch 1990 Chain 1 loss std 2.19e+02 variance 2.41e+04 smooth variance 2.19e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014821\n",
      " Loss: 0.000000\n",
      " Loss: 0.021900\n",
      " Loss: 0.000000\n",
      " Loss: 0.052971\n",
      " Loss: 0.000000\n",
      " Loss: 0.016871\n",
      " Loss: 0.000000\n",
      " Loss: 0.054276\n",
      " Loss: 0.000000\n",
      " Loss: 0.018793\n",
      " Loss: 0.000000\n",
      " Loss: 0.030179\n",
      " Loss: 0.000000\n",
      " Loss: 0.007789\n",
      " Loss: 0.000000\n",
      " Loss: 0.040096\n",
      " Loss: 0.000000\n",
      " Loss: 0.063981\n",
      "Epoch 1992 Chain 0 loss std 9.18e-04 variance 4.21e-07 smooth variance 5.43e-07 adaptive c -1.00\n",
      "Epoch 1992 Chain 1 loss std 2.02e+02 variance 2.05e+04 smooth variance 2.15e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.039913\n",
      " Loss: 0.000000\n",
      " Loss: 0.014460\n",
      " Loss: 0.000000\n",
      " Loss: 0.026585\n",
      " Loss: 0.000000\n",
      " Loss: 0.059195\n",
      " Loss: 0.000000\n",
      " Loss: 0.020684\n",
      " Loss: 0.000000\n",
      " Loss: 0.019877\n",
      " Loss: 0.000000\n",
      " Loss: 0.027708\n",
      " Loss: 0.000000\n",
      " Loss: 0.074712\n",
      " Loss: 0.000000\n",
      " Loss: 0.020416\n",
      " Loss: 0.000000\n",
      " Loss: 0.018124\n",
      "Epoch 1994 Chain 0 loss std 1.19e-03 variance 7.12e-07 smooth variance 5.94e-07 adaptive c -1.00\n",
      "Epoch 1994 Chain 1 loss std 2.11e+02 variance 2.24e+04 smooth variance 2.18e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025233\n",
      " Loss: 0.000000\n",
      " Loss: 0.023516\n",
      " Loss: 0.000000\n",
      " Loss: 0.055872\n",
      " Loss: 0.000000\n",
      " Loss: 0.036055\n",
      " Loss: 0.000000\n",
      " Loss: 0.020162\n",
      " Loss: 0.000000\n",
      " Loss: 0.061314\n",
      " Loss: 0.000000\n",
      " Loss: 0.043375\n",
      " Loss: 0.000000\n",
      " Loss: 0.017044\n",
      " Loss: 0.000000\n",
      " Loss: 0.022178\n",
      " Loss: 0.000000\n",
      " Loss: 0.016926\n",
      "Epoch 1996 Chain 0 loss std 8.79e-04 variance 3.86e-07 smooth variance 5.31e-07 adaptive c -1.00\n",
      "Epoch 1996 Chain 1 loss std 2.04e+02 variance 2.08e+04 smooth variance 2.15e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.042167\n",
      " Loss: 0.000000\n",
      " Loss: 0.022594\n",
      " Loss: 0.000000\n",
      " Loss: 0.019413\n",
      " Loss: 0.000000\n",
      " Loss: 0.021066\n",
      " Loss: 0.000000\n",
      " Loss: 0.055598\n",
      " Loss: 0.000000\n",
      " Loss: 0.016259\n",
      " Loss: 0.000000\n",
      " Loss: 0.059192\n",
      " Loss: 0.000000\n",
      " Loss: 0.028112\n",
      " Loss: 0.000000\n",
      " Loss: 0.022035\n",
      " Loss: 0.000000\n",
      " Loss: 0.035239\n",
      "Epoch 1998 Chain 0 loss std 1.08e-03 variance 5.88e-07 smooth variance 5.48e-07 adaptive c -1.00\n",
      "Epoch 1998 Chain 1 loss std 2.26e+02 variance 2.56e+04 smooth variance 2.27e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029685\n",
      " Loss: 0.000001\n",
      " Loss: 0.057567\n",
      " Loss: 0.000000\n",
      " Loss: 0.036422\n",
      " Loss: 0.000000\n",
      " Loss: 0.026067\n",
      " Loss: 0.000000\n",
      " Loss: 0.011097\n",
      " Loss: 0.000000\n",
      " Loss: 0.034226\n",
      " Loss: 0.000000\n",
      " Loss: 0.020045\n",
      " Loss: 0.000000\n",
      " Loss: 0.064918\n",
      " Loss: 0.000000\n",
      " Loss: 0.027291\n",
      " Loss: 0.000000\n",
      " Loss: 0.014359\n",
      "Epoch 2000 Chain 0 loss std 7.80e-04 variance 3.04e-07 smooth variance 4.75e-07 adaptive c -1.00\n",
      "Epoch 2000 Chain 1 loss std 2.04e+02 variance 2.08e+04 smooth variance 2.21e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.052442\n",
      " Loss: 0.000000\n",
      " Loss: 0.059026\n",
      " Loss: 0.000000\n",
      " Loss: 0.019813\n",
      " Loss: 0.000000\n",
      " Loss: 0.014873\n",
      " Loss: 0.000000\n",
      " Loss: 0.014684\n",
      " Loss: 0.000000\n",
      " Loss: 0.032386\n",
      " Loss: 0.000000\n",
      " Loss: 0.060644\n",
      " Loss: 0.000000\n",
      " Loss: 0.030275\n",
      " Loss: 0.000000\n",
      " Loss: 0.013651\n",
      " Loss: 0.000000\n",
      " Loss: 0.023881\n",
      "Epoch 2002 Chain 0 loss std 1.18e-03 variance 7.01e-07 smooth variance 5.43e-07 adaptive c -1.00\n",
      "Epoch 2002 Chain 1 loss std 2.04e+02 variance 2.07e+04 smooth variance 2.17e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020251\n",
      " Loss: 0.000000\n",
      " Loss: 0.077667\n",
      " Loss: 0.000000\n",
      " Loss: 0.021718\n",
      " Loss: 0.000000\n",
      " Loss: 0.017474\n",
      " Loss: 0.000000\n",
      " Loss: 0.023728\n",
      " Loss: 0.000000\n",
      " Loss: 0.013088\n",
      " Loss: 0.000000\n",
      " Loss: 0.021402\n",
      " Loss: 0.000000\n",
      " Loss: 0.083660\n",
      " Loss: 0.000000\n",
      " Loss: 0.022264\n",
      " Loss: 0.000000\n",
      " Loss: 0.020423\n",
      "Epoch 2004 Chain 0 loss std 6.37e-04 variance 2.03e-07 smooth variance 4.41e-07 adaptive c -1.00\n",
      "Epoch 2004 Chain 1 loss std 2.22e+02 variance 2.47e+04 smooth variance 2.26e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.077996\n",
      " Loss: 0.000000\n",
      " Loss: 0.016683\n",
      " Loss: 0.000000\n",
      " Loss: 0.013165\n",
      " Loss: 0.000000\n",
      " Loss: 0.026137\n",
      " Loss: 0.000000\n",
      " Loss: 0.026857\n",
      " Loss: 0.000000\n",
      " Loss: 0.015049\n",
      " Loss: 0.000000\n",
      " Loss: 0.033788\n",
      " Loss: 0.000000\n",
      " Loss: 0.077012\n",
      " Loss: 0.000000\n",
      " Loss: 0.012688\n",
      " Loss: 0.000000\n",
      " Loss: 0.022300\n",
      "Epoch 2006 Chain 0 loss std 7.82e-04 variance 3.06e-07 smooth variance 4.00e-07 adaptive c -1.00\n",
      "Epoch 2006 Chain 1 loss std 1.76e+02 variance 1.55e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.011079\n",
      " Loss: 0.000000\n",
      " Loss: 0.019607\n",
      " Loss: 0.000000\n",
      " Loss: 0.038439\n",
      " Loss: 0.000000\n",
      " Loss: 0.022472\n",
      " Loss: 0.000000\n",
      " Loss: 0.069240\n",
      " Loss: 0.000000\n",
      " Loss: 0.021632\n",
      " Loss: 0.000000\n",
      " Loss: 0.059272\n",
      " Loss: 0.000000\n",
      " Loss: 0.050553\n",
      " Loss: 0.000000\n",
      " Loss: 0.010418\n",
      " Loss: 0.000000\n",
      " Loss: 0.018963\n",
      "Epoch 2008 Chain 0 loss std 3.49e-04 variance 6.08e-08 smooth variance 2.98e-07 adaptive c -1.00\n",
      "Epoch 2008 Chain 1 loss std 2.63e+02 variance 3.45e+04 smooth variance 2.47e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023697\n",
      " Loss: 0.000000\n",
      " Loss: 0.020165\n",
      " Loss: 0.000000\n",
      " Loss: 0.021949\n",
      " Loss: 0.000000\n",
      " Loss: 0.018344\n",
      " Loss: 0.000000\n",
      " Loss: 0.076683\n",
      " Loss: 0.000000\n",
      " Loss: 0.031132\n",
      " Loss: 0.000000\n",
      " Loss: 0.057114\n",
      " Loss: 0.000000\n",
      " Loss: 0.014727\n",
      " Loss: 0.000000\n",
      " Loss: 0.035766\n",
      " Loss: 0.000000\n",
      " Loss: 0.022099\n",
      "Epoch 2010 Chain 0 loss std 1.29e-03 variance 8.37e-07 smooth variance 4.60e-07 adaptive c -1.00\n",
      "Epoch 2010 Chain 1 loss std 2.49e+02 variance 3.10e+04 smooth variance 2.66e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.012996\n",
      " Loss: 0.000000\n",
      " Loss: 0.073257\n",
      " Loss: 0.000000\n",
      " Loss: 0.019355\n",
      " Loss: 0.000000\n",
      " Loss: 0.023315\n",
      " Loss: 0.000000\n",
      " Loss: 0.031915\n",
      " Loss: 0.000000\n",
      " Loss: 0.059541\n",
      " Loss: 0.000000\n",
      " Loss: 0.022148\n",
      " Loss: 0.000000\n",
      " Loss: 0.038234\n",
      " Loss: 0.000000\n",
      " Loss: 0.012016\n",
      " Loss: 0.000000\n",
      " Loss: 0.028898\n",
      "Epoch 2012 Chain 0 loss std 1.12e-03 variance 6.24e-07 smooth variance 5.09e-07 adaptive c -1.00\n",
      "Epoch 2012 Chain 1 loss std 2.37e+02 variance 2.81e+04 smooth variance 2.70e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017794\n",
      " Loss: 0.000000\n",
      " Loss: 0.061192\n",
      " Loss: 0.000000\n",
      " Loss: 0.019318\n",
      " Loss: 0.000000\n",
      " Loss: 0.047729\n",
      " Loss: 0.000000\n",
      " Loss: 0.014805\n",
      " Loss: 0.000000\n",
      " Loss: 0.017594\n",
      " Loss: 0.000000\n",
      " Loss: 0.014140\n",
      " Loss: 0.000000\n",
      " Loss: 0.025606\n",
      " Loss: 0.000000\n",
      " Loss: 0.062250\n",
      " Loss: 0.000000\n",
      " Loss: 0.041248\n",
      "Epoch 2014 Chain 0 loss std 1.10e-03 variance 6.03e-07 smooth variance 5.37e-07 adaptive c -1.00\n",
      "Epoch 2014 Chain 1 loss std 2.19e+02 variance 2.41e+04 smooth variance 2.61e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014752\n",
      " Loss: 0.000000\n",
      " Loss: 0.018360\n",
      " Loss: 0.000000\n",
      " Loss: 0.023471\n",
      " Loss: 0.000000\n",
      " Loss: 0.062848\n",
      " Loss: 0.000000\n",
      " Loss: 0.041406\n",
      " Loss: 0.000000\n",
      " Loss: 0.031207\n",
      " Loss: 0.000000\n",
      " Loss: 0.031992\n",
      " Loss: 0.000000\n",
      " Loss: 0.062455\n",
      " Loss: 0.000000\n",
      " Loss: 0.020021\n",
      " Loss: 0.000000\n",
      " Loss: 0.015162\n",
      "Epoch 2016 Chain 0 loss std 1.24e-03 variance 7.69e-07 smooth variance 6.07e-07 adaptive c -1.00\n",
      "Epoch 2016 Chain 1 loss std 1.95e+02 variance 1.90e+04 smooth variance 2.40e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.030572\n",
      " Loss: 0.000000\n",
      " Loss: 0.059425\n",
      " Loss: 0.000000\n",
      " Loss: 0.029483\n",
      " Loss: 0.000000\n",
      " Loss: 0.028557\n",
      " Loss: 0.000000\n",
      " Loss: 0.012800\n",
      " Loss: 0.000000\n",
      " Loss: 0.060443\n",
      " Loss: 0.000000\n",
      " Loss: 0.038465\n",
      " Loss: 0.000000\n",
      " Loss: 0.016910\n",
      " Loss: 0.000000\n",
      " Loss: 0.027769\n",
      " Loss: 0.000000\n",
      " Loss: 0.017251\n",
      "Epoch 2018 Chain 0 loss std 7.61e-04 variance 2.90e-07 smooth variance 5.12e-07 adaptive c -1.00\n",
      "Epoch 2018 Chain 1 loss std 1.81e+02 variance 1.63e+04 smooth variance 2.17e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028734\n",
      " Loss: 0.000000\n",
      " Loss: 0.032409\n",
      " Loss: 0.000000\n",
      " Loss: 0.018923\n",
      " Loss: 0.000000\n",
      " Loss: 0.020865\n",
      " Loss: 0.000000\n",
      " Loss: 0.059906\n",
      " Loss: 0.000000\n",
      " Loss: 0.020186\n",
      " Loss: 0.000000\n",
      " Loss: 0.062307\n",
      " Loss: 0.000000\n",
      " Loss: 0.043460\n",
      " Loss: 0.000000\n",
      " Loss: 0.025165\n",
      " Loss: 0.000000\n",
      " Loss: 0.009720\n",
      "Epoch 2020 Chain 0 loss std 7.25e-04 variance 2.63e-07 smooth variance 4.37e-07 adaptive c -1.00\n",
      "Epoch 2020 Chain 1 loss std 1.98e+02 variance 1.95e+04 smooth variance 2.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.039800\n",
      " Loss: 0.000000\n",
      " Loss: 0.011635\n",
      " Loss: 0.000000\n",
      " Loss: 0.022256\n",
      " Loss: 0.000000\n",
      " Loss: 0.019004\n",
      " Loss: 0.000000\n",
      " Loss: 0.068142\n",
      " Loss: 0.000000\n",
      " Loss: 0.056571\n",
      " Loss: 0.000000\n",
      " Loss: 0.015511\n",
      " Loss: 0.000000\n",
      " Loss: 0.023920\n",
      " Loss: 0.000000\n",
      " Loss: 0.043629\n",
      " Loss: 0.000000\n",
      " Loss: 0.021207\n",
      "Epoch 2022 Chain 0 loss std 1.80e-03 variance 1.62e-06 smooth variance 7.91e-07 adaptive c -1.00\n",
      "Epoch 2022 Chain 1 loss std 1.96e+02 variance 1.93e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015890\n",
      " Loss: 0.000000\n",
      " Loss: 0.034115\n",
      " Loss: 0.000000\n",
      " Loss: 0.026145\n",
      " Loss: 0.000000\n",
      " Loss: 0.058403\n",
      " Loss: 0.000000\n",
      " Loss: 0.026284\n",
      " Loss: 0.000000\n",
      " Loss: 0.016888\n",
      " Loss: 0.000000\n",
      " Loss: 0.035175\n",
      " Loss: 0.000000\n",
      " Loss: 0.022934\n",
      " Loss: 0.000000\n",
      " Loss: 0.061668\n",
      " Loss: 0.000000\n",
      " Loss: 0.024172\n",
      "Epoch 2024 Chain 0 loss std 1.19e-03 variance 7.10e-07 smooth variance 7.67e-07 adaptive c -1.00\n",
      "Epoch 2024 Chain 1 loss std 2.38e+02 variance 2.84e+04 smooth variance 2.29e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016842\n",
      " Loss: 0.000000\n",
      " Loss: 0.068492\n",
      " Loss: 0.000000\n",
      " Loss: 0.023512\n",
      " Loss: 0.000000\n",
      " Loss: 0.019042\n",
      " Loss: 0.000000\n",
      " Loss: 0.032949\n",
      " Loss: 0.000000\n",
      " Loss: 0.042967\n",
      " Loss: 0.000000\n",
      " Loss: 0.058913\n",
      " Loss: 0.000000\n",
      " Loss: 0.018818\n",
      " Loss: 0.000000\n",
      " Loss: 0.017765\n",
      " Loss: 0.000000\n",
      " Loss: 0.022375\n",
      "Epoch 2026 Chain 0 loss std 6.71e-04 variance 2.25e-07 smooth variance 6.04e-07 adaptive c -1.00\n",
      "Epoch 2026 Chain 1 loss std 2.20e+02 variance 2.42e+04 smooth variance 2.33e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015957\n",
      " Loss: 0.000000\n",
      " Loss: 0.027383\n",
      " Loss: 0.000000\n",
      " Loss: 0.058495\n",
      " Loss: 0.000000\n",
      " Loss: 0.043334\n",
      " Loss: 0.000000\n",
      " Loss: 0.015668\n",
      " Loss: 0.000000\n",
      " Loss: 0.035575\n",
      " Loss: 0.000000\n",
      " Loss: 0.020876\n",
      " Loss: 0.000000\n",
      " Loss: 0.021255\n",
      " Loss: 0.000000\n",
      " Loss: 0.066760\n",
      " Loss: 0.000000\n",
      " Loss: 0.016372\n",
      "Epoch 2028 Chain 0 loss std 1.71e-03 variance 1.46e-06 smooth variance 8.60e-07 adaptive c -1.00\n",
      "Epoch 2028 Chain 1 loss std 2.42e+02 variance 2.92e+04 smooth variance 2.51e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023720\n",
      " Loss: 0.000000\n",
      " Loss: 0.057080\n",
      " Loss: 0.000000\n",
      " Loss: 0.019302\n",
      " Loss: 0.000000\n",
      " Loss: 0.044463\n",
      " Loss: 0.000000\n",
      " Loss: 0.016272\n",
      " Loss: 0.000000\n",
      " Loss: 0.035496\n",
      " Loss: 0.000000\n",
      " Loss: 0.020978\n",
      " Loss: 0.000000\n",
      " Loss: 0.014421\n",
      " Loss: 0.000000\n",
      " Loss: 0.074258\n",
      " Loss: 0.000000\n",
      " Loss: 0.015684\n",
      "Epoch 2030 Chain 0 loss std 7.77e-04 variance 3.02e-07 smooth variance 6.92e-07 adaptive c -1.00\n",
      "Epoch 2030 Chain 1 loss std 1.57e+02 variance 1.23e+04 smooth variance 2.12e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.038197\n",
      " Loss: 0.000000\n",
      " Loss: 0.013113\n",
      " Loss: 0.000000\n",
      " Loss: 0.028391\n",
      " Loss: 0.000000\n",
      " Loss: 0.059278\n",
      " Loss: 0.000000\n",
      " Loss: 0.021858\n",
      " Loss: 0.000000\n",
      " Loss: 0.017607\n",
      " Loss: 0.000000\n",
      " Loss: 0.028190\n",
      " Loss: 0.000000\n",
      " Loss: 0.071241\n",
      " Loss: 0.000000\n",
      " Loss: 0.020746\n",
      " Loss: 0.000000\n",
      " Loss: 0.023054\n",
      "Epoch 2032 Chain 0 loss std 6.18e-04 variance 1.91e-07 smooth variance 5.42e-07 adaptive c -1.00\n",
      "Epoch 2032 Chain 1 loss std 2.61e+02 variance 3.40e+04 smooth variance 2.50e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020367\n",
      " Loss: 0.000000\n",
      " Loss: 0.024707\n",
      " Loss: 0.000000\n",
      " Loss: 0.060999\n",
      " Loss: 0.000000\n",
      " Loss: 0.029090\n",
      " Loss: 0.000000\n",
      " Loss: 0.025674\n",
      " Loss: 0.000000\n",
      " Loss: 0.027190\n",
      " Loss: 0.000000\n",
      " Loss: 0.018926\n",
      " Loss: 0.000000\n",
      " Loss: 0.019056\n",
      " Loss: 0.000000\n",
      " Loss: 0.038362\n",
      " Loss: 0.000000\n",
      " Loss: 0.057303\n",
      "Epoch 2034 Chain 0 loss std 6.75e-04 variance 2.28e-07 smooth variance 4.48e-07 adaptive c -1.00\n",
      "Epoch 2034 Chain 1 loss std 2.10e+02 variance 2.20e+04 smooth variance 2.41e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019886\n",
      " Loss: 0.000000\n",
      " Loss: 0.030199\n",
      " Loss: 0.000000\n",
      " Loss: 0.021412\n",
      " Loss: 0.000000\n",
      " Loss: 0.012172\n",
      " Loss: 0.000000\n",
      " Loss: 0.077170\n",
      " Loss: 0.000000\n",
      " Loss: 0.034333\n",
      " Loss: 0.000000\n",
      " Loss: 0.062242\n",
      " Loss: 0.000000\n",
      " Loss: 0.013975\n",
      " Loss: 0.000000\n",
      " Loss: 0.032739\n",
      " Loss: 0.000000\n",
      " Loss: 0.017547\n",
      "Epoch 2036 Chain 0 loss std 1.25e-03 variance 7.84e-07 smooth variance 5.49e-07 adaptive c -1.00\n",
      "Epoch 2036 Chain 1 loss std 1.29e+02 variance 8.30e+03 smooth variance 1.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.055684\n",
      " Loss: 0.000000\n",
      " Loss: 0.023362\n",
      " Loss: 0.000000\n",
      " Loss: 0.038048\n",
      " Loss: 0.000000\n",
      " Loss: 0.017376\n",
      " Loss: 0.000000\n",
      " Loss: 0.026367\n",
      " Loss: 0.000000\n",
      " Loss: 0.019788\n",
      " Loss: 0.000000\n",
      " Loss: 0.058213\n",
      " Loss: 0.000000\n",
      " Loss: 0.028301\n",
      " Loss: 0.000000\n",
      " Loss: 0.022087\n",
      " Loss: 0.000000\n",
      " Loss: 0.032448\n",
      "Epoch 2038 Chain 0 loss std 8.85e-04 variance 3.91e-07 smooth variance 5.01e-07 adaptive c -1.00\n",
      "Epoch 2038 Chain 1 loss std 3.38e+02 variance 5.70e+04 smooth variance 3.07e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022783\n",
      " Loss: 0.000000\n",
      " Loss: 0.058805\n",
      " Loss: 0.000000\n",
      " Loss: 0.026929\n",
      " Loss: 0.000000\n",
      " Loss: 0.037970\n",
      " Loss: 0.000000\n",
      " Loss: 0.014351\n",
      " Loss: 0.000000\n",
      " Loss: 0.030871\n",
      " Loss: 0.000000\n",
      " Loss: 0.010602\n",
      " Loss: 0.000000\n",
      " Loss: 0.025892\n",
      " Loss: 0.000000\n",
      " Loss: 0.025037\n",
      " Loss: 0.000000\n",
      " Loss: 0.068436\n",
      "Epoch 2040 Chain 0 loss std 6.84e-04 variance 2.34e-07 smooth variance 4.21e-07 adaptive c -1.00\n",
      "Epoch 2040 Chain 1 loss std 1.62e+02 variance 1.31e+04 smooth variance 2.54e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021058\n",
      " Loss: 0.000000\n",
      " Loss: 0.021606\n",
      " Loss: 0.000000\n",
      " Loss: 0.019101\n",
      " Loss: 0.000000\n",
      " Loss: 0.062583\n",
      " Loss: 0.000000\n",
      " Loss: 0.036489\n",
      " Loss: 0.000000\n",
      " Loss: 0.024731\n",
      " Loss: 0.000000\n",
      " Loss: 0.020135\n",
      " Loss: 0.000000\n",
      " Loss: 0.062065\n",
      " Loss: 0.000000\n",
      " Loss: 0.019871\n",
      " Loss: 0.000000\n",
      " Loss: 0.034035\n",
      "Epoch 2042 Chain 0 loss std 1.09e-03 variance 5.91e-07 smooth variance 4.72e-07 adaptive c -1.00\n",
      "Epoch 2042 Chain 1 loss std 1.81e+02 variance 1.64e+04 smooth variance 2.27e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021731\n",
      " Loss: 0.000000\n",
      " Loss: 0.056722\n",
      " Loss: 0.000000\n",
      " Loss: 0.023543\n",
      " Loss: 0.000000\n",
      " Loss: 0.036472\n",
      " Loss: 0.000000\n",
      " Loss: 0.022370\n",
      " Loss: 0.000000\n",
      " Loss: 0.018884\n",
      " Loss: 0.000000\n",
      " Loss: 0.016432\n",
      " Loss: 0.000000\n",
      " Loss: 0.065140\n",
      " Loss: 0.000000\n",
      " Loss: 0.029709\n",
      " Loss: 0.000000\n",
      " Loss: 0.030672\n",
      "Epoch 2044 Chain 0 loss std 9.84e-04 variance 4.84e-07 smooth variance 4.76e-07 adaptive c -1.00\n",
      "Epoch 2044 Chain 1 loss std 1.38e+02 variance 9.49e+03 smooth variance 1.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.063323\n",
      " Loss: 0.000000\n",
      " Loss: 0.018719\n",
      " Loss: 0.000000\n",
      " Loss: 0.020377\n",
      " Loss: 0.000000\n",
      " Loss: 0.035986\n",
      " Loss: 0.000000\n",
      " Loss: 0.022432\n",
      " Loss: 0.000000\n",
      " Loss: 0.021318\n",
      " Loss: 0.000000\n",
      " Loss: 0.027566\n",
      " Loss: 0.000000\n",
      " Loss: 0.037291\n",
      " Loss: 0.000000\n",
      " Loss: 0.015506\n",
      " Loss: 0.000000\n",
      " Loss: 0.059155\n",
      "Epoch 2046 Chain 0 loss std 6.50e-04 variance 2.11e-07 smooth variance 3.96e-07 adaptive c -1.00\n",
      "Epoch 2046 Chain 1 loss std 1.77e+02 variance 1.56e+04 smooth variance 1.78e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022084\n",
      " Loss: 0.000000\n",
      " Loss: 0.075218\n",
      " Loss: 0.000000\n",
      " Loss: 0.021327\n",
      " Loss: 0.000000\n",
      " Loss: 0.022787\n",
      " Loss: 0.000000\n",
      " Loss: 0.019421\n",
      " Loss: 0.000000\n",
      " Loss: 0.064467\n",
      " Loss: 0.000000\n",
      " Loss: 0.052786\n",
      " Loss: 0.000000\n",
      " Loss: 0.014439\n",
      " Loss: 0.000000\n",
      " Loss: 0.012469\n",
      " Loss: 0.000000\n",
      " Loss: 0.016676\n",
      "Epoch 2048 Chain 0 loss std 1.49e-03 variance 1.10e-06 smooth variance 6.09e-07 adaptive c -1.00\n",
      "Epoch 2048 Chain 1 loss std 2.27e+02 variance 2.57e+04 smooth variance 2.02e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020103\n",
      " Loss: 0.000000\n",
      " Loss: 0.015578\n",
      " Loss: 0.000000\n",
      " Loss: 0.028701\n",
      " Loss: 0.000000\n",
      " Loss: 0.062495\n",
      " Loss: 0.000000\n",
      " Loss: 0.033961\n",
      " Loss: 0.000000\n",
      " Loss: 0.012373\n",
      " Loss: 0.000000\n",
      " Loss: 0.069648\n",
      " Loss: 0.000000\n",
      " Loss: 0.032000\n",
      " Loss: 0.000000\n",
      " Loss: 0.030190\n",
      " Loss: 0.000000\n",
      " Loss: 0.016626\n",
      "Epoch 2050 Chain 0 loss std 8.00e-04 variance 3.20e-07 smooth variance 5.22e-07 adaptive c -1.00\n",
      "Epoch 2050 Chain 1 loss std 2.25e+02 variance 2.53e+04 smooth variance 2.17e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026896\n",
      " Loss: 0.000000\n",
      " Loss: 0.082968\n",
      " Loss: 0.000000\n",
      " Loss: 0.021328\n",
      " Loss: 0.000000\n",
      " Loss: 0.018357\n",
      " Loss: 0.000000\n",
      " Loss: 0.011288\n",
      " Loss: 0.000000\n",
      " Loss: 0.023438\n",
      " Loss: 0.000000\n",
      " Loss: 0.018384\n",
      " Loss: 0.000000\n",
      " Loss: 0.020587\n",
      " Loss: 0.000000\n",
      " Loss: 0.035615\n",
      " Loss: 0.000000\n",
      " Loss: 0.062813\n",
      "Epoch 2052 Chain 0 loss std 9.60e-04 variance 4.61e-07 smooth variance 5.04e-07 adaptive c -1.00\n",
      "Epoch 2052 Chain 1 loss std 2.10e+02 variance 2.20e+04 smooth variance 2.18e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.011130\n",
      " Loss: 0.000000\n",
      " Loss: 0.057095\n",
      " Loss: 0.000000\n",
      " Loss: 0.022304\n",
      " Loss: 0.000000\n",
      " Loss: 0.041362\n",
      " Loss: 0.000000\n",
      " Loss: 0.028947\n",
      " Loss: 0.000000\n",
      " Loss: 0.010711\n",
      " Loss: 0.000000\n",
      " Loss: 0.083143\n",
      " Loss: 0.000000\n",
      " Loss: 0.024551\n",
      " Loss: 0.000000\n",
      " Loss: 0.019667\n",
      " Loss: 0.000000\n",
      " Loss: 0.022765\n",
      "Epoch 2054 Chain 0 loss std 9.82e-04 variance 4.82e-07 smooth variance 4.97e-07 adaptive c -1.00\n",
      "Epoch 2054 Chain 1 loss std 1.95e+02 variance 1.91e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020181\n",
      " Loss: 0.000000\n",
      " Loss: 0.084057\n",
      " Loss: 0.000000\n",
      " Loss: 0.021004\n",
      " Loss: 0.000000\n",
      " Loss: 0.022763\n",
      " Loss: 0.000000\n",
      " Loss: 0.012833\n",
      " Loss: 0.000000\n",
      " Loss: 0.028460\n",
      " Loss: 0.000000\n",
      " Loss: 0.022210\n",
      " Loss: 0.000000\n",
      " Loss: 0.024547\n",
      " Loss: 0.000000\n",
      " Loss: 0.065096\n",
      " Loss: 0.000000\n",
      " Loss: 0.020525\n",
      "Epoch 2056 Chain 0 loss std 1.02e-03 variance 5.17e-07 smooth variance 5.03e-07 adaptive c -1.00\n",
      "Epoch 2056 Chain 1 loss std 2.84e+02 variance 4.04e+04 smooth variance 2.68e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016048\n",
      " Loss: 0.000000\n",
      " Loss: 0.027569\n",
      " Loss: 0.000000\n",
      " Loss: 0.067842\n",
      " Loss: 0.000000\n",
      " Loss: 0.026309\n",
      " Loss: 0.000000\n",
      " Loss: 0.023070\n",
      " Loss: 0.000000\n",
      " Loss: 0.024257\n",
      " Loss: 0.000000\n",
      " Loss: 0.017659\n",
      " Loss: 0.000000\n",
      " Loss: 0.014821\n",
      " Loss: 0.000000\n",
      " Loss: 0.038023\n",
      " Loss: 0.000000\n",
      " Loss: 0.066078\n",
      "Epoch 2058 Chain 0 loss std 1.08e-03 variance 5.78e-07 smooth variance 5.26e-07 adaptive c -1.00\n",
      "Epoch 2058 Chain 1 loss std 2.34e+02 variance 2.74e+04 smooth variance 2.70e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061101\n",
      " Loss: 0.000000\n",
      " Loss: 0.013527\n",
      " Loss: 0.000000\n",
      " Loss: 0.032911\n",
      " Loss: 0.000000\n",
      " Loss: 0.016733\n",
      " Loss: 0.000000\n",
      " Loss: 0.036565\n",
      " Loss: 0.000000\n",
      " Loss: 0.022422\n",
      " Loss: 0.000000\n",
      " Loss: 0.039966\n",
      " Loss: 0.000000\n",
      " Loss: 0.015264\n",
      " Loss: 0.000000\n",
      " Loss: 0.065577\n",
      " Loss: 0.000000\n",
      " Loss: 0.017608\n",
      "Epoch 2060 Chain 0 loss std 1.66e-03 variance 1.38e-06 smooth variance 7.82e-07 adaptive c -1.00\n",
      "Epoch 2060 Chain 1 loss std 1.84e+02 variance 1.69e+04 smooth variance 2.40e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.013135\n",
      " Loss: 0.000000\n",
      " Loss: 0.037740\n",
      " Loss: 0.000000\n",
      " Loss: 0.015069\n",
      " Loss: 0.000000\n",
      " Loss: 0.028913\n",
      " Loss: 0.000000\n",
      " Loss: 0.065981\n",
      " Loss: 0.000000\n",
      " Loss: 0.038879\n",
      " Loss: 0.000000\n",
      " Loss: 0.063374\n",
      " Loss: 0.000000\n",
      " Loss: 0.023488\n",
      " Loss: 0.000000\n",
      " Loss: 0.013500\n",
      " Loss: 0.000000\n",
      " Loss: 0.021596\n",
      "Epoch 2062 Chain 0 loss std 6.66e-04 variance 2.22e-07 smooth variance 6.14e-07 adaptive c -1.00\n",
      "Epoch 2062 Chain 1 loss std 2.12e+02 variance 2.26e+04 smooth variance 2.35e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022417\n",
      " Loss: 0.000000\n",
      " Loss: 0.028681\n",
      " Loss: 0.000000\n",
      " Loss: 0.017596\n",
      " Loss: 0.000000\n",
      " Loss: 0.065046\n",
      " Loss: 0.000000\n",
      " Loss: 0.027098\n",
      " Loss: 0.000000\n",
      " Loss: 0.022941\n",
      " Loss: 0.000000\n",
      " Loss: 0.033221\n",
      " Loss: 0.000000\n",
      " Loss: 0.019114\n",
      " Loss: 0.000000\n",
      " Loss: 0.062903\n",
      " Loss: 0.000000\n",
      " Loss: 0.022658\n",
      "Epoch 2064 Chain 0 loss std 1.30e-03 variance 8.47e-07 smooth variance 6.84e-07 adaptive c -1.00\n",
      "Epoch 2064 Chain 1 loss std 1.79e+02 variance 1.60e+04 smooth variance 2.13e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.059401\n",
      " Loss: 0.000000\n",
      " Loss: 0.032419\n",
      " Loss: 0.000000\n",
      " Loss: 0.034414\n",
      " Loss: 0.000000\n",
      " Loss: 0.012309\n",
      " Loss: 0.000000\n",
      " Loss: 0.022294\n",
      " Loss: 0.000000\n",
      " Loss: 0.018789\n",
      " Loss: 0.000000\n",
      " Loss: 0.039123\n",
      " Loss: 0.000000\n",
      " Loss: 0.057918\n",
      " Loss: 0.000000\n",
      " Loss: 0.017933\n",
      " Loss: 0.000000\n",
      " Loss: 0.027075\n",
      "Epoch 2066 Chain 0 loss std 8.28e-04 variance 3.43e-07 smooth variance 5.82e-07 adaptive c -1.00\n",
      "Epoch 2066 Chain 1 loss std 1.94e+02 variance 1.89e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024501\n",
      " Loss: 0.000000\n",
      " Loss: 0.013906\n",
      " Loss: 0.000000\n",
      " Loss: 0.039477\n",
      " Loss: 0.000000\n",
      " Loss: 0.058306\n",
      " Loss: 0.000000\n",
      " Loss: 0.024648\n",
      " Loss: 0.000000\n",
      " Loss: 0.023750\n",
      " Loss: 0.000000\n",
      " Loss: 0.068602\n",
      " Loss: 0.000000\n",
      " Loss: 0.010586\n",
      " Loss: 0.000000\n",
      " Loss: 0.027241\n",
      " Loss: 0.000000\n",
      " Loss: 0.030659\n",
      "Epoch 2068 Chain 0 loss std 1.24e-03 variance 7.63e-07 smooth variance 6.36e-07 adaptive c -1.00\n",
      "Epoch 2068 Chain 1 loss std 2.49e+02 variance 3.11e+04 smooth variance 2.37e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.012132\n",
      " Loss: 0.000000\n",
      " Loss: 0.033206\n",
      " Loss: 0.000000\n",
      " Loss: 0.014177\n",
      " Loss: 0.000000\n",
      " Loss: 0.075651\n",
      " Loss: 0.000000\n",
      " Loss: 0.025672\n",
      " Loss: 0.000000\n",
      " Loss: 0.058330\n",
      " Loss: 0.000000\n",
      " Loss: 0.032375\n",
      " Loss: 0.000000\n",
      " Loss: 0.019338\n",
      " Loss: 0.000000\n",
      " Loss: 0.023536\n",
      " Loss: 0.000000\n",
      " Loss: 0.027258\n",
      "Epoch 2070 Chain 0 loss std 1.03e-03 variance 5.33e-07 smooth variance 6.05e-07 adaptive c -1.00\n",
      "Epoch 2070 Chain 1 loss std 1.87e+02 variance 1.75e+04 smooth variance 2.18e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018346\n",
      " Loss: 0.000000\n",
      " Loss: 0.058332\n",
      " Loss: 0.000000\n",
      " Loss: 0.019227\n",
      " Loss: 0.000000\n",
      " Loss: 0.018865\n",
      " Loss: 0.000000\n",
      " Loss: 0.046068\n",
      " Loss: 0.000000\n",
      " Loss: 0.018790\n",
      " Loss: 0.000000\n",
      " Loss: 0.031130\n",
      " Loss: 0.000000\n",
      " Loss: 0.026793\n",
      " Loss: 0.000000\n",
      " Loss: 0.061440\n",
      " Loss: 0.000000\n",
      " Loss: 0.022684\n",
      "Epoch 2072 Chain 0 loss std 5.19e-04 variance 1.35e-07 smooth variance 4.64e-07 adaptive c -1.00\n",
      "Epoch 2072 Chain 1 loss std 2.07e+02 variance 2.13e+04 smooth variance 2.17e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.012944\n",
      " Loss: 0.000000\n",
      " Loss: 0.039134\n",
      " Loss: 0.000000\n",
      " Loss: 0.017817\n",
      " Loss: 0.000000\n",
      " Loss: 0.024317\n",
      " Loss: 0.000000\n",
      " Loss: 0.066626\n",
      " Loss: 0.000000\n",
      " Loss: 0.021184\n",
      " Loss: 0.000000\n",
      " Loss: 0.022947\n",
      " Loss: 0.000000\n",
      " Loss: 0.039950\n",
      " Loss: 0.000000\n",
      " Loss: 0.065001\n",
      " Loss: 0.000000\n",
      " Loss: 0.011756\n",
      "Epoch 2074 Chain 0 loss std 9.83e-04 variance 4.83e-07 smooth variance 4.70e-07 adaptive c -1.00\n",
      "Epoch 2074 Chain 1 loss std 2.22e+02 variance 2.47e+04 smooth variance 2.26e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017333\n",
      " Loss: 0.000000\n",
      " Loss: 0.027355\n",
      " Loss: 0.000000\n",
      " Loss: 0.063334\n",
      " Loss: 0.000000\n",
      " Loss: 0.034187\n",
      " Loss: 0.000000\n",
      " Loss: 0.018629\n",
      " Loss: 0.000000\n",
      " Loss: 0.073188\n",
      " Loss: 0.000000\n",
      " Loss: 0.010979\n",
      " Loss: 0.000000\n",
      " Loss: 0.025646\n",
      " Loss: 0.000000\n",
      " Loss: 0.036116\n",
      " Loss: 0.000000\n",
      " Loss: 0.014909\n",
      "Epoch 2076 Chain 0 loss std 5.58e-04 variance 1.56e-07 smooth variance 3.75e-07 adaptive c -1.00\n",
      "Epoch 2076 Chain 1 loss std 1.87e+02 variance 1.75e+04 smooth variance 2.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020229\n",
      " Loss: 0.000000\n",
      " Loss: 0.013972\n",
      " Loss: 0.000000\n",
      " Loss: 0.014132\n",
      " Loss: 0.000000\n",
      " Loss: 0.033207\n",
      " Loss: 0.000000\n",
      " Loss: 0.079297\n",
      " Loss: 0.000000\n",
      " Loss: 0.024439\n",
      " Loss: 0.000000\n",
      " Loss: 0.038075\n",
      " Loss: 0.000000\n",
      " Loss: 0.024149\n",
      " Loss: 0.000000\n",
      " Loss: 0.061103\n",
      " Loss: 0.000000\n",
      " Loss: 0.013072\n",
      "Epoch 2078 Chain 0 loss std 8.48e-04 variance 3.60e-07 smooth variance 3.71e-07 adaptive c -1.00\n",
      "Epoch 2078 Chain 1 loss std 1.91e+02 variance 1.82e+04 smooth variance 2.02e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033705\n",
      " Loss: 0.000000\n",
      " Loss: 0.016303\n",
      " Loss: 0.000000\n",
      " Loss: 0.058620\n",
      " Loss: 0.000000\n",
      " Loss: 0.018869\n",
      " Loss: 0.000000\n",
      " Loss: 0.033340\n",
      " Loss: 0.000000\n",
      " Loss: 0.072019\n",
      " Loss: 0.000000\n",
      " Loss: 0.019492\n",
      " Loss: 0.000000\n",
      " Loss: 0.032082\n",
      " Loss: 0.000000\n",
      " Loss: 0.016329\n",
      " Loss: 0.000000\n",
      " Loss: 0.020917\n",
      "Epoch 2080 Chain 0 loss std 1.15e-03 variance 6.59e-07 smooth variance 4.57e-07 adaptive c -1.00\n",
      "Epoch 2080 Chain 1 loss std 1.88e+02 variance 1.76e+04 smooth variance 1.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017597\n",
      " Loss: 0.000000\n",
      " Loss: 0.014426\n",
      " Loss: 0.000000\n",
      " Loss: 0.064097\n",
      " Loss: 0.000000\n",
      " Loss: 0.029327\n",
      " Loss: 0.000000\n",
      " Loss: 0.035392\n",
      " Loss: 0.000000\n",
      " Loss: 0.075087\n",
      " Loss: 0.000000\n",
      " Loss: 0.023356\n",
      " Loss: 0.000000\n",
      " Loss: 0.015031\n",
      " Loss: 0.000000\n",
      " Loss: 0.022848\n",
      " Loss: 0.000000\n",
      " Loss: 0.024516\n",
      "Epoch 2082 Chain 0 loss std 1.19e-03 variance 7.06e-07 smooth variance 5.32e-07 adaptive c -1.00\n",
      "Epoch 2082 Chain 1 loss std 2.43e+02 variance 2.95e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029152\n",
      " Loss: 0.000000\n",
      " Loss: 0.067065\n",
      " Loss: 0.000000\n",
      " Loss: 0.019079\n",
      " Loss: 0.000000\n",
      " Loss: 0.018698\n",
      " Loss: 0.000000\n",
      " Loss: 0.026844\n",
      " Loss: 0.000000\n",
      " Loss: 0.016747\n",
      " Loss: 0.000000\n",
      " Loss: 0.026184\n",
      " Loss: 0.000000\n",
      " Loss: 0.033041\n",
      " Loss: 0.000000\n",
      " Loss: 0.062501\n",
      " Loss: 0.000000\n",
      " Loss: 0.022364\n",
      "Epoch 2084 Chain 0 loss std 1.06e-03 variance 5.60e-07 smooth variance 5.40e-07 adaptive c -1.00\n",
      "Epoch 2084 Chain 1 loss std 2.11e+02 variance 2.22e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020129\n",
      " Loss: 0.000000\n",
      " Loss: 0.034208\n",
      " Loss: 0.000000\n",
      " Loss: 0.052628\n",
      " Loss: 0.000000\n",
      " Loss: 0.024573\n",
      " Loss: 0.000000\n",
      " Loss: 0.029300\n",
      " Loss: 0.000000\n",
      " Loss: 0.056397\n",
      " Loss: 0.000000\n",
      " Loss: 0.016684\n",
      " Loss: 0.000000\n",
      " Loss: 0.033110\n",
      " Loss: 0.000000\n",
      " Loss: 0.022153\n",
      " Loss: 0.000000\n",
      " Loss: 0.032493\n",
      "Epoch 2086 Chain 0 loss std 1.18e-03 variance 7.00e-07 smooth variance 5.88e-07 adaptive c -1.00\n",
      "Epoch 2086 Chain 1 loss std 2.27e+02 variance 2.57e+04 smooth variance 2.34e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.073037\n",
      " Loss: 0.000000\n",
      " Loss: 0.021877\n",
      " Loss: 0.000000\n",
      " Loss: 0.022424\n",
      " Loss: 0.000000\n",
      " Loss: 0.028554\n",
      " Loss: 0.000000\n",
      " Loss: 0.014945\n",
      " Loss: 0.000000\n",
      " Loss: 0.046897\n",
      " Loss: 0.000000\n",
      " Loss: 0.012971\n",
      " Loss: 0.000000\n",
      " Loss: 0.057535\n",
      " Loss: 0.000000\n",
      " Loss: 0.017394\n",
      " Loss: 0.000000\n",
      " Loss: 0.026040\n",
      "Epoch 2088 Chain 0 loss std 6.61e-04 variance 2.19e-07 smooth variance 4.77e-07 adaptive c -1.00\n",
      "Epoch 2088 Chain 1 loss std 1.71e+02 variance 1.45e+04 smooth variance 2.07e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016811\n",
      " Loss: 0.000000\n",
      " Loss: 0.038112\n",
      " Loss: 0.000000\n",
      " Loss: 0.021415\n",
      " Loss: 0.000000\n",
      " Loss: 0.060388\n",
      " Loss: 0.000000\n",
      " Loss: 0.024111\n",
      " Loss: 0.000000\n",
      " Loss: 0.019657\n",
      " Loss: 0.000000\n",
      " Loss: 0.031048\n",
      " Loss: 0.000000\n",
      " Loss: 0.029414\n",
      " Loss: 0.000000\n",
      " Loss: 0.013677\n",
      " Loss: 0.000000\n",
      " Loss: 0.067043\n",
      "Epoch 2090 Chain 0 loss std 8.40e-04 variance 3.52e-07 smooth variance 4.40e-07 adaptive c -1.00\n",
      "Epoch 2090 Chain 1 loss std 1.79e+02 variance 1.60e+04 smooth variance 1.93e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020464\n",
      " Loss: 0.000000\n",
      " Loss: 0.018808\n",
      " Loss: 0.000000\n",
      " Loss: 0.063766\n",
      " Loss: 0.000000\n",
      " Loss: 0.044265\n",
      " Loss: 0.000000\n",
      " Loss: 0.013535\n",
      " Loss: 0.000000\n",
      " Loss: 0.021739\n",
      " Loss: 0.000000\n",
      " Loss: 0.038803\n",
      " Loss: 0.000000\n",
      " Loss: 0.058041\n",
      " Loss: 0.000000\n",
      " Loss: 0.018752\n",
      " Loss: 0.000000\n",
      " Loss: 0.023502\n",
      "Epoch 2092 Chain 0 loss std 8.70e-04 variance 3.78e-07 smooth variance 4.21e-07 adaptive c -1.00\n",
      "Epoch 2092 Chain 1 loss std 2.01e+02 variance 2.03e+04 smooth variance 1.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.079446\n",
      " Loss: 0.000000\n",
      " Loss: 0.012508\n",
      " Loss: 0.000000\n",
      " Loss: 0.033443\n",
      " Loss: 0.000000\n",
      " Loss: 0.012965\n",
      " Loss: 0.000000\n",
      " Loss: 0.022477\n",
      " Loss: 0.000000\n",
      " Loss: 0.042894\n",
      " Loss: 0.000000\n",
      " Loss: 0.060332\n",
      " Loss: 0.000000\n",
      " Loss: 0.024075\n",
      " Loss: 0.000000\n",
      " Loss: 0.009242\n",
      " Loss: 0.000000\n",
      " Loss: 0.024296\n",
      "Epoch 2094 Chain 0 loss std 9.70e-04 variance 4.71e-07 smooth variance 4.36e-07 adaptive c -1.00\n",
      "Epoch 2094 Chain 1 loss std 1.91e+02 variance 1.83e+04 smooth variance 1.92e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.034507\n",
      " Loss: 0.000000\n",
      " Loss: 0.012249\n",
      " Loss: 0.000000\n",
      " Loss: 0.017354\n",
      " Loss: 0.000000\n",
      " Loss: 0.068676\n",
      " Loss: 0.000000\n",
      " Loss: 0.028051\n",
      " Loss: 0.000000\n",
      " Loss: 0.022198\n",
      " Loss: 0.000000\n",
      " Loss: 0.037751\n",
      " Loss: 0.000000\n",
      " Loss: 0.013984\n",
      " Loss: 0.000000\n",
      " Loss: 0.028279\n",
      " Loss: 0.000000\n",
      " Loss: 0.058625\n",
      "Epoch 2096 Chain 0 loss std 9.95e-04 variance 4.95e-07 smooth variance 4.54e-07 adaptive c -1.00\n",
      "Epoch 2096 Chain 1 loss std 2.10e+02 variance 2.20e+04 smooth variance 2.01e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018165\n",
      " Loss: 0.000000\n",
      " Loss: 0.020570\n",
      " Loss: 0.000000\n",
      " Loss: 0.088554\n",
      " Loss: 0.000000\n",
      " Loss: 0.023989\n",
      " Loss: 0.000000\n",
      " Loss: 0.009560\n",
      " Loss: 0.000000\n",
      " Loss: 0.019654\n",
      " Loss: 0.000000\n",
      " Loss: 0.053824\n",
      " Loss: 0.000000\n",
      " Loss: 0.016695\n",
      " Loss: 0.000000\n",
      " Loss: 0.031860\n",
      " Loss: 0.000000\n",
      " Loss: 0.038804\n",
      "Epoch 2098 Chain 0 loss std 9.87e-04 variance 4.88e-07 smooth variance 4.64e-07 adaptive c -1.00\n",
      "Epoch 2098 Chain 1 loss std 1.75e+02 variance 1.54e+04 smooth variance 1.86e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.034323\n",
      " Loss: 0.000000\n",
      " Loss: 0.021156\n",
      " Loss: 0.000000\n",
      " Loss: 0.056614\n",
      " Loss: 0.000000\n",
      " Loss: 0.026451\n",
      " Loss: 0.000000\n",
      " Loss: 0.022294\n",
      " Loss: 0.000000\n",
      " Loss: 0.019630\n",
      " Loss: 0.000000\n",
      " Loss: 0.021901\n",
      " Loss: 0.000000\n",
      " Loss: 0.032973\n",
      " Loss: 0.000000\n",
      " Loss: 0.020203\n",
      " Loss: 0.000000\n",
      " Loss: 0.066130\n",
      "Epoch 2100 Chain 0 loss std 7.05e-04 variance 2.49e-07 smooth variance 3.99e-07 adaptive c -1.00\n",
      "Epoch 2100 Chain 1 loss std 2.77e+02 variance 3.84e+04 smooth variance 2.46e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029304\n",
      " Loss: 0.000000\n",
      " Loss: 0.019121\n",
      " Loss: 0.000000\n",
      " Loss: 0.057274\n",
      " Loss: 0.000000\n",
      " Loss: 0.030786\n",
      " Loss: 0.000000\n",
      " Loss: 0.024352\n",
      " Loss: 0.000000\n",
      " Loss: 0.016428\n",
      " Loss: 0.000000\n",
      " Loss: 0.018706\n",
      " Loss: 0.000000\n",
      " Loss: 0.022891\n",
      " Loss: 0.000000\n",
      " Loss: 0.059237\n",
      " Loss: 0.000000\n",
      " Loss: 0.043576\n",
      "Epoch 2102 Chain 0 loss std 8.20e-04 variance 3.36e-07 smooth variance 3.80e-07 adaptive c -1.00\n",
      "Epoch 2102 Chain 1 loss std 2.40e+02 variance 2.89e+04 smooth variance 2.59e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023850\n",
      " Loss: 0.000000\n",
      " Loss: 0.063401\n",
      " Loss: 0.000000\n",
      " Loss: 0.013383\n",
      " Loss: 0.000000\n",
      " Loss: 0.045253\n",
      " Loss: 0.000000\n",
      " Loss: 0.014951\n",
      " Loss: 0.000000\n",
      " Loss: 0.021581\n",
      " Loss: 0.000000\n",
      " Loss: 0.010429\n",
      " Loss: 0.000000\n",
      " Loss: 0.076242\n",
      " Loss: 0.000000\n",
      " Loss: 0.025071\n",
      " Loss: 0.000000\n",
      " Loss: 0.027514\n",
      "Epoch 2104 Chain 0 loss std 3.50e-04 variance 6.13e-08 smooth variance 2.85e-07 adaptive c -1.00\n",
      "Epoch 2104 Chain 1 loss std 2.29e+02 variance 2.62e+04 smooth variance 2.60e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015675\n",
      " Loss: 0.000000\n",
      " Loss: 0.035342\n",
      " Loss: 0.000000\n",
      " Loss: 0.022558\n",
      " Loss: 0.000000\n",
      " Loss: 0.062143\n",
      " Loss: 0.000000\n",
      " Loss: 0.025120\n",
      " Loss: 0.000000\n",
      " Loss: 0.041991\n",
      " Loss: 0.000000\n",
      " Loss: 0.022697\n",
      " Loss: 0.000000\n",
      " Loss: 0.018404\n",
      " Loss: 0.000000\n",
      " Loss: 0.063094\n",
      " Loss: 0.000000\n",
      " Loss: 0.014651\n",
      "Epoch 2106 Chain 0 loss std 1.50e-03 variance 1.13e-06 smooth variance 5.38e-07 adaptive c -1.00\n",
      "Epoch 2106 Chain 1 loss std 1.76e+02 variance 1.56e+04 smooth variance 2.29e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037433\n",
      " Loss: 0.000000\n",
      " Loss: 0.021795\n",
      " Loss: 0.000000\n",
      " Loss: 0.027245\n",
      " Loss: 0.000000\n",
      " Loss: 0.056123\n",
      " Loss: 0.000000\n",
      " Loss: 0.018242\n",
      " Loss: 0.000000\n",
      " Loss: 0.019983\n",
      " Loss: 0.000000\n",
      " Loss: 0.059230\n",
      " Loss: 0.000000\n",
      " Loss: 0.016036\n",
      " Loss: 0.000000\n",
      " Loss: 0.024498\n",
      " Loss: 0.000000\n",
      " Loss: 0.041090\n",
      "Epoch 2108 Chain 0 loss std 1.38e-03 variance 9.46e-07 smooth variance 6.60e-07 adaptive c -1.00\n",
      "Epoch 2108 Chain 1 loss std 1.83e+02 variance 1.67e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.045351\n",
      " Loss: 0.000000\n",
      " Loss: 0.017393\n",
      " Loss: 0.000000\n",
      " Loss: 0.016205\n",
      " Loss: 0.000000\n",
      " Loss: 0.017568\n",
      " Loss: 0.000000\n",
      " Loss: 0.064321\n",
      " Loss: 0.000000\n",
      " Loss: 0.032962\n",
      " Loss: 0.000000\n",
      " Loss: 0.061761\n",
      " Loss: 0.000000\n",
      " Loss: 0.021301\n",
      " Loss: 0.000000\n",
      " Loss: 0.027958\n",
      " Loss: 0.000000\n",
      " Loss: 0.016855\n",
      "Epoch 2110 Chain 0 loss std 1.39e-03 variance 9.68e-07 smooth variance 7.53e-07 adaptive c -1.00\n",
      "Epoch 2110 Chain 1 loss std 1.63e+02 variance 1.33e+04 smooth variance 1.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025903\n",
      " Loss: 0.000000\n",
      " Loss: 0.069594\n",
      " Loss: 0.000000\n",
      " Loss: 0.017414\n",
      " Loss: 0.000000\n",
      " Loss: 0.013253\n",
      " Loss: 0.000000\n",
      " Loss: 0.034674\n",
      " Loss: 0.000000\n",
      " Loss: 0.035185\n",
      " Loss: 0.000000\n",
      " Loss: 0.019880\n",
      " Loss: 0.000000\n",
      " Loss: 0.013647\n",
      " Loss: 0.000000\n",
      " Loss: 0.079109\n",
      " Loss: 0.000000\n",
      " Loss: 0.013017\n",
      "Epoch 2112 Chain 0 loss std 7.90e-04 variance 3.12e-07 smooth variance 6.21e-07 adaptive c -1.00\n",
      "Epoch 2112 Chain 1 loss std 2.22e+02 variance 2.46e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016758\n",
      " Loss: 0.000000\n",
      " Loss: 0.081773\n",
      " Loss: 0.000000\n",
      " Loss: 0.011544\n",
      " Loss: 0.000000\n",
      " Loss: 0.024898\n",
      " Loss: 0.000000\n",
      " Loss: 0.025866\n",
      " Loss: 0.000000\n",
      " Loss: 0.017564\n",
      " Loss: 0.000000\n",
      " Loss: 0.035947\n",
      " Loss: 0.000000\n",
      " Loss: 0.024146\n",
      " Loss: 0.000000\n",
      " Loss: 0.022786\n",
      " Loss: 0.000000\n",
      " Loss: 0.060395\n",
      "Epoch 2114 Chain 0 loss std 8.70e-04 variance 3.78e-07 smooth variance 5.48e-07 adaptive c -1.00\n",
      "Epoch 2114 Chain 1 loss std 2.11e+02 variance 2.22e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024803\n",
      " Loss: 0.000000\n",
      " Loss: 0.040714\n",
      " Loss: 0.000000\n",
      " Loss: 0.017454\n",
      " Loss: 0.000000\n",
      " Loss: 0.057891\n",
      " Loss: 0.000000\n",
      " Loss: 0.019976\n",
      " Loss: 0.000000\n",
      " Loss: 0.031395\n",
      " Loss: 0.000000\n",
      " Loss: 0.031636\n",
      " Loss: 0.000000\n",
      " Loss: 0.020340\n",
      " Loss: 0.000000\n",
      " Loss: 0.017313\n",
      " Loss: 0.000000\n",
      " Loss: 0.060154\n",
      "Epoch 2116 Chain 0 loss std 1.07e-03 variance 5.77e-07 smooth variance 5.57e-07 adaptive c -1.00\n",
      "Epoch 2116 Chain 1 loss std 3.02e+02 variance 4.58e+04 smooth variance 2.84e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019741\n",
      " Loss: 0.000000\n",
      " Loss: 0.022790\n",
      " Loss: 0.000000\n",
      " Loss: 0.018584\n",
      " Loss: 0.000000\n",
      " Loss: 0.065096\n",
      " Loss: 0.000000\n",
      " Loss: 0.034626\n",
      " Loss: 0.000000\n",
      " Loss: 0.067091\n",
      " Loss: 0.000000\n",
      " Loss: 0.025051\n",
      " Loss: 0.000000\n",
      " Loss: 0.034994\n",
      " Loss: 0.000000\n",
      " Loss: 0.017822\n",
      " Loss: 0.000000\n",
      " Loss: 0.015879\n",
      "Epoch 2118 Chain 0 loss std 1.19e-03 variance 7.13e-07 smooth variance 6.04e-07 adaptive c -1.00\n",
      "Epoch 2118 Chain 1 loss std 2.04e+02 variance 2.07e+04 smooth variance 2.61e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.071133\n",
      " Loss: 0.000000\n",
      " Loss: 0.022801\n",
      " Loss: 0.000000\n",
      " Loss: 0.014160\n",
      " Loss: 0.000000\n",
      " Loss: 0.022560\n",
      " Loss: 0.000000\n",
      " Loss: 0.030184\n",
      " Loss: 0.000000\n",
      " Loss: 0.056956\n",
      " Loss: 0.000000\n",
      " Loss: 0.015998\n",
      " Loss: 0.000000\n",
      " Loss: 0.022268\n",
      " Loss: 0.000000\n",
      " Loss: 0.033833\n",
      " Loss: 0.000000\n",
      " Loss: 0.031782\n",
      "Epoch 2120 Chain 0 loss std 1.04e-03 variance 5.39e-07 smooth variance 5.84e-07 adaptive c -1.00\n",
      "Epoch 2120 Chain 1 loss std 1.78e+02 variance 1.59e+04 smooth variance 2.30e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022836\n",
      " Loss: 0.000000\n",
      " Loss: 0.017231\n",
      " Loss: 0.000000\n",
      " Loss: 0.014725\n",
      " Loss: 0.000000\n",
      " Loss: 0.031996\n",
      " Loss: 0.000000\n",
      " Loss: 0.074050\n",
      " Loss: 0.000000\n",
      " Loss: 0.039393\n",
      " Loss: 0.000000\n",
      " Loss: 0.023369\n",
      " Loss: 0.000000\n",
      " Loss: 0.056729\n",
      " Loss: 0.000000\n",
      " Loss: 0.019546\n",
      " Loss: 0.000000\n",
      " Loss: 0.021800\n",
      "Epoch 2122 Chain 0 loss std 1.26e-03 variance 7.90e-07 smooth variance 6.46e-07 adaptive c -1.00\n",
      "Epoch 2122 Chain 1 loss std 2.97e+02 variance 4.42e+04 smooth variance 2.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028419\n",
      " Loss: 0.000000\n",
      " Loss: 0.062606\n",
      " Loss: 0.000000\n",
      " Loss: 0.018347\n",
      " Loss: 0.000000\n",
      " Loss: 0.022128\n",
      " Loss: 0.000000\n",
      " Loss: 0.029337\n",
      " Loss: 0.000000\n",
      " Loss: 0.060285\n",
      " Loss: 0.000000\n",
      " Loss: 0.026105\n",
      " Loss: 0.000000\n",
      " Loss: 0.024286\n",
      " Loss: 0.000000\n",
      " Loss: 0.036485\n",
      " Loss: 0.000000\n",
      " Loss: 0.013677\n",
      "Epoch 2124 Chain 0 loss std 1.05e-03 variance 5.50e-07 smooth variance 6.17e-07 adaptive c -1.00\n",
      "Epoch 2124 Chain 1 loss std 1.83e+02 variance 1.67e+04 smooth variance 2.56e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.042448\n",
      " Loss: 0.000000\n",
      " Loss: 0.019876\n",
      " Loss: 0.000000\n",
      " Loss: 0.062383\n",
      " Loss: 0.000000\n",
      " Loss: 0.021504\n",
      " Loss: 0.000000\n",
      " Loss: 0.014627\n",
      " Loss: 0.000000\n",
      " Loss: 0.017459\n",
      " Loss: 0.000000\n",
      " Loss: 0.019981\n",
      " Loss: 0.000000\n",
      " Loss: 0.038787\n",
      " Loss: 0.000000\n",
      " Loss: 0.022054\n",
      " Loss: 0.000000\n",
      " Loss: 0.062557\n",
      "Epoch 2126 Chain 0 loss std 8.56e-04 variance 3.66e-07 smooth variance 5.42e-07 adaptive c -1.00\n",
      "Epoch 2126 Chain 1 loss std 2.08e+02 variance 2.16e+04 smooth variance 2.44e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.055109\n",
      " Loss: 0.000000\n",
      " Loss: 0.011598\n",
      " Loss: 0.000000\n",
      " Loss: 0.048131\n",
      " Loss: 0.000000\n",
      " Loss: 0.026448\n",
      " Loss: 0.000000\n",
      " Loss: 0.019552\n",
      " Loss: 0.000000\n",
      " Loss: 0.023935\n",
      " Loss: 0.000000\n",
      " Loss: 0.060181\n",
      " Loss: 0.000000\n",
      " Loss: 0.026817\n",
      " Loss: 0.000000\n",
      " Loss: 0.018624\n",
      " Loss: 0.000000\n",
      " Loss: 0.031280\n",
      "Epoch 2128 Chain 0 loss std 1.13e-03 variance 6.44e-07 smooth variance 5.72e-07 adaptive c -1.00\n",
      "Epoch 2128 Chain 1 loss std 1.95e+02 variance 1.89e+04 smooth variance 2.28e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016412\n",
      " Loss: 0.000000\n",
      " Loss: 0.017404\n",
      " Loss: 0.000000\n",
      " Loss: 0.014483\n",
      " Loss: 0.000000\n",
      " Loss: 0.062979\n",
      " Loss: 0.000000\n",
      " Loss: 0.049560\n",
      " Loss: 0.000000\n",
      " Loss: 0.076915\n",
      " Loss: 0.000000\n",
      " Loss: 0.019366\n",
      " Loss: 0.000000\n",
      " Loss: 0.019743\n",
      " Loss: 0.000000\n",
      " Loss: 0.020141\n",
      " Loss: 0.000000\n",
      " Loss: 0.024673\n",
      "Epoch 2130 Chain 0 loss std 9.23e-04 variance 4.26e-07 smooth variance 5.28e-07 adaptive c -1.00\n",
      "Epoch 2130 Chain 1 loss std 2.25e+02 variance 2.54e+04 smooth variance 2.35e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019502\n",
      " Loss: 0.000000\n",
      " Loss: 0.018929\n",
      " Loss: 0.000000\n",
      " Loss: 0.020217\n",
      " Loss: 0.000000\n",
      " Loss: 0.017971\n",
      " Loss: 0.000000\n",
      " Loss: 0.084218\n",
      " Loss: 0.000000\n",
      " Loss: 0.025851\n",
      " Loss: 0.000000\n",
      " Loss: 0.015874\n",
      " Loss: 0.000000\n",
      " Loss: 0.019264\n",
      " Loss: 0.000000\n",
      " Loss: 0.082399\n",
      " Loss: 0.000000\n",
      " Loss: 0.017449\n",
      "Epoch 2132 Chain 0 loss std 1.28e-03 variance 8.17e-07 smooth variance 6.15e-07 adaptive c -1.00\n",
      "Epoch 2132 Chain 1 loss std 1.71e+02 variance 1.47e+04 smooth variance 2.09e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017959\n",
      " Loss: 0.000000\n",
      " Loss: 0.013843\n",
      " Loss: 0.000000\n",
      " Loss: 0.067394\n",
      " Loss: 0.000000\n",
      " Loss: 0.040011\n",
      " Loss: 0.000000\n",
      " Loss: 0.021630\n",
      " Loss: 0.000000\n",
      " Loss: 0.057152\n",
      " Loss: 0.000000\n",
      " Loss: 0.020576\n",
      " Loss: 0.000000\n",
      " Loss: 0.038425\n",
      " Loss: 0.000000\n",
      " Loss: 0.013649\n",
      " Loss: 0.000000\n",
      " Loss: 0.031035\n",
      "Epoch 2134 Chain 0 loss std 1.25e-03 variance 7.78e-07 smooth variance 6.64e-07 adaptive c -1.00\n",
      "Epoch 2134 Chain 1 loss std 2.15e+02 variance 2.32e+04 smooth variance 2.16e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022004\n",
      " Loss: 0.000000\n",
      " Loss: 0.022319\n",
      " Loss: 0.000000\n",
      " Loss: 0.018212\n",
      " Loss: 0.000000\n",
      " Loss: 0.036700\n",
      " Loss: 0.000000\n",
      " Loss: 0.061602\n",
      " Loss: 0.000000\n",
      " Loss: 0.062739\n",
      " Loss: 0.000000\n",
      " Loss: 0.017027\n",
      " Loss: 0.000000\n",
      " Loss: 0.018267\n",
      " Loss: 0.000000\n",
      " Loss: 0.027223\n",
      " Loss: 0.000000\n",
      " Loss: 0.035582\n",
      "Epoch 2136 Chain 0 loss std 9.50e-04 variance 4.51e-07 smooth variance 6.00e-07 adaptive c -1.00\n",
      "Epoch 2136 Chain 1 loss std 1.39e+02 variance 9.62e+03 smooth variance 1.80e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016951\n",
      " Loss: 0.000000\n",
      " Loss: 0.091491\n",
      " Loss: 0.000000\n",
      " Loss: 0.014753\n",
      " Loss: 0.000000\n",
      " Loss: 0.022887\n",
      " Loss: 0.000000\n",
      " Loss: 0.014756\n",
      " Loss: 0.000000\n",
      " Loss: 0.058865\n",
      " Loss: 0.000000\n",
      " Loss: 0.027844\n",
      " Loss: 0.000000\n",
      " Loss: 0.039996\n",
      " Loss: 0.000000\n",
      " Loss: 0.012208\n",
      " Loss: 0.000000\n",
      " Loss: 0.021925\n",
      "Epoch 2138 Chain 0 loss std 6.44e-04 variance 2.07e-07 smooth variance 4.82e-07 adaptive c -1.00\n",
      "Epoch 2138 Chain 1 loss std 1.43e+02 variance 1.02e+04 smooth variance 1.56e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025296\n",
      " Loss: 0.000000\n",
      " Loss: 0.022408\n",
      " Loss: 0.000000\n",
      " Loss: 0.031927\n",
      " Loss: 0.000000\n",
      " Loss: 0.070698\n",
      " Loss: 0.000000\n",
      " Loss: 0.010508\n",
      " Loss: 0.000000\n",
      " Loss: 0.026547\n",
      " Loss: 0.000000\n",
      " Loss: 0.024930\n",
      " Loss: 0.000000\n",
      " Loss: 0.015811\n",
      " Loss: 0.000000\n",
      " Loss: 0.016718\n",
      " Loss: 0.000000\n",
      " Loss: 0.076831\n",
      "Epoch 2140 Chain 0 loss std 9.55e-04 variance 4.56e-07 smooth variance 4.74e-07 adaptive c -1.00\n",
      "Epoch 2140 Chain 1 loss std 2.01e+02 variance 2.02e+04 smooth variance 1.70e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029795\n",
      " Loss: 0.000000\n",
      " Loss: 0.017065\n",
      " Loss: 0.000000\n",
      " Loss: 0.060053\n",
      " Loss: 0.000000\n",
      " Loss: 0.015026\n",
      " Loss: 0.000000\n",
      " Loss: 0.038898\n",
      " Loss: 0.000000\n",
      " Loss: 0.012407\n",
      " Loss: 0.000000\n",
      " Loss: 0.063013\n",
      " Loss: 0.000000\n",
      " Loss: 0.024953\n",
      " Loss: 0.000000\n",
      " Loss: 0.041839\n",
      " Loss: 0.000000\n",
      " Loss: 0.018627\n",
      "Epoch 2142 Chain 0 loss std 1.28e-03 variance 8.18e-07 smooth variance 5.78e-07 adaptive c -1.00\n",
      "Epoch 2142 Chain 1 loss std 2.47e+02 variance 3.05e+04 smooth variance 2.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036707\n",
      " Loss: 0.000000\n",
      " Loss: 0.021076\n",
      " Loss: 0.000000\n",
      " Loss: 0.065777\n",
      " Loss: 0.000000\n",
      " Loss: 0.016517\n",
      " Loss: 0.000000\n",
      " Loss: 0.020762\n",
      " Loss: 0.000000\n",
      " Loss: 0.040901\n",
      " Loss: 0.000000\n",
      " Loss: 0.012562\n",
      " Loss: 0.000000\n",
      " Loss: 0.024654\n",
      " Loss: 0.000000\n",
      " Loss: 0.018922\n",
      " Loss: 0.000000\n",
      " Loss: 0.063799\n",
      "Epoch 2144 Chain 0 loss std 4.02e-04 variance 8.08e-08 smooth variance 4.29e-07 adaptive c -1.00\n",
      "Epoch 2144 Chain 1 loss std 2.48e+02 variance 3.08e+04 smooth variance 2.40e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.069774\n",
      " Loss: 0.000000\n",
      " Loss: 0.038919\n",
      " Loss: 0.000000\n",
      " Loss: 0.017352\n",
      " Loss: 0.000000\n",
      " Loss: 0.015016\n",
      " Loss: 0.000000\n",
      " Loss: 0.019777\n",
      " Loss: 0.000000\n",
      " Loss: 0.019414\n",
      " Loss: 0.000000\n",
      " Loss: 0.020088\n",
      " Loss: 0.000000\n",
      " Loss: 0.072282\n",
      " Loss: 0.000000\n",
      " Loss: 0.026687\n",
      " Loss: 0.000000\n",
      " Loss: 0.022367\n",
      "Epoch 2146 Chain 0 loss std 1.05e-03 variance 5.47e-07 smooth variance 4.64e-07 adaptive c -1.00\n",
      "Epoch 2146 Chain 1 loss std 1.73e+02 variance 1.50e+04 smooth variance 2.13e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.042812\n",
      " Loss: 0.000000\n",
      " Loss: 0.019939\n",
      " Loss: 0.000000\n",
      " Loss: 0.029580\n",
      " Loss: 0.000000\n",
      " Loss: 0.012036\n",
      " Loss: 0.000000\n",
      " Loss: 0.056470\n",
      " Loss: 0.000000\n",
      " Loss: 0.066920\n",
      " Loss: 0.000000\n",
      " Loss: 0.034508\n",
      " Loss: 0.000000\n",
      " Loss: 0.016812\n",
      " Loss: 0.000000\n",
      " Loss: 0.014734\n",
      " Loss: 0.000000\n",
      " Loss: 0.027863\n",
      "Epoch 2148 Chain 0 loss std 7.07e-04 variance 2.50e-07 smooth variance 4.00e-07 adaptive c -1.00\n",
      "Epoch 2148 Chain 1 loss std 1.53e+02 variance 1.17e+04 smooth variance 1.84e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061050\n",
      " Loss: 0.000000\n",
      " Loss: 0.022843\n",
      " Loss: 0.000000\n",
      " Loss: 0.022747\n",
      " Loss: 0.000000\n",
      " Loss: 0.027214\n",
      " Loss: 0.000000\n",
      " Loss: 0.026984\n",
      " Loss: 0.000000\n",
      " Loss: 0.016933\n",
      " Loss: 0.000000\n",
      " Loss: 0.017958\n",
      " Loss: 0.000000\n",
      " Loss: 0.031163\n",
      " Loss: 0.000000\n",
      " Loss: 0.080708\n",
      " Loss: 0.000000\n",
      " Loss: 0.014076\n",
      "Epoch 2150 Chain 0 loss std 1.13e-03 variance 6.44e-07 smooth variance 4.73e-07 adaptive c -1.00\n",
      "Epoch 2150 Chain 1 loss std 2.47e+02 variance 3.05e+04 smooth variance 2.20e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017757\n",
      " Loss: 0.000000\n",
      " Loss: 0.078351\n",
      " Loss: 0.000000\n",
      " Loss: 0.015008\n",
      " Loss: 0.000000\n",
      " Loss: 0.025832\n",
      " Loss: 0.000000\n",
      " Loss: 0.023889\n",
      " Loss: 0.000000\n",
      " Loss: 0.012673\n",
      " Loss: 0.000000\n",
      " Loss: 0.018959\n",
      " Loss: 0.000000\n",
      " Loss: 0.016197\n",
      " Loss: 0.000000\n",
      " Loss: 0.079004\n",
      " Loss: 0.000000\n",
      " Loss: 0.034005\n",
      "Epoch 2152 Chain 0 loss std 5.14e-04 variance 1.32e-07 smooth variance 3.71e-07 adaptive c -1.00\n",
      "Epoch 2152 Chain 1 loss std 2.03e+02 variance 2.06e+04 smooth variance 2.16e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.059467\n",
      " Loss: 0.000000\n",
      " Loss: 0.018542\n",
      " Loss: 0.000000\n",
      " Loss: 0.012356\n",
      " Loss: 0.000000\n",
      " Loss: 0.039500\n",
      " Loss: 0.000000\n",
      " Loss: 0.030972\n",
      " Loss: 0.000000\n",
      " Loss: 0.019433\n",
      " Loss: 0.000000\n",
      " Loss: 0.010544\n",
      " Loss: 0.000000\n",
      " Loss: 0.032188\n",
      " Loss: 0.000000\n",
      " Loss: 0.054298\n",
      " Loss: 0.000000\n",
      " Loss: 0.044375\n",
      "Epoch 2154 Chain 0 loss std 6.36e-04 variance 2.03e-07 smooth variance 3.20e-07 adaptive c -1.00\n",
      "Epoch 2154 Chain 1 loss std 1.90e+02 variance 1.80e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015043\n",
      " Loss: 0.000000\n",
      " Loss: 0.031391\n",
      " Loss: 0.000000\n",
      " Loss: 0.021021\n",
      " Loss: 0.000000\n",
      " Loss: 0.060620\n",
      " Loss: 0.000000\n",
      " Loss: 0.032762\n",
      " Loss: 0.000000\n",
      " Loss: 0.061432\n",
      " Loss: 0.000000\n",
      " Loss: 0.025354\n",
      " Loss: 0.000000\n",
      " Loss: 0.033354\n",
      " Loss: 0.000000\n",
      " Loss: 0.021259\n",
      " Loss: 0.000000\n",
      " Loss: 0.019439\n",
      "Epoch 2156 Chain 0 loss std 5.55e-04 variance 1.54e-07 smooth variance 2.70e-07 adaptive c -1.00\n",
      "Epoch 2156 Chain 1 loss std 1.63e+02 variance 1.33e+04 smooth variance 1.83e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.038876\n",
      " Loss: 0.000000\n",
      " Loss: 0.074323\n",
      " Loss: 0.000000\n",
      " Loss: 0.022983\n",
      " Loss: 0.000000\n",
      " Loss: 0.010060\n",
      " Loss: 0.000000\n",
      " Loss: 0.014596\n",
      " Loss: 0.000000\n",
      " Loss: 0.061913\n",
      " Loss: 0.000000\n",
      " Loss: 0.012808\n",
      " Loss: 0.000000\n",
      " Loss: 0.013674\n",
      " Loss: 0.000000\n",
      " Loss: 0.030408\n",
      " Loss: 0.000000\n",
      " Loss: 0.042034\n",
      "Epoch 2158 Chain 0 loss std 1.01e-03 variance 5.09e-07 smooth variance 3.42e-07 adaptive c -1.00\n",
      "Epoch 2158 Chain 1 loss std 3.27e+02 variance 5.35e+04 smooth variance 2.89e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.030514\n",
      " Loss: 0.000000\n",
      " Loss: 0.045148\n",
      " Loss: 0.000000\n",
      " Loss: 0.011401\n",
      " Loss: 0.000000\n",
      " Loss: 0.014548\n",
      " Loss: 0.000000\n",
      " Loss: 0.059228\n",
      " Loss: 0.000000\n",
      " Loss: 0.024970\n",
      " Loss: 0.000000\n",
      " Loss: 0.058060\n",
      " Loss: 0.000000\n",
      " Loss: 0.021040\n",
      " Loss: 0.000000\n",
      " Loss: 0.023330\n",
      " Loss: 0.000000\n",
      " Loss: 0.033437\n",
      "Epoch 2160 Chain 0 loss std 6.34e-04 variance 2.01e-07 smooth variance 3.00e-07 adaptive c -1.00\n",
      "Epoch 2160 Chain 1 loss std 1.84e+02 variance 1.69e+04 smooth variance 2.53e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.057998\n",
      " Loss: 0.000000\n",
      " Loss: 0.023430\n",
      " Loss: 0.000000\n",
      " Loss: 0.046789\n",
      " Loss: 0.000000\n",
      " Loss: 0.013155\n",
      " Loss: 0.000000\n",
      " Loss: 0.019466\n",
      " Loss: 0.000000\n",
      " Loss: 0.044751\n",
      " Loss: 0.000000\n",
      " Loss: 0.065727\n",
      " Loss: 0.000000\n",
      " Loss: 0.019280\n",
      " Loss: 0.000000\n",
      " Loss: 0.015659\n",
      " Loss: 0.000000\n",
      " Loss: 0.015422\n",
      "Epoch 2162 Chain 0 loss std 1.18e-03 variance 7.00e-07 smooth variance 4.20e-07 adaptive c -1.00\n",
      "Epoch 2162 Chain 1 loss std 1.89e+02 variance 1.79e+04 smooth variance 2.31e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022028\n",
      " Loss: 0.000000\n",
      " Loss: 0.059669\n",
      " Loss: 0.000000\n",
      " Loss: 0.017662\n",
      " Loss: 0.000000\n",
      " Loss: 0.031181\n",
      " Loss: 0.000000\n",
      " Loss: 0.030298\n",
      " Loss: 0.000000\n",
      " Loss: 0.023652\n",
      " Loss: 0.000000\n",
      " Loss: 0.018350\n",
      " Loss: 0.000000\n",
      " Loss: 0.040334\n",
      " Loss: 0.000000\n",
      " Loss: 0.019661\n",
      " Loss: 0.000000\n",
      " Loss: 0.058841\n",
      "Epoch 2164 Chain 0 loss std 9.02e-04 variance 4.07e-07 smooth variance 4.16e-07 adaptive c -1.00\n",
      "Epoch 2164 Chain 1 loss std 2.20e+02 variance 2.41e+04 smooth variance 2.34e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024939\n",
      " Loss: 0.000000\n",
      " Loss: 0.010673\n",
      " Loss: 0.000000\n",
      " Loss: 0.025886\n",
      " Loss: 0.000000\n",
      " Loss: 0.064859\n",
      " Loss: 0.000000\n",
      " Loss: 0.034480\n",
      " Loss: 0.000000\n",
      " Loss: 0.028542\n",
      " Loss: 0.000000\n",
      " Loss: 0.016608\n",
      " Loss: 0.000000\n",
      " Loss: 0.063367\n",
      " Loss: 0.000000\n",
      " Loss: 0.028149\n",
      " Loss: 0.000000\n",
      " Loss: 0.024171\n",
      "Epoch 2166 Chain 0 loss std 7.61e-04 variance 2.90e-07 smooth variance 3.78e-07 adaptive c -1.00\n",
      "Epoch 2166 Chain 1 loss std 1.76e+02 variance 1.55e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019009\n",
      " Loss: 0.000000\n",
      " Loss: 0.026739\n",
      " Loss: 0.000000\n",
      " Loss: 0.022113\n",
      " Loss: 0.000000\n",
      " Loss: 0.010928\n",
      " Loss: 0.000000\n",
      " Loss: 0.082049\n",
      " Loss: 0.000000\n",
      " Loss: 0.029824\n",
      " Loss: 0.000000\n",
      " Loss: 0.039662\n",
      " Loss: 0.000000\n",
      " Loss: 0.052697\n",
      " Loss: 0.000000\n",
      " Loss: 0.013024\n",
      " Loss: 0.000000\n",
      " Loss: 0.025631\n",
      "Epoch 2168 Chain 0 loss std 1.17e-03 variance 6.89e-07 smooth variance 4.71e-07 adaptive c -1.00\n",
      "Epoch 2168 Chain 1 loss std 2.38e+02 variance 2.83e+04 smooth variance 2.32e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017493\n",
      " Loss: 0.000000\n",
      " Loss: 0.016554\n",
      " Loss: 0.000000\n",
      " Loss: 0.028148\n",
      " Loss: 0.000000\n",
      " Loss: 0.066270\n",
      " Loss: 0.000000\n",
      " Loss: 0.032373\n",
      " Loss: 0.000000\n",
      " Loss: 0.025157\n",
      " Loss: 0.000000\n",
      " Loss: 0.016854\n",
      " Loss: 0.000000\n",
      " Loss: 0.016698\n",
      " Loss: 0.000000\n",
      " Loss: 0.065394\n",
      " Loss: 0.000000\n",
      " Loss: 0.036734\n",
      "Epoch 2170 Chain 0 loss std 8.10e-04 variance 3.28e-07 smooth variance 4.28e-07 adaptive c -1.00\n",
      "Epoch 2170 Chain 1 loss std 2.70e+02 variance 3.66e+04 smooth variance 2.72e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016655\n",
      " Loss: 0.000000\n",
      " Loss: 0.014261\n",
      " Loss: 0.000000\n",
      " Loss: 0.017652\n",
      " Loss: 0.000000\n",
      " Loss: 0.088354\n",
      " Loss: 0.000000\n",
      " Loss: 0.023915\n",
      " Loss: 0.000000\n",
      " Loss: 0.047054\n",
      " Loss: 0.000000\n",
      " Loss: 0.065549\n",
      " Loss: 0.000000\n",
      " Loss: 0.013999\n",
      " Loss: 0.000000\n",
      " Loss: 0.016261\n",
      " Loss: 0.000000\n",
      " Loss: 0.017975\n",
      "Epoch 2172 Chain 0 loss std 1.13e-03 variance 6.43e-07 smooth variance 4.93e-07 adaptive c -1.00\n",
      "Epoch 2172 Chain 1 loss std 1.68e+02 variance 1.41e+04 smooth variance 2.33e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.076056\n",
      " Loss: 0.000000\n",
      " Loss: 0.019644\n",
      " Loss: 0.000000\n",
      " Loss: 0.017901\n",
      " Loss: 0.000000\n",
      " Loss: 0.014334\n",
      " Loss: 0.000000\n",
      " Loss: 0.032901\n",
      " Loss: 0.000000\n",
      " Loss: 0.029461\n",
      " Loss: 0.000000\n",
      " Loss: 0.010209\n",
      " Loss: 0.000000\n",
      " Loss: 0.056706\n",
      " Loss: 0.000000\n",
      " Loss: 0.015828\n",
      " Loss: 0.000000\n",
      " Loss: 0.048633\n",
      "Epoch 2174 Chain 0 loss std 1.19e-03 variance 7.12e-07 smooth variance 5.59e-07 adaptive c -1.00\n",
      "Epoch 2174 Chain 1 loss std 2.08e+02 variance 2.17e+04 smooth variance 2.28e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017494\n",
      " Loss: 0.000000\n",
      " Loss: 0.020983\n",
      " Loss: 0.000000\n",
      " Loss: 0.063104\n",
      " Loss: 0.000000\n",
      " Loss: 0.025843\n",
      " Loss: 0.000000\n",
      " Loss: 0.033414\n",
      " Loss: 0.000000\n",
      " Loss: 0.024442\n",
      " Loss: 0.000000\n",
      " Loss: 0.027493\n",
      " Loss: 0.000000\n",
      " Loss: 0.012574\n",
      " Loss: 0.000000\n",
      " Loss: 0.076909\n",
      " Loss: 0.000000\n",
      " Loss: 0.019420\n",
      "Epoch 2176 Chain 0 loss std 1.24e-03 variance 7.65e-07 smooth variance 6.21e-07 adaptive c -1.00\n",
      "Epoch 2176 Chain 1 loss std 1.42e+02 variance 1.01e+04 smooth variance 1.90e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.031327\n",
      " Loss: 0.000000\n",
      " Loss: 0.019223\n",
      " Loss: 0.000000\n",
      " Loss: 0.019142\n",
      " Loss: 0.000000\n",
      " Loss: 0.034244\n",
      " Loss: 0.000000\n",
      " Loss: 0.056901\n",
      " Loss: 0.000000\n",
      " Loss: 0.017753\n",
      " Loss: 0.000000\n",
      " Loss: 0.028958\n",
      " Loss: 0.000000\n",
      " Loss: 0.036844\n",
      " Loss: 0.000000\n",
      " Loss: 0.018995\n",
      " Loss: 0.000000\n",
      " Loss: 0.058288\n",
      "Epoch 2178 Chain 0 loss std 1.24e-03 variance 7.69e-07 smooth variance 6.65e-07 adaptive c -1.00\n",
      "Epoch 2178 Chain 1 loss std 2.27e+02 variance 2.58e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020747\n",
      " Loss: 0.000000\n",
      " Loss: 0.076446\n",
      " Loss: 0.000000\n",
      " Loss: 0.017361\n",
      " Loss: 0.000000\n",
      " Loss: 0.025485\n",
      " Loss: 0.000000\n",
      " Loss: 0.020800\n",
      " Loss: 0.000000\n",
      " Loss: 0.008965\n",
      " Loss: 0.000000\n",
      " Loss: 0.020352\n",
      " Loss: 0.000000\n",
      " Loss: 0.046131\n",
      " Loss: 0.000000\n",
      " Loss: 0.060391\n",
      " Loss: 0.000000\n",
      " Loss: 0.024999\n",
      "Epoch 2180 Chain 0 loss std 9.62e-04 variance 4.63e-07 smooth variance 6.04e-07 adaptive c -1.00\n",
      "Epoch 2180 Chain 1 loss std 3.03e+02 variance 4.58e+04 smooth variance 2.84e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.087124\n",
      " Loss: 0.000000\n",
      " Loss: 0.009670\n",
      " Loss: 0.000000\n",
      " Loss: 0.018075\n",
      " Loss: 0.000000\n",
      " Loss: 0.023530\n",
      " Loss: 0.000000\n",
      " Loss: 0.022438\n",
      " Loss: 0.000000\n",
      " Loss: 0.023466\n",
      " Loss: 0.000000\n",
      " Loss: 0.021423\n",
      " Loss: 0.000000\n",
      " Loss: 0.038136\n",
      " Loss: 0.000000\n",
      " Loss: 0.014684\n",
      " Loss: 0.000000\n",
      " Loss: 0.063129\n",
      "Epoch 2182 Chain 0 loss std 1.14e-03 variance 6.51e-07 smooth variance 6.18e-07 adaptive c -1.00\n",
      "Epoch 2182 Chain 1 loss std 1.58e+02 variance 1.25e+04 smooth variance 2.37e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029206\n",
      " Loss: 0.000000\n",
      " Loss: 0.019810\n",
      " Loss: 0.000000\n",
      " Loss: 0.020524\n",
      " Loss: 0.000000\n",
      " Loss: 0.060464\n",
      " Loss: 0.000000\n",
      " Loss: 0.030835\n",
      " Loss: 0.000000\n",
      " Loss: 0.065646\n",
      " Loss: 0.000000\n",
      " Loss: 0.019566\n",
      " Loss: 0.000000\n",
      " Loss: 0.033472\n",
      " Loss: 0.000000\n",
      " Loss: 0.021021\n",
      " Loss: 0.000000\n",
      " Loss: 0.021133\n",
      "Epoch 2184 Chain 0 loss std 1.10e-03 variance 6.00e-07 smooth variance 6.13e-07 adaptive c -1.00\n",
      "Epoch 2184 Chain 1 loss std 1.65e+02 variance 1.36e+04 smooth variance 2.06e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.034098\n",
      " Loss: 0.000000\n",
      " Loss: 0.061925\n",
      " Loss: 0.000000\n",
      " Loss: 0.023587\n",
      " Loss: 0.000000\n",
      " Loss: 0.017115\n",
      " Loss: 0.000000\n",
      " Loss: 0.024112\n",
      " Loss: 0.000000\n",
      " Loss: 0.017449\n",
      " Loss: 0.000000\n",
      " Loss: 0.023676\n",
      " Loss: 0.000000\n",
      " Loss: 0.061728\n",
      " Loss: 0.000000\n",
      " Loss: 0.042390\n",
      " Loss: 0.000000\n",
      " Loss: 0.015594\n",
      "Epoch 2186 Chain 0 loss std 8.21e-04 variance 3.37e-07 smooth variance 5.30e-07 adaptive c -1.00\n",
      "Epoch 2186 Chain 1 loss std 2.29e+02 variance 2.62e+04 smooth variance 2.23e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.076699\n",
      " Loss: 0.000000\n",
      " Loss: 0.014588\n",
      " Loss: 0.000000\n",
      " Loss: 0.023195\n",
      " Loss: 0.000000\n",
      " Loss: 0.026931\n",
      " Loss: 0.000000\n",
      " Loss: 0.019426\n",
      " Loss: 0.000000\n",
      " Loss: 0.063353\n",
      " Loss: 0.000000\n",
      " Loss: 0.014409\n",
      " Loss: 0.000000\n",
      " Loss: 0.023830\n",
      " Loss: 0.000000\n",
      " Loss: 0.025505\n",
      " Loss: 0.000000\n",
      " Loss: 0.033740\n",
      "Epoch 2188 Chain 0 loss std 8.25e-04 variance 3.40e-07 smooth variance 4.73e-07 adaptive c -1.00\n",
      "Epoch 2188 Chain 1 loss std 1.98e+02 variance 1.96e+04 smooth variance 2.15e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020563\n",
      " Loss: 0.000000\n",
      " Loss: 0.060547\n",
      " Loss: 0.000000\n",
      " Loss: 0.034528\n",
      " Loss: 0.000000\n",
      " Loss: 0.019193\n",
      " Loss: 0.000000\n",
      " Loss: 0.026007\n",
      " Loss: 0.000000\n",
      " Loss: 0.063769\n",
      " Loss: 0.000000\n",
      " Loss: 0.037975\n",
      " Loss: 0.000000\n",
      " Loss: 0.021399\n",
      " Loss: 0.000000\n",
      " Loss: 0.019952\n",
      " Loss: 0.000000\n",
      " Loss: 0.017742\n",
      "Epoch 2190 Chain 0 loss std 7.10e-04 variance 2.52e-07 smooth variance 4.07e-07 adaptive c -1.00\n",
      "Epoch 2190 Chain 1 loss std 2.24e+02 variance 2.50e+04 smooth variance 2.25e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017213\n",
      " Loss: 0.000000\n",
      " Loss: 0.017837\n",
      " Loss: 0.000000\n",
      " Loss: 0.041836\n",
      " Loss: 0.000000\n",
      " Loss: 0.023470\n",
      " Loss: 0.000000\n",
      " Loss: 0.060481\n",
      " Loss: 0.000000\n",
      " Loss: 0.014826\n",
      " Loss: 0.000000\n",
      " Loss: 0.022524\n",
      " Loss: 0.000000\n",
      " Loss: 0.029133\n",
      " Loss: 0.000000\n",
      " Loss: 0.061307\n",
      " Loss: 0.000000\n",
      " Loss: 0.033049\n",
      "Epoch 2192 Chain 0 loss std 8.87e-04 variance 3.94e-07 smooth variance 4.03e-07 adaptive c -1.00\n",
      "Epoch 2192 Chain 1 loss std 1.72e+02 variance 1.48e+04 smooth variance 2.02e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.062048\n",
      " Loss: 0.000000\n",
      " Loss: 0.012607\n",
      " Loss: 0.000000\n",
      " Loss: 0.016469\n",
      " Loss: 0.000000\n",
      " Loss: 0.030405\n",
      " Loss: 0.000000\n",
      " Loss: 0.039308\n",
      " Loss: 0.000000\n",
      " Loss: 0.019987\n",
      " Loss: 0.000000\n",
      " Loss: 0.023095\n",
      " Loss: 0.000000\n",
      " Loss: 0.021134\n",
      " Loss: 0.000000\n",
      " Loss: 0.055103\n",
      " Loss: 0.000000\n",
      " Loss: 0.041519\n",
      "Epoch 2194 Chain 0 loss std 1.04e-03 variance 5.38e-07 smooth variance 4.44e-07 adaptive c -1.00\n",
      "Epoch 2194 Chain 1 loss std 1.67e+02 variance 1.40e+04 smooth variance 1.84e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.064521\n",
      " Loss: 0.000000\n",
      " Loss: 0.020633\n",
      " Loss: 0.000000\n",
      " Loss: 0.018417\n",
      " Loss: 0.000000\n",
      " Loss: 0.022733\n",
      " Loss: 0.000000\n",
      " Loss: 0.034535\n",
      " Loss: 0.000000\n",
      " Loss: 0.022084\n",
      " Loss: 0.000000\n",
      " Loss: 0.029688\n",
      " Loss: 0.000000\n",
      " Loss: 0.021965\n",
      " Loss: 0.000000\n",
      " Loss: 0.071610\n",
      " Loss: 0.000000\n",
      " Loss: 0.015490\n",
      "Epoch 2196 Chain 0 loss std 8.44e-04 variance 3.56e-07 smooth variance 4.17e-07 adaptive c -1.00\n",
      "Epoch 2196 Chain 1 loss std 2.02e+02 variance 2.03e+04 smooth variance 1.89e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037863\n",
      " Loss: 0.000000\n",
      " Loss: 0.015521\n",
      " Loss: 0.000000\n",
      " Loss: 0.066730\n",
      " Loss: 0.000000\n",
      " Loss: 0.012997\n",
      " Loss: 0.000000\n",
      " Loss: 0.027726\n",
      " Loss: 0.000000\n",
      " Loss: 0.030651\n",
      " Loss: 0.000000\n",
      " Loss: 0.028358\n",
      " Loss: 0.000000\n",
      " Loss: 0.012948\n",
      " Loss: 0.000000\n",
      " Loss: 0.018097\n",
      " Loss: 0.000000\n",
      " Loss: 0.070784\n",
      "Epoch 2198 Chain 0 loss std 1.51e-03 variance 1.13e-06 smooth variance 6.33e-07 adaptive c -1.00\n",
      "Epoch 2198 Chain 1 loss std 2.26e+02 variance 2.56e+04 smooth variance 2.09e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.081084\n",
      " Loss: 0.000000\n",
      " Loss: 0.012623\n",
      " Loss: 0.000000\n",
      " Loss: 0.009353\n",
      " Loss: 0.000000\n",
      " Loss: 0.021109\n",
      " Loss: 0.000000\n",
      " Loss: 0.036668\n",
      " Loss: 0.000000\n",
      " Loss: 0.026370\n",
      " Loss: 0.000000\n",
      " Loss: 0.022831\n",
      " Loss: 0.000000\n",
      " Loss: 0.019186\n",
      " Loss: 0.000000\n",
      " Loss: 0.077376\n",
      " Loss: 0.000000\n",
      " Loss: 0.015075\n",
      "Epoch 2200 Chain 0 loss std 1.10e-03 variance 6.00e-07 smooth variance 6.23e-07 adaptive c -1.00\n",
      "Epoch 2200 Chain 1 loss std 2.19e+02 variance 2.41e+04 smooth variance 2.19e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023966\n",
      " Loss: 0.000000\n",
      " Loss: 0.016010\n",
      " Loss: 0.000000\n",
      " Loss: 0.039543\n",
      " Loss: 0.000000\n",
      " Loss: 0.018978\n",
      " Loss: 0.000000\n",
      " Loss: 0.062340\n",
      " Loss: 0.000000\n",
      " Loss: 0.018686\n",
      " Loss: 0.000000\n",
      " Loss: 0.032721\n",
      " Loss: 0.000000\n",
      " Loss: 0.020763\n",
      " Loss: 0.000000\n",
      " Loss: 0.023408\n",
      " Loss: 0.000000\n",
      " Loss: 0.065259\n",
      "Epoch 2202 Chain 0 loss std 1.53e-03 variance 1.17e-06 smooth variance 7.88e-07 adaptive c -1.00\n",
      "Epoch 2202 Chain 1 loss std 2.34e+02 variance 2.75e+04 smooth variance 2.36e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017570\n",
      " Loss: 0.000000\n",
      " Loss: 0.038290\n",
      " Loss: 0.000000\n",
      " Loss: 0.019979\n",
      " Loss: 0.000000\n",
      " Loss: 0.067908\n",
      " Loss: 0.000000\n",
      " Loss: 0.017092\n",
      " Loss: 0.000000\n",
      " Loss: 0.020154\n",
      " Loss: 0.000000\n",
      " Loss: 0.033795\n",
      " Loss: 0.000000\n",
      " Loss: 0.073683\n",
      " Loss: 0.000000\n",
      " Loss: 0.015272\n",
      " Loss: 0.000000\n",
      " Loss: 0.017934\n",
      "Epoch 2204 Chain 0 loss std 7.22e-04 variance 2.61e-07 smooth variance 6.30e-07 adaptive c -1.00\n",
      "Epoch 2204 Chain 1 loss std 1.94e+02 variance 1.88e+04 smooth variance 2.21e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016128\n",
      " Loss: 0.000000\n",
      " Loss: 0.029077\n",
      " Loss: 0.000000\n",
      " Loss: 0.059919\n",
      " Loss: 0.000000\n",
      " Loss: 0.018747\n",
      " Loss: 0.000000\n",
      " Loss: 0.036966\n",
      " Loss: 0.000000\n",
      " Loss: 0.013683\n",
      " Loss: 0.000000\n",
      " Loss: 0.058589\n",
      " Loss: 0.000000\n",
      " Loss: 0.020896\n",
      " Loss: 0.000000\n",
      " Loss: 0.038645\n",
      " Loss: 0.000000\n",
      " Loss: 0.029024\n",
      "Epoch 2206 Chain 0 loss std 6.16e-04 variance 1.90e-07 smooth variance 4.98e-07 adaptive c -1.00\n",
      "Epoch 2206 Chain 1 loss std 1.41e+02 variance 9.93e+03 smooth variance 1.85e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.062274\n",
      " Loss: 0.000000\n",
      " Loss: 0.042392\n",
      " Loss: 0.000000\n",
      " Loss: 0.019351\n",
      " Loss: 0.000000\n",
      " Loss: 0.026954\n",
      " Loss: 0.000000\n",
      " Loss: 0.009866\n",
      " Loss: 0.000000\n",
      " Loss: 0.024812\n",
      " Loss: 0.000000\n",
      " Loss: 0.039123\n",
      " Loss: 0.000000\n",
      " Loss: 0.015535\n",
      " Loss: 0.000000\n",
      " Loss: 0.016600\n",
      " Loss: 0.000000\n",
      " Loss: 0.064767\n",
      "Epoch 2208 Chain 0 loss std 5.50e-04 variance 1.51e-07 smooth variance 3.94e-07 adaptive c -1.00\n",
      "Epoch 2208 Chain 1 loss std 2.23e+02 variance 2.48e+04 smooth variance 2.04e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016570\n",
      " Loss: 0.000000\n",
      " Loss: 0.029364\n",
      " Loss: 0.000000\n",
      " Loss: 0.033451\n",
      " Loss: 0.000000\n",
      " Loss: 0.064025\n",
      " Loss: 0.000000\n",
      " Loss: 0.017429\n",
      " Loss: 0.000000\n",
      " Loss: 0.016911\n",
      " Loss: 0.000000\n",
      " Loss: 0.030010\n",
      " Loss: 0.000000\n",
      " Loss: 0.019244\n",
      " Loss: 0.000000\n",
      " Loss: 0.080921\n",
      " Loss: 0.000000\n",
      " Loss: 0.013752\n",
      "Epoch 2210 Chain 0 loss std 8.15e-04 variance 3.32e-07 smooth variance 3.75e-07 adaptive c -1.00\n",
      "Epoch 2210 Chain 1 loss std 1.73e+02 variance 1.49e+04 smooth variance 1.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.060534\n",
      " Loss: 0.000000\n",
      " Loss: 0.024411\n",
      " Loss: 0.000000\n",
      " Loss: 0.017108\n",
      " Loss: 0.000000\n",
      " Loss: 0.037973\n",
      " Loss: 0.000000\n",
      " Loss: 0.020812\n",
      " Loss: 0.000000\n",
      " Loss: 0.018077\n",
      " Loss: 0.000000\n",
      " Loss: 0.021967\n",
      " Loss: 0.000000\n",
      " Loss: 0.023796\n",
      " Loss: 0.000000\n",
      " Loss: 0.060061\n",
      " Loss: 0.000000\n",
      " Loss: 0.036935\n",
      "Epoch 2212 Chain 0 loss std 5.58e-04 variance 1.56e-07 smooth variance 3.09e-07 adaptive c -1.00\n",
      "Epoch 2212 Chain 1 loss std 1.83e+02 variance 1.68e+04 smooth variance 1.81e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019578\n",
      " Loss: 0.000000\n",
      " Loss: 0.014367\n",
      " Loss: 0.000000\n",
      " Loss: 0.017217\n",
      " Loss: 0.000000\n",
      " Loss: 0.019236\n",
      " Loss: 0.000000\n",
      " Loss: 0.090439\n",
      " Loss: 0.000000\n",
      " Loss: 0.017893\n",
      " Loss: 0.000000\n",
      " Loss: 0.036636\n",
      " Loss: 0.000000\n",
      " Loss: 0.063096\n",
      " Loss: 0.000000\n",
      " Loss: 0.018284\n",
      " Loss: 0.000000\n",
      " Loss: 0.024929\n",
      "Epoch 2214 Chain 0 loss std 1.50e-03 variance 1.13e-06 smooth variance 5.55e-07 adaptive c -1.00\n",
      "Epoch 2214 Chain 1 loss std 1.67e+02 variance 1.40e+04 smooth variance 1.69e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018085\n",
      " Loss: 0.000000\n",
      " Loss: 0.015191\n",
      " Loss: 0.000000\n",
      " Loss: 0.022292\n",
      " Loss: 0.000000\n",
      " Loss: 0.075213\n",
      " Loss: 0.000000\n",
      " Loss: 0.030057\n",
      " Loss: 0.000000\n",
      " Loss: 0.015601\n",
      " Loss: 0.000000\n",
      " Loss: 0.022353\n",
      " Loss: 0.000000\n",
      " Loss: 0.041698\n",
      " Loss: 0.000000\n",
      " Loss: 0.024262\n",
      " Loss: 0.000000\n",
      " Loss: 0.056924\n",
      "Epoch 2216 Chain 0 loss std 1.01e-03 variance 5.09e-07 smooth variance 5.41e-07 adaptive c -1.00\n",
      "Epoch 2216 Chain 1 loss std 1.86e+02 variance 1.73e+04 smooth variance 1.70e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021720\n",
      " Loss: 0.000000\n",
      " Loss: 0.021718\n",
      " Loss: 0.000000\n",
      " Loss: 0.027358\n",
      " Loss: 0.000000\n",
      " Loss: 0.060529\n",
      " Loss: 0.000000\n",
      " Loss: 0.029513\n",
      " Loss: 0.000000\n",
      " Loss: 0.038933\n",
      " Loss: 0.000000\n",
      " Loss: 0.022628\n",
      " Loss: 0.000000\n",
      " Loss: 0.063639\n",
      " Loss: 0.000000\n",
      " Loss: 0.017447\n",
      " Loss: 0.000000\n",
      " Loss: 0.018191\n",
      "Epoch 2218 Chain 0 loss std 9.12e-04 variance 4.16e-07 smooth variance 5.04e-07 adaptive c -1.00\n",
      "Epoch 2218 Chain 1 loss std 1.53e+02 variance 1.18e+04 smooth variance 1.54e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022263\n",
      " Loss: 0.000000\n",
      " Loss: 0.022112\n",
      " Loss: 0.000000\n",
      " Loss: 0.012226\n",
      " Loss: 0.000000\n",
      " Loss: 0.026062\n",
      " Loss: 0.000000\n",
      " Loss: 0.078175\n",
      " Loss: 0.000000\n",
      " Loss: 0.036364\n",
      " Loss: 0.000000\n",
      " Loss: 0.012604\n",
      " Loss: 0.000000\n",
      " Loss: 0.022350\n",
      " Loss: 0.000000\n",
      " Loss: 0.064928\n",
      " Loss: 0.000000\n",
      " Loss: 0.024591\n",
      "Epoch 2220 Chain 0 loss std 6.54e-04 variance 2.14e-07 smooth variance 4.17e-07 adaptive c -1.00\n",
      "Epoch 2220 Chain 1 loss std 2.74e+02 variance 3.75e+04 smooth variance 2.20e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.064133\n",
      " Loss: 0.000000\n",
      " Loss: 0.032013\n",
      " Loss: 0.000000\n",
      " Loss: 0.029956\n",
      " Loss: 0.000000\n",
      " Loss: 0.011689\n",
      " Loss: 0.000000\n",
      " Loss: 0.023046\n",
      " Loss: 0.000000\n",
      " Loss: 0.022378\n",
      " Loss: 0.000000\n",
      " Loss: 0.013535\n",
      " Loss: 0.000000\n",
      " Loss: 0.062390\n",
      " Loss: 0.000000\n",
      " Loss: 0.023297\n",
      " Loss: 0.000000\n",
      " Loss: 0.039237\n",
      "Epoch 2222 Chain 0 loss std 1.01e-03 variance 5.07e-07 smooth variance 4.44e-07 adaptive c -1.00\n",
      "Epoch 2222 Chain 1 loss std 1.79e+02 variance 1.61e+04 smooth variance 2.03e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.058876\n",
      " Loss: 0.000000\n",
      " Loss: 0.033803\n",
      " Loss: 0.000000\n",
      " Loss: 0.035889\n",
      " Loss: 0.000000\n",
      " Loss: 0.015717\n",
      " Loss: 0.000000\n",
      " Loss: 0.016553\n",
      " Loss: 0.000000\n",
      " Loss: 0.031063\n",
      " Loss: 0.000000\n",
      " Loss: 0.021511\n",
      " Loss: 0.000000\n",
      " Loss: 0.057362\n",
      " Loss: 0.000000\n",
      " Loss: 0.015506\n",
      " Loss: 0.000000\n",
      " Loss: 0.035396\n",
      "Epoch 2224 Chain 0 loss std 8.44e-04 variance 3.56e-07 smooth variance 4.18e-07 adaptive c -1.00\n",
      "Epoch 2224 Chain 1 loss std 2.69e+02 variance 3.62e+04 smooth variance 2.50e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.030058\n",
      " Loss: 0.000000\n",
      " Loss: 0.063295\n",
      " Loss: 0.000000\n",
      " Loss: 0.026268\n",
      " Loss: 0.000000\n",
      " Loss: 0.023794\n",
      " Loss: 0.000000\n",
      " Loss: 0.017423\n",
      " Loss: 0.000000\n",
      " Loss: 0.062718\n",
      " Loss: 0.000000\n",
      " Loss: 0.022541\n",
      " Loss: 0.000000\n",
      " Loss: 0.022968\n",
      " Loss: 0.000000\n",
      " Loss: 0.032443\n",
      " Loss: 0.000000\n",
      " Loss: 0.020168\n",
      "Epoch 2226 Chain 0 loss std 1.03e-03 variance 5.33e-07 smooth variance 4.52e-07 adaptive c -1.00\n",
      "Epoch 2226 Chain 1 loss std 1.54e+02 variance 1.19e+04 smooth variance 2.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037365\n",
      " Loss: 0.000000\n",
      " Loss: 0.024777\n",
      " Loss: 0.000000\n",
      " Loss: 0.064735\n",
      " Loss: 0.000000\n",
      " Loss: 0.012118\n",
      " Loss: 0.000000\n",
      " Loss: 0.021841\n",
      " Loss: 0.000000\n",
      " Loss: 0.073736\n",
      " Loss: 0.000000\n",
      " Loss: 0.012865\n",
      " Loss: 0.000000\n",
      " Loss: 0.021502\n",
      " Loss: 0.000000\n",
      " Loss: 0.019977\n",
      " Loss: 0.000000\n",
      " Loss: 0.032758\n",
      "Epoch 2228 Chain 0 loss std 9.87e-04 variance 4.87e-07 smooth variance 4.63e-07 adaptive c -1.00\n",
      "Epoch 2228 Chain 1 loss std 1.99e+02 variance 1.99e+04 smooth variance 2.07e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.059819\n",
      " Loss: 0.000000\n",
      " Loss: 0.021480\n",
      " Loss: 0.000000\n",
      " Loss: 0.038188\n",
      " Loss: 0.000000\n",
      " Loss: 0.022415\n",
      " Loss: 0.000000\n",
      " Loss: 0.018935\n",
      " Loss: 0.000000\n",
      " Loss: 0.064430\n",
      " Loss: 0.000000\n",
      " Loss: 0.036704\n",
      " Loss: 0.000000\n",
      " Loss: 0.023730\n",
      " Loss: 0.000000\n",
      " Loss: 0.019472\n",
      " Loss: 0.000000\n",
      " Loss: 0.016503\n",
      "Epoch 2230 Chain 0 loss std 1.13e-03 variance 6.40e-07 smooth variance 5.16e-07 adaptive c -1.00\n",
      "Epoch 2230 Chain 1 loss std 2.04e+02 variance 2.09e+04 smooth variance 2.08e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021537\n",
      " Loss: 0.000000\n",
      " Loss: 0.018380\n",
      " Loss: 0.000000\n",
      " Loss: 0.084365\n",
      " Loss: 0.000000\n",
      " Loss: 0.018860\n",
      " Loss: 0.000000\n",
      " Loss: 0.017695\n",
      " Loss: 0.000000\n",
      " Loss: 0.070284\n",
      " Loss: 0.000000\n",
      " Loss: 0.033507\n",
      " Loss: 0.000000\n",
      " Loss: 0.019303\n",
      " Loss: 0.000000\n",
      " Loss: 0.020139\n",
      " Loss: 0.000000\n",
      " Loss: 0.017605\n",
      "Epoch 2232 Chain 0 loss std 1.35e-03 variance 9.12e-07 smooth variance 6.35e-07 adaptive c -1.00\n",
      "Epoch 2232 Chain 1 loss std 2.24e+02 variance 2.50e+04 smooth variance 2.20e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028624\n",
      " Loss: 0.000000\n",
      " Loss: 0.058957\n",
      " Loss: 0.000000\n",
      " Loss: 0.023307\n",
      " Loss: 0.000000\n",
      " Loss: 0.036207\n",
      " Loss: 0.000000\n",
      " Loss: 0.013743\n",
      " Loss: 0.000000\n",
      " Loss: 0.015753\n",
      " Loss: 0.000000\n",
      " Loss: 0.016160\n",
      " Loss: 0.000000\n",
      " Loss: 0.069317\n",
      " Loss: 0.000000\n",
      " Loss: 0.032045\n",
      " Loss: 0.000000\n",
      " Loss: 0.027563\n",
      "Epoch 2234 Chain 0 loss std 6.14e-04 variance 1.88e-07 smooth variance 5.01e-07 adaptive c -1.00\n",
      "Epoch 2234 Chain 1 loss std 1.38e+02 variance 9.50e+03 smooth variance 1.83e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027281\n",
      " Loss: 0.000000\n",
      " Loss: 0.075868\n",
      " Loss: 0.000000\n",
      " Loss: 0.020413\n",
      " Loss: 0.000000\n",
      " Loss: 0.013036\n",
      " Loss: 0.000000\n",
      " Loss: 0.024239\n",
      " Loss: 0.000000\n",
      " Loss: 0.075727\n",
      " Loss: 0.000000\n",
      " Loss: 0.020705\n",
      " Loss: 0.000000\n",
      " Loss: 0.016943\n",
      " Loss: 0.000000\n",
      " Loss: 0.013456\n",
      " Loss: 0.000000\n",
      " Loss: 0.034007\n",
      "Epoch 2236 Chain 0 loss std 7.26e-04 variance 2.63e-07 smooth variance 4.30e-07 adaptive c -1.00\n",
      "Epoch 2236 Chain 1 loss std 1.98e+02 variance 1.96e+04 smooth variance 1.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025441\n",
      " Loss: 0.000000\n",
      " Loss: 0.076941\n",
      " Loss: 0.000000\n",
      " Loss: 0.014027\n",
      " Loss: 0.000000\n",
      " Loss: 0.015972\n",
      " Loss: 0.000000\n",
      " Loss: 0.028457\n",
      " Loss: 0.000000\n",
      " Loss: 0.014057\n",
      " Loss: 0.000000\n",
      " Loss: 0.015068\n",
      " Loss: 0.000000\n",
      " Loss: 0.065953\n",
      " Loss: 0.000000\n",
      " Loss: 0.042825\n",
      " Loss: 0.000000\n",
      " Loss: 0.022936\n",
      "Epoch 2238 Chain 0 loss std 9.23e-04 variance 4.26e-07 smooth variance 4.29e-07 adaptive c -1.00\n",
      "Epoch 2238 Chain 1 loss std 2.09e+02 variance 2.18e+04 smooth variance 1.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061927\n",
      " Loss: 0.000000\n",
      " Loss: 0.014997\n",
      " Loss: 0.000000\n",
      " Loss: 0.034293\n",
      " Loss: 0.000000\n",
      " Loss: 0.021437\n",
      " Loss: 0.000000\n",
      " Loss: 0.028184\n",
      " Loss: 0.000000\n",
      " Loss: 0.016449\n",
      " Loss: 0.000000\n",
      " Loss: 0.027574\n",
      " Loss: 0.000000\n",
      " Loss: 0.058317\n",
      " Loss: 0.000000\n",
      " Loss: 0.040435\n",
      " Loss: 0.000000\n",
      " Loss: 0.018062\n",
      "Epoch 2240 Chain 0 loss std 9.01e-04 variance 4.06e-07 smooth variance 4.22e-07 adaptive c -1.00\n",
      "Epoch 2240 Chain 1 loss std 1.47e+02 variance 1.07e+04 smooth variance 1.70e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.064641\n",
      " Loss: 0.000000\n",
      " Loss: 0.032879\n",
      " Loss: 0.000000\n",
      " Loss: 0.025099\n",
      " Loss: 0.000000\n",
      " Loss: 0.025208\n",
      " Loss: 0.000000\n",
      " Loss: 0.013010\n",
      " Loss: 0.000000\n",
      " Loss: 0.031450\n",
      " Loss: 0.000000\n",
      " Loss: 0.018198\n",
      " Loss: 0.000000\n",
      " Loss: 0.026624\n",
      " Loss: 0.000000\n",
      " Loss: 0.065967\n",
      " Loss: 0.000000\n",
      " Loss: 0.018597\n",
      "Epoch 2242 Chain 0 loss std 1.10e-03 variance 6.03e-07 smooth variance 4.76e-07 adaptive c -1.00\n",
      "Epoch 2242 Chain 1 loss std 2.39e+02 variance 2.84e+04 smooth variance 2.04e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.010363\n",
      " Loss: 0.000000\n",
      " Loss: 0.041943\n",
      " Loss: 0.000000\n",
      " Loss: 0.061433\n",
      " Loss: 0.000000\n",
      " Loss: 0.028598\n",
      " Loss: 0.000000\n",
      " Loss: 0.018500\n",
      " Loss: 0.000000\n",
      " Loss: 0.062660\n",
      " Loss: 0.000000\n",
      " Loss: 0.015573\n",
      " Loss: 0.000000\n",
      " Loss: 0.031049\n",
      " Loss: 0.000000\n",
      " Loss: 0.015989\n",
      " Loss: 0.000000\n",
      " Loss: 0.035567\n",
      "Epoch 2244 Chain 0 loss std 1.50e-03 variance 1.13e-06 smooth variance 6.73e-07 adaptive c -1.00\n",
      "Epoch 2244 Chain 1 loss std 1.97e+02 variance 1.94e+04 smooth variance 2.01e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016195\n",
      " Loss: 0.000000\n",
      " Loss: 0.028868\n",
      " Loss: 0.000000\n",
      " Loss: 0.017138\n",
      " Loss: 0.000000\n",
      " Loss: 0.017746\n",
      " Loss: 0.000000\n",
      " Loss: 0.080891\n",
      " Loss: 0.000000\n",
      " Loss: 0.038578\n",
      " Loss: 0.000000\n",
      " Loss: 0.060948\n",
      " Loss: 0.000000\n",
      " Loss: 0.023838\n",
      " Loss: 0.000000\n",
      " Loss: 0.016152\n",
      " Loss: 0.000000\n",
      " Loss: 0.021321\n",
      "Epoch 2246 Chain 0 loss std 1.16e-03 variance 6.72e-07 smooth variance 6.72e-07 adaptive c -1.00\n",
      "Epoch 2246 Chain 1 loss std 2.67e+02 variance 3.57e+04 smooth variance 2.48e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018007\n",
      " Loss: 0.000000\n",
      " Loss: 0.055775\n",
      " Loss: 0.000000\n",
      " Loss: 0.042983\n",
      " Loss: 0.000000\n",
      " Loss: 0.012142\n",
      " Loss: 0.000000\n",
      " Loss: 0.031930\n",
      " Loss: 0.000000\n",
      " Loss: 0.025348\n",
      " Loss: 0.000000\n",
      " Loss: 0.018566\n",
      " Loss: 0.000000\n",
      " Loss: 0.066495\n",
      " Loss: 0.000000\n",
      " Loss: 0.012743\n",
      " Loss: 0.000000\n",
      " Loss: 0.037686\n",
      "Epoch 2248 Chain 0 loss std 8.47e-04 variance 3.59e-07 smooth variance 5.78e-07 adaptive c -1.00\n",
      "Epoch 2248 Chain 1 loss std 1.53e+02 variance 1.17e+04 smooth variance 2.09e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.055643\n",
      " Loss: 0.000000\n",
      " Loss: 0.030558\n",
      " Loss: 0.000000\n",
      " Loss: 0.022108\n",
      " Loss: 0.000000\n",
      " Loss: 0.019647\n",
      " Loss: 0.000000\n",
      " Loss: 0.032882\n",
      " Loss: 0.000000\n",
      " Loss: 0.018176\n",
      " Loss: 0.000000\n",
      " Loss: 0.013683\n",
      " Loss: 0.000000\n",
      " Loss: 0.017640\n",
      " Loss: 0.000000\n",
      " Loss: 0.062674\n",
      " Loss: 0.000000\n",
      " Loss: 0.048664\n",
      "Epoch 2250 Chain 0 loss std 1.26e-03 variance 7.91e-07 smooth variance 6.42e-07 adaptive c -1.00\n",
      "Epoch 2250 Chain 1 loss std 1.59e+02 variance 1.26e+04 smooth variance 1.84e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020549\n",
      " Loss: 0.000000\n",
      " Loss: 0.030649\n",
      " Loss: 0.000000\n",
      " Loss: 0.061075\n",
      " Loss: 0.000000\n",
      " Loss: 0.017445\n",
      " Loss: 0.000000\n",
      " Loss: 0.031120\n",
      " Loss: 0.000000\n",
      " Loss: 0.054388\n",
      " Loss: 0.000000\n",
      " Loss: 0.016701\n",
      " Loss: 0.000000\n",
      " Loss: 0.026463\n",
      " Loss: 0.000000\n",
      " Loss: 0.042243\n",
      " Loss: 0.000000\n",
      " Loss: 0.021042\n",
      "Epoch 2252 Chain 0 loss std 6.30e-04 variance 1.99e-07 smooth variance 5.09e-07 adaptive c -1.00\n",
      "Epoch 2252 Chain 1 loss std 2.54e+02 variance 3.23e+04 smooth variance 2.26e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025629\n",
      " Loss: 0.000000\n",
      " Loss: 0.019192\n",
      " Loss: 0.000000\n",
      " Loss: 0.042026\n",
      " Loss: 0.000000\n",
      " Loss: 0.061728\n",
      " Loss: 0.000000\n",
      " Loss: 0.012262\n",
      " Loss: 0.000000\n",
      " Loss: 0.014551\n",
      " Loss: 0.000000\n",
      " Loss: 0.045547\n",
      " Loss: 0.000000\n",
      " Loss: 0.021509\n",
      " Loss: 0.000000\n",
      " Loss: 0.067794\n",
      " Loss: 0.000000\n",
      " Loss: 0.011437\n",
      "Epoch 2254 Chain 0 loss std 1.23e-03 variance 7.56e-07 smooth variance 5.83e-07 adaptive c -1.00\n",
      "Epoch 2254 Chain 1 loss std 1.58e+02 variance 1.24e+04 smooth variance 1.95e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016175\n",
      " Loss: 0.000000\n",
      " Loss: 0.032750\n",
      " Loss: 0.000000\n",
      " Loss: 0.013289\n",
      " Loss: 0.000000\n",
      " Loss: 0.075080\n",
      " Loss: 0.000000\n",
      " Loss: 0.023544\n",
      " Loss: 0.000000\n",
      " Loss: 0.064673\n",
      " Loss: 0.000000\n",
      " Loss: 0.016112\n",
      " Loss: 0.000000\n",
      " Loss: 0.016354\n",
      " Loss: 0.000000\n",
      " Loss: 0.046835\n",
      " Loss: 0.000000\n",
      " Loss: 0.016863\n",
      "Epoch 2256 Chain 0 loss std 8.04e-04 variance 3.23e-07 smooth variance 5.05e-07 adaptive c -1.00\n",
      "Epoch 2256 Chain 1 loss std 2.61e+02 variance 3.42e+04 smooth variance 2.39e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020913\n",
      " Loss: 0.000000\n",
      " Loss: 0.015088\n",
      " Loss: 0.000000\n",
      " Loss: 0.032432\n",
      " Loss: 0.000000\n",
      " Loss: 0.030892\n",
      " Loss: 0.000000\n",
      " Loss: 0.061514\n",
      " Loss: 0.000000\n",
      " Loss: 0.069895\n",
      " Loss: 0.000000\n",
      " Loss: 0.020003\n",
      " Loss: 0.000000\n",
      " Loss: 0.018918\n",
      " Loss: 0.000000\n",
      " Loss: 0.023390\n",
      " Loss: 0.000000\n",
      " Loss: 0.028631\n",
      "Epoch 2258 Chain 0 loss std 9.06e-04 variance 4.10e-07 smooth variance 4.77e-07 adaptive c -1.00\n",
      "Epoch 2258 Chain 1 loss std 1.57e+02 variance 1.23e+04 smooth variance 2.04e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.009854\n",
      " Loss: 0.000000\n",
      " Loss: 0.090986\n",
      " Loss: 0.000000\n",
      " Loss: 0.017962\n",
      " Loss: 0.000000\n",
      " Loss: 0.017410\n",
      " Loss: 0.000000\n",
      " Loss: 0.024625\n",
      " Loss: 0.000000\n",
      " Loss: 0.034310\n",
      " Loss: 0.000000\n",
      " Loss: 0.022410\n",
      " Loss: 0.000000\n",
      " Loss: 0.016448\n",
      " Loss: 0.000000\n",
      " Loss: 0.070731\n",
      " Loss: 0.000000\n",
      " Loss: 0.016939\n",
      "Epoch 2260 Chain 0 loss std 8.00e-04 variance 3.20e-07 smooth variance 4.30e-07 adaptive c -1.00\n",
      "Epoch 2260 Chain 1 loss std 1.85e+02 variance 1.71e+04 smooth variance 1.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033493\n",
      " Loss: 0.000000\n",
      " Loss: 0.025612\n",
      " Loss: 0.000000\n",
      " Loss: 0.019652\n",
      " Loss: 0.000000\n",
      " Loss: 0.061797\n",
      " Loss: 0.000000\n",
      " Loss: 0.020284\n",
      " Loss: 0.000000\n",
      " Loss: 0.023772\n",
      " Loss: 0.000000\n",
      " Loss: 0.030684\n",
      " Loss: 0.000000\n",
      " Loss: 0.007449\n",
      " Loss: 0.000000\n",
      " Loss: 0.065495\n",
      " Loss: 0.000000\n",
      " Loss: 0.033438\n",
      "Epoch 2262 Chain 0 loss std 9.52e-04 variance 4.53e-07 smooth variance 4.37e-07 adaptive c -1.00\n",
      "Epoch 2262 Chain 1 loss std 1.49e+02 variance 1.11e+04 smooth variance 1.69e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061232\n",
      " Loss: 0.000000\n",
      " Loss: 0.029988\n",
      " Loss: 0.000000\n",
      " Loss: 0.016485\n",
      " Loss: 0.000000\n",
      " Loss: 0.016048\n",
      " Loss: 0.000000\n",
      " Loss: 0.037085\n",
      " Loss: 0.000000\n",
      " Loss: 0.009281\n",
      " Loss: 0.000000\n",
      " Loss: 0.018599\n",
      " Loss: 0.000000\n",
      " Loss: 0.067813\n",
      " Loss: 0.000000\n",
      " Loss: 0.027218\n",
      " Loss: 0.000000\n",
      " Loss: 0.037927\n",
      "Epoch 2264 Chain 0 loss std 8.62e-04 variance 3.72e-07 smooth variance 4.17e-07 adaptive c -1.00\n",
      "Epoch 2264 Chain 1 loss std 1.87e+02 variance 1.76e+04 smooth variance 1.71e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037461\n",
      " Loss: 0.000000\n",
      " Loss: 0.020281\n",
      " Loss: 0.000000\n",
      " Loss: 0.024318\n",
      " Loss: 0.000000\n",
      " Loss: 0.058253\n",
      " Loss: 0.000000\n",
      " Loss: 0.020525\n",
      " Loss: 0.000000\n",
      " Loss: 0.020154\n",
      " Loss: 0.000000\n",
      " Loss: 0.022561\n",
      " Loss: 0.000000\n",
      " Loss: 0.036362\n",
      " Loss: 0.000000\n",
      " Loss: 0.020562\n",
      " Loss: 0.000000\n",
      " Loss: 0.061199\n",
      "Epoch 2266 Chain 0 loss std 1.03e-03 variance 5.29e-07 smooth variance 4.51e-07 adaptive c -1.00\n",
      "Epoch 2266 Chain 1 loss std 2.04e+02 variance 2.08e+04 smooth variance 1.82e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.010049\n",
      " Loss: 0.000000\n",
      " Loss: 0.037104\n",
      " Loss: 0.000000\n",
      " Loss: 0.019862\n",
      " Loss: 0.000000\n",
      " Loss: 0.023193\n",
      " Loss: 0.000000\n",
      " Loss: 0.070630\n",
      " Loss: 0.000000\n",
      " Loss: 0.019955\n",
      " Loss: 0.000000\n",
      " Loss: 0.021260\n",
      " Loss: 0.000000\n",
      " Loss: 0.027951\n",
      " Loss: 0.000000\n",
      " Loss: 0.020012\n",
      " Loss: 0.000000\n",
      " Loss: 0.071659\n",
      "Epoch 2268 Chain 0 loss std 9.04e-04 variance 4.08e-07 smooth variance 4.38e-07 adaptive c -1.00\n",
      "Epoch 2268 Chain 1 loss std 1.61e+02 variance 1.29e+04 smooth variance 1.66e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015050\n",
      " Loss: 0.000000\n",
      " Loss: 0.021626\n",
      " Loss: 0.000000\n",
      " Loss: 0.064701\n",
      " Loss: 0.000000\n",
      " Loss: 0.049302\n",
      " Loss: 0.000000\n",
      " Loss: 0.010158\n",
      " Loss: 0.000000\n",
      " Loss: 0.018024\n",
      " Loss: 0.000000\n",
      " Loss: 0.065834\n",
      " Loss: 0.000000\n",
      " Loss: 0.013245\n",
      " Loss: 0.000000\n",
      " Loss: 0.034738\n",
      " Loss: 0.000000\n",
      " Loss: 0.028996\n",
      "Epoch 2270 Chain 0 loss std 8.95e-04 variance 4.00e-07 smooth variance 4.27e-07 adaptive c -1.00\n",
      "Epoch 2270 Chain 1 loss std 2.59e+02 variance 3.35e+04 smooth variance 2.17e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.044922\n",
      " Loss: 0.000000\n",
      " Loss: 0.029523\n",
      " Loss: 0.000000\n",
      " Loss: 0.060678\n",
      " Loss: 0.000000\n",
      " Loss: 0.013006\n",
      " Loss: 0.000000\n",
      " Loss: 0.012710\n",
      " Loss: 0.000000\n",
      " Loss: 0.015819\n",
      " Loss: 0.000000\n",
      " Loss: 0.091856\n",
      " Loss: 0.000000\n",
      " Loss: 0.017619\n",
      " Loss: 0.000000\n",
      " Loss: 0.022768\n",
      " Loss: 0.000000\n",
      " Loss: 0.012776\n",
      "Epoch 2272 Chain 0 loss std 1.12e-03 variance 6.24e-07 smooth variance 4.86e-07 adaptive c -1.00\n",
      "Epoch 2272 Chain 1 loss std 2.16e+02 variance 2.33e+04 smooth variance 2.22e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.062609\n",
      " Loss: 0.000000\n",
      " Loss: 0.020571\n",
      " Loss: 0.000000\n",
      " Loss: 0.016832\n",
      " Loss: 0.000000\n",
      " Loss: 0.041899\n",
      " Loss: 0.000000\n",
      " Loss: 0.018927\n",
      " Loss: 0.000000\n",
      " Loss: 0.062502\n",
      " Loss: 0.000000\n",
      " Loss: 0.036912\n",
      " Loss: 0.000000\n",
      " Loss: 0.011300\n",
      " Loss: 0.000000\n",
      " Loss: 0.032137\n",
      " Loss: 0.000000\n",
      " Loss: 0.017986\n",
      "Epoch 2274 Chain 0 loss std 9.61e-04 variance 4.62e-07 smooth variance 4.79e-07 adaptive c -1.00\n",
      "Epoch 2274 Chain 1 loss std 1.90e+02 variance 1.81e+04 smooth variance 2.09e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.009941\n",
      " Loss: 0.000000\n",
      " Loss: 0.033697\n",
      " Loss: 0.000000\n",
      " Loss: 0.061459\n",
      " Loss: 0.000000\n",
      " Loss: 0.019058\n",
      " Loss: 0.000000\n",
      " Loss: 0.036683\n",
      " Loss: 0.000000\n",
      " Loss: 0.015606\n",
      " Loss: 0.000000\n",
      " Loss: 0.040260\n",
      " Loss: 0.000000\n",
      " Loss: 0.065391\n",
      " Loss: 0.000000\n",
      " Loss: 0.016071\n",
      " Loss: 0.000000\n",
      " Loss: 0.023510\n",
      "Epoch 2276 Chain 0 loss std 6.75e-04 variance 2.28e-07 smooth variance 4.04e-07 adaptive c -1.00\n",
      "Epoch 2276 Chain 1 loss std 1.92e+02 variance 1.85e+04 smooth variance 2.02e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029608\n",
      " Loss: 0.000000\n",
      " Loss: 0.070859\n",
      " Loss: 0.000000\n",
      " Loss: 0.019378\n",
      " Loss: 0.000000\n",
      " Loss: 0.018504\n",
      " Loss: 0.000000\n",
      " Loss: 0.022488\n",
      " Loss: 0.000000\n",
      " Loss: 0.073461\n",
      " Loss: 0.000000\n",
      " Loss: 0.018272\n",
      " Loss: 0.000000\n",
      " Loss: 0.030652\n",
      " Loss: 0.000000\n",
      " Loss: 0.019268\n",
      " Loss: 0.000000\n",
      " Loss: 0.019185\n",
      "Epoch 2278 Chain 0 loss std 6.72e-04 variance 2.26e-07 smooth variance 3.50e-07 adaptive c -1.00\n",
      "Epoch 2278 Chain 1 loss std 2.13e+02 variance 2.27e+04 smooth variance 2.09e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037823\n",
      " Loss: 0.000000\n",
      " Loss: 0.067231\n",
      " Loss: 0.000000\n",
      " Loss: 0.019934\n",
      " Loss: 0.000000\n",
      " Loss: 0.019659\n",
      " Loss: 0.000000\n",
      " Loss: 0.016190\n",
      " Loss: 0.000000\n",
      " Loss: 0.013383\n",
      " Loss: 0.000000\n",
      " Loss: 0.015383\n",
      " Loss: 0.000000\n",
      " Loss: 0.061974\n",
      " Loss: 0.000000\n",
      " Loss: 0.033404\n",
      " Loss: 0.000000\n",
      " Loss: 0.036693\n",
      "Epoch 2280 Chain 0 loss std 8.75e-04 variance 3.83e-07 smooth variance 3.60e-07 adaptive c -1.00\n",
      "Epoch 2280 Chain 1 loss std 2.02e+02 variance 2.04e+04 smooth variance 2.08e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021383\n",
      " Loss: 0.000000\n",
      " Loss: 0.062619\n",
      " Loss: 0.000000\n",
      " Loss: 0.036372\n",
      " Loss: 0.000000\n",
      " Loss: 0.022433\n",
      " Loss: 0.000000\n",
      " Loss: 0.018030\n",
      " Loss: 0.000000\n",
      " Loss: 0.025912\n",
      " Loss: 0.000000\n",
      " Loss: 0.021536\n",
      " Loss: 0.000000\n",
      " Loss: 0.040479\n",
      " Loss: 0.000000\n",
      " Loss: 0.020078\n",
      " Loss: 0.000000\n",
      " Loss: 0.052833\n",
      "Epoch 2282 Chain 0 loss std 6.76e-04 variance 2.29e-07 smooth variance 3.21e-07 adaptive c -1.00\n",
      "Epoch 2282 Chain 1 loss std 2.90e+02 variance 4.20e+04 smooth variance 2.71e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.031140\n",
      " Loss: 0.000000\n",
      " Loss: 0.022645\n",
      " Loss: 0.000000\n",
      " Loss: 0.059004\n",
      " Loss: 0.000000\n",
      " Loss: 0.016015\n",
      " Loss: 0.000000\n",
      " Loss: 0.032034\n",
      " Loss: 0.000000\n",
      " Loss: 0.060484\n",
      " Loss: 0.000000\n",
      " Loss: 0.037212\n",
      " Loss: 0.000000\n",
      " Loss: 0.016987\n",
      " Loss: 0.000000\n",
      " Loss: 0.020740\n",
      " Loss: 0.000000\n",
      " Loss: 0.025414\n",
      "Epoch 2284 Chain 0 loss std 7.85e-04 variance 3.08e-07 smooth variance 3.17e-07 adaptive c -1.00\n",
      "Epoch 2284 Chain 1 loss std 1.79e+02 variance 1.60e+04 smooth variance 2.38e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020133\n",
      " Loss: 0.000000\n",
      " Loss: 0.028710\n",
      " Loss: 0.000000\n",
      " Loss: 0.016269\n",
      " Loss: 0.000000\n",
      " Loss: 0.020271\n",
      " Loss: 0.000000\n",
      " Loss: 0.075454\n",
      " Loss: 0.000000\n",
      " Loss: 0.015799\n",
      " Loss: 0.000000\n",
      " Loss: 0.023985\n",
      " Loss: 0.000000\n",
      " Loss: 0.060146\n",
      " Loss: 0.000000\n",
      " Loss: 0.017707\n",
      " Loss: 0.000000\n",
      " Loss: 0.043200\n",
      "Epoch 2286 Chain 0 loss std 7.39e-04 variance 2.73e-07 smooth variance 3.04e-07 adaptive c -1.00\n",
      "Epoch 2286 Chain 1 loss std 1.41e+02 variance 9.92e+03 smooth variance 1.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023040\n",
      " Loss: 0.000000\n",
      " Loss: 0.030761\n",
      " Loss: 0.000000\n",
      " Loss: 0.025443\n",
      " Loss: 0.000000\n",
      " Loss: 0.020058\n",
      " Loss: 0.000000\n",
      " Loss: 0.061535\n",
      " Loss: 0.000000\n",
      " Loss: 0.022612\n",
      " Loss: 0.000000\n",
      " Loss: 0.060107\n",
      " Loss: 0.000000\n",
      " Loss: 0.020262\n",
      " Loss: 0.000000\n",
      " Loss: 0.035875\n",
      " Loss: 0.000000\n",
      " Loss: 0.021981\n",
      "Epoch 2288 Chain 0 loss std 1.11e-03 variance 6.17e-07 smooth variance 3.98e-07 adaptive c -1.00\n",
      "Epoch 2288 Chain 1 loss std 2.66e+02 variance 3.54e+04 smooth variance 2.44e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014398\n",
      " Loss: 0.000000\n",
      " Loss: 0.038394\n",
      " Loss: 0.000000\n",
      " Loss: 0.065981\n",
      " Loss: 0.000000\n",
      " Loss: 0.023291\n",
      " Loss: 0.000000\n",
      " Loss: 0.018773\n",
      " Loss: 0.000000\n",
      " Loss: 0.021938\n",
      " Loss: 0.000000\n",
      " Loss: 0.058984\n",
      " Loss: 0.000000\n",
      " Loss: 0.031687\n",
      " Loss: 0.000000\n",
      " Loss: 0.026324\n",
      " Loss: 0.000000\n",
      " Loss: 0.021904\n",
      "Epoch 2290 Chain 0 loss std 5.54e-04 variance 1.54e-07 smooth variance 3.25e-07 adaptive c -1.00\n",
      "Epoch 2290 Chain 1 loss std 2.49e+02 variance 3.09e+04 smooth variance 2.63e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020539\n",
      " Loss: 0.000000\n",
      " Loss: 0.012523\n",
      " Loss: 0.000000\n",
      " Loss: 0.023952\n",
      " Loss: 0.000000\n",
      " Loss: 0.023487\n",
      " Loss: 0.000000\n",
      " Loss: 0.080337\n",
      " Loss: 0.000000\n",
      " Loss: 0.017561\n",
      " Loss: 0.000000\n",
      " Loss: 0.079038\n",
      " Loss: 0.000000\n",
      " Loss: 0.025885\n",
      " Loss: 0.000000\n",
      " Loss: 0.023348\n",
      " Loss: 0.000000\n",
      " Loss: 0.015005\n",
      "Epoch 2292 Chain 0 loss std 6.00e-04 variance 1.80e-07 smooth variance 2.81e-07 adaptive c -1.00\n",
      "Epoch 2292 Chain 1 loss std 2.25e+02 variance 2.53e+04 smooth variance 2.60e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019277\n",
      " Loss: 0.000000\n",
      " Loss: 0.012580\n",
      " Loss: 0.000000\n",
      " Loss: 0.018992\n",
      " Loss: 0.000000\n",
      " Loss: 0.023942\n",
      " Loss: 0.000000\n",
      " Loss: 0.086047\n",
      " Loss: 0.000000\n",
      " Loss: 0.032895\n",
      " Loss: 0.000000\n",
      " Loss: 0.021959\n",
      " Loss: 0.000000\n",
      " Loss: 0.020414\n",
      " Loss: 0.000000\n",
      " Loss: 0.057759\n",
      " Loss: 0.000000\n",
      " Loss: 0.027811\n",
      "Epoch 2294 Chain 0 loss std 1.18e-03 variance 7.01e-07 smooth variance 4.07e-07 adaptive c -1.00\n",
      "Epoch 2294 Chain 1 loss std 1.91e+02 variance 1.82e+04 smooth variance 2.37e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027936\n",
      " Loss: 0.000000\n",
      " Loss: 0.021303\n",
      " Loss: 0.000000\n",
      " Loss: 0.080578\n",
      " Loss: 0.000000\n",
      " Loss: 0.018346\n",
      " Loss: 0.000000\n",
      " Loss: 0.012674\n",
      " Loss: 0.000000\n",
      " Loss: 0.034551\n",
      " Loss: 0.000000\n",
      " Loss: 0.053960\n",
      " Loss: 0.000000\n",
      " Loss: 0.024438\n",
      " Loss: 0.000000\n",
      " Loss: 0.023014\n",
      " Loss: 0.000000\n",
      " Loss: 0.024874\n",
      "Epoch 2296 Chain 0 loss std 7.36e-04 variance 2.71e-07 smooth variance 3.66e-07 adaptive c -1.00\n",
      "Epoch 2296 Chain 1 loss std 2.53e+02 variance 3.20e+04 smooth variance 2.62e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.071178\n",
      " Loss: 0.000000\n",
      " Loss: 0.011782\n",
      " Loss: 0.000000\n",
      " Loss: 0.017338\n",
      " Loss: 0.000000\n",
      " Loss: 0.039577\n",
      " Loss: 0.000000\n",
      " Loss: 0.020963\n",
      " Loss: 0.000000\n",
      " Loss: 0.037201\n",
      " Loss: 0.000000\n",
      " Loss: 0.030446\n",
      " Loss: 0.000000\n",
      " Loss: 0.017635\n",
      " Loss: 0.000000\n",
      " Loss: 0.064296\n",
      " Loss: 0.000000\n",
      " Loss: 0.011260\n",
      "Epoch 2298 Chain 0 loss std 9.71e-04 variance 4.71e-07 smooth variance 3.98e-07 adaptive c -1.00\n",
      "Epoch 2298 Chain 1 loss std 2.54e+02 variance 3.23e+04 smooth variance 2.80e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.057651\n",
      " Loss: 0.000000\n",
      " Loss: 0.015675\n",
      " Loss: 0.000000\n",
      " Loss: 0.037226\n",
      " Loss: 0.000000\n",
      " Loss: 0.021494\n",
      " Loss: 0.000000\n",
      " Loss: 0.028791\n",
      " Loss: 0.000000\n",
      " Loss: 0.034825\n",
      " Loss: 0.000000\n",
      " Loss: 0.061991\n",
      " Loss: 0.000000\n",
      " Loss: 0.025455\n",
      " Loss: 0.000000\n",
      " Loss: 0.025155\n",
      " Loss: 0.000000\n",
      " Loss: 0.013413\n",
      "Epoch 2300 Chain 0 loss std 6.75e-04 variance 2.28e-07 smooth variance 3.47e-07 adaptive c -1.00\n",
      "Epoch 2300 Chain 1 loss std 1.95e+02 variance 1.90e+04 smooth variance 2.53e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.009843\n",
      " Loss: 0.000000\n",
      " Loss: 0.019376\n",
      " Loss: 0.000000\n",
      " Loss: 0.071355\n",
      " Loss: 0.000000\n",
      " Loss: 0.022759\n",
      " Loss: 0.000000\n",
      " Loss: 0.037505\n",
      " Loss: 0.000000\n",
      " Loss: 0.015383\n",
      " Loss: 0.000000\n",
      " Loss: 0.022723\n",
      " Loss: 0.000000\n",
      " Loss: 0.013295\n",
      " Loss: 0.000000\n",
      " Loss: 0.040327\n",
      " Loss: 0.000000\n",
      " Loss: 0.069109\n",
      "Epoch 2302 Chain 0 loss std 1.18e-03 variance 6.96e-07 smooth variance 4.52e-07 adaptive c -1.00\n",
      "Epoch 2302 Chain 1 loss std 1.63e+02 variance 1.33e+04 smooth variance 2.17e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019137\n",
      " Loss: 0.000000\n",
      " Loss: 0.041273\n",
      " Loss: 0.000000\n",
      " Loss: 0.068383\n",
      " Loss: 0.000000\n",
      " Loss: 0.013467\n",
      " Loss: 0.000000\n",
      " Loss: 0.018577\n",
      " Loss: 0.000000\n",
      " Loss: 0.082447\n",
      " Loss: 0.000000\n",
      " Loss: 0.022577\n",
      " Loss: 0.000000\n",
      " Loss: 0.025504\n",
      " Loss: 0.000000\n",
      " Loss: 0.010556\n",
      " Loss: 0.000000\n",
      " Loss: 0.019753\n",
      "Epoch 2304 Chain 0 loss std 1.29e-03 variance 8.34e-07 smooth variance 5.66e-07 adaptive c -1.00\n",
      "Epoch 2304 Chain 1 loss std 1.63e+02 variance 1.32e+04 smooth variance 1.92e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.043621\n",
      " Loss: 0.000000\n",
      " Loss: 0.015854\n",
      " Loss: 0.000000\n",
      " Loss: 0.063861\n",
      " Loss: 0.000000\n",
      " Loss: 0.020688\n",
      " Loss: 0.000000\n",
      " Loss: 0.016813\n",
      " Loss: 0.000000\n",
      " Loss: 0.040361\n",
      " Loss: 0.000000\n",
      " Loss: 0.013740\n",
      " Loss: 0.000000\n",
      " Loss: 0.023461\n",
      " Loss: 0.000000\n",
      " Loss: 0.063232\n",
      " Loss: 0.000000\n",
      " Loss: 0.020044\n",
      "Epoch 2306 Chain 0 loss std 5.86e-04 variance 1.72e-07 smooth variance 4.48e-07 adaptive c -1.00\n",
      "Epoch 2306 Chain 1 loss std 2.01e+02 variance 2.01e+04 smooth variance 1.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018456\n",
      " Loss: 0.000000\n",
      " Loss: 0.075820\n",
      " Loss: 0.000000\n",
      " Loss: 0.019986\n",
      " Loss: 0.000000\n",
      " Loss: 0.029171\n",
      " Loss: 0.000000\n",
      " Loss: 0.017405\n",
      " Loss: 0.000000\n",
      " Loss: 0.024036\n",
      " Loss: 0.000000\n",
      " Loss: 0.022306\n",
      " Loss: 0.000000\n",
      " Loss: 0.026837\n",
      " Loss: 0.000000\n",
      " Loss: 0.013903\n",
      " Loss: 0.000000\n",
      " Loss: 0.073755\n",
      "Epoch 2308 Chain 0 loss std 4.43e-04 variance 9.79e-08 smooth variance 3.43e-07 adaptive c -1.00\n",
      "Epoch 2308 Chain 1 loss std 2.25e+02 variance 2.52e+04 smooth variance 2.12e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026485\n",
      " Loss: 0.000000\n",
      " Loss: 0.036940\n",
      " Loss: 0.000000\n",
      " Loss: 0.014255\n",
      " Loss: 0.000000\n",
      " Loss: 0.061242\n",
      " Loss: 0.000000\n",
      " Loss: 0.021916\n",
      " Loss: 0.000000\n",
      " Loss: 0.069295\n",
      " Loss: 0.000000\n",
      " Loss: 0.011660\n",
      " Loss: 0.000000\n",
      " Loss: 0.017349\n",
      " Loss: 0.000000\n",
      " Loss: 0.043219\n",
      " Loss: 0.000000\n",
      " Loss: 0.019315\n",
      "Epoch 2310 Chain 0 loss std 5.72e-04 variance 1.64e-07 smooth variance 2.89e-07 adaptive c -1.00\n",
      "Epoch 2310 Chain 1 loss std 2.86e+02 variance 4.08e+04 smooth variance 2.71e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032403\n",
      " Loss: 0.000000\n",
      " Loss: 0.020865\n",
      " Loss: 0.000000\n",
      " Loss: 0.015268\n",
      " Loss: 0.000000\n",
      " Loss: 0.016364\n",
      " Loss: 0.000000\n",
      " Loss: 0.075936\n",
      " Loss: 0.000000\n",
      " Loss: 0.045031\n",
      " Loss: 0.000000\n",
      " Loss: 0.021792\n",
      " Loss: 0.000000\n",
      " Loss: 0.022216\n",
      " Loss: 0.000000\n",
      " Loss: 0.015715\n",
      " Loss: 0.000000\n",
      " Loss: 0.056083\n",
      "Epoch 2312 Chain 0 loss std 1.16e-03 variance 6.72e-07 smooth variance 4.04e-07 adaptive c -1.00\n",
      "Epoch 2312 Chain 1 loss std 2.66e+02 variance 3.55e+04 smooth variance 2.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.039093\n",
      " Loss: 0.000000\n",
      " Loss: 0.024609\n",
      " Loss: 0.000000\n",
      " Loss: 0.057948\n",
      " Loss: 0.000000\n",
      " Loss: 0.009659\n",
      " Loss: 0.000000\n",
      " Loss: 0.029529\n",
      " Loss: 0.000000\n",
      " Loss: 0.024349\n",
      " Loss: 0.000000\n",
      " Loss: 0.057981\n",
      " Loss: 0.000000\n",
      " Loss: 0.030473\n",
      " Loss: 0.000000\n",
      " Loss: 0.021027\n",
      " Loss: 0.000000\n",
      " Loss: 0.027008\n",
      "Epoch 2314 Chain 0 loss std 1.37e-03 variance 9.34e-07 smooth variance 5.63e-07 adaptive c -1.00\n",
      "Epoch 2314 Chain 1 loss std 2.63e+02 variance 3.45e+04 smooth variance 3.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036040\n",
      " Loss: 0.000000\n",
      " Loss: 0.017734\n",
      " Loss: 0.000000\n",
      " Loss: 0.062367\n",
      " Loss: 0.000000\n",
      " Loss: 0.013291\n",
      " Loss: 0.000000\n",
      " Loss: 0.031405\n",
      " Loss: 0.000000\n",
      " Loss: 0.063049\n",
      " Loss: 0.000000\n",
      " Loss: 0.030534\n",
      " Loss: 0.000000\n",
      " Loss: 0.016525\n",
      " Loss: 0.000000\n",
      " Loss: 0.034275\n",
      " Loss: 0.000000\n",
      " Loss: 0.016455\n",
      "Epoch 2316 Chain 0 loss std 1.02e-03 variance 5.24e-07 smooth variance 5.51e-07 adaptive c -1.00\n",
      "Epoch 2316 Chain 1 loss std 1.92e+02 variance 1.84e+04 smooth variance 2.73e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.040021\n",
      " Loss: 0.000000\n",
      " Loss: 0.068327\n",
      " Loss: 0.000000\n",
      " Loss: 0.017536\n",
      " Loss: 0.000000\n",
      " Loss: 0.015132\n",
      " Loss: 0.000000\n",
      " Loss: 0.019821\n",
      " Loss: 0.000000\n",
      " Loss: 0.029937\n",
      " Loss: 0.000000\n",
      " Loss: 0.015177\n",
      " Loss: 0.000000\n",
      " Loss: 0.061144\n",
      " Loss: 0.000000\n",
      " Loss: 0.035884\n",
      " Loss: 0.000000\n",
      " Loss: 0.018696\n",
      "Epoch 2318 Chain 0 loss std 8.83e-04 variance 3.90e-07 smooth variance 5.03e-07 adaptive c -1.00\n",
      "Epoch 2318 Chain 1 loss std 2.41e+02 variance 2.91e+04 smooth variance 2.78e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.013599\n",
      " Loss: 0.000000\n",
      " Loss: 0.066962\n",
      " Loss: 0.000000\n",
      " Loss: 0.029408\n",
      " Loss: 0.000000\n",
      " Loss: 0.012356\n",
      " Loss: 0.000000\n",
      " Loss: 0.038513\n",
      " Loss: 0.000000\n",
      " Loss: 0.038386\n",
      " Loss: 0.000000\n",
      " Loss: 0.070534\n",
      " Loss: 0.000000\n",
      " Loss: 0.021976\n",
      " Loss: 0.000000\n",
      " Loss: 0.017755\n",
      " Loss: 0.000000\n",
      " Loss: 0.012186\n",
      "Epoch 2320 Chain 0 loss std 8.44e-04 variance 3.56e-07 smooth variance 4.59e-07 adaptive c -1.00\n",
      "Epoch 2320 Chain 1 loss std 1.88e+02 variance 1.78e+04 smooth variance 2.48e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.074521\n",
      " Loss: 0.000000\n",
      " Loss: 0.018681\n",
      " Loss: 0.000000\n",
      " Loss: 0.013221\n",
      " Loss: 0.000000\n",
      " Loss: 0.033563\n",
      " Loss: 0.000000\n",
      " Loss: 0.020851\n",
      " Loss: 0.000000\n",
      " Loss: 0.018674\n",
      " Loss: 0.000000\n",
      " Loss: 0.018241\n",
      " Loss: 0.000000\n",
      " Loss: 0.034547\n",
      " Loss: 0.000000\n",
      " Loss: 0.062719\n",
      " Loss: 0.000000\n",
      " Loss: 0.026657\n",
      "Epoch 2322 Chain 0 loss std 1.11e-03 variance 6.17e-07 smooth variance 5.06e-07 adaptive c -1.00\n",
      "Epoch 2322 Chain 1 loss std 1.73e+02 variance 1.49e+04 smooth variance 2.18e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.039824\n",
      " Loss: 0.000000\n",
      " Loss: 0.026618\n",
      " Loss: 0.000000\n",
      " Loss: 0.014621\n",
      " Loss: 0.000000\n",
      " Loss: 0.063667\n",
      " Loss: 0.000000\n",
      " Loss: 0.016108\n",
      " Loss: 0.000000\n",
      " Loss: 0.016931\n",
      " Loss: 0.000000\n",
      " Loss: 0.026887\n",
      " Loss: 0.000000\n",
      " Loss: 0.020073\n",
      " Loss: 0.000000\n",
      " Loss: 0.021550\n",
      " Loss: 0.000000\n",
      " Loss: 0.075397\n",
      "Epoch 2324 Chain 0 loss std 1.02e-03 variance 5.25e-07 smooth variance 5.12e-07 adaptive c -1.00\n",
      "Epoch 2324 Chain 1 loss std 1.93e+02 variance 1.86e+04 smooth variance 2.09e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020046\n",
      " Loss: 0.000000\n",
      " Loss: 0.073678\n",
      " Loss: 0.000000\n",
      " Loss: 0.032081\n",
      " Loss: 0.000000\n",
      " Loss: 0.014787\n",
      " Loss: 0.000000\n",
      " Loss: 0.020245\n",
      " Loss: 0.000000\n",
      " Loss: 0.041545\n",
      " Loss: 0.000000\n",
      " Loss: 0.015509\n",
      " Loss: 0.000000\n",
      " Loss: 0.015636\n",
      " Loss: 0.000000\n",
      " Loss: 0.019216\n",
      " Loss: 0.000000\n",
      " Loss: 0.068932\n",
      "Epoch 2326 Chain 0 loss std 1.03e-03 variance 5.31e-07 smooth variance 5.18e-07 adaptive c -1.00\n",
      "Epoch 2326 Chain 1 loss std 1.80e+02 variance 1.61e+04 smooth variance 1.95e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.066264\n",
      " Loss: 0.000000\n",
      " Loss: 0.025486\n",
      " Loss: 0.000000\n",
      " Loss: 0.023813\n",
      " Loss: 0.000000\n",
      " Loss: 0.013796\n",
      " Loss: 0.000000\n",
      " Loss: 0.031478\n",
      " Loss: 0.000000\n",
      " Loss: 0.012353\n",
      " Loss: 0.000000\n",
      " Loss: 0.021099\n",
      " Loss: 0.000000\n",
      " Loss: 0.022150\n",
      " Loss: 0.000000\n",
      " Loss: 0.083040\n",
      " Loss: 0.000000\n",
      " Loss: 0.022195\n",
      "Epoch 2328 Chain 0 loss std 7.67e-04 variance 2.94e-07 smooth variance 4.51e-07 adaptive c -1.00\n",
      "Epoch 2328 Chain 1 loss std 1.85e+02 variance 1.71e+04 smooth variance 1.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023305\n",
      " Loss: 0.000000\n",
      " Loss: 0.030509\n",
      " Loss: 0.000000\n",
      " Loss: 0.026805\n",
      " Loss: 0.000000\n",
      " Loss: 0.017590\n",
      " Loss: 0.000000\n",
      " Loss: 0.062629\n",
      " Loss: 0.000000\n",
      " Loss: 0.020144\n",
      " Loss: 0.000000\n",
      " Loss: 0.013597\n",
      " Loss: 0.000000\n",
      " Loss: 0.026497\n",
      " Loss: 0.000000\n",
      " Loss: 0.077594\n",
      " Loss: 0.000000\n",
      " Loss: 0.023005\n",
      "Epoch 2330 Chain 0 loss std 1.06e-03 variance 5.63e-07 smooth variance 4.84e-07 adaptive c -1.00\n",
      "Epoch 2330 Chain 1 loss std 1.69e+02 variance 1.43e+04 smooth variance 1.74e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.012187\n",
      " Loss: 0.000000\n",
      " Loss: 0.026793\n",
      " Loss: 0.000000\n",
      " Loss: 0.034817\n",
      " Loss: 0.000000\n",
      " Loss: 0.065397\n",
      " Loss: 0.000000\n",
      " Loss: 0.021644\n",
      " Loss: 0.000000\n",
      " Loss: 0.018935\n",
      " Loss: 0.000000\n",
      " Loss: 0.036027\n",
      " Loss: 0.000000\n",
      " Loss: 0.015978\n",
      " Loss: 0.000000\n",
      " Loss: 0.059585\n",
      " Loss: 0.000000\n",
      " Loss: 0.030313\n",
      "Epoch 2332 Chain 0 loss std 1.31e-03 variance 8.60e-07 smooth variance 5.97e-07 adaptive c -1.00\n",
      "Epoch 2332 Chain 1 loss std 1.90e+02 variance 1.81e+04 smooth variance 1.76e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.011362\n",
      " Loss: 0.000000\n",
      " Loss: 0.025330\n",
      " Loss: 0.000000\n",
      " Loss: 0.033842\n",
      " Loss: 0.000000\n",
      " Loss: 0.021198\n",
      " Loss: 0.000000\n",
      " Loss: 0.069105\n",
      " Loss: 0.000000\n",
      " Loss: 0.058447\n",
      " Loss: 0.000000\n",
      " Loss: 0.021045\n",
      " Loss: 0.000000\n",
      " Loss: 0.025684\n",
      " Loss: 0.000000\n",
      " Loss: 0.044030\n",
      " Loss: 0.000000\n",
      " Loss: 0.011631\n",
      "Epoch 2334 Chain 0 loss std 6.76e-04 variance 2.29e-07 smooth variance 4.86e-07 adaptive c -1.00\n",
      "Epoch 2334 Chain 1 loss std 1.89e+02 variance 1.78e+04 smooth variance 1.77e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027675\n",
      " Loss: 0.000000\n",
      " Loss: 0.059371\n",
      " Loss: 0.000000\n",
      " Loss: 0.019779\n",
      " Loss: 0.000000\n",
      " Loss: 0.017375\n",
      " Loss: 0.000000\n",
      " Loss: 0.036638\n",
      " Loss: 0.000000\n",
      " Loss: 0.033938\n",
      " Loss: 0.000000\n",
      " Loss: 0.024660\n",
      " Loss: 0.000000\n",
      " Loss: 0.013463\n",
      " Loss: 0.000000\n",
      " Loss: 0.058616\n",
      " Loss: 0.000000\n",
      " Loss: 0.030160\n",
      "Epoch 2336 Chain 0 loss std 1.11e-03 variance 6.18e-07 smooth variance 5.26e-07 adaptive c -1.00\n",
      "Epoch 2336 Chain 1 loss std 2.30e+02 variance 2.65e+04 smooth variance 2.03e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.085341\n",
      " Loss: 0.000000\n",
      " Loss: 0.023183\n",
      " Loss: 0.000000\n",
      " Loss: 0.018415\n",
      " Loss: 0.000000\n",
      " Loss: 0.012350\n",
      " Loss: 0.000000\n",
      " Loss: 0.021548\n",
      " Loss: 0.000000\n",
      " Loss: 0.015078\n",
      " Loss: 0.000000\n",
      " Loss: 0.017096\n",
      " Loss: 0.000000\n",
      " Loss: 0.016427\n",
      " Loss: 0.000000\n",
      " Loss: 0.045913\n",
      " Loss: 0.000000\n",
      " Loss: 0.066322\n",
      "Epoch 2338 Chain 0 loss std 1.12e-03 variance 6.32e-07 smooth variance 5.58e-07 adaptive c -1.00\n",
      "Epoch 2338 Chain 1 loss std 1.64e+02 variance 1.35e+04 smooth variance 1.83e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024173\n",
      " Loss: 0.000000\n",
      " Loss: 0.056594\n",
      " Loss: 0.000000\n",
      " Loss: 0.018667\n",
      " Loss: 0.000000\n",
      " Loss: 0.040338\n",
      " Loss: 0.000000\n",
      " Loss: 0.021066\n",
      " Loss: 0.000000\n",
      " Loss: 0.062605\n",
      " Loss: 0.000000\n",
      " Loss: 0.022804\n",
      " Loss: 0.000000\n",
      " Loss: 0.036342\n",
      " Loss: 0.000000\n",
      " Loss: 0.016937\n",
      " Loss: 0.000000\n",
      " Loss: 0.022149\n",
      "Epoch 2340 Chain 0 loss std 1.07e-03 variance 5.76e-07 smooth variance 5.63e-07 adaptive c -1.00\n",
      "Epoch 2340 Chain 1 loss std 1.84e+02 variance 1.70e+04 smooth variance 1.79e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028525\n",
      " Loss: 0.000000\n",
      " Loss: 0.015229\n",
      " Loss: 0.000000\n",
      " Loss: 0.022124\n",
      " Loss: 0.000000\n",
      " Loss: 0.033021\n",
      " Loss: 0.000000\n",
      " Loss: 0.061938\n",
      " Loss: 0.000000\n",
      " Loss: 0.015710\n",
      " Loss: 0.000000\n",
      " Loss: 0.046798\n",
      " Loss: 0.000000\n",
      " Loss: 0.017161\n",
      " Loss: 0.000000\n",
      " Loss: 0.062667\n",
      " Loss: 0.000000\n",
      " Loss: 0.018503\n",
      "Epoch 2342 Chain 0 loss std 1.54e-03 variance 1.18e-06 smooth variance 7.49e-07 adaptive c -1.00\n",
      "Epoch 2342 Chain 1 loss std 1.61e+02 variance 1.30e+04 smooth variance 1.64e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019404\n",
      " Loss: 0.000000\n",
      " Loss: 0.065615\n",
      " Loss: 0.000000\n",
      " Loss: 0.034482\n",
      " Loss: 0.000000\n",
      " Loss: 0.021567\n",
      " Loss: 0.000000\n",
      " Loss: 0.019770\n",
      " Loss: 0.000000\n",
      " Loss: 0.026307\n",
      " Loss: 0.000000\n",
      " Loss: 0.066905\n",
      " Loss: 0.000000\n",
      " Loss: 0.015959\n",
      " Loss: 0.000000\n",
      " Loss: 0.014486\n",
      " Loss: 0.000000\n",
      " Loss: 0.037181\n",
      "Epoch 2344 Chain 0 loss std 1.09e-03 variance 5.99e-07 smooth variance 7.04e-07 adaptive c -1.00\n",
      "Epoch 2344 Chain 1 loss std 2.51e+02 variance 3.16e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014335\n",
      " Loss: 0.000000\n",
      " Loss: 0.017263\n",
      " Loss: 0.000000\n",
      " Loss: 0.027371\n",
      " Loss: 0.000000\n",
      " Loss: 0.063187\n",
      " Loss: 0.000000\n",
      " Loss: 0.038682\n",
      " Loss: 0.000000\n",
      " Loss: 0.025774\n",
      " Loss: 0.000000\n",
      " Loss: 0.058226\n",
      " Loss: 0.000000\n",
      " Loss: 0.031707\n",
      " Loss: 0.000000\n",
      " Loss: 0.017857\n",
      " Loss: 0.000000\n",
      " Loss: 0.027274\n",
      "Epoch 2346 Chain 0 loss std 1.32e-03 variance 8.77e-07 smooth variance 7.56e-07 adaptive c -1.00\n",
      "Epoch 2346 Chain 1 loss std 1.70e+02 variance 1.45e+04 smooth variance 1.90e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015996\n",
      " Loss: 0.000000\n",
      " Loss: 0.065809\n",
      " Loss: 0.000000\n",
      " Loss: 0.044992\n",
      " Loss: 0.000000\n",
      " Loss: 0.011180\n",
      " Loss: 0.000000\n",
      " Loss: 0.022861\n",
      " Loss: 0.000000\n",
      " Loss: 0.046309\n",
      " Loss: 0.000000\n",
      " Loss: 0.020287\n",
      " Loss: 0.000000\n",
      " Loss: 0.012795\n",
      " Loss: 0.000000\n",
      " Loss: 0.062290\n",
      " Loss: 0.000000\n",
      " Loss: 0.019157\n",
      "Epoch 2348 Chain 0 loss std 9.62e-04 variance 4.63e-07 smooth variance 6.68e-07 adaptive c -1.00\n",
      "Epoch 2348 Chain 1 loss std 2.34e+02 variance 2.73e+04 smooth variance 2.15e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028719\n",
      " Loss: 0.000000\n",
      " Loss: 0.014224\n",
      " Loss: 0.000000\n",
      " Loss: 0.059620\n",
      " Loss: 0.000000\n",
      " Loss: 0.040779\n",
      " Loss: 0.000000\n",
      " Loss: 0.017496\n",
      " Loss: 0.000000\n",
      " Loss: 0.038929\n",
      " Loss: 0.000000\n",
      " Loss: 0.026195\n",
      " Loss: 0.000000\n",
      " Loss: 0.066876\n",
      " Loss: 0.000000\n",
      " Loss: 0.009178\n",
      " Loss: 0.000000\n",
      " Loss: 0.019659\n",
      "Epoch 2350 Chain 0 loss std 9.16e-04 variance 4.20e-07 smooth variance 5.94e-07 adaptive c -1.00\n",
      "Epoch 2350 Chain 1 loss std 2.36e+02 variance 2.78e+04 smooth variance 2.34e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.038536\n",
      " Loss: 0.000000\n",
      " Loss: 0.057100\n",
      " Loss: 0.000000\n",
      " Loss: 0.029784\n",
      " Loss: 0.000000\n",
      " Loss: 0.013218\n",
      " Loss: 0.000000\n",
      " Loss: 0.022199\n",
      " Loss: 0.000000\n",
      " Loss: 0.015949\n",
      " Loss: 0.000000\n",
      " Loss: 0.065546\n",
      " Loss: 0.000000\n",
      " Loss: 0.027777\n",
      " Loss: 0.000000\n",
      " Loss: 0.021072\n",
      " Loss: 0.000000\n",
      " Loss: 0.030493\n",
      "Epoch 2352 Chain 0 loss std 8.03e-04 variance 3.22e-07 smooth variance 5.12e-07 adaptive c -1.00\n",
      "Epoch 2352 Chain 1 loss std 1.76e+02 variance 1.55e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014343\n",
      " Loss: 0.000000\n",
      " Loss: 0.024047\n",
      " Loss: 0.000000\n",
      " Loss: 0.036357\n",
      " Loss: 0.000000\n",
      " Loss: 0.021538\n",
      " Loss: 0.000000\n",
      " Loss: 0.064553\n",
      " Loss: 0.000000\n",
      " Loss: 0.034972\n",
      " Loss: 0.000000\n",
      " Loss: 0.023332\n",
      " Loss: 0.000000\n",
      " Loss: 0.057034\n",
      " Loss: 0.000000\n",
      " Loss: 0.020302\n",
      " Loss: 0.000000\n",
      " Loss: 0.025198\n",
      "Epoch 2354 Chain 0 loss std 5.33e-04 variance 1.42e-07 smooth variance 4.01e-07 adaptive c -1.00\n",
      "Epoch 2354 Chain 1 loss std 1.93e+02 variance 1.87e+04 smooth variance 2.03e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.072300\n",
      " Loss: 0.000000\n",
      " Loss: 0.014867\n",
      " Loss: 0.000000\n",
      " Loss: 0.017855\n",
      " Loss: 0.000000\n",
      " Loss: 0.033359\n",
      " Loss: 0.000000\n",
      " Loss: 0.022456\n",
      " Loss: 0.000000\n",
      " Loss: 0.016888\n",
      " Loss: 0.000000\n",
      " Loss: 0.060950\n",
      " Loss: 0.000000\n",
      " Loss: 0.020569\n",
      " Loss: 0.000000\n",
      " Loss: 0.023384\n",
      " Loss: 0.000000\n",
      " Loss: 0.039046\n",
      "Epoch 2356 Chain 0 loss std 1.02e-03 variance 5.18e-07 smooth variance 4.36e-07 adaptive c -1.00\n",
      "Epoch 2356 Chain 1 loss std 2.96e+02 variance 4.37e+04 smooth variance 2.73e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016797\n",
      " Loss: 0.000000\n",
      " Loss: 0.064424\n",
      " Loss: 0.000000\n",
      " Loss: 0.013164\n",
      " Loss: 0.000000\n",
      " Loss: 0.034830\n",
      " Loss: 0.000000\n",
      " Loss: 0.031623\n",
      " Loss: 0.000000\n",
      " Loss: 0.018683\n",
      " Loss: 0.000000\n",
      " Loss: 0.060636\n",
      " Loss: 0.000000\n",
      " Loss: 0.017190\n",
      " Loss: 0.000000\n",
      " Loss: 0.032631\n",
      " Loss: 0.000000\n",
      " Loss: 0.031697\n",
      "Epoch 2358 Chain 0 loss std 1.52e-03 variance 1.16e-06 smooth variance 6.52e-07 adaptive c -1.00\n",
      "Epoch 2358 Chain 1 loss std 2.25e+02 variance 2.54e+04 smooth variance 2.68e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019980\n",
      " Loss: 0.000000\n",
      " Loss: 0.024925\n",
      " Loss: 0.000000\n",
      " Loss: 0.018045\n",
      " Loss: 0.000000\n",
      " Loss: 0.026599\n",
      " Loss: 0.000000\n",
      " Loss: 0.071289\n",
      " Loss: 0.000000\n",
      " Loss: 0.041904\n",
      " Loss: 0.000000\n",
      " Loss: 0.057529\n",
      " Loss: 0.000000\n",
      " Loss: 0.020752\n",
      " Loss: 0.000000\n",
      " Loss: 0.021053\n",
      " Loss: 0.000000\n",
      " Loss: 0.019600\n",
      "Epoch 2360 Chain 0 loss std 8.60e-04 variance 3.70e-07 smooth variance 5.67e-07 adaptive c -1.00\n",
      "Epoch 2360 Chain 1 loss std 1.75e+02 variance 1.54e+04 smooth variance 2.33e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026273\n",
      " Loss: 0.000000\n",
      " Loss: 0.025206\n",
      " Loss: 0.000000\n",
      " Loss: 0.034930\n",
      " Loss: 0.000000\n",
      " Loss: 0.020050\n",
      " Loss: 0.000000\n",
      " Loss: 0.054379\n",
      " Loss: 0.000000\n",
      " Loss: 0.023684\n",
      " Loss: 0.000000\n",
      " Loss: 0.034603\n",
      " Loss: 0.000000\n",
      " Loss: 0.017829\n",
      " Loss: 0.000000\n",
      " Loss: 0.069953\n",
      " Loss: 0.000000\n",
      " Loss: 0.014769\n",
      "Epoch 2362 Chain 0 loss std 1.18e-03 variance 6.98e-07 smooth variance 6.06e-07 adaptive c -1.00\n",
      "Epoch 2362 Chain 1 loss std 2.33e+02 variance 2.71e+04 smooth variance 2.45e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.012643\n",
      " Loss: 0.000000\n",
      " Loss: 0.018866\n",
      " Loss: 0.000000\n",
      " Loss: 0.034756\n",
      " Loss: 0.000000\n",
      " Loss: 0.027223\n",
      " Loss: 0.000000\n",
      " Loss: 0.067350\n",
      " Loss: 0.000000\n",
      " Loss: 0.064827\n",
      " Loss: 0.000000\n",
      " Loss: 0.015556\n",
      " Loss: 0.000000\n",
      " Loss: 0.044174\n",
      " Loss: 0.000000\n",
      " Loss: 0.017337\n",
      " Loss: 0.000000\n",
      " Loss: 0.018943\n",
      "Epoch 2364 Chain 0 loss std 1.69e-03 variance 1.43e-06 smooth variance 8.53e-07 adaptive c -1.00\n",
      "Epoch 2364 Chain 1 loss std 2.27e+02 variance 2.58e+04 smooth variance 2.49e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.039397\n",
      " Loss: 0.000000\n",
      " Loss: 0.024324\n",
      " Loss: 0.000000\n",
      " Loss: 0.016074\n",
      " Loss: 0.000000\n",
      " Loss: 0.054923\n",
      " Loss: 0.000000\n",
      " Loss: 0.026120\n",
      " Loss: 0.000000\n",
      " Loss: 0.027588\n",
      " Loss: 0.000000\n",
      " Loss: 0.076294\n",
      " Loss: 0.000000\n",
      " Loss: 0.029799\n",
      " Loss: 0.000000\n",
      " Loss: 0.012806\n",
      " Loss: 0.000000\n",
      " Loss: 0.014352\n",
      "Epoch 2366 Chain 0 loss std 1.03e-03 variance 5.29e-07 smooth variance 7.56e-07 adaptive c -1.00\n",
      "Epoch 2366 Chain 1 loss std 1.82e+02 variance 1.66e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.068722\n",
      " Loss: 0.000000\n",
      " Loss: 0.016723\n",
      " Loss: 0.000000\n",
      " Loss: 0.023083\n",
      " Loss: 0.000000\n",
      " Loss: 0.021111\n",
      " Loss: 0.000000\n",
      " Loss: 0.031198\n",
      " Loss: 0.000000\n",
      " Loss: 0.016054\n",
      " Loss: 0.000000\n",
      " Loss: 0.021772\n",
      " Loss: 0.000000\n",
      " Loss: 0.072817\n",
      " Loss: 0.000000\n",
      " Loss: 0.038535\n",
      " Loss: 0.000000\n",
      " Loss: 0.011660\n",
      "Epoch 2368 Chain 0 loss std 1.34e-03 variance 8.92e-07 smooth variance 7.96e-07 adaptive c -1.00\n",
      "Epoch 2368 Chain 1 loss std 1.56e+02 variance 1.21e+04 smooth variance 1.93e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018930\n",
      " Loss: 0.000000\n",
      " Loss: 0.014043\n",
      " Loss: 0.000000\n",
      " Loss: 0.059388\n",
      " Loss: 0.000000\n",
      " Loss: 0.038291\n",
      " Loss: 0.000000\n",
      " Loss: 0.030186\n",
      " Loss: 0.000000\n",
      " Loss: 0.017459\n",
      " Loss: 0.000000\n",
      " Loss: 0.017315\n",
      " Loss: 0.000000\n",
      " Loss: 0.038329\n",
      " Loss: 0.000000\n",
      " Loss: 0.026536\n",
      " Loss: 0.000000\n",
      " Loss: 0.061199\n",
      "Epoch 2370 Chain 0 loss std 1.20e-03 variance 7.21e-07 smooth variance 7.74e-07 adaptive c -1.00\n",
      "Epoch 2370 Chain 1 loss std 1.96e+02 variance 1.92e+04 smooth variance 1.93e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.031921\n",
      " Loss: 0.000000\n",
      " Loss: 0.032867\n",
      " Loss: 0.000000\n",
      " Loss: 0.022378\n",
      " Loss: 0.000000\n",
      " Loss: 0.010397\n",
      " Loss: 0.000000\n",
      " Loss: 0.063275\n",
      " Loss: 0.000000\n",
      " Loss: 0.032463\n",
      " Loss: 0.000000\n",
      " Loss: 0.018146\n",
      " Loss: 0.000000\n",
      " Loss: 0.024789\n",
      " Loss: 0.000000\n",
      " Loss: 0.061991\n",
      " Loss: 0.000000\n",
      " Loss: 0.023448\n",
      "Epoch 2372 Chain 0 loss std 9.81e-04 variance 4.82e-07 smooth variance 6.86e-07 adaptive c -1.00\n",
      "Epoch 2372 Chain 1 loss std 1.68e+02 variance 1.41e+04 smooth variance 1.77e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026971\n",
      " Loss: 0.000000\n",
      " Loss: 0.019957\n",
      " Loss: 0.000000\n",
      " Loss: 0.074366\n",
      " Loss: 0.000000\n",
      " Loss: 0.023332\n",
      " Loss: 0.000000\n",
      " Loss: 0.016212\n",
      " Loss: 0.000000\n",
      " Loss: 0.019743\n",
      " Loss: 0.000000\n",
      " Loss: 0.023144\n",
      " Loss: 0.000000\n",
      " Loss: 0.018742\n",
      " Loss: 0.000000\n",
      " Loss: 0.039644\n",
      " Loss: 0.000000\n",
      " Loss: 0.059565\n",
      "Epoch 2374 Chain 0 loss std 1.25e-03 variance 7.78e-07 smooth variance 7.14e-07 adaptive c -1.00\n",
      "Epoch 2374 Chain 1 loss std 1.90e+02 variance 1.80e+04 smooth variance 1.78e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026655\n",
      " Loss: 0.000000\n",
      " Loss: 0.015638\n",
      " Loss: 0.000000\n",
      " Loss: 0.018935\n",
      " Loss: 0.000000\n",
      " Loss: 0.062323\n",
      " Loss: 0.000000\n",
      " Loss: 0.037287\n",
      " Loss: 0.000000\n",
      " Loss: 0.072923\n",
      " Loss: 0.000000\n",
      " Loss: 0.015681\n",
      " Loss: 0.000000\n",
      " Loss: 0.030485\n",
      " Loss: 0.000000\n",
      " Loss: 0.026052\n",
      " Loss: 0.000000\n",
      " Loss: 0.015697\n",
      "Epoch 2376 Chain 0 loss std 9.69e-04 variance 4.70e-07 smooth variance 6.40e-07 adaptive c -1.00\n",
      "Epoch 2376 Chain 1 loss std 2.50e+02 variance 3.13e+04 smooth variance 2.19e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014992\n",
      " Loss: 0.000000\n",
      " Loss: 0.079613\n",
      " Loss: 0.000000\n",
      " Loss: 0.022273\n",
      " Loss: 0.000000\n",
      " Loss: 0.028843\n",
      " Loss: 0.000000\n",
      " Loss: 0.015117\n",
      " Loss: 0.000000\n",
      " Loss: 0.012183\n",
      " Loss: 0.000000\n",
      " Loss: 0.031077\n",
      " Loss: 0.000000\n",
      " Loss: 0.043284\n",
      " Loss: 0.000000\n",
      " Loss: 0.059101\n",
      " Loss: 0.000000\n",
      " Loss: 0.015192\n",
      "Epoch 2378 Chain 0 loss std 1.08e-03 variance 5.78e-07 smooth variance 6.22e-07 adaptive c -1.00\n",
      "Epoch 2378 Chain 1 loss std 1.68e+02 variance 1.42e+04 smooth variance 1.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025025\n",
      " Loss: 0.000000\n",
      " Loss: 0.035694\n",
      " Loss: 0.000000\n",
      " Loss: 0.012605\n",
      " Loss: 0.000000\n",
      " Loss: 0.057034\n",
      " Loss: 0.000000\n",
      " Loss: 0.030479\n",
      " Loss: 0.000000\n",
      " Loss: 0.029452\n",
      " Loss: 0.000000\n",
      " Loss: 0.019688\n",
      " Loss: 0.000000\n",
      " Loss: 0.026422\n",
      " Loss: 0.000000\n",
      " Loss: 0.021110\n",
      " Loss: 0.000000\n",
      " Loss: 0.064166\n",
      "Epoch 2380 Chain 0 loss std 1.36e-03 variance 9.29e-07 smooth variance 7.14e-07 adaptive c -1.00\n",
      "Epoch 2380 Chain 1 loss std 2.55e+02 variance 3.25e+04 smooth variance 2.34e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.059699\n",
      " Loss: 0.000000\n",
      " Loss: 0.041901\n",
      " Loss: 0.000000\n",
      " Loss: 0.021677\n",
      " Loss: 0.000000\n",
      " Loss: 0.016119\n",
      " Loss: 0.000000\n",
      " Loss: 0.021441\n",
      " Loss: 0.000000\n",
      " Loss: 0.019323\n",
      " Loss: 0.000000\n",
      " Loss: 0.067857\n",
      " Loss: 0.000000\n",
      " Loss: 0.023028\n",
      " Loss: 0.000000\n",
      " Loss: 0.014260\n",
      " Loss: 0.000000\n",
      " Loss: 0.036370\n",
      "Epoch 2382 Chain 0 loss std 9.31e-04 variance 4.33e-07 smooth variance 6.30e-07 adaptive c -1.00\n",
      "Epoch 2382 Chain 1 loss std 2.26e+02 variance 2.55e+04 smooth variance 2.41e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.060098\n",
      " Loss: 0.000000\n",
      " Loss: 0.018313\n",
      " Loss: 0.000000\n",
      " Loss: 0.045264\n",
      " Loss: 0.000000\n",
      " Loss: 0.015051\n",
      " Loss: 0.000000\n",
      " Loss: 0.022111\n",
      " Loss: 0.000000\n",
      " Loss: 0.024309\n",
      " Loss: 0.000000\n",
      " Loss: 0.021223\n",
      " Loss: 0.000000\n",
      " Loss: 0.012616\n",
      " Loss: 0.000000\n",
      " Loss: 0.067619\n",
      " Loss: 0.000000\n",
      " Loss: 0.035071\n",
      "Epoch 2384 Chain 0 loss std 6.62e-04 variance 2.19e-07 smooth variance 5.07e-07 adaptive c -1.00\n",
      "Epoch 2384 Chain 1 loss std 1.92e+02 variance 1.84e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.088990\n",
      " Loss: 0.000000\n",
      " Loss: 0.013339\n",
      " Loss: 0.000000\n",
      " Loss: 0.021829\n",
      " Loss: 0.000000\n",
      " Loss: 0.016998\n",
      " Loss: 0.000000\n",
      " Loss: 0.019683\n",
      " Loss: 0.000000\n",
      " Loss: 0.028282\n",
      " Loss: 0.000000\n",
      " Loss: 0.013460\n",
      " Loss: 0.000000\n",
      " Loss: 0.021239\n",
      " Loss: 0.000000\n",
      " Loss: 0.058809\n",
      " Loss: 0.000000\n",
      " Loss: 0.039048\n",
      "Epoch 2386 Chain 0 loss std 7.09e-04 variance 2.51e-07 smooth variance 4.30e-07 adaptive c -1.00\n",
      "Epoch 2386 Chain 1 loss std 1.62e+02 variance 1.32e+04 smooth variance 1.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033304\n",
      " Loss: 0.000000\n",
      " Loss: 0.062444\n",
      " Loss: 0.000000\n",
      " Loss: 0.024740\n",
      " Loss: 0.000000\n",
      " Loss: 0.016355\n",
      " Loss: 0.000000\n",
      " Loss: 0.023994\n",
      " Loss: 0.000000\n",
      " Loss: 0.029749\n",
      " Loss: 0.000000\n",
      " Loss: 0.060756\n",
      " Loss: 0.000000\n",
      " Loss: 0.020306\n",
      " Loss: 0.000000\n",
      " Loss: 0.025445\n",
      " Loss: 0.000000\n",
      " Loss: 0.024581\n",
      "Epoch 2388 Chain 0 loss std 8.09e-04 variance 3.27e-07 smooth variance 3.99e-07 adaptive c -1.00\n",
      "Epoch 2388 Chain 1 loss std 1.65e+02 variance 1.36e+04 smooth variance 1.78e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033880\n",
      " Loss: 0.000000\n",
      " Loss: 0.070218\n",
      " Loss: 0.000000\n",
      " Loss: 0.017133\n",
      " Loss: 0.000000\n",
      " Loss: 0.021522\n",
      " Loss: 0.000000\n",
      " Loss: 0.018085\n",
      " Loss: 0.000000\n",
      " Loss: 0.019082\n",
      " Loss: 0.000000\n",
      " Loss: 0.025563\n",
      " Loss: 0.000000\n",
      " Loss: 0.032874\n",
      " Loss: 0.000000\n",
      " Loss: 0.024181\n",
      " Loss: 0.000000\n",
      " Loss: 0.059137\n",
      "Epoch 2390 Chain 0 loss std 9.47e-04 variance 4.48e-07 smooth variance 4.14e-07 adaptive c -1.00\n",
      "Epoch 2390 Chain 1 loss std 2.53e+02 variance 3.21e+04 smooth variance 2.21e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026867\n",
      " Loss: 0.000000\n",
      " Loss: 0.025117\n",
      " Loss: 0.000000\n",
      " Loss: 0.011710\n",
      " Loss: 0.000000\n",
      " Loss: 0.015679\n",
      " Loss: 0.000000\n",
      " Loss: 0.081465\n",
      " Loss: 0.000000\n",
      " Loss: 0.063220\n",
      " Loss: 0.000000\n",
      " Loss: 0.019487\n",
      " Loss: 0.000000\n",
      " Loss: 0.013798\n",
      " Loss: 0.000000\n",
      " Loss: 0.041107\n",
      " Loss: 0.000000\n",
      " Loss: 0.023225\n",
      "Epoch 2392 Chain 0 loss std 1.28e-03 variance 8.14e-07 smooth variance 5.34e-07 adaptive c -1.00\n",
      "Epoch 2392 Chain 1 loss std 1.68e+02 variance 1.41e+04 smooth variance 1.97e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.069462\n",
      " Loss: 0.000000\n",
      " Loss: 0.013961\n",
      " Loss: 0.000000\n",
      " Loss: 0.021355\n",
      " Loss: 0.000000\n",
      " Loss: 0.022158\n",
      " Loss: 0.000000\n",
      " Loss: 0.033901\n",
      " Loss: 0.000000\n",
      " Loss: 0.075957\n",
      " Loss: 0.000000\n",
      " Loss: 0.030274\n",
      " Loss: 0.000000\n",
      " Loss: 0.018975\n",
      " Loss: 0.000000\n",
      " Loss: 0.018075\n",
      " Loss: 0.000000\n",
      " Loss: 0.017557\n",
      "Epoch 2394 Chain 0 loss std 1.08e-03 variance 5.79e-07 smooth variance 5.47e-07 adaptive c -1.00\n",
      "Epoch 2394 Chain 1 loss std 2.42e+02 variance 2.93e+04 smooth variance 2.26e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016353\n",
      " Loss: 0.000000\n",
      " Loss: 0.024763\n",
      " Loss: 0.000000\n",
      " Loss: 0.062590\n",
      " Loss: 0.000000\n",
      " Loss: 0.041934\n",
      " Loss: 0.000000\n",
      " Loss: 0.015197\n",
      " Loss: 0.000000\n",
      " Loss: 0.074505\n",
      " Loss: 0.000000\n",
      " Loss: 0.024557\n",
      " Loss: 0.000000\n",
      " Loss: 0.024631\n",
      " Loss: 0.000000\n",
      " Loss: 0.023335\n",
      " Loss: 0.000000\n",
      " Loss: 0.013810\n",
      "Epoch 2396 Chain 0 loss std 1.07e-03 variance 5.70e-07 smooth variance 5.54e-07 adaptive c -1.00\n",
      "Epoch 2396 Chain 1 loss std 1.56e+02 variance 1.21e+04 smooth variance 1.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037583\n",
      " Loss: 0.000000\n",
      " Loss: 0.027163\n",
      " Loss: 0.000000\n",
      " Loss: 0.059720\n",
      " Loss: 0.000000\n",
      " Loss: 0.021248\n",
      " Loss: 0.000000\n",
      " Loss: 0.015123\n",
      " Loss: 0.000000\n",
      " Loss: 0.012867\n",
      " Loss: 0.000000\n",
      " Loss: 0.029238\n",
      " Loss: 0.000000\n",
      " Loss: 0.023000\n",
      " Loss: 0.000000\n",
      " Loss: 0.084505\n",
      " Loss: 0.000000\n",
      " Loss: 0.011228\n",
      "Epoch 2398 Chain 0 loss std 1.16e-03 variance 6.78e-07 smooth variance 5.91e-07 adaptive c -1.00\n",
      "Epoch 2398 Chain 1 loss std 2.26e+02 variance 2.55e+04 smooth variance 2.13e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018989\n",
      " Loss: 0.000000\n",
      " Loss: 0.018877\n",
      " Loss: 0.000000\n",
      " Loss: 0.055193\n",
      " Loss: 0.000000\n",
      " Loss: 0.047855\n",
      " Loss: 0.000000\n",
      " Loss: 0.019923\n",
      " Loss: 0.000000\n",
      " Loss: 0.016484\n",
      " Loss: 0.000000\n",
      " Loss: 0.011621\n",
      " Loss: 0.000000\n",
      " Loss: 0.019434\n",
      " Loss: 0.000000\n",
      " Loss: 0.063703\n",
      " Loss: 0.000000\n",
      " Loss: 0.049596\n",
      "Epoch 2400 Chain 0 loss std 1.25e-03 variance 7.76e-07 smooth variance 6.47e-07 adaptive c -1.00\n",
      "Epoch 2400 Chain 1 loss std 1.84e+02 variance 1.68e+04 smooth variance 1.99e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029488\n",
      " Loss: 0.000000\n",
      " Loss: 0.027732\n",
      " Loss: 0.000000\n",
      " Loss: 0.059771\n",
      " Loss: 0.000000\n",
      " Loss: 0.016302\n",
      " Loss: 0.000000\n",
      " Loss: 0.027544\n",
      " Loss: 0.000000\n",
      " Loss: 0.019865\n",
      " Loss: 0.000000\n",
      " Loss: 0.036424\n",
      " Loss: 0.000000\n",
      " Loss: 0.065644\n",
      " Loss: 0.000000\n",
      " Loss: 0.021953\n",
      " Loss: 0.000000\n",
      " Loss: 0.016951\n",
      "Epoch 2402 Chain 0 loss std 1.03e-03 variance 5.30e-07 smooth variance 6.12e-07 adaptive c -1.00\n",
      "Epoch 2402 Chain 1 loss std 1.63e+02 variance 1.33e+04 smooth variance 1.79e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.009498\n",
      " Loss: 0.000000\n",
      " Loss: 0.042726\n",
      " Loss: 0.000000\n",
      " Loss: 0.056470\n",
      " Loss: 0.000000\n",
      " Loss: 0.027820\n",
      " Loss: 0.000000\n",
      " Loss: 0.024323\n",
      " Loss: 0.000000\n",
      " Loss: 0.018011\n",
      " Loss: 0.000000\n",
      " Loss: 0.038521\n",
      " Loss: 0.000000\n",
      " Loss: 0.056037\n",
      " Loss: 0.000000\n",
      " Loss: 0.027187\n",
      " Loss: 0.000000\n",
      " Loss: 0.021081\n",
      "Epoch 2404 Chain 0 loss std 1.24e-03 variance 7.66e-07 smooth variance 6.58e-07 adaptive c -1.00\n",
      "Epoch 2404 Chain 1 loss std 1.99e+02 variance 1.99e+04 smooth variance 1.85e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.039749\n",
      " Loss: 0.000000\n",
      " Loss: 0.024759\n",
      " Loss: 0.000000\n",
      " Loss: 0.018359\n",
      " Loss: 0.000000\n",
      " Loss: 0.015855\n",
      " Loss: 0.000000\n",
      " Loss: 0.062115\n",
      " Loss: 0.000000\n",
      " Loss: 0.080388\n",
      " Loss: 0.000000\n",
      " Loss: 0.015926\n",
      " Loss: 0.000000\n",
      " Loss: 0.029673\n",
      " Loss: 0.000000\n",
      " Loss: 0.018065\n",
      " Loss: 0.000000\n",
      " Loss: 0.016786\n",
      "Epoch 2406 Chain 0 loss std 6.86e-04 variance 2.36e-07 smooth variance 5.31e-07 adaptive c -1.00\n",
      "Epoch 2406 Chain 1 loss std 1.84e+02 variance 1.70e+04 smooth variance 1.81e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.059554\n",
      " Loss: 0.000000\n",
      " Loss: 0.019835\n",
      " Loss: 0.000000\n",
      " Loss: 0.029584\n",
      " Loss: 0.000000\n",
      " Loss: 0.035304\n",
      " Loss: 0.000000\n",
      " Loss: 0.016561\n",
      " Loss: 0.000000\n",
      " Loss: 0.019530\n",
      " Loss: 0.000000\n",
      " Loss: 0.032701\n",
      " Loss: 0.000000\n",
      " Loss: 0.009670\n",
      " Loss: 0.000000\n",
      " Loss: 0.073763\n",
      " Loss: 0.000000\n",
      " Loss: 0.025174\n",
      "Epoch 2408 Chain 0 loss std 8.24e-04 variance 3.39e-07 smooth variance 4.74e-07 adaptive c -1.00\n",
      "Epoch 2408 Chain 1 loss std 1.64e+02 variance 1.34e+04 smooth variance 1.67e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019486\n",
      " Loss: 0.000000\n",
      " Loss: 0.024993\n",
      " Loss: 0.000000\n",
      " Loss: 0.040097\n",
      " Loss: 0.000000\n",
      " Loss: 0.021446\n",
      " Loss: 0.000000\n",
      " Loss: 0.054816\n",
      " Loss: 0.000000\n",
      " Loss: 0.029700\n",
      " Loss: 0.000000\n",
      " Loss: 0.014977\n",
      " Loss: 0.000000\n",
      " Loss: 0.017220\n",
      " Loss: 0.000000\n",
      " Loss: 0.023034\n",
      " Loss: 0.000000\n",
      " Loss: 0.075906\n",
      "Epoch 2410 Chain 0 loss std 1.24e-03 variance 7.74e-07 smooth variance 5.64e-07 adaptive c -1.00\n",
      "Epoch 2410 Chain 1 loss std 2.34e+02 variance 2.73e+04 smooth variance 1.99e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.056200\n",
      " Loss: 0.000000\n",
      " Loss: 0.018626\n",
      " Loss: 0.000000\n",
      " Loss: 0.042915\n",
      " Loss: 0.000000\n",
      " Loss: 0.023726\n",
      " Loss: 0.000000\n",
      " Loss: 0.019370\n",
      " Loss: 0.000000\n",
      " Loss: 0.032948\n",
      " Loss: 0.000000\n",
      " Loss: 0.030612\n",
      " Loss: 0.000000\n",
      " Loss: 0.015060\n",
      " Loss: 0.000000\n",
      " Loss: 0.022918\n",
      " Loss: 0.000000\n",
      " Loss: 0.059299\n",
      "Epoch 2412 Chain 0 loss std 1.27e-03 variance 8.11e-07 smooth variance 6.38e-07 adaptive c -1.00\n",
      "Epoch 2412 Chain 1 loss std 2.11e+02 variance 2.22e+04 smooth variance 2.06e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017671\n",
      " Loss: 0.000000\n",
      " Loss: 0.017235\n",
      " Loss: 0.000000\n",
      " Loss: 0.014422\n",
      " Loss: 0.000000\n",
      " Loss: 0.062628\n",
      " Loss: 0.000000\n",
      " Loss: 0.048882\n",
      " Loss: 0.000000\n",
      " Loss: 0.024427\n",
      " Loss: 0.000000\n",
      " Loss: 0.018119\n",
      " Loss: 0.000000\n",
      " Loss: 0.025482\n",
      " Loss: 0.000000\n",
      " Loss: 0.020945\n",
      " Loss: 0.000000\n",
      " Loss: 0.071864\n",
      "Epoch 2414 Chain 0 loss std 9.89e-04 variance 4.89e-07 smooth variance 5.93e-07 adaptive c -1.00\n",
      "Epoch 2414 Chain 1 loss std 2.00e+02 variance 2.01e+04 smooth variance 2.04e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032763\n",
      " Loss: 0.000000\n",
      " Loss: 0.017767\n",
      " Loss: 0.000000\n",
      " Loss: 0.012788\n",
      " Loss: 0.000000\n",
      " Loss: 0.078993\n",
      " Loss: 0.000000\n",
      " Loss: 0.018526\n",
      " Loss: 0.000000\n",
      " Loss: 0.012245\n",
      " Loss: 0.000000\n",
      " Loss: 0.025612\n",
      " Loss: 0.000000\n",
      " Loss: 0.019957\n",
      " Loss: 0.000000\n",
      " Loss: 0.033144\n",
      " Loss: 0.000000\n",
      " Loss: 0.069881\n",
      "Epoch 2416 Chain 0 loss std 9.41e-04 variance 4.43e-07 smooth variance 5.48e-07 adaptive c -1.00\n",
      "Epoch 2416 Chain 1 loss std 1.62e+02 variance 1.31e+04 smooth variance 1.82e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.056296\n",
      " Loss: 0.000000\n",
      " Loss: 0.023494\n",
      " Loss: 0.000000\n",
      " Loss: 0.024798\n",
      " Loss: 0.000000\n",
      " Loss: 0.013622\n",
      " Loss: 0.000000\n",
      " Loss: 0.042628\n",
      " Loss: 0.000000\n",
      " Loss: 0.017770\n",
      " Loss: 0.000000\n",
      " Loss: 0.037029\n",
      " Loss: 0.000000\n",
      " Loss: 0.064978\n",
      " Loss: 0.000000\n",
      " Loss: 0.026304\n",
      " Loss: 0.000000\n",
      " Loss: 0.014757\n",
      "Epoch 2418 Chain 0 loss std 7.62e-04 variance 2.90e-07 smooth variance 4.71e-07 adaptive c -1.00\n",
      "Epoch 2418 Chain 1 loss std 1.81e+02 variance 1.64e+04 smooth variance 1.77e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029264\n",
      " Loss: 0.000000\n",
      " Loss: 0.061241\n",
      " Loss: 0.000000\n",
      " Loss: 0.018030\n",
      " Loss: 0.000000\n",
      " Loss: 0.017844\n",
      " Loss: 0.000000\n",
      " Loss: 0.034458\n",
      " Loss: 0.000000\n",
      " Loss: 0.021439\n",
      " Loss: 0.000000\n",
      " Loss: 0.036047\n",
      " Loss: 0.000000\n",
      " Loss: 0.067310\n",
      " Loss: 0.000000\n",
      " Loss: 0.014995\n",
      " Loss: 0.000000\n",
      " Loss: 0.021046\n",
      "Epoch 2420 Chain 0 loss std 1.08e-03 variance 5.78e-07 smooth variance 5.03e-07 adaptive c -1.00\n",
      "Epoch 2420 Chain 1 loss std 1.87e+02 variance 1.75e+04 smooth variance 1.76e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028184\n",
      " Loss: 0.000000\n",
      " Loss: 0.018748\n",
      " Loss: 0.000000\n",
      " Loss: 0.022017\n",
      " Loss: 0.000000\n",
      " Loss: 0.018275\n",
      " Loss: 0.000000\n",
      " Loss: 0.073615\n",
      " Loss: 0.000000\n",
      " Loss: 0.012602\n",
      " Loss: 0.000000\n",
      " Loss: 0.033211\n",
      " Loss: 0.000000\n",
      " Loss: 0.044872\n",
      " Loss: 0.000000\n",
      " Loss: 0.058588\n",
      " Loss: 0.000000\n",
      " Loss: 0.011564\n",
      "Epoch 2422 Chain 0 loss std 1.16e-03 variance 6.77e-07 smooth variance 5.55e-07 adaptive c -1.00\n",
      "Epoch 2422 Chain 1 loss std 1.62e+02 variance 1.32e+04 smooth variance 1.63e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.068095\n",
      " Loss: 0.000000\n",
      " Loss: 0.011044\n",
      " Loss: 0.000000\n",
      " Loss: 0.029888\n",
      " Loss: 0.000000\n",
      " Loss: 0.021656\n",
      " Loss: 0.000000\n",
      " Loss: 0.030154\n",
      " Loss: 0.000000\n",
      " Loss: 0.023718\n",
      " Loss: 0.000000\n",
      " Loss: 0.075170\n",
      " Loss: 0.000000\n",
      " Loss: 0.032814\n",
      " Loss: 0.000000\n",
      " Loss: 0.016846\n",
      " Loss: 0.000000\n",
      " Loss: 0.012290\n",
      "Epoch 2424 Chain 0 loss std 5.06e-04 variance 1.28e-07 smooth variance 4.27e-07 adaptive c -1.00\n",
      "Epoch 2424 Chain 1 loss std 2.05e+02 variance 2.10e+04 smooth variance 1.77e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018911\n",
      " Loss: 0.000000\n",
      " Loss: 0.014233\n",
      " Loss: 0.000000\n",
      " Loss: 0.023800\n",
      " Loss: 0.000000\n",
      " Loss: 0.024608\n",
      " Loss: 0.000000\n",
      " Loss: 0.079285\n",
      " Loss: 0.000000\n",
      " Loss: 0.081387\n",
      " Loss: 0.000000\n",
      " Loss: 0.027772\n",
      " Loss: 0.000000\n",
      " Loss: 0.022253\n",
      " Loss: 0.000000\n",
      " Loss: 0.014273\n",
      " Loss: 0.000000\n",
      " Loss: 0.015153\n",
      "Epoch 2426 Chain 0 loss std 1.15e-03 variance 6.60e-07 smooth variance 4.97e-07 adaptive c -1.00\n",
      "Epoch 2426 Chain 1 loss std 1.58e+02 variance 1.25e+04 smooth variance 1.61e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019482\n",
      " Loss: 0.000000\n",
      " Loss: 0.055082\n",
      " Loss: 0.000000\n",
      " Loss: 0.023552\n",
      " Loss: 0.000000\n",
      " Loss: 0.046239\n",
      " Loss: 0.000000\n",
      " Loss: 0.016483\n",
      " Loss: 0.000000\n",
      " Loss: 0.014721\n",
      " Loss: 0.000000\n",
      " Loss: 0.026357\n",
      " Loss: 0.000000\n",
      " Loss: 0.065396\n",
      " Loss: 0.000000\n",
      " Loss: 0.015755\n",
      " Loss: 0.000000\n",
      " Loss: 0.038608\n",
      "Epoch 2428 Chain 0 loss std 1.05e-03 variance 5.50e-07 smooth variance 5.13e-07 adaptive c -1.00\n",
      "Epoch 2428 Chain 1 loss std 1.68e+02 variance 1.40e+04 smooth variance 1.55e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016232\n",
      " Loss: 0.000000\n",
      " Loss: 0.015036\n",
      " Loss: 0.000000\n",
      " Loss: 0.065946\n",
      " Loss: 0.000000\n",
      " Loss: 0.029210\n",
      " Loss: 0.000000\n",
      " Loss: 0.034415\n",
      " Loss: 0.000000\n",
      " Loss: 0.016467\n",
      " Loss: 0.000000\n",
      " Loss: 0.050031\n",
      " Loss: 0.000000\n",
      " Loss: 0.015259\n",
      " Loss: 0.000000\n",
      " Loss: 0.064573\n",
      " Loss: 0.000000\n",
      " Loss: 0.014507\n",
      "Epoch 2430 Chain 0 loss std 9.45e-04 variance 4.47e-07 smooth variance 4.93e-07 adaptive c -1.00\n",
      "Epoch 2430 Chain 1 loss std 1.84e+02 variance 1.69e+04 smooth variance 1.59e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.043962\n",
      " Loss: 0.000000\n",
      " Loss: 0.016432\n",
      " Loss: 0.000000\n",
      " Loss: 0.061157\n",
      " Loss: 0.000000\n",
      " Loss: 0.020182\n",
      " Loss: 0.000000\n",
      " Loss: 0.019105\n",
      " Loss: 0.000000\n",
      " Loss: 0.041869\n",
      " Loss: 0.000000\n",
      " Loss: 0.021687\n",
      " Loss: 0.000000\n",
      " Loss: 0.014256\n",
      " Loss: 0.000000\n",
      " Loss: 0.061589\n",
      " Loss: 0.000000\n",
      " Loss: 0.021437\n",
      "Epoch 2432 Chain 0 loss std 1.21e-03 variance 7.30e-07 smooth variance 5.64e-07 adaptive c -1.00\n",
      "Epoch 2432 Chain 1 loss std 2.08e+02 variance 2.16e+04 smooth variance 1.76e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022278\n",
      " Loss: 0.000000\n",
      " Loss: 0.016750\n",
      " Loss: 0.000000\n",
      " Loss: 0.064446\n",
      " Loss: 0.000000\n",
      " Loss: 0.041194\n",
      " Loss: 0.000000\n",
      " Loss: 0.016170\n",
      " Loss: 0.000000\n",
      " Loss: 0.083677\n",
      " Loss: 0.000000\n",
      " Loss: 0.022637\n",
      " Loss: 0.000000\n",
      " Loss: 0.016422\n",
      " Loss: 0.000000\n",
      " Loss: 0.013611\n",
      " Loss: 0.000000\n",
      " Loss: 0.024490\n",
      "Epoch 2434 Chain 0 loss std 9.32e-04 variance 4.34e-07 smooth variance 5.25e-07 adaptive c -1.00\n",
      "Epoch 2434 Chain 1 loss std 2.65e+02 variance 3.51e+04 smooth variance 2.29e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025186\n",
      " Loss: 0.000000\n",
      " Loss: 0.059234\n",
      " Loss: 0.000000\n",
      " Loss: 0.038788\n",
      " Loss: 0.000000\n",
      " Loss: 0.020989\n",
      " Loss: 0.000000\n",
      " Loss: 0.016640\n",
      " Loss: 0.000000\n",
      " Loss: 0.071474\n",
      " Loss: 0.000000\n",
      " Loss: 0.015531\n",
      " Loss: 0.000000\n",
      " Loss: 0.033189\n",
      " Loss: 0.000000\n",
      " Loss: 0.017604\n",
      " Loss: 0.000000\n",
      " Loss: 0.023040\n",
      "Epoch 2436 Chain 0 loss std 9.89e-04 variance 4.89e-07 smooth variance 5.14e-07 adaptive c -1.00\n",
      "Epoch 2436 Chain 1 loss std 2.11e+02 variance 2.23e+04 smooth variance 2.27e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018305\n",
      " Loss: 0.000000\n",
      " Loss: 0.068918\n",
      " Loss: 0.000000\n",
      " Loss: 0.041870\n",
      " Loss: 0.000000\n",
      " Loss: 0.015952\n",
      " Loss: 0.000000\n",
      " Loss: 0.015793\n",
      " Loss: 0.000000\n",
      " Loss: 0.061075\n",
      " Loss: 0.000000\n",
      " Loss: 0.039593\n",
      " Loss: 0.000000\n",
      " Loss: 0.019485\n",
      " Loss: 0.000000\n",
      " Loss: 0.017667\n",
      " Loss: 0.000000\n",
      " Loss: 0.023017\n",
      "Epoch 2438 Chain 0 loss std 9.36e-04 variance 4.38e-07 smooth variance 4.91e-07 adaptive c -1.00\n",
      "Epoch 2438 Chain 1 loss std 1.76e+02 variance 1.54e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.064836\n",
      " Loss: 0.000000\n",
      " Loss: 0.033099\n",
      " Loss: 0.000000\n",
      " Loss: 0.014211\n",
      " Loss: 0.000000\n",
      " Loss: 0.023381\n",
      " Loss: 0.000000\n",
      " Loss: 0.025311\n",
      " Loss: 0.000000\n",
      " Loss: 0.063641\n",
      " Loss: 0.000000\n",
      " Loss: 0.020227\n",
      " Loss: 0.000000\n",
      " Loss: 0.015260\n",
      " Loss: 0.000000\n",
      " Loss: 0.048188\n",
      " Loss: 0.000000\n",
      " Loss: 0.013521\n",
      "Epoch 2440 Chain 0 loss std 9.44e-04 variance 4.45e-07 smooth variance 4.78e-07 adaptive c -1.00\n",
      "Epoch 2440 Chain 1 loss std 2.20e+02 variance 2.43e+04 smooth variance 2.16e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.077068\n",
      " Loss: 0.000000\n",
      " Loss: 0.021873\n",
      " Loss: 0.000000\n",
      " Loss: 0.011989\n",
      " Loss: 0.000000\n",
      " Loss: 0.014802\n",
      " Loss: 0.000000\n",
      " Loss: 0.035106\n",
      " Loss: 0.000000\n",
      " Loss: 0.037087\n",
      " Loss: 0.000000\n",
      " Loss: 0.029142\n",
      " Loss: 0.000000\n",
      " Loss: 0.056640\n",
      " Loss: 0.000000\n",
      " Loss: 0.019915\n",
      " Loss: 0.000000\n",
      " Loss: 0.018053\n",
      "Epoch 2442 Chain 0 loss std 8.13e-04 variance 3.30e-07 smooth variance 4.33e-07 adaptive c -1.00\n",
      "Epoch 2442 Chain 1 loss std 2.00e+02 variance 1.99e+04 smooth variance 2.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021249\n",
      " Loss: 0.000000\n",
      " Loss: 0.024744\n",
      " Loss: 0.000000\n",
      " Loss: 0.065731\n",
      " Loss: 0.000000\n",
      " Loss: 0.019916\n",
      " Loss: 0.000000\n",
      " Loss: 0.029198\n",
      " Loss: 0.000000\n",
      " Loss: 0.014508\n",
      " Loss: 0.000000\n",
      " Loss: 0.046878\n",
      " Loss: 0.000000\n",
      " Loss: 0.021371\n",
      " Loss: 0.000000\n",
      " Loss: 0.063046\n",
      " Loss: 0.000000\n",
      " Loss: 0.015035\n",
      "Epoch 2444 Chain 0 loss std 7.37e-04 variance 2.71e-07 smooth variance 3.85e-07 adaptive c -1.00\n",
      "Epoch 2444 Chain 1 loss std 1.65e+02 variance 1.36e+04 smooth variance 1.89e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023098\n",
      " Loss: 0.000000\n",
      " Loss: 0.016619\n",
      " Loss: 0.000000\n",
      " Loss: 0.054267\n",
      " Loss: 0.000000\n",
      " Loss: 0.041249\n",
      " Loss: 0.000000\n",
      " Loss: 0.025605\n",
      " Loss: 0.000000\n",
      " Loss: 0.019200\n",
      " Loss: 0.000000\n",
      " Loss: 0.021960\n",
      " Loss: 0.000000\n",
      " Loss: 0.011842\n",
      " Loss: 0.000000\n",
      " Loss: 0.046297\n",
      " Loss: 0.000000\n",
      " Loss: 0.061539\n",
      "Epoch 2446 Chain 0 loss std 1.18e-03 variance 6.91e-07 smooth variance 4.77e-07 adaptive c -1.00\n",
      "Epoch 2446 Chain 1 loss std 2.55e+02 variance 3.24e+04 smooth variance 2.29e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020329\n",
      " Loss: 0.000000\n",
      " Loss: 0.021518\n",
      " Loss: 0.000000\n",
      " Loss: 0.021303\n",
      " Loss: 0.000000\n",
      " Loss: 0.055624\n",
      " Loss: 0.000000\n",
      " Loss: 0.042063\n",
      " Loss: 0.000000\n",
      " Loss: 0.063871\n",
      " Loss: 0.000000\n",
      " Loss: 0.019482\n",
      " Loss: 0.000000\n",
      " Loss: 0.021661\n",
      " Loss: 0.000000\n",
      " Loss: 0.038411\n",
      " Loss: 0.000000\n",
      " Loss: 0.017413\n",
      "Epoch 2448 Chain 0 loss std 9.74e-04 variance 4.74e-07 smooth variance 4.76e-07 adaptive c -1.00\n",
      "Epoch 2448 Chain 1 loss std 2.82e+02 variance 3.99e+04 smooth variance 2.80e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.057896\n",
      " Loss: 0.000000\n",
      " Loss: 0.023706\n",
      " Loss: 0.000000\n",
      " Loss: 0.020198\n",
      " Loss: 0.000000\n",
      " Loss: 0.023690\n",
      " Loss: 0.000000\n",
      " Loss: 0.035348\n",
      " Loss: 0.000000\n",
      " Loss: 0.026328\n",
      " Loss: 0.000000\n",
      " Loss: 0.024290\n",
      " Loss: 0.000000\n",
      " Loss: 0.010245\n",
      " Loss: 0.000000\n",
      " Loss: 0.058901\n",
      " Loss: 0.000000\n",
      " Loss: 0.041074\n",
      "Epoch 2450 Chain 0 loss std 1.29e-03 variance 8.33e-07 smooth variance 5.83e-07 adaptive c -1.00\n",
      "Epoch 2450 Chain 1 loss std 1.59e+02 variance 1.27e+04 smooth variance 2.34e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020096\n",
      " Loss: 0.000000\n",
      " Loss: 0.028156\n",
      " Loss: 0.000000\n",
      " Loss: 0.030596\n",
      " Loss: 0.000000\n",
      " Loss: 0.016861\n",
      " Loss: 0.000000\n",
      " Loss: 0.065128\n",
      " Loss: 0.000000\n",
      " Loss: 0.027194\n",
      " Loss: 0.000000\n",
      " Loss: 0.025943\n",
      " Loss: 0.000000\n",
      " Loss: 0.024755\n",
      " Loss: 0.000000\n",
      " Loss: 0.021499\n",
      " Loss: 0.000000\n",
      " Loss: 0.061446\n",
      "Epoch 2452 Chain 0 loss std 8.89e-04 variance 3.95e-07 smooth variance 5.27e-07 adaptive c -1.00\n",
      "Epoch 2452 Chain 1 loss std 2.36e+02 variance 2.78e+04 smooth variance 2.47e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021111\n",
      " Loss: 0.000000\n",
      " Loss: 0.013664\n",
      " Loss: 0.000000\n",
      " Loss: 0.080102\n",
      " Loss: 0.000000\n",
      " Loss: 0.022948\n",
      " Loss: 0.000000\n",
      " Loss: 0.023012\n",
      " Loss: 0.000000\n",
      " Loss: 0.024781\n",
      " Loss: 0.000000\n",
      " Loss: 0.079225\n",
      " Loss: 0.000000\n",
      " Loss: 0.024215\n",
      " Loss: 0.000000\n",
      " Loss: 0.017507\n",
      " Loss: 0.000000\n",
      " Loss: 0.015110\n",
      "Epoch 2454 Chain 0 loss std 8.07e-04 variance 3.26e-07 smooth variance 4.66e-07 adaptive c -1.00\n",
      "Epoch 2454 Chain 1 loss std 2.13e+02 variance 2.26e+04 smooth variance 2.41e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018981\n",
      " Loss: 0.000000\n",
      " Loss: 0.065171\n",
      " Loss: 0.000000\n",
      " Loss: 0.030707\n",
      " Loss: 0.000000\n",
      " Loss: 0.016339\n",
      " Loss: 0.000000\n",
      " Loss: 0.029639\n",
      " Loss: 0.000000\n",
      " Loss: 0.075801\n",
      " Loss: 0.000000\n",
      " Loss: 0.031705\n",
      " Loss: 0.000000\n",
      " Loss: 0.012547\n",
      " Loss: 0.000000\n",
      " Loss: 0.021931\n",
      " Loss: 0.000000\n",
      " Loss: 0.018854\n",
      "Epoch 2456 Chain 0 loss std 6.69e-04 variance 2.23e-07 smooth variance 3.94e-07 adaptive c -1.00\n",
      "Epoch 2456 Chain 1 loss std 2.01e+02 variance 2.02e+04 smooth variance 2.29e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027440\n",
      " Loss: 0.000000\n",
      " Loss: 0.023285\n",
      " Loss: 0.000000\n",
      " Loss: 0.032080\n",
      " Loss: 0.000000\n",
      " Loss: 0.018026\n",
      " Loss: 0.000000\n",
      " Loss: 0.060007\n",
      " Loss: 0.000000\n",
      " Loss: 0.018329\n",
      " Loss: 0.000000\n",
      " Loss: 0.024945\n",
      " Loss: 0.000000\n",
      " Loss: 0.020197\n",
      " Loss: 0.000000\n",
      " Loss: 0.029602\n",
      " Loss: 0.000000\n",
      " Loss: 0.067765\n",
      "Epoch 2458 Chain 0 loss std 1.29e-03 variance 8.37e-07 smooth variance 5.27e-07 adaptive c -1.00\n",
      "Epoch 2458 Chain 1 loss std 1.82e+02 variance 1.66e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014347\n",
      " Loss: 0.000000\n",
      " Loss: 0.060393\n",
      " Loss: 0.000000\n",
      " Loss: 0.023381\n",
      " Loss: 0.000000\n",
      " Loss: 0.026705\n",
      " Loss: 0.000000\n",
      " Loss: 0.036012\n",
      " Loss: 0.000000\n",
      " Loss: 0.067071\n",
      " Loss: 0.000000\n",
      " Loss: 0.020666\n",
      " Loss: 0.000000\n",
      " Loss: 0.020356\n",
      " Loss: 0.000000\n",
      " Loss: 0.033006\n",
      " Loss: 0.000000\n",
      " Loss: 0.019737\n",
      "Epoch 2460 Chain 0 loss std 1.13e-03 variance 6.42e-07 smooth variance 5.61e-07 adaptive c -1.00\n",
      "Epoch 2460 Chain 1 loss std 1.95e+02 variance 1.90e+04 smooth variance 2.04e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.064940\n",
      " Loss: 0.000000\n",
      " Loss: 0.015999\n",
      " Loss: 0.000000\n",
      " Loss: 0.021975\n",
      " Loss: 0.000000\n",
      " Loss: 0.026291\n",
      " Loss: 0.000000\n",
      " Loss: 0.031633\n",
      " Loss: 0.000000\n",
      " Loss: 0.070239\n",
      " Loss: 0.000000\n",
      " Loss: 0.017957\n",
      " Loss: 0.000000\n",
      " Loss: 0.020894\n",
      " Loss: 0.000000\n",
      " Loss: 0.017616\n",
      " Loss: 0.000000\n",
      " Loss: 0.034131\n",
      "Epoch 2462 Chain 0 loss std 9.50e-04 variance 4.51e-07 smooth variance 5.28e-07 adaptive c -1.00\n",
      "Epoch 2462 Chain 1 loss std 2.00e+02 variance 2.01e+04 smooth variance 2.03e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.039428\n",
      " Loss: 0.000000\n",
      " Loss: 0.025270\n",
      " Loss: 0.000000\n",
      " Loss: 0.012740\n",
      " Loss: 0.000000\n",
      " Loss: 0.026950\n",
      " Loss: 0.000000\n",
      " Loss: 0.056450\n",
      " Loss: 0.000000\n",
      " Loss: 0.028452\n",
      " Loss: 0.000000\n",
      " Loss: 0.032046\n",
      " Loss: 0.000000\n",
      " Loss: 0.019401\n",
      " Loss: 0.000000\n",
      " Loss: 0.021962\n",
      " Loss: 0.000000\n",
      " Loss: 0.058977\n",
      "Epoch 2464 Chain 0 loss std 6.54e-04 variance 2.14e-07 smooth variance 4.34e-07 adaptive c -1.00\n",
      "Epoch 2464 Chain 1 loss std 1.62e+02 variance 1.31e+04 smooth variance 1.81e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025307\n",
      " Loss: 0.000000\n",
      " Loss: 0.015411\n",
      " Loss: 0.000000\n",
      " Loss: 0.035148\n",
      " Loss: 0.000000\n",
      " Loss: 0.065097\n",
      " Loss: 0.000000\n",
      " Loss: 0.019876\n",
      " Loss: 0.000000\n",
      " Loss: 0.060578\n",
      " Loss: 0.000000\n",
      " Loss: 0.025087\n",
      " Loss: 0.000000\n",
      " Loss: 0.036642\n",
      " Loss: 0.000000\n",
      " Loss: 0.021899\n",
      " Loss: 0.000000\n",
      " Loss: 0.016631\n",
      "Epoch 2466 Chain 0 loss std 9.21e-04 variance 4.24e-07 smooth variance 4.31e-07 adaptive c -1.00\n",
      "Epoch 2466 Chain 1 loss std 2.86e+02 variance 4.08e+04 smooth variance 2.49e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022604\n",
      " Loss: 0.000000\n",
      " Loss: 0.020580\n",
      " Loss: 0.000000\n",
      " Loss: 0.053922\n",
      " Loss: 0.000000\n",
      " Loss: 0.017111\n",
      " Loss: 0.000000\n",
      " Loss: 0.046621\n",
      " Loss: 0.000000\n",
      " Loss: 0.019554\n",
      " Loss: 0.000000\n",
      " Loss: 0.076864\n",
      " Loss: 0.000000\n",
      " Loss: 0.013573\n",
      " Loss: 0.000000\n",
      " Loss: 0.024391\n",
      " Loss: 0.000000\n",
      " Loss: 0.026455\n",
      "Epoch 2468 Chain 0 loss std 1.30e-03 variance 8.51e-07 smooth variance 5.57e-07 adaptive c -1.00\n",
      "Epoch 2468 Chain 1 loss std 1.98e+02 variance 1.96e+04 smooth variance 2.33e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036035\n",
      " Loss: 0.000000\n",
      " Loss: 0.018959\n",
      " Loss: 0.000000\n",
      " Loss: 0.063623\n",
      " Loss: 0.000000\n",
      " Loss: 0.016884\n",
      " Loss: 0.000000\n",
      " Loss: 0.025337\n",
      " Loss: 0.000000\n",
      " Loss: 0.068694\n",
      " Loss: 0.000000\n",
      " Loss: 0.031580\n",
      " Loss: 0.000000\n",
      " Loss: 0.017951\n",
      " Loss: 0.000000\n",
      " Loss: 0.019793\n",
      " Loss: 0.000000\n",
      " Loss: 0.022820\n",
      "Epoch 2470 Chain 0 loss std 7.29e-04 variance 2.66e-07 smooth variance 4.70e-07 adaptive c -1.00\n",
      "Epoch 2470 Chain 1 loss std 1.89e+02 variance 1.79e+04 smooth variance 2.17e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021565\n",
      " Loss: 0.000000\n",
      " Loss: 0.016969\n",
      " Loss: 0.000000\n",
      " Loss: 0.025336\n",
      " Loss: 0.000000\n",
      " Loss: 0.059842\n",
      " Loss: 0.000000\n",
      " Loss: 0.037125\n",
      " Loss: 0.000000\n",
      " Loss: 0.027291\n",
      " Loss: 0.000000\n",
      " Loss: 0.022719\n",
      " Loss: 0.000000\n",
      " Loss: 0.020021\n",
      " Loss: 0.000000\n",
      " Loss: 0.011789\n",
      " Loss: 0.000000\n",
      " Loss: 0.079018\n",
      "Epoch 2472 Chain 0 loss std 8.64e-04 variance 3.73e-07 smooth variance 4.41e-07 adaptive c -1.00\n",
      "Epoch 2472 Chain 1 loss std 1.65e+02 variance 1.37e+04 smooth variance 1.93e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.054280\n",
      " Loss: 0.000000\n",
      " Loss: 0.021992\n",
      " Loss: 0.000000\n",
      " Loss: 0.030943\n",
      " Loss: 0.000000\n",
      " Loss: 0.037500\n",
      " Loss: 0.000000\n",
      " Loss: 0.016123\n",
      " Loss: 0.000000\n",
      " Loss: 0.027449\n",
      " Loss: 0.000000\n",
      " Loss: 0.016822\n",
      " Loss: 0.000000\n",
      " Loss: 0.059795\n",
      " Loss: 0.000000\n",
      " Loss: 0.036896\n",
      " Loss: 0.000000\n",
      " Loss: 0.019876\n",
      "Epoch 2474 Chain 0 loss std 6.46e-04 variance 2.08e-07 smooth variance 3.71e-07 adaptive c -1.00\n",
      "Epoch 2474 Chain 1 loss std 1.80e+02 variance 1.62e+04 smooth variance 1.84e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022308\n",
      " Loss: 0.000000\n",
      " Loss: 0.063683\n",
      " Loss: 0.000000\n",
      " Loss: 0.017183\n",
      " Loss: 0.000000\n",
      " Loss: 0.026098\n",
      " Loss: 0.000000\n",
      " Loss: 0.031566\n",
      " Loss: 0.000000\n",
      " Loss: 0.028283\n",
      " Loss: 0.000000\n",
      " Loss: 0.027623\n",
      " Loss: 0.000000\n",
      " Loss: 0.010243\n",
      " Loss: 0.000000\n",
      " Loss: 0.034941\n",
      " Loss: 0.000000\n",
      " Loss: 0.059748\n",
      "Epoch 2476 Chain 0 loss std 9.55e-04 variance 4.56e-07 smooth variance 3.96e-07 adaptive c -1.00\n",
      "Epoch 2476 Chain 1 loss std 1.77e+02 variance 1.57e+04 smooth variance 1.76e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027866\n",
      " Loss: 0.000000\n",
      " Loss: 0.018030\n",
      " Loss: 0.000000\n",
      " Loss: 0.036790\n",
      " Loss: 0.000000\n",
      " Loss: 0.059323\n",
      " Loss: 0.000000\n",
      " Loss: 0.018829\n",
      " Loss: 0.000000\n",
      " Loss: 0.019846\n",
      " Loss: 0.000000\n",
      " Loss: 0.060440\n",
      " Loss: 0.000000\n",
      " Loss: 0.020974\n",
      " Loss: 0.000000\n",
      " Loss: 0.012410\n",
      " Loss: 0.000000\n",
      " Loss: 0.047167\n",
      "Epoch 2478 Chain 0 loss std 6.96e-04 variance 2.42e-07 smooth variance 3.50e-07 adaptive c -1.00\n",
      "Epoch 2478 Chain 1 loss std 1.86e+02 variance 1.72e+04 smooth variance 1.75e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.069772\n",
      " Loss: 0.000000\n",
      " Loss: 0.034969\n",
      " Loss: 0.000000\n",
      " Loss: 0.024766\n",
      " Loss: 0.000000\n",
      " Loss: 0.019577\n",
      " Loss: 0.000000\n",
      " Loss: 0.011754\n",
      " Loss: 0.000000\n",
      " Loss: 0.027362\n",
      " Loss: 0.000000\n",
      " Loss: 0.057258\n",
      " Loss: 0.000000\n",
      " Loss: 0.033560\n",
      " Loss: 0.000000\n",
      " Loss: 0.010216\n",
      " Loss: 0.000000\n",
      " Loss: 0.032442\n",
      "Epoch 2480 Chain 0 loss std 5.92e-04 variance 1.75e-07 smooth variance 2.98e-07 adaptive c -1.00\n",
      "Epoch 2480 Chain 1 loss std 2.50e+02 variance 3.13e+04 smooth variance 2.16e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019326\n",
      " Loss: 0.000000\n",
      " Loss: 0.016588\n",
      " Loss: 0.000000\n",
      " Loss: 0.023941\n",
      " Loss: 0.000000\n",
      " Loss: 0.043898\n",
      " Loss: 0.000000\n",
      " Loss: 0.057084\n",
      " Loss: 0.000000\n",
      " Loss: 0.016832\n",
      " Loss: 0.000000\n",
      " Loss: 0.036101\n",
      " Loss: 0.000000\n",
      " Loss: 0.036002\n",
      " Loss: 0.000000\n",
      " Loss: 0.017869\n",
      " Loss: 0.000000\n",
      " Loss: 0.054035\n",
      "Epoch 2482 Chain 0 loss std 1.19e-03 variance 7.04e-07 smooth variance 4.20e-07 adaptive c -1.00\n",
      "Epoch 2482 Chain 1 loss std 2.46e+02 variance 3.02e+04 smooth variance 2.42e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.038530\n",
      " Loss: 0.000000\n",
      " Loss: 0.012996\n",
      " Loss: 0.000000\n",
      " Loss: 0.024738\n",
      " Loss: 0.000000\n",
      " Loss: 0.060147\n",
      " Loss: 0.000000\n",
      " Loss: 0.024426\n",
      " Loss: 0.000000\n",
      " Loss: 0.066248\n",
      " Loss: 0.000000\n",
      " Loss: 0.018162\n",
      " Loss: 0.000000\n",
      " Loss: 0.018823\n",
      " Loss: 0.000000\n",
      " Loss: 0.038845\n",
      " Loss: 0.000000\n",
      " Loss: 0.018759\n",
      "Epoch 2484 Chain 0 loss std 7.62e-04 variance 2.91e-07 smooth variance 3.81e-07 adaptive c -1.00\n",
      "Epoch 2484 Chain 1 loss std 1.81e+02 variance 1.64e+04 smooth variance 2.19e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021935\n",
      " Loss: 0.000000\n",
      " Loss: 0.033106\n",
      " Loss: 0.000000\n",
      " Loss: 0.018881\n",
      " Loss: 0.000000\n",
      " Loss: 0.060899\n",
      " Loss: 0.000000\n",
      " Loss: 0.026017\n",
      " Loss: 0.000000\n",
      " Loss: 0.060073\n",
      " Loss: 0.000000\n",
      " Loss: 0.023293\n",
      " Loss: 0.000000\n",
      " Loss: 0.014924\n",
      " Loss: 0.000000\n",
      " Loss: 0.041967\n",
      " Loss: 0.000000\n",
      " Loss: 0.020581\n",
      "Epoch 2486 Chain 0 loss std 4.43e-04 variance 9.83e-08 smooth variance 2.96e-07 adaptive c -1.00\n",
      "Epoch 2486 Chain 1 loss std 1.88e+02 variance 1.76e+04 smooth variance 2.06e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025037\n",
      " Loss: 0.000000\n",
      " Loss: 0.080375\n",
      " Loss: 0.000000\n",
      " Loss: 0.016854\n",
      " Loss: 0.000000\n",
      " Loss: 0.020689\n",
      " Loss: 0.000000\n",
      " Loss: 0.017882\n",
      " Loss: 0.000000\n",
      " Loss: 0.018409\n",
      " Loss: 0.000000\n",
      " Loss: 0.021738\n",
      " Loss: 0.000000\n",
      " Loss: 0.020908\n",
      " Loss: 0.000000\n",
      " Loss: 0.055341\n",
      " Loss: 0.000000\n",
      " Loss: 0.044442\n",
      "Epoch 2488 Chain 0 loss std 9.29e-04 variance 4.32e-07 smooth variance 3.37e-07 adaptive c -1.00\n",
      "Epoch 2488 Chain 1 loss std 1.48e+02 variance 1.10e+04 smooth variance 1.77e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017962\n",
      " Loss: 0.000000\n",
      " Loss: 0.028201\n",
      " Loss: 0.000000\n",
      " Loss: 0.041846\n",
      " Loss: 0.000000\n",
      " Loss: 0.010948\n",
      " Loss: 0.000000\n",
      " Loss: 0.061880\n",
      " Loss: 0.000000\n",
      " Loss: 0.031799\n",
      " Loss: 0.000000\n",
      " Loss: 0.022699\n",
      " Loss: 0.000000\n",
      " Loss: 0.016522\n",
      " Loss: 0.000000\n",
      " Loss: 0.015675\n",
      " Loss: 0.000000\n",
      " Loss: 0.074143\n",
      "Epoch 2490 Chain 0 loss std 3.86e-04 variance 7.46e-08 smooth variance 2.58e-07 adaptive c -1.00\n",
      "Epoch 2490 Chain 1 loss std 2.77e+02 variance 3.83e+04 smooth variance 2.39e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015533\n",
      " Loss: 0.000000\n",
      " Loss: 0.067913\n",
      " Loss: 0.000000\n",
      " Loss: 0.036449\n",
      " Loss: 0.000000\n",
      " Loss: 0.019334\n",
      " Loss: 0.000000\n",
      " Loss: 0.021608\n",
      " Loss: 0.000000\n",
      " Loss: 0.059936\n",
      " Loss: 0.000000\n",
      " Loss: 0.017671\n",
      " Loss: 0.000000\n",
      " Loss: 0.025421\n",
      " Loss: 0.000000\n",
      " Loss: 0.033306\n",
      " Loss: 0.000000\n",
      " Loss: 0.024504\n",
      "Epoch 2492 Chain 0 loss std 9.94e-04 variance 4.94e-07 smooth variance 3.29e-07 adaptive c -1.00\n",
      "Epoch 2492 Chain 1 loss std 2.12e+02 variance 2.24e+04 smooth variance 2.34e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.062907\n",
      " Loss: 0.000000\n",
      " Loss: 0.023856\n",
      " Loss: 0.000000\n",
      " Loss: 0.018564\n",
      " Loss: 0.000000\n",
      " Loss: 0.019027\n",
      " Loss: 0.000000\n",
      " Loss: 0.036483\n",
      " Loss: 0.000000\n",
      " Loss: 0.016139\n",
      " Loss: 0.000000\n",
      " Loss: 0.019527\n",
      " Loss: 0.000000\n",
      " Loss: 0.077433\n",
      " Loss: 0.000000\n",
      " Loss: 0.033081\n",
      " Loss: 0.000000\n",
      " Loss: 0.014658\n",
      "Epoch 2494 Chain 0 loss std 6.77e-04 variance 2.29e-07 smooth variance 2.99e-07 adaptive c -1.00\n",
      "Epoch 2494 Chain 1 loss std 1.50e+02 variance 1.12e+04 smooth variance 1.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027235\n",
      " Loss: 0.000000\n",
      " Loss: 0.015261\n",
      " Loss: 0.000000\n",
      " Loss: 0.034746\n",
      " Loss: 0.000000\n",
      " Loss: 0.061247\n",
      " Loss: 0.000000\n",
      " Loss: 0.022349\n",
      " Loss: 0.000000\n",
      " Loss: 0.037990\n",
      " Loss: 0.000000\n",
      " Loss: 0.027816\n",
      " Loss: 0.000000\n",
      " Loss: 0.065984\n",
      " Loss: 0.000000\n",
      " Loss: 0.016581\n",
      " Loss: 0.000000\n",
      " Loss: 0.012467\n",
      "Epoch 2496 Chain 0 loss std 1.15e-03 variance 6.63e-07 smooth variance 4.08e-07 adaptive c -1.00\n",
      "Epoch 2496 Chain 1 loss std 2.43e+02 variance 2.94e+04 smooth variance 2.27e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.057493\n",
      " Loss: 0.000000\n",
      " Loss: 0.032942\n",
      " Loss: 0.000000\n",
      " Loss: 0.013883\n",
      " Loss: 0.000000\n",
      " Loss: 0.021563\n",
      " Loss: 0.000000\n",
      " Loss: 0.034956\n",
      " Loss: 0.000000\n",
      " Loss: 0.036392\n",
      " Loss: 0.000000\n",
      " Loss: 0.019889\n",
      " Loss: 0.000000\n",
      " Loss: 0.020158\n",
      " Loss: 0.000000\n",
      " Loss: 0.027303\n",
      " Loss: 0.000000\n",
      " Loss: 0.057096\n",
      "Epoch 2498 Chain 0 loss std 7.59e-04 variance 2.88e-07 smooth variance 3.72e-07 adaptive c -1.00\n",
      "Epoch 2498 Chain 1 loss std 2.52e+02 variance 3.19e+04 smooth variance 2.54e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021916\n",
      " Loss: 0.000000\n",
      " Loss: 0.026993\n",
      " Loss: 0.000000\n",
      " Loss: 0.019427\n",
      " Loss: 0.000000\n",
      " Loss: 0.014984\n",
      " Loss: 0.000000\n",
      " Loss: 0.077518\n",
      " Loss: 0.000000\n",
      " Loss: 0.017204\n",
      " Loss: 0.000000\n",
      " Loss: 0.027028\n",
      " Loss: 0.000000\n",
      " Loss: 0.062271\n",
      " Loss: 0.000000\n",
      " Loss: 0.027192\n",
      " Loss: 0.000000\n",
      " Loss: 0.027141\n",
      "Epoch 2500 Chain 0 loss std 7.30e-04 variance 2.67e-07 smooth variance 3.40e-07 adaptive c -1.00\n",
      "Epoch 2500 Chain 1 loss std 1.76e+02 variance 1.55e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.078155\n",
      " Loss: 0.000000\n",
      " Loss: 0.019374\n",
      " Loss: 0.000000\n",
      " Loss: 0.023996\n",
      " Loss: 0.000000\n",
      " Loss: 0.019681\n",
      " Loss: 0.000000\n",
      " Loss: 0.019632\n",
      " Loss: 0.000000\n",
      " Loss: 0.065821\n",
      " Loss: 0.000000\n",
      " Loss: 0.020517\n",
      " Loss: 0.000000\n",
      " Loss: 0.034974\n",
      " Loss: 0.000000\n",
      " Loss: 0.020356\n",
      " Loss: 0.000000\n",
      " Loss: 0.019170\n",
      "Epoch 2502 Chain 0 loss std 1.11e-03 variance 6.19e-07 smooth variance 4.24e-07 adaptive c -1.00\n",
      "Epoch 2502 Chain 1 loss std 1.59e+02 variance 1.27e+04 smooth variance 1.95e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036758\n",
      " Loss: 0.000000\n",
      " Loss: 0.059661\n",
      " Loss: 0.000000\n",
      " Loss: 0.012714\n",
      " Loss: 0.000000\n",
      " Loss: 0.015344\n",
      " Loss: 0.000000\n",
      " Loss: 0.036360\n",
      " Loss: 0.000000\n",
      " Loss: 0.023382\n",
      " Loss: 0.000000\n",
      " Loss: 0.022878\n",
      " Loss: 0.000000\n",
      " Loss: 0.072203\n",
      " Loss: 0.000000\n",
      " Loss: 0.018252\n",
      " Loss: 0.000000\n",
      " Loss: 0.024123\n",
      "Epoch 2504 Chain 0 loss std 5.14e-04 variance 1.32e-07 smooth variance 3.36e-07 adaptive c -1.00\n",
      "Epoch 2504 Chain 1 loss std 1.45e+02 variance 1.06e+04 smooth variance 1.68e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061276\n",
      " Loss: 0.000000\n",
      " Loss: 0.021986\n",
      " Loss: 0.000000\n",
      " Loss: 0.038541\n",
      " Loss: 0.000000\n",
      " Loss: 0.026930\n",
      " Loss: 0.000000\n",
      " Loss: 0.012105\n",
      " Loss: 0.000000\n",
      " Loss: 0.030874\n",
      " Loss: 0.000000\n",
      " Loss: 0.041583\n",
      " Loss: 0.000000\n",
      " Loss: 0.009144\n",
      " Loss: 0.000000\n",
      " Loss: 0.013297\n",
      " Loss: 0.000000\n",
      " Loss: 0.065939\n",
      "Epoch 2506 Chain 0 loss std 7.44e-04 variance 2.77e-07 smooth variance 3.19e-07 adaptive c -1.00\n",
      "Epoch 2506 Chain 1 loss std 1.73e+02 variance 1.49e+04 smooth variance 1.63e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014218\n",
      " Loss: 0.000000\n",
      " Loss: 0.018592\n",
      " Loss: 0.000000\n",
      " Loss: 0.036917\n",
      " Loss: 0.000000\n",
      " Loss: 0.014637\n",
      " Loss: 0.000000\n",
      " Loss: 0.076474\n",
      " Loss: 0.000000\n",
      " Loss: 0.026779\n",
      " Loss: 0.000000\n",
      " Loss: 0.023926\n",
      " Loss: 0.000000\n",
      " Loss: 0.081080\n",
      " Loss: 0.000000\n",
      " Loss: 0.017744\n",
      " Loss: 0.000000\n",
      " Loss: 0.011308\n",
      "Epoch 2508 Chain 0 loss std 1.15e-03 variance 6.58e-07 smooth variance 4.20e-07 adaptive c -1.00\n",
      "Epoch 2508 Chain 1 loss std 2.69e+02 variance 3.61e+04 smooth variance 2.22e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022327\n",
      " Loss: 0.000000\n",
      " Loss: 0.064480\n",
      " Loss: 0.000000\n",
      " Loss: 0.014163\n",
      " Loss: 0.000000\n",
      " Loss: 0.012032\n",
      " Loss: 0.000000\n",
      " Loss: 0.047836\n",
      " Loss: 0.000000\n",
      " Loss: 0.017267\n",
      " Loss: 0.000000\n",
      " Loss: 0.060731\n",
      " Loss: 0.000000\n",
      " Loss: 0.022397\n",
      " Loss: 0.000000\n",
      " Loss: 0.047554\n",
      " Loss: 0.000000\n",
      " Loss: 0.012888\n",
      "Epoch 2510 Chain 0 loss std 8.68e-04 variance 3.77e-07 smooth variance 4.07e-07 adaptive c -1.00\n",
      "Epoch 2510 Chain 1 loss std 2.22e+02 variance 2.47e+04 smooth variance 2.30e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028291\n",
      " Loss: 0.000000\n",
      " Loss: 0.022927\n",
      " Loss: 0.000000\n",
      " Loss: 0.015416\n",
      " Loss: 0.000000\n",
      " Loss: 0.032463\n",
      " Loss: 0.000000\n",
      " Loss: 0.061740\n",
      " Loss: 0.000000\n",
      " Loss: 0.019885\n",
      " Loss: 0.000000\n",
      " Loss: 0.014736\n",
      " Loss: 0.000000\n",
      " Loss: 0.065224\n",
      " Loss: 0.000000\n",
      " Loss: 0.042464\n",
      " Loss: 0.000000\n",
      " Loss: 0.018528\n",
      "Epoch 2512 Chain 0 loss std 5.52e-04 variance 1.52e-07 smooth variance 3.31e-07 adaptive c -1.00\n",
      "Epoch 2512 Chain 1 loss std 2.10e+02 variance 2.20e+04 smooth variance 2.27e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036624\n",
      " Loss: 0.000000\n",
      " Loss: 0.019408\n",
      " Loss: 0.000000\n",
      " Loss: 0.018333\n",
      " Loss: 0.000000\n",
      " Loss: 0.013709\n",
      " Loss: 0.000000\n",
      " Loss: 0.072763\n",
      " Loss: 0.000000\n",
      " Loss: 0.016236\n",
      " Loss: 0.000000\n",
      " Loss: 0.028282\n",
      " Loss: 0.000000\n",
      " Loss: 0.029725\n",
      " Loss: 0.000000\n",
      " Loss: 0.027923\n",
      " Loss: 0.000000\n",
      " Loss: 0.058672\n",
      "Epoch 2514 Chain 0 loss std 1.25e-03 variance 7.81e-07 smooth variance 4.66e-07 adaptive c -1.00\n",
      "Epoch 2514 Chain 1 loss std 2.24e+02 variance 2.51e+04 smooth variance 2.34e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019632\n",
      " Loss: 0.000000\n",
      " Loss: 0.022073\n",
      " Loss: 0.000000\n",
      " Loss: 0.089334\n",
      " Loss: 0.000000\n",
      " Loss: 0.020734\n",
      " Loss: 0.000000\n",
      " Loss: 0.009065\n",
      " Loss: 0.000000\n",
      " Loss: 0.018477\n",
      " Loss: 0.000000\n",
      " Loss: 0.048680\n",
      " Loss: 0.000000\n",
      " Loss: 0.056827\n",
      " Loss: 0.000000\n",
      " Loss: 0.018097\n",
      " Loss: 0.000000\n",
      " Loss: 0.018757\n",
      "Epoch 2516 Chain 0 loss std 7.74e-04 variance 2.99e-07 smooth variance 4.16e-07 adaptive c -1.00\n",
      "Epoch 2516 Chain 1 loss std 2.29e+02 variance 2.63e+04 smooth variance 2.43e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019046\n",
      " Loss: 0.000000\n",
      " Loss: 0.023810\n",
      " Loss: 0.000000\n",
      " Loss: 0.013582\n",
      " Loss: 0.000000\n",
      " Loss: 0.061231\n",
      " Loss: 0.000000\n",
      " Loss: 0.043167\n",
      " Loss: 0.000000\n",
      " Loss: 0.057503\n",
      " Loss: 0.000000\n",
      " Loss: 0.013581\n",
      " Loss: 0.000000\n",
      " Loss: 0.018881\n",
      " Loss: 0.000000\n",
      " Loss: 0.043235\n",
      " Loss: 0.000000\n",
      " Loss: 0.027637\n",
      "Epoch 2518 Chain 0 loss std 8.32e-04 variance 3.46e-07 smooth variance 3.95e-07 adaptive c -1.00\n",
      "Epoch 2518 Chain 1 loss std 1.73e+02 variance 1.49e+04 smooth variance 2.15e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016227\n",
      " Loss: 0.000000\n",
      " Loss: 0.023558\n",
      " Loss: 0.000000\n",
      " Loss: 0.013503\n",
      " Loss: 0.000000\n",
      " Loss: 0.043196\n",
      " Loss: 0.000000\n",
      " Loss: 0.064353\n",
      " Loss: 0.000000\n",
      " Loss: 0.015715\n",
      " Loss: 0.000000\n",
      " Loss: 0.036962\n",
      " Loss: 0.000000\n",
      " Loss: 0.063734\n",
      " Loss: 0.000000\n",
      " Loss: 0.034284\n",
      " Loss: 0.000000\n",
      " Loss: 0.010142\n",
      "Epoch 2520 Chain 0 loss std 9.69e-04 variance 4.69e-07 smooth variance 4.17e-07 adaptive c -1.00\n",
      "Epoch 2520 Chain 1 loss std 2.59e+02 variance 3.36e+04 smooth variance 2.51e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022633\n",
      " Loss: 0.000000\n",
      " Loss: 0.014135\n",
      " Loss: 0.000000\n",
      " Loss: 0.024431\n",
      " Loss: 0.000000\n",
      " Loss: 0.038580\n",
      " Loss: 0.000000\n",
      " Loss: 0.061058\n",
      " Loss: 0.000000\n",
      " Loss: 0.019778\n",
      " Loss: 0.000000\n",
      " Loss: 0.033364\n",
      " Loss: 0.000000\n",
      " Loss: 0.029489\n",
      " Loss: 0.000000\n",
      " Loss: 0.059662\n",
      " Loss: 0.000000\n",
      " Loss: 0.018544\n",
      "Epoch 2522 Chain 0 loss std 1.11e-03 variance 6.16e-07 smooth variance 4.77e-07 adaptive c -1.00\n",
      "Epoch 2522 Chain 1 loss std 2.17e+02 variance 2.36e+04 smooth variance 2.47e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.065748\n",
      " Loss: 0.000000\n",
      " Loss: 0.019888\n",
      " Loss: 0.000000\n",
      " Loss: 0.016456\n",
      " Loss: 0.000000\n",
      " Loss: 0.020235\n",
      " Loss: 0.000000\n",
      " Loss: 0.038511\n",
      " Loss: 0.000000\n",
      " Loss: 0.023607\n",
      " Loss: 0.000000\n",
      " Loss: 0.016486\n",
      " Loss: 0.000000\n",
      " Loss: 0.015618\n",
      " Loss: 0.000000\n",
      " Loss: 0.033313\n",
      " Loss: 0.000000\n",
      " Loss: 0.071813\n",
      "Epoch 2524 Chain 0 loss std 9.14e-04 variance 4.18e-07 smooth variance 4.59e-07 adaptive c -1.00\n",
      "Epoch 2524 Chain 1 loss std 1.85e+02 variance 1.70e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019487\n",
      " Loss: 0.000000\n",
      " Loss: 0.013026\n",
      " Loss: 0.000000\n",
      " Loss: 0.071286\n",
      " Loss: 0.000000\n",
      " Loss: 0.020317\n",
      " Loss: 0.000000\n",
      " Loss: 0.036722\n",
      " Loss: 0.000000\n",
      " Loss: 0.070347\n",
      " Loss: 0.000000\n",
      " Loss: 0.028598\n",
      " Loss: 0.000000\n",
      " Loss: 0.011581\n",
      " Loss: 0.000000\n",
      " Loss: 0.031523\n",
      " Loss: 0.000000\n",
      " Loss: 0.018787\n",
      "Epoch 2526 Chain 0 loss std 7.93e-04 variance 3.15e-07 smooth variance 4.16e-07 adaptive c -1.00\n",
      "Epoch 2526 Chain 1 loss std 2.23e+02 variance 2.49e+04 smooth variance 2.31e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.072749\n",
      " Loss: 0.000000\n",
      " Loss: 0.017711\n",
      " Loss: 0.000000\n",
      " Loss: 0.020413\n",
      " Loss: 0.000000\n",
      " Loss: 0.010931\n",
      " Loss: 0.000000\n",
      " Loss: 0.039034\n",
      " Loss: 0.000000\n",
      " Loss: 0.014590\n",
      " Loss: 0.000000\n",
      " Loss: 0.018976\n",
      " Loss: 0.000000\n",
      " Loss: 0.059693\n",
      " Loss: 0.000000\n",
      " Loss: 0.027050\n",
      " Loss: 0.000000\n",
      " Loss: 0.040529\n",
      "Epoch 2528 Chain 0 loss std 7.61e-04 variance 2.89e-07 smooth variance 3.78e-07 adaptive c -1.00\n",
      "Epoch 2528 Chain 1 loss std 1.70e+02 variance 1.45e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.080156\n",
      " Loss: 0.000000\n",
      " Loss: 0.016332\n",
      " Loss: 0.000000\n",
      " Loss: 0.026657\n",
      " Loss: 0.000000\n",
      " Loss: 0.019126\n",
      " Loss: 0.000000\n",
      " Loss: 0.018568\n",
      " Loss: 0.000000\n",
      " Loss: 0.020854\n",
      " Loss: 0.000000\n",
      " Loss: 0.015095\n",
      " Loss: 0.000000\n",
      " Loss: 0.061570\n",
      " Loss: 0.000000\n",
      " Loss: 0.026345\n",
      " Loss: 0.000000\n",
      " Loss: 0.036973\n",
      "Epoch 2530 Chain 0 loss std 7.14e-04 variance 2.55e-07 smooth variance 3.41e-07 adaptive c -1.00\n",
      "Epoch 2530 Chain 1 loss std 1.72e+02 variance 1.49e+04 smooth variance 1.88e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.012217\n",
      " Loss: 0.000000\n",
      " Loss: 0.043007\n",
      " Loss: 0.000000\n",
      " Loss: 0.023995\n",
      " Loss: 0.000000\n",
      " Loss: 0.021661\n",
      " Loss: 0.000000\n",
      " Loss: 0.059958\n",
      " Loss: 0.000000\n",
      " Loss: 0.030224\n",
      " Loss: 0.000000\n",
      " Loss: 0.014953\n",
      " Loss: 0.000000\n",
      " Loss: 0.014313\n",
      " Loss: 0.000000\n",
      " Loss: 0.062380\n",
      " Loss: 0.000000\n",
      " Loss: 0.038967\n",
      "Epoch 2532 Chain 0 loss std 1.06e-03 variance 5.64e-07 smooth variance 4.08e-07 adaptive c -1.00\n",
      "Epoch 2532 Chain 1 loss std 1.69e+02 variance 1.42e+04 smooth variance 1.75e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017505\n",
      " Loss: 0.000000\n",
      " Loss: 0.066026\n",
      " Loss: 0.000000\n",
      " Loss: 0.024307\n",
      " Loss: 0.000000\n",
      " Loss: 0.034938\n",
      " Loss: 0.000000\n",
      " Loss: 0.018061\n",
      " Loss: 0.000000\n",
      " Loss: 0.013913\n",
      " Loss: 0.000000\n",
      " Loss: 0.019778\n",
      " Loss: 0.000000\n",
      " Loss: 0.066448\n",
      " Loss: 0.000000\n",
      " Loss: 0.018307\n",
      " Loss: 0.000000\n",
      " Loss: 0.042391\n",
      "Epoch 2534 Chain 0 loss std 8.49e-04 variance 3.60e-07 smooth variance 3.94e-07 adaptive c -1.00\n",
      "Epoch 2534 Chain 1 loss std 1.58e+02 variance 1.25e+04 smooth variance 1.60e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020664\n",
      " Loss: 0.000000\n",
      " Loss: 0.017844\n",
      " Loss: 0.000000\n",
      " Loss: 0.058832\n",
      " Loss: 0.000000\n",
      " Loss: 0.015782\n",
      " Loss: 0.000000\n",
      " Loss: 0.047716\n",
      " Loss: 0.000000\n",
      " Loss: 0.020965\n",
      " Loss: 0.000000\n",
      " Loss: 0.026067\n",
      " Loss: 0.000000\n",
      " Loss: 0.033471\n",
      " Loss: 0.000000\n",
      " Loss: 0.020619\n",
      " Loss: 0.000000\n",
      " Loss: 0.059716\n",
      "Epoch 2536 Chain 0 loss std 1.36e-03 variance 9.23e-07 smooth variance 5.52e-07 adaptive c -1.00\n",
      "Epoch 2536 Chain 1 loss std 2.49e+02 variance 3.09e+04 smooth variance 2.04e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021021\n",
      " Loss: 0.000000\n",
      " Loss: 0.079274\n",
      " Loss: 0.000000\n",
      " Loss: 0.028971\n",
      " Loss: 0.000000\n",
      " Loss: 0.022039\n",
      " Loss: 0.000000\n",
      " Loss: 0.009533\n",
      " Loss: 0.000000\n",
      " Loss: 0.046378\n",
      " Loss: 0.000000\n",
      " Loss: 0.066355\n",
      " Loss: 0.000000\n",
      " Loss: 0.013123\n",
      " Loss: 0.000000\n",
      " Loss: 0.015515\n",
      " Loss: 0.000000\n",
      " Loss: 0.019467\n",
      "Epoch 2538 Chain 0 loss std 1.21e-03 variance 7.28e-07 smooth variance 6.05e-07 adaptive c -1.00\n",
      "Epoch 2538 Chain 1 loss std 2.60e+02 variance 3.38e+04 smooth variance 2.44e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.067232\n",
      " Loss: 0.000000\n",
      " Loss: 0.011115\n",
      " Loss: 0.000000\n",
      " Loss: 0.019845\n",
      " Loss: 0.000000\n",
      " Loss: 0.041822\n",
      " Loss: 0.000000\n",
      " Loss: 0.020824\n",
      " Loss: 0.000000\n",
      " Loss: 0.014909\n",
      " Loss: 0.000000\n",
      " Loss: 0.015074\n",
      " Loss: 0.000000\n",
      " Loss: 0.069958\n",
      " Loss: 0.000000\n",
      " Loss: 0.024350\n",
      " Loss: 0.000000\n",
      " Loss: 0.036547\n",
      "Epoch 2540 Chain 0 loss std 7.53e-04 variance 2.84e-07 smooth variance 5.09e-07 adaptive c -1.00\n",
      "Epoch 2540 Chain 1 loss std 2.63e+02 variance 3.46e+04 smooth variance 2.75e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027109\n",
      " Loss: 0.000000\n",
      " Loss: 0.038549\n",
      " Loss: 0.000000\n",
      " Loss: 0.019003\n",
      " Loss: 0.000000\n",
      " Loss: 0.058751\n",
      " Loss: 0.000000\n",
      " Loss: 0.017426\n",
      " Loss: 0.000000\n",
      " Loss: 0.014379\n",
      " Loss: 0.000000\n",
      " Loss: 0.020220\n",
      " Loss: 0.000000\n",
      " Loss: 0.078995\n",
      " Loss: 0.000000\n",
      " Loss: 0.015447\n",
      " Loss: 0.000000\n",
      " Loss: 0.031798\n",
      "Epoch 2542 Chain 0 loss std 1.09e-03 variance 5.95e-07 smooth variance 5.35e-07 adaptive c -1.00\n",
      "Epoch 2542 Chain 1 loss std 2.44e+02 variance 2.97e+04 smooth variance 2.82e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016378\n",
      " Loss: 0.000000\n",
      " Loss: 0.029235\n",
      " Loss: 0.000000\n",
      " Loss: 0.055808\n",
      " Loss: 0.000000\n",
      " Loss: 0.031884\n",
      " Loss: 0.000000\n",
      " Loss: 0.027532\n",
      " Loss: 0.000000\n",
      " Loss: 0.025750\n",
      " Loss: 0.000000\n",
      " Loss: 0.013257\n",
      " Loss: 0.000000\n",
      " Loss: 0.036609\n",
      " Loss: 0.000000\n",
      " Loss: 0.022671\n",
      " Loss: 0.000000\n",
      " Loss: 0.062550\n",
      "Epoch 2544 Chain 0 loss std 1.01e-03 variance 5.05e-07 smooth variance 5.26e-07 adaptive c -1.00\n",
      "Epoch 2544 Chain 1 loss std 1.42e+02 variance 1.01e+04 smooth variance 2.27e+04 adaptive c -1.00\n",
      " Loss: 0.000001\n",
      " Loss: 0.055058\n",
      " Loss: 0.000000\n",
      " Loss: 0.022945\n",
      " Loss: 0.000000\n",
      " Loss: 0.051419\n",
      " Loss: 0.000000\n",
      " Loss: 0.011858\n",
      " Loss: 0.000000\n",
      " Loss: 0.019558\n",
      " Loss: 0.000000\n",
      " Loss: 0.022100\n",
      " Loss: 0.000000\n",
      " Loss: 0.035785\n",
      " Loss: 0.000000\n",
      " Loss: 0.014109\n",
      " Loss: 0.000000\n",
      " Loss: 0.016897\n",
      " Loss: 0.000000\n",
      " Loss: 0.071946\n",
      "Epoch 2546 Chain 0 loss std 1.42e-03 variance 1.01e-06 smooth variance 6.71e-07 adaptive c -1.00\n",
      "Epoch 2546 Chain 1 loss std 1.87e+02 variance 1.74e+04 smooth variance 2.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037107\n",
      " Loss: 0.000000\n",
      " Loss: 0.016895\n",
      " Loss: 0.000000\n",
      " Loss: 0.017984\n",
      " Loss: 0.000000\n",
      " Loss: 0.025240\n",
      " Loss: 0.000000\n",
      " Loss: 0.063611\n",
      " Loss: 0.000000\n",
      " Loss: 0.023406\n",
      " Loss: 0.000000\n",
      " Loss: 0.062193\n",
      " Loss: 0.000000\n",
      " Loss: 0.022082\n",
      " Loss: 0.000000\n",
      " Loss: 0.038982\n",
      " Loss: 0.000000\n",
      " Loss: 0.014174\n",
      "Epoch 2548 Chain 0 loss std 7.90e-04 variance 3.12e-07 smooth variance 5.63e-07 adaptive c -1.00\n",
      "Epoch 2548 Chain 1 loss std 2.18e+02 variance 2.37e+04 smooth variance 2.19e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021331\n",
      " Loss: 0.000000\n",
      " Loss: 0.033430\n",
      " Loss: 0.000000\n",
      " Loss: 0.027702\n",
      " Loss: 0.000000\n",
      " Loss: 0.058608\n",
      " Loss: 0.000000\n",
      " Loss: 0.019767\n",
      " Loss: 0.000000\n",
      " Loss: 0.024479\n",
      " Loss: 0.000000\n",
      " Loss: 0.028713\n",
      " Loss: 0.000000\n",
      " Loss: 0.058530\n",
      " Loss: 0.000000\n",
      " Loss: 0.021397\n",
      " Loss: 0.000000\n",
      " Loss: 0.027719\n",
      "Epoch 2550 Chain 0 loss std 1.00e-03 variance 5.05e-07 smooth variance 5.46e-07 adaptive c -1.00\n",
      "Epoch 2550 Chain 1 loss std 1.81e+02 variance 1.63e+04 smooth variance 2.02e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.041963\n",
      " Loss: 0.000000\n",
      " Loss: 0.033247\n",
      " Loss: 0.000000\n",
      " Loss: 0.014790\n",
      " Loss: 0.000000\n",
      " Loss: 0.016428\n",
      " Loss: 0.000000\n",
      " Loss: 0.054409\n",
      " Loss: 0.000000\n",
      " Loss: 0.022252\n",
      " Loss: 0.000000\n",
      " Loss: 0.022738\n",
      " Loss: 0.000000\n",
      " Loss: 0.061106\n",
      " Loss: 0.000000\n",
      " Loss: 0.043429\n",
      " Loss: 0.000000\n",
      " Loss: 0.011313\n",
      "Epoch 2552 Chain 0 loss std 9.35e-04 variance 4.37e-07 smooth variance 5.13e-07 adaptive c -1.00\n",
      "Epoch 2552 Chain 1 loss std 1.64e+02 variance 1.34e+04 smooth variance 1.82e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.062340\n",
      " Loss: 0.000000\n",
      " Loss: 0.023040\n",
      " Loss: 0.000000\n",
      " Loss: 0.011034\n",
      " Loss: 0.000000\n",
      " Loss: 0.042992\n",
      " Loss: 0.000000\n",
      " Loss: 0.021431\n",
      " Loss: 0.000000\n",
      " Loss: 0.018707\n",
      " Loss: 0.000000\n",
      " Loss: 0.027971\n",
      " Loss: 0.000000\n",
      " Loss: 0.024134\n",
      " Loss: 0.000000\n",
      " Loss: 0.079473\n",
      " Loss: 0.000000\n",
      " Loss: 0.010553\n",
      "Epoch 2554 Chain 0 loss std 7.94e-04 variance 3.15e-07 smooth variance 4.54e-07 adaptive c -1.00\n",
      "Epoch 2554 Chain 1 loss std 1.76e+02 variance 1.55e+04 smooth variance 1.74e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.040709\n",
      " Loss: 0.000000\n",
      " Loss: 0.019535\n",
      " Loss: 0.000000\n",
      " Loss: 0.017758\n",
      " Loss: 0.000000\n",
      " Loss: 0.063426\n",
      " Loss: 0.000000\n",
      " Loss: 0.019410\n",
      " Loss: 0.000000\n",
      " Loss: 0.079975\n",
      " Loss: 0.000000\n",
      " Loss: 0.019008\n",
      " Loss: 0.000000\n",
      " Loss: 0.025726\n",
      " Loss: 0.000000\n",
      " Loss: 0.022510\n",
      " Loss: 0.000000\n",
      " Loss: 0.013618\n",
      "Epoch 2556 Chain 0 loss std 5.85e-04 variance 1.71e-07 smooth variance 3.69e-07 adaptive c -1.00\n",
      "Epoch 2556 Chain 1 loss std 2.39e+02 variance 2.84e+04 smooth variance 2.07e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037115\n",
      " Loss: 0.000000\n",
      " Loss: 0.017870\n",
      " Loss: 0.000001\n",
      " Loss: 0.059248\n",
      " Loss: 0.000000\n",
      " Loss: 0.018713\n",
      " Loss: 0.000000\n",
      " Loss: 0.027892\n",
      " Loss: 0.000000\n",
      " Loss: 0.065478\n",
      " Loss: 0.000000\n",
      " Loss: 0.020511\n",
      " Loss: 0.000000\n",
      " Loss: 0.019043\n",
      " Loss: 0.000000\n",
      " Loss: 0.016236\n",
      " Loss: 0.000000\n",
      " Loss: 0.039569\n",
      "Epoch 2558 Chain 0 loss std 1.43e-03 variance 1.03e-06 smooth variance 5.66e-07 adaptive c -1.00\n",
      "Epoch 2558 Chain 1 loss std 3.00e+02 variance 4.51e+04 smooth variance 2.80e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029198\n",
      " Loss: 0.000000\n",
      " Loss: 0.036877\n",
      " Loss: 0.000000\n",
      " Loss: 0.018240\n",
      " Loss: 0.000000\n",
      " Loss: 0.018564\n",
      " Loss: 0.000000\n",
      " Loss: 0.057958\n",
      " Loss: 0.000000\n",
      " Loss: 0.021392\n",
      " Loss: 0.000000\n",
      " Loss: 0.031573\n",
      " Loss: 0.000000\n",
      " Loss: 0.013318\n",
      " Loss: 0.000000\n",
      " Loss: 0.060133\n",
      " Loss: 0.000000\n",
      " Loss: 0.034422\n",
      "Epoch 2560 Chain 0 loss std 1.04e-03 variance 5.43e-07 smooth variance 5.59e-07 adaptive c -1.00\n",
      "Epoch 2560 Chain 1 loss std 2.51e+02 variance 3.14e+04 smooth variance 2.90e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017377\n",
      " Loss: 0.000000\n",
      " Loss: 0.061745\n",
      " Loss: 0.000000\n",
      " Loss: 0.047130\n",
      " Loss: 0.000000\n",
      " Loss: 0.022710\n",
      " Loss: 0.000000\n",
      " Loss: 0.011875\n",
      " Loss: 0.000000\n",
      " Loss: 0.011130\n",
      " Loss: 0.000000\n",
      " Loss: 0.039327\n",
      " Loss: 0.000000\n",
      " Loss: 0.032929\n",
      " Loss: 0.000000\n",
      " Loss: 0.015293\n",
      " Loss: 0.000000\n",
      " Loss: 0.062159\n",
      "Epoch 2562 Chain 0 loss std 6.59e-04 variance 2.17e-07 smooth variance 4.56e-07 adaptive c -1.00\n",
      "Epoch 2562 Chain 1 loss std 2.05e+02 variance 2.11e+04 smooth variance 2.67e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024888\n",
      " Loss: 0.000000\n",
      " Loss: 0.016500\n",
      " Loss: 0.000000\n",
      " Loss: 0.077155\n",
      " Loss: 0.000000\n",
      " Loss: 0.022220\n",
      " Loss: 0.000000\n",
      " Loss: 0.020075\n",
      " Loss: 0.000000\n",
      " Loss: 0.014952\n",
      " Loss: 0.000000\n",
      " Loss: 0.023759\n",
      " Loss: 0.000000\n",
      " Loss: 0.030908\n",
      " Loss: 0.000000\n",
      " Loss: 0.017074\n",
      " Loss: 0.000000\n",
      " Loss: 0.074145\n",
      "Epoch 2564 Chain 0 loss std 9.57e-04 variance 4.58e-07 smooth variance 4.57e-07 adaptive c -1.00\n",
      "Epoch 2564 Chain 1 loss std 1.59e+02 variance 1.26e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.057866\n",
      " Loss: 0.000000\n",
      " Loss: 0.038314\n",
      " Loss: 0.000000\n",
      " Loss: 0.020853\n",
      " Loss: 0.000000\n",
      " Loss: 0.022563\n",
      " Loss: 0.000000\n",
      " Loss: 0.021242\n",
      " Loss: 0.000000\n",
      " Loss: 0.021906\n",
      " Loss: 0.000000\n",
      " Loss: 0.012715\n",
      " Loss: 0.000000\n",
      " Loss: 0.075873\n",
      " Loss: 0.000000\n",
      " Loss: 0.016553\n",
      " Loss: 0.000000\n",
      " Loss: 0.033790\n",
      "Epoch 2566 Chain 0 loss std 7.41e-04 variance 2.74e-07 smooth variance 4.02e-07 adaptive c -1.00\n",
      "Epoch 2566 Chain 1 loss std 2.25e+02 variance 2.54e+04 smooth variance 2.33e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.027895\n",
      " Loss: 0.000000\n",
      " Loss: 0.011441\n",
      " Loss: 0.000000\n",
      " Loss: 0.027514\n",
      " Loss: 0.000000\n",
      " Loss: 0.011815\n",
      " Loss: 0.000000\n",
      " Loss: 0.082172\n",
      " Loss: 0.000000\n",
      " Loss: 0.046183\n",
      " Loss: 0.000000\n",
      " Loss: 0.015671\n",
      " Loss: 0.000000\n",
      " Loss: 0.067260\n",
      " Loss: 0.000000\n",
      " Loss: 0.019387\n",
      " Loss: 0.000000\n",
      " Loss: 0.012337\n",
      "Epoch 2568 Chain 0 loss std 4.80e-04 variance 1.15e-07 smooth variance 3.16e-07 adaptive c -1.00\n",
      "Epoch 2568 Chain 1 loss std 1.61e+02 variance 1.30e+04 smooth variance 2.02e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017351\n",
      " Loss: 0.000000\n",
      " Loss: 0.061796\n",
      " Loss: 0.000000\n",
      " Loss: 0.012918\n",
      " Loss: 0.000000\n",
      " Loss: 0.045944\n",
      " Loss: 0.000000\n",
      " Loss: 0.022828\n",
      " Loss: 0.000000\n",
      " Loss: 0.040858\n",
      " Loss: 0.000000\n",
      " Loss: 0.025390\n",
      " Loss: 0.000000\n",
      " Loss: 0.019874\n",
      " Loss: 0.000000\n",
      " Loss: 0.017038\n",
      " Loss: 0.000000\n",
      " Loss: 0.057678\n",
      "Epoch 2570 Chain 0 loss std 1.62e-03 variance 1.31e-06 smooth variance 6.16e-07 adaptive c -1.00\n",
      "Epoch 2570 Chain 1 loss std 2.83e+02 variance 4.00e+04 smooth variance 2.61e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.012669\n",
      " Loss: 0.000000\n",
      " Loss: 0.018883\n",
      " Loss: 0.000000\n",
      " Loss: 0.043094\n",
      " Loss: 0.000000\n",
      " Loss: 0.071427\n",
      " Loss: 0.000000\n",
      " Loss: 0.014764\n",
      " Loss: 0.000000\n",
      " Loss: 0.012570\n",
      " Loss: 0.000000\n",
      " Loss: 0.020156\n",
      " Loss: 0.000000\n",
      " Loss: 0.017160\n",
      " Loss: 0.000000\n",
      " Loss: 0.074146\n",
      " Loss: 0.000000\n",
      " Loss: 0.036806\n",
      "Epoch 2572 Chain 0 loss std 8.81e-04 variance 3.88e-07 smooth variance 5.47e-07 adaptive c -1.00\n",
      "Epoch 2572 Chain 1 loss std 2.79e+02 variance 3.90e+04 smooth variance 3.00e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020059\n",
      " Loss: 0.000000\n",
      " Loss: 0.071653\n",
      " Loss: 0.000000\n",
      " Loss: 0.013810\n",
      " Loss: 0.000000\n",
      " Loss: 0.036914\n",
      " Loss: 0.000000\n",
      " Loss: 0.018402\n",
      " Loss: 0.000000\n",
      " Loss: 0.026144\n",
      " Loss: 0.000000\n",
      " Loss: 0.058260\n",
      " Loss: 0.000000\n",
      " Loss: 0.014682\n",
      " Loss: 0.000000\n",
      " Loss: 0.024587\n",
      " Loss: 0.000000\n",
      " Loss: 0.037164\n",
      "Epoch 2574 Chain 0 loss std 1.03e-03 variance 5.33e-07 smooth variance 5.43e-07 adaptive c -1.00\n",
      "Epoch 2574 Chain 1 loss std 1.82e+02 variance 1.66e+04 smooth variance 2.60e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032965\n",
      " Loss: 0.000000\n",
      " Loss: 0.026129\n",
      " Loss: 0.000000\n",
      " Loss: 0.019994\n",
      " Loss: 0.000000\n",
      " Loss: 0.015040\n",
      " Loss: 0.000000\n",
      " Loss: 0.066709\n",
      " Loss: 0.000000\n",
      " Loss: 0.060096\n",
      " Loss: 0.000000\n",
      " Loss: 0.015863\n",
      " Loss: 0.000000\n",
      " Loss: 0.018327\n",
      " Loss: 0.000000\n",
      " Loss: 0.029128\n",
      " Loss: 0.000000\n",
      " Loss: 0.037423\n",
      "Epoch 2576 Chain 0 loss std 1.17e-03 variance 6.80e-07 smooth variance 5.84e-07 adaptive c -1.00\n",
      "Epoch 2576 Chain 1 loss std 2.95e+02 variance 4.36e+04 smooth variance 3.13e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035245\n",
      " Loss: 0.000000\n",
      " Loss: 0.020007\n",
      " Loss: 0.000000\n",
      " Loss: 0.074749\n",
      " Loss: 0.000000\n",
      " Loss: 0.017434\n",
      " Loss: 0.000000\n",
      " Loss: 0.013402\n",
      " Loss: 0.000000\n",
      " Loss: 0.087065\n",
      " Loss: 0.000000\n",
      " Loss: 0.017822\n",
      " Loss: 0.000000\n",
      " Loss: 0.017609\n",
      " Loss: 0.000000\n",
      " Loss: 0.021027\n",
      " Loss: 0.000000\n",
      " Loss: 0.017315\n",
      "Epoch 2578 Chain 0 loss std 7.07e-04 variance 2.50e-07 smooth variance 4.84e-07 adaptive c -1.00\n",
      "Epoch 2578 Chain 1 loss std 2.32e+02 variance 2.69e+04 smooth variance 2.99e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021575\n",
      " Loss: 0.000000\n",
      " Loss: 0.078573\n",
      " Loss: 0.000000\n",
      " Loss: 0.019151\n",
      " Loss: 0.000000\n",
      " Loss: 0.015590\n",
      " Loss: 0.000000\n",
      " Loss: 0.025949\n",
      " Loss: 0.000000\n",
      " Loss: 0.021621\n",
      " Loss: 0.000000\n",
      " Loss: 0.022363\n",
      " Loss: 0.000000\n",
      " Loss: 0.062491\n",
      " Loss: 0.000000\n",
      " Loss: 0.032146\n",
      " Loss: 0.000000\n",
      " Loss: 0.022217\n",
      "Epoch 2580 Chain 0 loss std 7.34e-04 variance 2.70e-07 smooth variance 4.19e-07 adaptive c -1.00\n",
      "Epoch 2580 Chain 1 loss std 2.41e+02 variance 2.91e+04 smooth variance 2.97e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023900\n",
      " Loss: 0.000000\n",
      " Loss: 0.022652\n",
      " Loss: 0.000000\n",
      " Loss: 0.016582\n",
      " Loss: 0.000000\n",
      " Loss: 0.078997\n",
      " Loss: 0.000000\n",
      " Loss: 0.018707\n",
      " Loss: 0.000000\n",
      " Loss: 0.091521\n",
      " Loss: 0.000000\n",
      " Loss: 0.012199\n",
      " Loss: 0.000000\n",
      " Loss: 0.018455\n",
      " Loss: 0.000000\n",
      " Loss: 0.018653\n",
      " Loss: 0.000000\n",
      " Loss: 0.020011\n",
      "Epoch 2582 Chain 0 loss std 1.52e-03 variance 1.16e-06 smooth variance 6.41e-07 adaptive c -1.00\n",
      "Epoch 2582 Chain 1 loss std 1.82e+02 variance 1.67e+04 smooth variance 2.58e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026334\n",
      " Loss: 0.000000\n",
      " Loss: 0.033191\n",
      " Loss: 0.000000\n",
      " Loss: 0.017173\n",
      " Loss: 0.000000\n",
      " Loss: 0.028396\n",
      " Loss: 0.000000\n",
      " Loss: 0.055744\n",
      " Loss: 0.000000\n",
      " Loss: 0.015341\n",
      " Loss: 0.000000\n",
      " Loss: 0.019479\n",
      " Loss: 0.000000\n",
      " Loss: 0.081799\n",
      " Loss: 0.000000\n",
      " Loss: 0.025532\n",
      " Loss: 0.000000\n",
      " Loss: 0.018686\n",
      "Epoch 2584 Chain 0 loss std 1.22e-03 variance 7.41e-07 smooth variance 6.71e-07 adaptive c -1.00\n",
      "Epoch 2584 Chain 1 loss std 1.45e+02 variance 1.05e+04 smooth variance 2.12e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018885\n",
      " Loss: 0.000000\n",
      " Loss: 0.072716\n",
      " Loss: 0.000000\n",
      " Loss: 0.033499\n",
      " Loss: 0.000000\n",
      " Loss: 0.010964\n",
      " Loss: 0.000000\n",
      " Loss: 0.024774\n",
      " Loss: 0.000000\n",
      " Loss: 0.014068\n",
      " Loss: 0.000000\n",
      " Loss: 0.039775\n",
      " Loss: 0.000000\n",
      " Loss: 0.018464\n",
      " Loss: 0.000000\n",
      " Loss: 0.068406\n",
      " Loss: 0.000000\n",
      " Loss: 0.020125\n",
      "Epoch 2586 Chain 0 loss std 9.05e-04 variance 4.10e-07 smooth variance 5.93e-07 adaptive c -1.00\n",
      "Epoch 2586 Chain 1 loss std 1.99e+02 variance 1.98e+04 smooth variance 2.08e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024868\n",
      " Loss: 0.000000\n",
      " Loss: 0.016078\n",
      " Loss: 0.000000\n",
      " Loss: 0.022798\n",
      " Loss: 0.000000\n",
      " Loss: 0.077291\n",
      " Loss: 0.000000\n",
      " Loss: 0.019803\n",
      " Loss: 0.000000\n",
      " Loss: 0.018327\n",
      " Loss: 0.000000\n",
      " Loss: 0.033561\n",
      " Loss: 0.000000\n",
      " Loss: 0.069352\n",
      " Loss: 0.000000\n",
      " Loss: 0.024469\n",
      " Loss: 0.000000\n",
      " Loss: 0.015130\n",
      "Epoch 2588 Chain 0 loss std 6.37e-04 variance 2.03e-07 smooth variance 4.76e-07 adaptive c -1.00\n",
      "Epoch 2588 Chain 1 loss std 1.71e+02 variance 1.46e+04 smooth variance 1.89e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024406\n",
      " Loss: 0.000000\n",
      " Loss: 0.033649\n",
      " Loss: 0.000000\n",
      " Loss: 0.011405\n",
      " Loss: 0.000000\n",
      " Loss: 0.065176\n",
      " Loss: 0.000000\n",
      " Loss: 0.026201\n",
      " Loss: 0.000000\n",
      " Loss: 0.017829\n",
      " Loss: 0.000000\n",
      " Loss: 0.014948\n",
      " Loss: 0.000000\n",
      " Loss: 0.023565\n",
      " Loss: 0.000000\n",
      " Loss: 0.067113\n",
      " Loss: 0.000000\n",
      " Loss: 0.037383\n",
      "Epoch 2590 Chain 0 loss std 7.60e-04 variance 2.89e-07 smooth variance 4.20e-07 adaptive c -1.00\n",
      "Epoch 2590 Chain 1 loss std 2.66e+02 variance 3.53e+04 smooth variance 2.38e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015462\n",
      " Loss: 0.000000\n",
      " Loss: 0.034695\n",
      " Loss: 0.000000\n",
      " Loss: 0.075385\n",
      " Loss: 0.000000\n",
      " Loss: 0.013999\n",
      " Loss: 0.000000\n",
      " Loss: 0.021297\n",
      " Loss: 0.000000\n",
      " Loss: 0.014430\n",
      " Loss: 0.000000\n",
      " Loss: 0.020134\n",
      " Loss: 0.000000\n",
      " Loss: 0.041312\n",
      " Loss: 0.000000\n",
      " Loss: 0.059715\n",
      " Loss: 0.000000\n",
      " Loss: 0.025247\n",
      "Epoch 2592 Chain 0 loss std 6.41e-04 variance 2.05e-07 smooth variance 3.55e-07 adaptive c -1.00\n",
      "Epoch 2592 Chain 1 loss std 2.57e+02 variance 3.31e+04 smooth variance 2.66e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.011576\n",
      " Loss: 0.000000\n",
      " Loss: 0.021142\n",
      " Loss: 0.000000\n",
      " Loss: 0.081623\n",
      " Loss: 0.000000\n",
      " Loss: 0.021698\n",
      " Loss: 0.000000\n",
      " Loss: 0.024799\n",
      " Loss: 0.000000\n",
      " Loss: 0.063838\n",
      " Loss: 0.000000\n",
      " Loss: 0.035105\n",
      " Loss: 0.000000\n",
      " Loss: 0.014352\n",
      " Loss: 0.000000\n",
      " Loss: 0.018735\n",
      " Loss: 0.000000\n",
      " Loss: 0.028807\n",
      "Epoch 2594 Chain 0 loss std 9.05e-04 variance 4.09e-07 smooth variance 3.72e-07 adaptive c -1.00\n",
      "Epoch 2594 Chain 1 loss std 2.38e+02 variance 2.82e+04 smooth variance 2.71e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.065639\n",
      " Loss: 0.000000\n",
      " Loss: 0.029336\n",
      " Loss: 0.000000\n",
      " Loss: 0.022499\n",
      " Loss: 0.000000\n",
      " Loss: 0.019679\n",
      " Loss: 0.000000\n",
      " Loss: 0.023685\n",
      " Loss: 0.000000\n",
      " Loss: 0.021188\n",
      " Loss: 0.000000\n",
      " Loss: 0.075409\n",
      " Loss: 0.000000\n",
      " Loss: 0.014817\n",
      " Loss: 0.000000\n",
      " Loss: 0.023369\n",
      " Loss: 0.000000\n",
      " Loss: 0.026055\n",
      "Epoch 2596 Chain 0 loss std 1.29e-03 variance 8.30e-07 smooth variance 5.09e-07 adaptive c -1.00\n",
      "Epoch 2596 Chain 1 loss std 1.69e+02 variance 1.43e+04 smooth variance 2.33e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016537\n",
      " Loss: 0.000000\n",
      " Loss: 0.018186\n",
      " Loss: 0.000000\n",
      " Loss: 0.068621\n",
      " Loss: 0.000000\n",
      " Loss: 0.031046\n",
      " Loss: 0.000000\n",
      " Loss: 0.026448\n",
      " Loss: 0.000000\n",
      " Loss: 0.060019\n",
      " Loss: 0.000000\n",
      " Loss: 0.037480\n",
      " Loss: 0.000000\n",
      " Loss: 0.014365\n",
      " Loss: 0.000000\n",
      " Loss: 0.018245\n",
      " Loss: 0.000000\n",
      " Loss: 0.030729\n",
      "Epoch 2598 Chain 0 loss std 1.14e-03 variance 6.47e-07 smooth variance 5.50e-07 adaptive c -1.00\n",
      "Epoch 2598 Chain 1 loss std 2.35e+02 variance 2.76e+04 smooth variance 2.46e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020899\n",
      " Loss: 0.000000\n",
      " Loss: 0.039495\n",
      " Loss: 0.000000\n",
      " Loss: 0.013615\n",
      " Loss: 0.000000\n",
      " Loss: 0.062795\n",
      " Loss: 0.000000\n",
      " Loss: 0.024034\n",
      " Loss: 0.000000\n",
      " Loss: 0.015829\n",
      " Loss: 0.000000\n",
      " Loss: 0.039198\n",
      " Loss: 0.000000\n",
      " Loss: 0.061523\n",
      " Loss: 0.000000\n",
      " Loss: 0.017632\n",
      " Loss: 0.000000\n",
      " Loss: 0.026656\n",
      "Epoch 2600 Chain 0 loss std 9.43e-04 variance 4.45e-07 smooth variance 5.19e-07 adaptive c -1.00\n",
      "Epoch 2600 Chain 1 loss std 1.39e+02 variance 9.63e+03 smooth variance 2.01e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018915\n",
      " Loss: 0.000000\n",
      " Loss: 0.017818\n",
      " Loss: 0.000000\n",
      " Loss: 0.068998\n",
      " Loss: 0.000000\n",
      " Loss: 0.028625\n",
      " Loss: 0.000000\n",
      " Loss: 0.026481\n",
      " Loss: 0.000000\n",
      " Loss: 0.021309\n",
      " Loss: 0.000000\n",
      " Loss: 0.071482\n",
      " Loss: 0.000000\n",
      " Loss: 0.035058\n",
      " Loss: 0.000000\n",
      " Loss: 0.018275\n",
      " Loss: 0.000000\n",
      " Loss: 0.014713\n",
      "Epoch 2602 Chain 0 loss std 5.61e-04 variance 1.57e-07 smooth variance 4.10e-07 adaptive c -1.00\n",
      "Epoch 2602 Chain 1 loss std 2.08e+02 variance 2.16e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.030662\n",
      " Loss: 0.000000\n",
      " Loss: 0.019499\n",
      " Loss: 0.000000\n",
      " Loss: 0.014139\n",
      " Loss: 0.000000\n",
      " Loss: 0.077637\n",
      " Loss: 0.000000\n",
      " Loss: 0.018900\n",
      " Loss: 0.000000\n",
      " Loss: 0.023474\n",
      " Loss: 0.000000\n",
      " Loss: 0.038114\n",
      " Loss: 0.000000\n",
      " Loss: 0.016958\n",
      " Loss: 0.000000\n",
      " Loss: 0.071720\n",
      " Loss: 0.000000\n",
      " Loss: 0.010573\n",
      "Epoch 2604 Chain 0 loss std 8.76e-04 variance 3.84e-07 smooth variance 4.02e-07 adaptive c -1.00\n",
      "Epoch 2604 Chain 1 loss std 2.09e+02 variance 2.18e+04 smooth variance 2.09e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.072320\n",
      " Loss: 0.000000\n",
      " Loss: 0.032979\n",
      " Loss: 0.000000\n",
      " Loss: 0.016780\n",
      " Loss: 0.000000\n",
      " Loss: 0.026624\n",
      " Loss: 0.000000\n",
      " Loss: 0.012134\n",
      " Loss: 0.000000\n",
      " Loss: 0.021789\n",
      " Loss: 0.000000\n",
      " Loss: 0.030894\n",
      " Loss: 0.000000\n",
      " Loss: 0.016529\n",
      " Loss: 0.000000\n",
      " Loss: 0.032024\n",
      " Loss: 0.000000\n",
      " Loss: 0.059602\n",
      "Epoch 2606 Chain 0 loss std 9.36e-04 variance 4.38e-07 smooth variance 4.13e-07 adaptive c -1.00\n",
      "Epoch 2606 Chain 1 loss std 1.72e+02 variance 1.48e+04 smooth variance 1.91e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015140\n",
      " Loss: 0.000000\n",
      " Loss: 0.014964\n",
      " Loss: 0.000000\n",
      " Loss: 0.065899\n",
      " Loss: 0.000000\n",
      " Loss: 0.043718\n",
      " Loss: 0.000000\n",
      " Loss: 0.021117\n",
      " Loss: 0.000000\n",
      " Loss: 0.057842\n",
      " Loss: 0.000000\n",
      " Loss: 0.026315\n",
      " Loss: 0.000000\n",
      " Loss: 0.027506\n",
      " Loss: 0.000000\n",
      " Loss: 0.018751\n",
      " Loss: 0.000000\n",
      " Loss: 0.030424\n",
      "Epoch 2608 Chain 0 loss std 8.18e-04 variance 3.35e-07 smooth variance 3.90e-07 adaptive c -1.00\n",
      "Epoch 2608 Chain 1 loss std 2.04e+02 variance 2.07e+04 smooth variance 1.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020316\n",
      " Loss: 0.000000\n",
      " Loss: 0.057954\n",
      " Loss: 0.000000\n",
      " Loss: 0.039435\n",
      " Loss: 0.000000\n",
      " Loss: 0.013497\n",
      " Loss: 0.000000\n",
      " Loss: 0.029635\n",
      " Loss: 0.000000\n",
      " Loss: 0.061539\n",
      " Loss: 0.000000\n",
      " Loss: 0.040890\n",
      " Loss: 0.000000\n",
      " Loss: 0.024915\n",
      " Loss: 0.000000\n",
      " Loss: 0.015587\n",
      " Loss: 0.000000\n",
      " Loss: 0.017906\n",
      "Epoch 2610 Chain 0 loss std 9.38e-04 variance 4.40e-07 smooth variance 4.05e-07 adaptive c -1.00\n",
      "Epoch 2610 Chain 1 loss std 2.02e+02 variance 2.04e+04 smooth variance 1.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022760\n",
      " Loss: 0.000000\n",
      " Loss: 0.073969\n",
      " Loss: 0.000000\n",
      " Loss: 0.015590\n",
      " Loss: 0.000000\n",
      " Loss: 0.034712\n",
      " Loss: 0.000000\n",
      " Loss: 0.013806\n",
      " Loss: 0.000000\n",
      " Loss: 0.029081\n",
      " Loss: 0.000000\n",
      " Loss: 0.036575\n",
      " Loss: 0.000000\n",
      " Loss: 0.020953\n",
      " Loss: 0.000000\n",
      " Loss: 0.058233\n",
      " Loss: 0.000000\n",
      " Loss: 0.015996\n",
      "Epoch 2612 Chain 0 loss std 1.40e-03 variance 9.80e-07 smooth variance 5.77e-07 adaptive c -1.00\n",
      "Epoch 2612 Chain 1 loss std 2.36e+02 variance 2.79e+04 smooth variance 2.23e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020511\n",
      " Loss: 0.000000\n",
      " Loss: 0.031959\n",
      " Loss: 0.000000\n",
      " Loss: 0.029379\n",
      " Loss: 0.000000\n",
      " Loss: 0.012579\n",
      " Loss: 0.000000\n",
      " Loss: 0.066409\n",
      " Loss: 0.000000\n",
      " Loss: 0.013040\n",
      " Loss: 0.000000\n",
      " Loss: 0.028439\n",
      " Loss: 0.000000\n",
      " Loss: 0.024563\n",
      " Loss: 0.000000\n",
      " Loss: 0.073214\n",
      " Loss: 0.000000\n",
      " Loss: 0.021582\n",
      "Epoch 2614 Chain 0 loss std 9.94e-04 variance 4.94e-07 smooth variance 5.52e-07 adaptive c -1.00\n",
      "Epoch 2614 Chain 1 loss std 3.11e+02 variance 4.82e+04 smooth variance 3.00e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021783\n",
      " Loss: 0.000000\n",
      " Loss: 0.034641\n",
      " Loss: 0.000000\n",
      " Loss: 0.063506\n",
      " Loss: 0.000000\n",
      " Loss: 0.019202\n",
      " Loss: 0.000000\n",
      " Loss: 0.021705\n",
      " Loss: 0.000000\n",
      " Loss: 0.012425\n",
      " Loss: 0.000000\n",
      " Loss: 0.024749\n",
      " Loss: 0.000000\n",
      " Loss: 0.037005\n",
      " Loss: 0.000000\n",
      " Loss: 0.024139\n",
      " Loss: 0.000000\n",
      " Loss: 0.062520\n",
      "Epoch 2616 Chain 0 loss std 7.30e-04 variance 2.66e-07 smooth variance 4.66e-07 adaptive c -1.00\n",
      "Epoch 2616 Chain 1 loss std 2.11e+02 variance 2.23e+04 smooth variance 2.77e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017712\n",
      " Loss: 0.000000\n",
      " Loss: 0.023789\n",
      " Loss: 0.000000\n",
      " Loss: 0.061438\n",
      " Loss: 0.000000\n",
      " Loss: 0.022010\n",
      " Loss: 0.000000\n",
      " Loss: 0.035889\n",
      " Loss: 0.000000\n",
      " Loss: 0.017657\n",
      " Loss: 0.000000\n",
      " Loss: 0.071120\n",
      " Loss: 0.000000\n",
      " Loss: 0.016867\n",
      " Loss: 0.000000\n",
      " Loss: 0.018466\n",
      " Loss: 0.000000\n",
      " Loss: 0.036728\n",
      "Epoch 2618 Chain 0 loss std 5.97e-04 variance 1.78e-07 smooth variance 3.80e-07 adaptive c -1.00\n",
      "Epoch 2618 Chain 1 loss std 1.46e+02 variance 1.07e+04 smooth variance 2.26e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021024\n",
      " Loss: 0.000000\n",
      " Loss: 0.042482\n",
      " Loss: 0.000000\n",
      " Loss: 0.063736\n",
      " Loss: 0.000000\n",
      " Loss: 0.019615\n",
      " Loss: 0.000000\n",
      " Loss: 0.013981\n",
      " Loss: 0.000000\n",
      " Loss: 0.033916\n",
      " Loss: 0.000000\n",
      " Loss: 0.023151\n",
      " Loss: 0.000000\n",
      " Loss: 0.059563\n",
      " Loss: 0.000000\n",
      " Loss: 0.013762\n",
      " Loss: 0.000000\n",
      " Loss: 0.030445\n",
      "Epoch 2620 Chain 0 loss std 9.48e-04 variance 4.49e-07 smooth variance 4.01e-07 adaptive c -1.00\n",
      "Epoch 2620 Chain 1 loss std 2.13e+02 variance 2.27e+04 smooth variance 2.26e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021413\n",
      " Loss: 0.000000\n",
      " Loss: 0.063883\n",
      " Loss: 0.000000\n",
      " Loss: 0.017037\n",
      " Loss: 0.000000\n",
      " Loss: 0.036623\n",
      " Loss: 0.000000\n",
      " Loss: 0.021881\n",
      " Loss: 0.000000\n",
      " Loss: 0.031335\n",
      " Loss: 0.000000\n",
      " Loss: 0.067558\n",
      " Loss: 0.000000\n",
      " Loss: 0.017860\n",
      " Loss: 0.000000\n",
      " Loss: 0.021975\n",
      " Loss: 0.000000\n",
      " Loss: 0.022110\n",
      "Epoch 2622 Chain 0 loss std 1.35e-03 variance 9.17e-07 smooth variance 5.56e-07 adaptive c -1.00\n",
      "Epoch 2622 Chain 1 loss std 1.58e+02 variance 1.25e+04 smooth variance 1.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.065544\n",
      " Loss: 0.000000\n",
      " Loss: 0.018163\n",
      " Loss: 0.000000\n",
      " Loss: 0.033186\n",
      " Loss: 0.000000\n",
      " Loss: 0.016584\n",
      " Loss: 0.000000\n",
      " Loss: 0.027360\n",
      " Loss: 0.000000\n",
      " Loss: 0.018460\n",
      " Loss: 0.000000\n",
      " Loss: 0.058511\n",
      " Loss: 0.000000\n",
      " Loss: 0.031844\n",
      " Loss: 0.000000\n",
      " Loss: 0.025283\n",
      " Loss: 0.000000\n",
      " Loss: 0.026739\n",
      "Epoch 2624 Chain 0 loss std 6.31e-04 variance 1.99e-07 smooth variance 4.49e-07 adaptive c -1.00\n",
      "Epoch 2624 Chain 1 loss std 1.77e+02 variance 1.57e+04 smooth variance 1.84e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024561\n",
      " Loss: 0.000000\n",
      " Loss: 0.030336\n",
      " Loss: 0.000000\n",
      " Loss: 0.017391\n",
      " Loss: 0.000000\n",
      " Loss: 0.020094\n",
      " Loss: 0.000000\n",
      " Loss: 0.068456\n",
      " Loss: 0.000000\n",
      " Loss: 0.022244\n",
      " Loss: 0.000000\n",
      " Loss: 0.030168\n",
      " Loss: 0.000000\n",
      " Loss: 0.067372\n",
      " Loss: 0.000000\n",
      " Loss: 0.021173\n",
      " Loss: 0.000000\n",
      " Loss: 0.019881\n",
      "Epoch 2626 Chain 0 loss std 9.95e-04 variance 4.95e-07 smooth variance 4.63e-07 adaptive c -1.00\n",
      "Epoch 2626 Chain 1 loss std 2.67e+02 variance 3.56e+04 smooth variance 2.36e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017043\n",
      " Loss: 0.000000\n",
      " Loss: 0.065884\n",
      " Loss: 0.000000\n",
      " Loss: 0.023744\n",
      " Loss: 0.000000\n",
      " Loss: 0.034251\n",
      " Loss: 0.000000\n",
      " Loss: 0.019916\n",
      " Loss: 0.000000\n",
      " Loss: 0.055351\n",
      " Loss: 0.000000\n",
      " Loss: 0.035503\n",
      " Loss: 0.000000\n",
      " Loss: 0.021405\n",
      " Loss: 0.000000\n",
      " Loss: 0.032726\n",
      " Loss: 0.000000\n",
      " Loss: 0.015853\n",
      "Epoch 2628 Chain 0 loss std 6.22e-04 variance 1.93e-07 smooth variance 3.82e-07 adaptive c -1.00\n",
      "Epoch 2628 Chain 1 loss std 1.83e+02 variance 1.67e+04 smooth variance 2.15e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017572\n",
      " Loss: 0.000000\n",
      " Loss: 0.065478\n",
      " Loss: 0.000000\n",
      " Loss: 0.019185\n",
      " Loss: 0.000000\n",
      " Loss: 0.039390\n",
      " Loss: 0.000000\n",
      " Loss: 0.019213\n",
      " Loss: 0.000000\n",
      " Loss: 0.020661\n",
      " Loss: 0.000000\n",
      " Loss: 0.059696\n",
      " Loss: 0.000000\n",
      " Loss: 0.042988\n",
      " Loss: 0.000000\n",
      " Loss: 0.014887\n",
      " Loss: 0.000000\n",
      " Loss: 0.022606\n",
      "Epoch 2630 Chain 0 loss std 7.40e-04 variance 2.74e-07 smooth variance 3.49e-07 adaptive c -1.00\n",
      "Epoch 2630 Chain 1 loss std 1.92e+02 variance 1.84e+04 smooth variance 2.06e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025842\n",
      " Loss: 0.000000\n",
      " Loss: 0.041734\n",
      " Loss: 0.000000\n",
      " Loss: 0.057490\n",
      " Loss: 0.000000\n",
      " Loss: 0.018069\n",
      " Loss: 0.000000\n",
      " Loss: 0.017703\n",
      " Loss: 0.000000\n",
      " Loss: 0.013993\n",
      " Loss: 0.000000\n",
      " Loss: 0.021486\n",
      " Loss: 0.000000\n",
      " Loss: 0.060199\n",
      " Loss: 0.000000\n",
      " Loss: 0.049589\n",
      " Loss: 0.000000\n",
      " Loss: 0.015571\n",
      "Epoch 2632 Chain 0 loss std 1.12e-03 variance 6.29e-07 smooth variance 4.33e-07 adaptive c -1.00\n",
      "Epoch 2632 Chain 1 loss std 2.26e+02 variance 2.56e+04 smooth variance 2.21e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035814\n",
      " Loss: 0.000000\n",
      " Loss: 0.020336\n",
      " Loss: 0.000000\n",
      " Loss: 0.031550\n",
      " Loss: 0.000000\n",
      " Loss: 0.019418\n",
      " Loss: 0.000000\n",
      " Loss: 0.053720\n",
      " Loss: 0.000000\n",
      " Loss: 0.021813\n",
      " Loss: 0.000000\n",
      " Loss: 0.012779\n",
      " Loss: 0.000000\n",
      " Loss: 0.018522\n",
      " Loss: 0.000000\n",
      " Loss: 0.088396\n",
      " Loss: 0.000000\n",
      " Loss: 0.019329\n",
      "Epoch 2634 Chain 0 loss std 9.25e-04 variance 4.28e-07 smooth variance 4.32e-07 adaptive c -1.00\n",
      "Epoch 2634 Chain 1 loss std 1.72e+02 variance 1.49e+04 smooth variance 1.99e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035842\n",
      " Loss: 0.000000\n",
      " Loss: 0.025009\n",
      " Loss: 0.000000\n",
      " Loss: 0.026253\n",
      " Loss: 0.000000\n",
      " Loss: 0.021226\n",
      " Loss: 0.000000\n",
      " Loss: 0.052507\n",
      " Loss: 0.000000\n",
      " Loss: 0.022509\n",
      " Loss: 0.000000\n",
      " Loss: 0.038178\n",
      " Loss: 0.000000\n",
      " Loss: 0.013701\n",
      " Loss: 0.000000\n",
      " Loss: 0.020393\n",
      " Loss: 0.000000\n",
      " Loss: 0.066057\n",
      "Epoch 2636 Chain 0 loss std 8.04e-04 variance 3.23e-07 smooth variance 3.99e-07 adaptive c -1.00\n",
      "Epoch 2636 Chain 1 loss std 1.75e+02 variance 1.54e+04 smooth variance 1.86e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020022\n",
      " Loss: 0.000000\n",
      " Loss: 0.022453\n",
      " Loss: 0.000000\n",
      " Loss: 0.012940\n",
      " Loss: 0.000000\n",
      " Loss: 0.022553\n",
      " Loss: 0.000000\n",
      " Loss: 0.082869\n",
      " Loss: 0.000000\n",
      " Loss: 0.014205\n",
      " Loss: 0.000000\n",
      " Loss: 0.028980\n",
      " Loss: 0.000000\n",
      " Loss: 0.023678\n",
      " Loss: 0.000000\n",
      " Loss: 0.071512\n",
      " Loss: 0.000000\n",
      " Loss: 0.022463\n",
      "Epoch 2638 Chain 0 loss std 7.72e-04 variance 2.98e-07 smooth variance 3.69e-07 adaptive c -1.00\n",
      "Epoch 2638 Chain 1 loss std 2.40e+02 variance 2.87e+04 smooth variance 2.16e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.055281\n",
      " Loss: 0.000000\n",
      " Loss: 0.017494\n",
      " Loss: 0.000000\n",
      " Loss: 0.020717\n",
      " Loss: 0.000000\n",
      " Loss: 0.034045\n",
      " Loss: 0.000000\n",
      " Loss: 0.033301\n",
      " Loss: 0.000000\n",
      " Loss: 0.016338\n",
      " Loss: 0.000000\n",
      " Loss: 0.023266\n",
      " Loss: 0.000000\n",
      " Loss: 0.035889\n",
      " Loss: 0.000000\n",
      " Loss: 0.060443\n",
      " Loss: 0.000000\n",
      " Loss: 0.024901\n",
      "Epoch 2640 Chain 0 loss std 8.78e-04 variance 3.86e-07 smooth variance 3.74e-07 adaptive c -1.00\n",
      "Epoch 2640 Chain 1 loss std 1.83e+02 variance 1.67e+04 smooth variance 2.01e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037432\n",
      " Loss: 0.000000\n",
      " Loss: 0.015557\n",
      " Loss: 0.000000\n",
      " Loss: 0.022485\n",
      " Loss: 0.000000\n",
      " Loss: 0.018039\n",
      " Loss: 0.000000\n",
      " Loss: 0.067326\n",
      " Loss: 0.000000\n",
      " Loss: 0.016647\n",
      " Loss: 0.000000\n",
      " Loss: 0.028471\n",
      " Loss: 0.000000\n",
      " Loss: 0.022609\n",
      " Loss: 0.000000\n",
      " Loss: 0.056604\n",
      " Loss: 0.000000\n",
      " Loss: 0.036507\n",
      "Epoch 2642 Chain 0 loss std 7.16e-04 variance 2.57e-07 smooth variance 3.39e-07 adaptive c -1.00\n",
      "Epoch 2642 Chain 1 loss std 2.80e+02 variance 3.91e+04 smooth variance 2.58e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037398\n",
      " Loss: 0.000000\n",
      " Loss: 0.072326\n",
      " Loss: 0.000000\n",
      " Loss: 0.017002\n",
      " Loss: 0.000000\n",
      " Loss: 0.011422\n",
      " Loss: 0.000000\n",
      " Loss: 0.022690\n",
      " Loss: 0.000000\n",
      " Loss: 0.067509\n",
      " Loss: 0.000000\n",
      " Loss: 0.018920\n",
      " Loss: 0.000000\n",
      " Loss: 0.036328\n",
      " Loss: 0.000000\n",
      " Loss: 0.019758\n",
      " Loss: 0.000000\n",
      " Loss: 0.018323\n",
      "Epoch 2644 Chain 0 loss std 1.11e-03 variance 6.17e-07 smooth variance 4.22e-07 adaptive c -1.00\n",
      "Epoch 2644 Chain 1 loss std 2.12e+02 variance 2.25e+04 smooth variance 2.48e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.012991\n",
      " Loss: 0.000000\n",
      " Loss: 0.028977\n",
      " Loss: 0.000000\n",
      " Loss: 0.021473\n",
      " Loss: 0.000000\n",
      " Loss: 0.022668\n",
      " Loss: 0.000000\n",
      " Loss: 0.074729\n",
      " Loss: 0.000000\n",
      " Loss: 0.016609\n",
      " Loss: 0.000000\n",
      " Loss: 0.057805\n",
      " Loss: 0.000000\n",
      " Loss: 0.024466\n",
      " Loss: 0.000000\n",
      " Loss: 0.044721\n",
      " Loss: 0.000000\n",
      " Loss: 0.017238\n",
      "Epoch 2646 Chain 0 loss std 5.77e-04 variance 1.66e-07 smooth variance 3.45e-07 adaptive c -1.00\n",
      "Epoch 2646 Chain 1 loss std 2.45e+02 variance 3.00e+04 smooth variance 2.64e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021020\n",
      " Loss: 0.000000\n",
      " Loss: 0.072712\n",
      " Loss: 0.000000\n",
      " Loss: 0.019855\n",
      " Loss: 0.000000\n",
      " Loss: 0.012436\n",
      " Loss: 0.000000\n",
      " Loss: 0.034815\n",
      " Loss: 0.000000\n",
      " Loss: 0.017168\n",
      " Loss: 0.000000\n",
      " Loss: 0.078569\n",
      " Loss: 0.000000\n",
      " Loss: 0.023535\n",
      " Loss: 0.000000\n",
      " Loss: 0.019047\n",
      " Loss: 0.000000\n",
      " Loss: 0.022519\n",
      "Epoch 2648 Chain 0 loss std 7.70e-04 variance 2.96e-07 smooth variance 3.31e-07 adaptive c -1.00\n",
      "Epoch 2648 Chain 1 loss std 2.12e+02 variance 2.24e+04 smooth variance 2.52e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015674\n",
      " Loss: 0.000000\n",
      " Loss: 0.045801\n",
      " Loss: 0.000000\n",
      " Loss: 0.023188\n",
      " Loss: 0.000000\n",
      " Loss: 0.023840\n",
      " Loss: 0.000000\n",
      " Loss: 0.052334\n",
      " Loss: 0.000000\n",
      " Loss: 0.025461\n",
      " Loss: 0.000000\n",
      " Loss: 0.043754\n",
      " Loss: 0.000000\n",
      " Loss: 0.060338\n",
      " Loss: 0.000000\n",
      " Loss: 0.014101\n",
      " Loss: 0.000000\n",
      " Loss: 0.017184\n",
      "Epoch 2650 Chain 0 loss std 1.42e-03 variance 1.00e-06 smooth variance 5.33e-07 adaptive c -1.00\n",
      "Epoch 2650 Chain 1 loss std 1.54e+02 variance 1.19e+04 smooth variance 2.12e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.079000\n",
      " Loss: 0.000000\n",
      " Loss: 0.019518\n",
      " Loss: 0.000000\n",
      " Loss: 0.017442\n",
      " Loss: 0.000000\n",
      " Loss: 0.025169\n",
      " Loss: 0.000000\n",
      " Loss: 0.019708\n",
      " Loss: 0.000000\n",
      " Loss: 0.016749\n",
      " Loss: 0.000000\n",
      " Loss: 0.036492\n",
      " Loss: 0.000000\n",
      " Loss: 0.020814\n",
      " Loss: 0.000000\n",
      " Loss: 0.024719\n",
      " Loss: 0.000000\n",
      " Loss: 0.062064\n",
      "Epoch 2652 Chain 0 loss std 7.24e-04 variance 2.62e-07 smooth variance 4.52e-07 adaptive c -1.00\n",
      "Epoch 2652 Chain 1 loss std 2.14e+02 variance 2.28e+04 smooth variance 2.17e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.056984\n",
      " Loss: 0.000000\n",
      " Loss: 0.015193\n",
      " Loss: 0.000000\n",
      " Loss: 0.045422\n",
      " Loss: 0.000000\n",
      " Loss: 0.026311\n",
      " Loss: 0.000000\n",
      " Loss: 0.016927\n",
      " Loss: 0.000000\n",
      " Loss: 0.037671\n",
      " Loss: 0.000000\n",
      " Loss: 0.015031\n",
      " Loss: 0.000000\n",
      " Loss: 0.031218\n",
      " Loss: 0.000000\n",
      " Loss: 0.018043\n",
      " Loss: 0.000000\n",
      " Loss: 0.058875\n",
      "Epoch 2654 Chain 0 loss std 9.48e-04 variance 4.50e-07 smooth variance 4.51e-07 adaptive c -1.00\n",
      "Epoch 2654 Chain 1 loss std 2.19e+02 variance 2.40e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.031885\n",
      " Loss: 0.000000\n",
      " Loss: 0.017755\n",
      " Loss: 0.000000\n",
      " Loss: 0.015920\n",
      " Loss: 0.000000\n",
      " Loss: 0.026515\n",
      " Loss: 0.000000\n",
      " Loss: 0.068762\n",
      " Loss: 0.000000\n",
      " Loss: 0.059441\n",
      " Loss: 0.000000\n",
      " Loss: 0.021804\n",
      " Loss: 0.000000\n",
      " Loss: 0.030463\n",
      " Loss: 0.000000\n",
      " Loss: 0.010999\n",
      " Loss: 0.000000\n",
      " Loss: 0.038131\n",
      "Epoch 2656 Chain 0 loss std 1.28e-03 variance 8.25e-07 smooth variance 5.63e-07 adaptive c -1.00\n",
      "Epoch 2656 Chain 1 loss std 1.90e+02 variance 1.80e+04 smooth variance 2.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.030835\n",
      " Loss: 0.000000\n",
      " Loss: 0.016733\n",
      " Loss: 0.000000\n",
      " Loss: 0.020372\n",
      " Loss: 0.000000\n",
      " Loss: 0.012640\n",
      " Loss: 0.000000\n",
      " Loss: 0.080257\n",
      " Loss: 0.000000\n",
      " Loss: 0.012892\n",
      " Loss: 0.000000\n",
      " Loss: 0.012525\n",
      " Loss: 0.000000\n",
      " Loss: 0.068762\n",
      " Loss: 0.000000\n",
      " Loss: 0.022857\n",
      " Loss: 0.000000\n",
      " Loss: 0.043802\n",
      "Epoch 2658 Chain 0 loss std 1.51e-03 variance 1.14e-06 smooth variance 7.37e-07 adaptive c -1.00\n",
      "Epoch 2658 Chain 1 loss std 1.79e+02 variance 1.61e+04 smooth variance 1.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018981\n",
      " Loss: 0.000000\n",
      " Loss: 0.033753\n",
      " Loss: 0.000000\n",
      " Loss: 0.011523\n",
      " Loss: 0.000000\n",
      " Loss: 0.082889\n",
      " Loss: 0.000000\n",
      " Loss: 0.013692\n",
      " Loss: 0.000000\n",
      " Loss: 0.017942\n",
      " Loss: 0.000000\n",
      " Loss: 0.018913\n",
      " Loss: 0.000000\n",
      " Loss: 0.032415\n",
      " Loss: 0.000000\n",
      " Loss: 0.029716\n",
      " Loss: 0.000000\n",
      " Loss: 0.061852\n",
      "Epoch 2660 Chain 0 loss std 1.06e-03 variance 5.63e-07 smooth variance 6.85e-07 adaptive c -1.00\n",
      "Epoch 2660 Chain 1 loss std 2.60e+02 variance 3.38e+04 smooth variance 2.38e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.060001\n",
      " Loss: 0.000000\n",
      " Loss: 0.019763\n",
      " Loss: 0.000000\n",
      " Loss: 0.022860\n",
      " Loss: 0.000000\n",
      " Loss: 0.019639\n",
      " Loss: 0.000000\n",
      " Loss: 0.038574\n",
      " Loss: 0.000000\n",
      " Loss: 0.055851\n",
      " Loss: 0.000000\n",
      " Loss: 0.022414\n",
      " Loss: 0.000000\n",
      " Loss: 0.027040\n",
      " Loss: 0.000000\n",
      " Loss: 0.017186\n",
      " Loss: 0.000000\n",
      " Loss: 0.038346\n",
      "Epoch 2662 Chain 0 loss std 1.16e-03 variance 6.73e-07 smooth variance 6.82e-07 adaptive c -1.00\n",
      "Epoch 2662 Chain 1 loss std 1.92e+02 variance 1.84e+04 smooth variance 2.22e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018987\n",
      " Loss: 0.000000\n",
      " Loss: 0.024228\n",
      " Loss: 0.000000\n",
      " Loss: 0.022999\n",
      " Loss: 0.000000\n",
      " Loss: 0.073685\n",
      " Loss: 0.000000\n",
      " Loss: 0.020939\n",
      " Loss: 0.000000\n",
      " Loss: 0.063528\n",
      " Loss: 0.000000\n",
      " Loss: 0.030341\n",
      " Loss: 0.000000\n",
      " Loss: 0.033245\n",
      " Loss: 0.000000\n",
      " Loss: 0.023148\n",
      " Loss: 0.000000\n",
      " Loss: 0.010576\n",
      "Epoch 2664 Chain 0 loss std 1.05e-03 variance 5.49e-07 smooth variance 6.42e-07 adaptive c -1.00\n",
      "Epoch 2664 Chain 1 loss std 2.04e+02 variance 2.08e+04 smooth variance 2.18e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.038728\n",
      " Loss: 0.000000\n",
      " Loss: 0.010877\n",
      " Loss: 0.000000\n",
      " Loss: 0.011641\n",
      " Loss: 0.000000\n",
      " Loss: 0.072336\n",
      " Loss: 0.000000\n",
      " Loss: 0.027256\n",
      " Loss: 0.000000\n",
      " Loss: 0.013485\n",
      " Loss: 0.000000\n",
      " Loss: 0.042713\n",
      " Loss: 0.000000\n",
      " Loss: 0.011727\n",
      " Loss: 0.000000\n",
      " Loss: 0.071401\n",
      " Loss: 0.000000\n",
      " Loss: 0.021511\n",
      "Epoch 2666 Chain 0 loss std 1.03e-03 variance 5.27e-07 smooth variance 6.07e-07 adaptive c -1.00\n",
      "Epoch 2666 Chain 1 loss std 1.55e+02 variance 1.20e+04 smooth variance 1.88e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.028854\n",
      " Loss: 0.000000\n",
      " Loss: 0.017453\n",
      " Loss: 0.000000\n",
      " Loss: 0.015774\n",
      " Loss: 0.000000\n",
      " Loss: 0.062816\n",
      " Loss: 0.000000\n",
      " Loss: 0.035940\n",
      " Loss: 0.000000\n",
      " Loss: 0.065964\n",
      " Loss: 0.000000\n",
      " Loss: 0.036902\n",
      " Loss: 0.000000\n",
      " Loss: 0.019304\n",
      " Loss: 0.000000\n",
      " Loss: 0.017404\n",
      " Loss: 0.000000\n",
      " Loss: 0.021263\n",
      "Epoch 2668 Chain 0 loss std 8.35e-04 variance 3.48e-07 smooth variance 5.30e-07 adaptive c -1.00\n",
      "Epoch 2668 Chain 1 loss std 1.72e+02 variance 1.48e+04 smooth variance 1.76e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015635\n",
      " Loss: 0.000000\n",
      " Loss: 0.056546\n",
      " Loss: 0.000000\n",
      " Loss: 0.031658\n",
      " Loss: 0.000000\n",
      " Loss: 0.041176\n",
      " Loss: 0.000000\n",
      " Loss: 0.015823\n",
      " Loss: 0.000000\n",
      " Loss: 0.015183\n",
      " Loss: 0.000000\n",
      " Loss: 0.083795\n",
      " Loss: 0.000000\n",
      " Loss: 0.024237\n",
      " Loss: 0.000000\n",
      " Loss: 0.022726\n",
      " Loss: 0.000000\n",
      " Loss: 0.014897\n",
      "Epoch 2670 Chain 0 loss std 7.57e-04 variance 2.87e-07 smooth variance 4.57e-07 adaptive c -1.00\n",
      "Epoch 2670 Chain 1 loss std 2.24e+02 variance 2.50e+04 smooth variance 1.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024055\n",
      " Loss: 0.000000\n",
      " Loss: 0.032344\n",
      " Loss: 0.000000\n",
      " Loss: 0.027181\n",
      " Loss: 0.000000\n",
      " Loss: 0.055894\n",
      " Loss: 0.000000\n",
      " Loss: 0.021363\n",
      " Loss: 0.000000\n",
      " Loss: 0.049640\n",
      " Loss: 0.000000\n",
      " Loss: 0.012928\n",
      " Loss: 0.000000\n",
      " Loss: 0.018404\n",
      " Loss: 0.000000\n",
      " Loss: 0.018293\n",
      " Loss: 0.000000\n",
      " Loss: 0.061574\n",
      "Epoch 2672 Chain 0 loss std 8.83e-04 variance 3.89e-07 smooth variance 4.37e-07 adaptive c -1.00\n",
      "Epoch 2672 Chain 1 loss std 2.21e+02 variance 2.44e+04 smooth variance 2.12e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037013\n",
      " Loss: 0.000000\n",
      " Loss: 0.023562\n",
      " Loss: 0.000000\n",
      " Loss: 0.018545\n",
      " Loss: 0.000000\n",
      " Loss: 0.060928\n",
      " Loss: 0.000000\n",
      " Loss: 0.020790\n",
      " Loss: 0.000000\n",
      " Loss: 0.011641\n",
      " Loss: 0.000000\n",
      " Loss: 0.026265\n",
      " Loss: 0.000000\n",
      " Loss: 0.036924\n",
      " Loss: 0.000000\n",
      " Loss: 0.058776\n",
      " Loss: 0.000000\n",
      " Loss: 0.027232\n",
      "Epoch 2674 Chain 0 loss std 4.06e-04 variance 8.24e-08 smooth variance 3.30e-07 adaptive c -1.00\n",
      "Epoch 2674 Chain 1 loss std 2.98e+02 variance 4.45e+04 smooth variance 2.82e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.056363\n",
      " Loss: 0.000000\n",
      " Loss: 0.017001\n",
      " Loss: 0.000000\n",
      " Loss: 0.023582\n",
      " Loss: 0.000000\n",
      " Loss: 0.028213\n",
      " Loss: 0.000000\n",
      " Loss: 0.035679\n",
      " Loss: 0.000000\n",
      " Loss: 0.014027\n",
      " Loss: 0.000000\n",
      " Loss: 0.026211\n",
      " Loss: 0.000000\n",
      " Loss: 0.082195\n",
      " Loss: 0.000000\n",
      " Loss: 0.009819\n",
      " Loss: 0.000000\n",
      " Loss: 0.028585\n",
      "Epoch 2676 Chain 0 loss std 1.23e-03 variance 7.52e-07 smooth variance 4.57e-07 adaptive c -1.00\n",
      "Epoch 2676 Chain 1 loss std 2.87e+02 variance 4.11e+04 smooth variance 3.21e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020963\n",
      " Loss: 0.000000\n",
      " Loss: 0.077630\n",
      " Loss: 0.000000\n",
      " Loss: 0.024704\n",
      " Loss: 0.000000\n",
      " Loss: 0.013604\n",
      " Loss: 0.000000\n",
      " Loss: 0.023937\n",
      " Loss: 0.000000\n",
      " Loss: 0.020684\n",
      " Loss: 0.000000\n",
      " Loss: 0.058359\n",
      " Loss: 0.000000\n",
      " Loss: 0.039686\n",
      " Loss: 0.000000\n",
      " Loss: 0.020275\n",
      " Loss: 0.000000\n",
      " Loss: 0.021834\n",
      "Epoch 2678 Chain 0 loss std 1.62e-03 variance 1.31e-06 smooth variance 7.12e-07 adaptive c -1.00\n",
      "Epoch 2678 Chain 1 loss std 2.33e+02 variance 2.72e+04 smooth variance 3.06e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021336\n",
      " Loss: 0.000000\n",
      " Loss: 0.059229\n",
      " Loss: 0.000000\n",
      " Loss: 0.020844\n",
      " Loss: 0.000000\n",
      " Loss: 0.035545\n",
      " Loss: 0.000000\n",
      " Loss: 0.023883\n",
      " Loss: 0.000000\n",
      " Loss: 0.018292\n",
      " Loss: 0.000000\n",
      " Loss: 0.066742\n",
      " Loss: 0.000000\n",
      " Loss: 0.017831\n",
      " Loss: 0.000000\n",
      " Loss: 0.016669\n",
      " Loss: 0.000000\n",
      " Loss: 0.041303\n",
      "Epoch 2680 Chain 0 loss std 9.06e-04 variance 4.11e-07 smooth variance 6.21e-07 adaptive c -1.00\n",
      "Epoch 2680 Chain 1 loss std 1.96e+02 variance 1.93e+04 smooth variance 2.72e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022314\n",
      " Loss: 0.000000\n",
      " Loss: 0.026800\n",
      " Loss: 0.000000\n",
      " Loss: 0.009075\n",
      " Loss: 0.000000\n",
      " Loss: 0.081150\n",
      " Loss: 0.000000\n",
      " Loss: 0.021499\n",
      " Loss: 0.000000\n",
      " Loss: 0.024922\n",
      " Loss: 0.000000\n",
      " Loss: 0.016555\n",
      " Loss: 0.000000\n",
      " Loss: 0.014245\n",
      " Loss: 0.000000\n",
      " Loss: 0.042577\n",
      " Loss: 0.000000\n",
      " Loss: 0.062538\n",
      "Epoch 2682 Chain 0 loss std 1.57e-03 variance 1.23e-06 smooth variance 8.05e-07 adaptive c -1.00\n",
      "Epoch 2682 Chain 1 loss std 1.80e+02 variance 1.62e+04 smooth variance 2.39e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033073\n",
      " Loss: 0.000000\n",
      " Loss: 0.015733\n",
      " Loss: 0.000000\n",
      " Loss: 0.021469\n",
      " Loss: 0.000000\n",
      " Loss: 0.018374\n",
      " Loss: 0.000000\n",
      " Loss: 0.072189\n",
      " Loss: 0.000000\n",
      " Loss: 0.015393\n",
      " Loss: 0.000000\n",
      " Loss: 0.076736\n",
      " Loss: 0.000000\n",
      " Loss: 0.022884\n",
      " Loss: 0.000000\n",
      " Loss: 0.017857\n",
      " Loss: 0.000000\n",
      " Loss: 0.027967\n",
      "Epoch 2684 Chain 0 loss std 1.28e-03 variance 8.25e-07 smooth variance 8.11e-07 adaptive c -1.00\n",
      "Epoch 2684 Chain 1 loss std 2.28e+02 variance 2.60e+04 smooth variance 2.45e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.051910\n",
      " Loss: 0.000000\n",
      " Loss: 0.013653\n",
      " Loss: 0.000000\n",
      " Loss: 0.019433\n",
      " Loss: 0.000000\n",
      " Loss: 0.017017\n",
      " Loss: 0.000000\n",
      " Loss: 0.058825\n",
      " Loss: 0.000000\n",
      " Loss: 0.033889\n",
      " Loss: 0.000000\n",
      " Loss: 0.017090\n",
      " Loss: 0.000000\n",
      " Loss: 0.022235\n",
      " Loss: 0.000000\n",
      " Loss: 0.033982\n",
      " Loss: 0.000000\n",
      " Loss: 0.053641\n",
      "Epoch 2686 Chain 0 loss std 6.30e-04 variance 1.99e-07 smooth variance 6.27e-07 adaptive c -1.00\n",
      "Epoch 2686 Chain 1 loss std 1.77e+02 variance 1.56e+04 smooth variance 2.19e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.060611\n",
      " Loss: 0.000000\n",
      " Loss: 0.030826\n",
      " Loss: 0.000000\n",
      " Loss: 0.024127\n",
      " Loss: 0.000000\n",
      " Loss: 0.035230\n",
      " Loss: 0.000000\n",
      " Loss: 0.010044\n",
      " Loss: 0.000000\n",
      " Loss: 0.048994\n",
      " Loss: 0.000000\n",
      " Loss: 0.057039\n",
      " Loss: 0.000000\n",
      " Loss: 0.017663\n",
      " Loss: 0.000000\n",
      " Loss: 0.008377\n",
      " Loss: 0.000000\n",
      " Loss: 0.028765\n",
      "Epoch 2688 Chain 0 loss std 1.51e-03 variance 1.14e-06 smooth variance 7.81e-07 adaptive c -1.00\n",
      "Epoch 2688 Chain 1 loss std 1.91e+02 variance 1.83e+04 smooth variance 2.08e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.064115\n",
      " Loss: 0.000000\n",
      " Loss: 0.025102\n",
      " Loss: 0.000000\n",
      " Loss: 0.013205\n",
      " Loss: 0.000000\n",
      " Loss: 0.024775\n",
      " Loss: 0.000000\n",
      " Loss: 0.033641\n",
      " Loss: 0.000000\n",
      " Loss: 0.057475\n",
      " Loss: 0.000000\n",
      " Loss: 0.021324\n",
      " Loss: 0.000000\n",
      " Loss: 0.018932\n",
      " Loss: 0.000000\n",
      " Loss: 0.046358\n",
      " Loss: 0.000000\n",
      " Loss: 0.016749\n",
      "Epoch 2690 Chain 0 loss std 1.01e-03 variance 5.07e-07 smooth variance 6.98e-07 adaptive c -1.00\n",
      "Epoch 2690 Chain 1 loss std 1.49e+02 variance 1.11e+04 smooth variance 1.79e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021233\n",
      " Loss: 0.000000\n",
      " Loss: 0.019025\n",
      " Loss: 0.000000\n",
      " Loss: 0.024222\n",
      " Loss: 0.000000\n",
      " Loss: 0.063709\n",
      " Loss: 0.000000\n",
      " Loss: 0.032649\n",
      " Loss: 0.000000\n",
      " Loss: 0.023472\n",
      " Loss: 0.000000\n",
      " Loss: 0.054358\n",
      " Loss: 0.000000\n",
      " Loss: 0.026235\n",
      " Loss: 0.000000\n",
      " Loss: 0.026374\n",
      " Loss: 0.000000\n",
      " Loss: 0.030398\n",
      "Epoch 2692 Chain 0 loss std 7.66e-04 variance 2.93e-07 smooth variance 5.77e-07 adaptive c -1.00\n",
      "Epoch 2692 Chain 1 loss std 1.66e+02 variance 1.38e+04 smooth variance 1.67e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.030392\n",
      " Loss: 0.000000\n",
      " Loss: 0.059581\n",
      " Loss: 0.000000\n",
      " Loss: 0.027114\n",
      " Loss: 0.000000\n",
      " Loss: 0.026865\n",
      " Loss: 0.000000\n",
      " Loss: 0.016886\n",
      " Loss: 0.000000\n",
      " Loss: 0.039621\n",
      " Loss: 0.000000\n",
      " Loss: 0.026650\n",
      " Loss: 0.000000\n",
      " Loss: 0.013926\n",
      " Loss: 0.000000\n",
      " Loss: 0.060763\n",
      " Loss: 0.000000\n",
      " Loss: 0.019877\n",
      "Epoch 2694 Chain 0 loss std 6.04e-04 variance 1.83e-07 smooth variance 4.59e-07 adaptive c -1.00\n",
      "Epoch 2694 Chain 1 loss std 1.89e+02 variance 1.79e+04 smooth variance 1.70e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037909\n",
      " Loss: 0.000000\n",
      " Loss: 0.018478\n",
      " Loss: 0.000000\n",
      " Loss: 0.021205\n",
      " Loss: 0.000000\n",
      " Loss: 0.024006\n",
      " Loss: 0.000000\n",
      " Loss: 0.059240\n",
      " Loss: 0.000000\n",
      " Loss: 0.027721\n",
      " Loss: 0.000000\n",
      " Loss: 0.065663\n",
      " Loss: 0.000000\n",
      " Loss: 0.016721\n",
      " Loss: 0.000000\n",
      " Loss: 0.015829\n",
      " Loss: 0.000000\n",
      " Loss: 0.034904\n",
      "Epoch 2696 Chain 0 loss std 7.86e-04 variance 3.09e-07 smooth variance 4.14e-07 adaptive c -1.00\n",
      "Epoch 2696 Chain 1 loss std 2.72e+02 variance 3.71e+04 smooth variance 2.30e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017558\n",
      " Loss: 0.000000\n",
      " Loss: 0.012336\n",
      " Loss: 0.000000\n",
      " Loss: 0.037031\n",
      " Loss: 0.000000\n",
      " Loss: 0.066613\n",
      " Loss: 0.000000\n",
      " Loss: 0.027300\n",
      " Loss: 0.000000\n",
      " Loss: 0.036594\n",
      " Loss: 0.000000\n",
      " Loss: 0.015944\n",
      " Loss: 0.000000\n",
      " Loss: 0.066846\n",
      " Loss: 0.000000\n",
      " Loss: 0.014661\n",
      " Loss: 0.000000\n",
      " Loss: 0.026792\n",
      "Epoch 2698 Chain 0 loss std 1.50e-03 variance 1.13e-06 smooth variance 6.28e-07 adaptive c -1.00\n",
      "Epoch 2698 Chain 1 loss std 3.01e+02 variance 4.54e+04 smooth variance 2.97e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.012467\n",
      " Loss: 0.000000\n",
      " Loss: 0.035078\n",
      " Loss: 0.000000\n",
      " Loss: 0.024997\n",
      " Loss: 0.000000\n",
      " Loss: 0.067930\n",
      " Loss: 0.000000\n",
      " Loss: 0.020366\n",
      " Loss: 0.000000\n",
      " Loss: 0.079144\n",
      " Loss: 0.000000\n",
      " Loss: 0.030752\n",
      " Loss: 0.000000\n",
      " Loss: 0.017592\n",
      " Loss: 0.000000\n",
      " Loss: 0.014998\n",
      " Loss: 0.000000\n",
      " Loss: 0.018351\n",
      "Epoch 2700 Chain 0 loss std 8.13e-04 variance 3.31e-07 smooth variance 5.39e-07 adaptive c -1.00\n",
      "Epoch 2700 Chain 1 loss std 2.77e+02 variance 3.84e+04 smooth variance 3.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.030820\n",
      " Loss: 0.000000\n",
      " Loss: 0.037094\n",
      " Loss: 0.000000\n",
      " Loss: 0.008813\n",
      " Loss: 0.000000\n",
      " Loss: 0.058098\n",
      " Loss: 0.000000\n",
      " Loss: 0.026013\n",
      " Loss: 0.000000\n",
      " Loss: 0.059400\n",
      " Loss: 0.000000\n",
      " Loss: 0.020099\n",
      " Loss: 0.000000\n",
      " Loss: 0.020651\n",
      " Loss: 0.000000\n",
      " Loss: 0.040476\n",
      " Loss: 0.000000\n",
      " Loss: 0.020212\n",
      "Epoch 2702 Chain 0 loss std 1.05e-03 variance 5.52e-07 smooth variance 5.43e-07 adaptive c -1.00\n",
      "Epoch 2702 Chain 1 loss std 2.06e+02 variance 2.13e+04 smooth variance 2.90e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.030017\n",
      " Loss: 0.000000\n",
      " Loss: 0.023895\n",
      " Loss: 0.000000\n",
      " Loss: 0.024861\n",
      " Loss: 0.000000\n",
      " Loss: 0.024666\n",
      " Loss: 0.000000\n",
      " Loss: 0.057399\n",
      " Loss: 0.000000\n",
      " Loss: 0.023711\n",
      " Loss: 0.000000\n",
      " Loss: 0.016560\n",
      " Loss: 0.000000\n",
      " Loss: 0.016769\n",
      " Loss: 0.000000\n",
      " Loss: 0.078813\n",
      " Loss: 0.000000\n",
      " Loss: 0.024984\n",
      "Epoch 2704 Chain 0 loss std 8.50e-04 variance 3.61e-07 smooth variance 4.89e-07 adaptive c -1.00\n",
      "Epoch 2704 Chain 1 loss std 2.17e+02 variance 2.35e+04 smooth variance 2.74e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.041566\n",
      " Loss: 0.000000\n",
      " Loss: 0.061266\n",
      " Loss: 0.000000\n",
      " Loss: 0.023398\n",
      " Loss: 0.000000\n",
      " Loss: 0.012736\n",
      " Loss: 0.000000\n",
      " Loss: 0.021871\n",
      " Loss: 0.000000\n",
      " Loss: 0.059199\n",
      " Loss: 0.000000\n",
      " Loss: 0.029084\n",
      " Loss: 0.000000\n",
      " Loss: 0.015973\n",
      " Loss: 0.000000\n",
      " Loss: 0.044262\n",
      " Loss: 0.000000\n",
      " Loss: 0.012320\n",
      "Epoch 2706 Chain 0 loss std 1.04e-03 variance 5.43e-07 smooth variance 5.05e-07 adaptive c -1.00\n",
      "Epoch 2706 Chain 1 loss std 1.79e+02 variance 1.60e+04 smooth variance 2.40e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035223\n",
      " Loss: 0.000000\n",
      " Loss: 0.058506\n",
      " Loss: 0.000000\n",
      " Loss: 0.032346\n",
      " Loss: 0.000000\n",
      " Loss: 0.020928\n",
      " Loss: 0.000000\n",
      " Loss: 0.013834\n",
      " Loss: 0.000000\n",
      " Loss: 0.059647\n",
      " Loss: 0.000000\n",
      " Loss: 0.030150\n",
      " Loss: 0.000000\n",
      " Loss: 0.022896\n",
      " Loss: 0.000000\n",
      " Loss: 0.016630\n",
      " Loss: 0.000000\n",
      " Loss: 0.031515\n",
      "Epoch 2708 Chain 0 loss std 7.86e-04 variance 3.09e-07 smooth variance 4.46e-07 adaptive c -1.00\n",
      "Epoch 2708 Chain 1 loss std 2.41e+02 variance 2.91e+04 smooth variance 2.55e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.086848\n",
      " Loss: 0.000000\n",
      " Loss: 0.027487\n",
      " Loss: 0.000000\n",
      " Loss: 0.016749\n",
      " Loss: 0.000000\n",
      " Loss: 0.009964\n",
      " Loss: 0.000000\n",
      " Loss: 0.019790\n",
      " Loss: 0.000000\n",
      " Loss: 0.062989\n",
      " Loss: 0.000000\n",
      " Loss: 0.019562\n",
      " Loss: 0.000000\n",
      " Loss: 0.017300\n",
      " Loss: 0.000000\n",
      " Loss: 0.042216\n",
      " Loss: 0.000000\n",
      " Loss: 0.018770\n",
      "Epoch 2710 Chain 0 loss std 9.83e-04 variance 4.83e-07 smooth variance 4.57e-07 adaptive c -1.00\n",
      "Epoch 2710 Chain 1 loss std 2.82e+02 variance 3.97e+04 smooth variance 2.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.055017\n",
      " Loss: 0.000000\n",
      " Loss: 0.034135\n",
      " Loss: 0.000000\n",
      " Loss: 0.039777\n",
      " Loss: 0.000000\n",
      " Loss: 0.009775\n",
      " Loss: 0.000000\n",
      " Loss: 0.022133\n",
      " Loss: 0.000000\n",
      " Loss: 0.027853\n",
      " Loss: 0.000000\n",
      " Loss: 0.015960\n",
      " Loss: 0.000000\n",
      " Loss: 0.059412\n",
      " Loss: 0.000000\n",
      " Loss: 0.026298\n",
      " Loss: 0.000000\n",
      " Loss: 0.031314\n",
      "Epoch 2712 Chain 0 loss std 1.15e-03 variance 6.61e-07 smooth variance 5.18e-07 adaptive c -1.00\n",
      "Epoch 2712 Chain 1 loss std 2.60e+02 variance 3.39e+04 smooth variance 3.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.063743\n",
      " Loss: 0.000000\n",
      " Loss: 0.022342\n",
      " Loss: 0.000000\n",
      " Loss: 0.030753\n",
      " Loss: 0.000000\n",
      " Loss: 0.021918\n",
      " Loss: 0.000000\n",
      " Loss: 0.022082\n",
      " Loss: 0.000000\n",
      " Loss: 0.019734\n",
      " Loss: 0.000000\n",
      " Loss: 0.055461\n",
      " Loss: 0.000000\n",
      " Loss: 0.023880\n",
      " Loss: 0.000000\n",
      " Loss: 0.017466\n",
      " Loss: 0.000000\n",
      " Loss: 0.044296\n",
      "Epoch 2714 Chain 0 loss std 7.60e-04 variance 2.88e-07 smooth variance 4.49e-07 adaptive c -1.00\n",
      "Epoch 2714 Chain 1 loss std 2.38e+02 variance 2.83e+04 smooth variance 3.02e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018630\n",
      " Loss: 0.000000\n",
      " Loss: 0.016763\n",
      " Loss: 0.000000\n",
      " Loss: 0.027659\n",
      " Loss: 0.000000\n",
      " Loss: 0.017538\n",
      " Loss: 0.000000\n",
      " Loss: 0.080248\n",
      " Loss: 0.000000\n",
      " Loss: 0.070329\n",
      " Loss: 0.000000\n",
      " Loss: 0.017816\n",
      " Loss: 0.000000\n",
      " Loss: 0.015066\n",
      " Loss: 0.000000\n",
      " Loss: 0.017269\n",
      " Loss: 0.000000\n",
      " Loss: 0.040357\n",
      "Epoch 2716 Chain 0 loss std 8.52e-04 variance 3.63e-07 smooth variance 4.23e-07 adaptive c -1.00\n",
      "Epoch 2716 Chain 1 loss std 2.46e+02 variance 3.01e+04 smooth variance 3.02e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.065524\n",
      " Loss: 0.000000\n",
      " Loss: 0.025869\n",
      " Loss: 0.000000\n",
      " Loss: 0.032090\n",
      " Loss: 0.000000\n",
      " Loss: 0.021957\n",
      " Loss: 0.000000\n",
      " Loss: 0.015399\n",
      " Loss: 0.000000\n",
      " Loss: 0.015950\n",
      " Loss: 0.000000\n",
      " Loss: 0.016601\n",
      " Loss: 0.000000\n",
      " Loss: 0.065851\n",
      " Loss: 0.000000\n",
      " Loss: 0.036970\n",
      " Loss: 0.000000\n",
      " Loss: 0.025465\n",
      "Epoch 2718 Chain 0 loss std 8.90e-04 variance 3.96e-07 smooth variance 4.15e-07 adaptive c -1.00\n",
      "Epoch 2718 Chain 1 loss std 2.01e+02 variance 2.01e+04 smooth variance 2.72e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.067173\n",
      " Loss: 0.000000\n",
      " Loss: 0.014484\n",
      " Loss: 0.000000\n",
      " Loss: 0.022273\n",
      " Loss: 0.000000\n",
      " Loss: 0.039835\n",
      " Loss: 0.000000\n",
      " Loss: 0.017073\n",
      " Loss: 0.000000\n",
      " Loss: 0.056498\n",
      " Loss: 0.000000\n",
      " Loss: 0.033660\n",
      " Loss: 0.000000\n",
      " Loss: 0.037278\n",
      " Loss: 0.000000\n",
      " Loss: 0.018900\n",
      " Loss: 0.000000\n",
      " Loss: 0.014502\n",
      "Epoch 2720 Chain 0 loss std 6.46e-04 variance 2.09e-07 smooth variance 3.53e-07 adaptive c -1.00\n",
      "Epoch 2720 Chain 1 loss std 1.39e+02 variance 9.64e+03 smooth variance 2.19e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026625\n",
      " Loss: 0.000000\n",
      " Loss: 0.013576\n",
      " Loss: 0.000000\n",
      " Loss: 0.038832\n",
      " Loss: 0.000000\n",
      " Loss: 0.019871\n",
      " Loss: 0.000000\n",
      " Loss: 0.061933\n",
      " Loss: 0.000000\n",
      " Loss: 0.015493\n",
      " Loss: 0.000000\n",
      " Loss: 0.075538\n",
      " Loss: 0.000000\n",
      " Loss: 0.020162\n",
      " Loss: 0.000000\n",
      " Loss: 0.024474\n",
      " Loss: 0.000000\n",
      " Loss: 0.025171\n",
      "Epoch 2722 Chain 0 loss std 1.12e-03 variance 6.22e-07 smooth variance 4.34e-07 adaptive c -1.00\n",
      "Epoch 2722 Chain 1 loss std 2.59e+02 variance 3.34e+04 smooth variance 2.54e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020462\n",
      " Loss: 0.000000\n",
      " Loss: 0.020474\n",
      " Loss: 0.000000\n",
      " Loss: 0.024455\n",
      " Loss: 0.000000\n",
      " Loss: 0.017158\n",
      " Loss: 0.000000\n",
      " Loss: 0.078288\n",
      " Loss: 0.000000\n",
      " Loss: 0.022930\n",
      " Loss: 0.000000\n",
      " Loss: 0.039728\n",
      " Loss: 0.000000\n",
      " Loss: 0.019403\n",
      " Loss: 0.000000\n",
      " Loss: 0.022917\n",
      " Loss: 0.000000\n",
      " Loss: 0.055859\n",
      "Epoch 2724 Chain 0 loss std 8.24e-04 variance 3.40e-07 smooth variance 4.06e-07 adaptive c -1.00\n",
      "Epoch 2724 Chain 1 loss std 1.95e+02 variance 1.90e+04 smooth variance 2.35e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014270\n",
      " Loss: 0.000000\n",
      " Loss: 0.030845\n",
      " Loss: 0.000000\n",
      " Loss: 0.023898\n",
      " Loss: 0.000000\n",
      " Loss: 0.063972\n",
      " Loss: 0.000000\n",
      " Loss: 0.027853\n",
      " Loss: 0.000000\n",
      " Loss: 0.019670\n",
      " Loss: 0.000000\n",
      " Loss: 0.027577\n",
      " Loss: 0.000000\n",
      " Loss: 0.014353\n",
      " Loss: 0.000000\n",
      " Loss: 0.064875\n",
      " Loss: 0.000000\n",
      " Loss: 0.034363\n",
      "Epoch 2726 Chain 0 loss std 1.45e-03 variance 1.05e-06 smooth variance 5.99e-07 adaptive c -1.00\n",
      "Epoch 2726 Chain 1 loss std 1.85e+02 variance 1.70e+04 smooth variance 2.15e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023899\n",
      " Loss: 0.000000\n",
      " Loss: 0.018662\n",
      " Loss: 0.000000\n",
      " Loss: 0.018277\n",
      " Loss: 0.000000\n",
      " Loss: 0.076818\n",
      " Loss: 0.000000\n",
      " Loss: 0.023181\n",
      " Loss: 0.000000\n",
      " Loss: 0.019116\n",
      " Loss: 0.000000\n",
      " Loss: 0.033361\n",
      " Loss: 0.000000\n",
      " Loss: 0.021838\n",
      " Loss: 0.000000\n",
      " Loss: 0.021169\n",
      " Loss: 0.000000\n",
      " Loss: 0.065353\n",
      "Epoch 2728 Chain 0 loss std 1.17e-03 variance 6.84e-07 smooth variance 6.24e-07 adaptive c -1.00\n",
      "Epoch 2728 Chain 1 loss std 1.87e+02 variance 1.74e+04 smooth variance 2.03e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061161\n",
      " Loss: 0.000000\n",
      " Loss: 0.026025\n",
      " Loss: 0.000000\n",
      " Loss: 0.016443\n",
      " Loss: 0.000000\n",
      " Loss: 0.020931\n",
      " Loss: 0.000000\n",
      " Loss: 0.036277\n",
      " Loss: 0.000000\n",
      " Loss: 0.018968\n",
      " Loss: 0.000000\n",
      " Loss: 0.067344\n",
      " Loss: 0.000000\n",
      " Loss: 0.020473\n",
      " Loss: 0.000000\n",
      " Loss: 0.032650\n",
      " Loss: 0.000000\n",
      " Loss: 0.021403\n",
      "Epoch 2730 Chain 0 loss std 9.23e-04 variance 4.26e-07 smooth variance 5.65e-07 adaptive c -1.00\n",
      "Epoch 2730 Chain 1 loss std 1.90e+02 variance 1.80e+04 smooth variance 1.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.071608\n",
      " Loss: 0.000000\n",
      " Loss: 0.024505\n",
      " Loss: 0.000000\n",
      " Loss: 0.030177\n",
      " Loss: 0.000000\n",
      " Loss: 0.020759\n",
      " Loss: 0.000000\n",
      " Loss: 0.013789\n",
      " Loss: 0.000000\n",
      " Loss: 0.021884\n",
      " Loss: 0.000000\n",
      " Loss: 0.026126\n",
      " Loss: 0.000000\n",
      " Loss: 0.057763\n",
      " Loss: 0.000000\n",
      " Loss: 0.012861\n",
      " Loss: 0.000000\n",
      " Loss: 0.042204\n",
      "Epoch 2732 Chain 0 loss std 5.87e-04 variance 1.72e-07 smooth variance 4.47e-07 adaptive c -1.00\n",
      "Epoch 2732 Chain 1 loss std 2.02e+02 variance 2.05e+04 smooth variance 1.99e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029909\n",
      " Loss: 0.000000\n",
      " Loss: 0.061617\n",
      " Loss: 0.000000\n",
      " Loss: 0.017977\n",
      " Loss: 0.000000\n",
      " Loss: 0.041009\n",
      " Loss: 0.000000\n",
      " Loss: 0.010326\n",
      " Loss: 0.000000\n",
      " Loss: 0.038379\n",
      " Loss: 0.000000\n",
      " Loss: 0.015922\n",
      " Loss: 0.000000\n",
      " Loss: 0.022668\n",
      " Loss: 0.000000\n",
      " Loss: 0.018317\n",
      " Loss: 0.000000\n",
      " Loss: 0.065552\n",
      "Epoch 2734 Chain 0 loss std 6.67e-04 variance 2.22e-07 smooth variance 3.80e-07 adaptive c -1.00\n",
      "Epoch 2734 Chain 1 loss std 1.60e+02 variance 1.28e+04 smooth variance 1.78e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019540\n",
      " Loss: 0.000000\n",
      " Loss: 0.035385\n",
      " Loss: 0.000000\n",
      " Loss: 0.021025\n",
      " Loss: 0.000000\n",
      " Loss: 0.027471\n",
      " Loss: 0.000000\n",
      " Loss: 0.057415\n",
      " Loss: 0.000000\n",
      " Loss: 0.032203\n",
      " Loss: 0.000000\n",
      " Loss: 0.019762\n",
      " Loss: 0.000000\n",
      " Loss: 0.019855\n",
      " Loss: 0.000000\n",
      " Loss: 0.017165\n",
      " Loss: 0.000000\n",
      " Loss: 0.071853\n",
      "Epoch 2736 Chain 0 loss std 1.30e-03 variance 8.48e-07 smooth variance 5.20e-07 adaptive c -1.00\n",
      "Epoch 2736 Chain 1 loss std 2.37e+02 variance 2.80e+04 smooth variance 2.08e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023193\n",
      " Loss: 0.000000\n",
      " Loss: 0.059060\n",
      " Loss: 0.000000\n",
      " Loss: 0.014292\n",
      " Loss: 0.000000\n",
      " Loss: 0.038763\n",
      " Loss: 0.000000\n",
      " Loss: 0.025530\n",
      " Loss: 0.000000\n",
      " Loss: 0.030741\n",
      " Loss: 0.000000\n",
      " Loss: 0.019329\n",
      " Loss: 0.000000\n",
      " Loss: 0.027130\n",
      " Loss: 0.000000\n",
      " Loss: 0.066082\n",
      " Loss: 0.000000\n",
      " Loss: 0.017555\n",
      "Epoch 2738 Chain 0 loss std 4.57e-04 variance 1.05e-07 smooth variance 3.95e-07 adaptive c -1.00\n",
      "Epoch 2738 Chain 1 loss std 1.81e+02 variance 1.63e+04 smooth variance 1.95e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017184\n",
      " Loss: 0.000000\n",
      " Loss: 0.030556\n",
      " Loss: 0.000000\n",
      " Loss: 0.017434\n",
      " Loss: 0.000000\n",
      " Loss: 0.033277\n",
      " Loss: 0.000000\n",
      " Loss: 0.062386\n",
      " Loss: 0.000000\n",
      " Loss: 0.016545\n",
      " Loss: 0.000000\n",
      " Loss: 0.062574\n",
      " Loss: 0.000000\n",
      " Loss: 0.042328\n",
      " Loss: 0.000000\n",
      " Loss: 0.023505\n",
      " Loss: 0.000000\n",
      " Loss: 0.015886\n",
      "Epoch 2740 Chain 0 loss std 4.74e-04 variance 1.12e-07 smooth variance 3.10e-07 adaptive c -1.00\n",
      "Epoch 2740 Chain 1 loss std 1.45e+02 variance 1.06e+04 smooth variance 1.68e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.064396\n",
      " Loss: 0.000000\n",
      " Loss: 0.023430\n",
      " Loss: 0.000000\n",
      " Loss: 0.034222\n",
      " Loss: 0.000000\n",
      " Loss: 0.014689\n",
      " Loss: 0.000000\n",
      " Loss: 0.024101\n",
      " Loss: 0.000000\n",
      " Loss: 0.013466\n",
      " Loss: 0.000000\n",
      " Loss: 0.074759\n",
      " Loss: 0.000000\n",
      " Loss: 0.013300\n",
      " Loss: 0.000000\n",
      " Loss: 0.037414\n",
      " Loss: 0.000000\n",
      " Loss: 0.021898\n",
      "Epoch 2742 Chain 0 loss std 9.71e-04 variance 4.71e-07 smooth variance 3.59e-07 adaptive c -1.00\n",
      "Epoch 2742 Chain 1 loss std 2.26e+02 variance 2.55e+04 smooth variance 1.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024489\n",
      " Loss: 0.000000\n",
      " Loss: 0.020984\n",
      " Loss: 0.000000\n",
      " Loss: 0.081841\n",
      " Loss: 0.000000\n",
      " Loss: 0.016496\n",
      " Loss: 0.000000\n",
      " Loss: 0.017027\n",
      " Loss: 0.000000\n",
      " Loss: 0.071120\n",
      " Loss: 0.000000\n",
      " Loss: 0.027963\n",
      " Loss: 0.000000\n",
      " Loss: 0.030114\n",
      " Loss: 0.000000\n",
      " Loss: 0.016561\n",
      " Loss: 0.000000\n",
      " Loss: 0.015080\n",
      "Epoch 2744 Chain 0 loss std 9.48e-04 variance 4.49e-07 smooth variance 3.86e-07 adaptive c -1.00\n",
      "Epoch 2744 Chain 1 loss std 2.32e+02 variance 2.68e+04 smooth variance 2.16e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.037116\n",
      " Loss: 0.000000\n",
      " Loss: 0.024091\n",
      " Loss: 0.000000\n",
      " Loss: 0.058054\n",
      " Loss: 0.000000\n",
      " Loss: 0.018412\n",
      " Loss: 0.000000\n",
      " Loss: 0.023165\n",
      " Loss: 0.000000\n",
      " Loss: 0.032223\n",
      " Loss: 0.000000\n",
      " Loss: 0.022937\n",
      " Loss: 0.000000\n",
      " Loss: 0.018387\n",
      " Loss: 0.000000\n",
      " Loss: 0.022852\n",
      " Loss: 0.000000\n",
      " Loss: 0.064439\n",
      "Epoch 2746 Chain 0 loss std 7.98e-04 variance 3.18e-07 smooth variance 3.66e-07 adaptive c -1.00\n",
      "Epoch 2746 Chain 1 loss std 2.17e+02 variance 2.36e+04 smooth variance 2.22e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026849\n",
      " Loss: 0.000000\n",
      " Loss: 0.026283\n",
      " Loss: 0.000000\n",
      " Loss: 0.055286\n",
      " Loss: 0.000000\n",
      " Loss: 0.015113\n",
      " Loss: 0.000000\n",
      " Loss: 0.037308\n",
      " Loss: 0.000000\n",
      " Loss: 0.023114\n",
      " Loss: 0.000000\n",
      " Loss: 0.011090\n",
      " Loss: 0.000000\n",
      " Loss: 0.038766\n",
      " Loss: 0.000000\n",
      " Loss: 0.021237\n",
      " Loss: 0.000000\n",
      " Loss: 0.066631\n",
      "Epoch 2748 Chain 0 loss std 1.25e-03 variance 7.84e-07 smooth variance 4.91e-07 adaptive c -1.00\n",
      "Epoch 2748 Chain 1 loss std 1.85e+02 variance 1.70e+04 smooth variance 2.07e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018519\n",
      " Loss: 0.000000\n",
      " Loss: 0.063590\n",
      " Loss: 0.000000\n",
      " Loss: 0.043158\n",
      " Loss: 0.000000\n",
      " Loss: 0.016619\n",
      " Loss: 0.000000\n",
      " Loss: 0.018952\n",
      " Loss: 0.000000\n",
      " Loss: 0.021671\n",
      " Loss: 0.000000\n",
      " Loss: 0.026662\n",
      " Loss: 0.000000\n",
      " Loss: 0.056126\n",
      " Loss: 0.000000\n",
      " Loss: 0.031775\n",
      " Loss: 0.000000\n",
      " Loss: 0.024604\n",
      "Epoch 2750 Chain 0 loss std 9.83e-04 variance 4.83e-07 smooth variance 4.89e-07 adaptive c -1.00\n",
      "Epoch 2750 Chain 1 loss std 1.85e+02 variance 1.72e+04 smooth variance 1.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.068096\n",
      " Loss: 0.000000\n",
      " Loss: 0.036245\n",
      " Loss: 0.000000\n",
      " Loss: 0.020076\n",
      " Loss: 0.000000\n",
      " Loss: 0.020138\n",
      " Loss: 0.000000\n",
      " Loss: 0.016283\n",
      " Loss: 0.000000\n",
      " Loss: 0.072545\n",
      " Loss: 0.000000\n",
      " Loss: 0.017804\n",
      " Loss: 0.000000\n",
      " Loss: 0.031129\n",
      " Loss: 0.000000\n",
      " Loss: 0.017987\n",
      " Loss: 0.000000\n",
      " Loss: 0.021373\n",
      "Epoch 2752 Chain 0 loss std 5.33e-04 variance 1.42e-07 smooth variance 3.85e-07 adaptive c -1.00\n",
      "Epoch 2752 Chain 1 loss std 2.10e+02 variance 2.20e+04 smooth variance 2.03e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.013091\n",
      " Loss: 0.000000\n",
      " Loss: 0.009665\n",
      " Loss: 0.000000\n",
      " Loss: 0.035124\n",
      " Loss: 0.000000\n",
      " Loss: 0.086197\n",
      " Loss: 0.000000\n",
      " Loss: 0.016761\n",
      " Loss: 0.000000\n",
      " Loss: 0.021105\n",
      " Loss: 0.000000\n",
      " Loss: 0.016540\n",
      " Loss: 0.000000\n",
      " Loss: 0.063667\n",
      " Loss: 0.000000\n",
      " Loss: 0.023409\n",
      " Loss: 0.000000\n",
      " Loss: 0.036117\n",
      "Epoch 2754 Chain 0 loss std 1.19e-03 variance 7.08e-07 smooth variance 4.82e-07 adaptive c -1.00\n",
      "Epoch 2754 Chain 1 loss std 1.51e+02 variance 1.15e+04 smooth variance 1.77e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033527\n",
      " Loss: 0.000000\n",
      " Loss: 0.012765\n",
      " Loss: 0.000000\n",
      " Loss: 0.057516\n",
      " Loss: 0.000000\n",
      " Loss: 0.035585\n",
      " Loss: 0.000000\n",
      " Loss: 0.021445\n",
      " Loss: 0.000000\n",
      " Loss: 0.035563\n",
      " Loss: 0.000000\n",
      " Loss: 0.014144\n",
      " Loss: 0.000000\n",
      " Loss: 0.024174\n",
      " Loss: 0.000000\n",
      " Loss: 0.069970\n",
      " Loss: 0.000000\n",
      " Loss: 0.016987\n",
      "Epoch 2756 Chain 0 loss std 7.03e-04 variance 2.47e-07 smooth variance 4.11e-07 adaptive c -1.00\n",
      "Epoch 2756 Chain 1 loss std 2.35e+02 variance 2.75e+04 smooth variance 2.06e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015408\n",
      " Loss: 0.000000\n",
      " Loss: 0.018353\n",
      " Loss: 0.000000\n",
      " Loss: 0.089135\n",
      " Loss: 0.000000\n",
      " Loss: 0.016529\n",
      " Loss: 0.000000\n",
      " Loss: 0.021413\n",
      " Loss: 0.000000\n",
      " Loss: 0.024148\n",
      " Loss: 0.000000\n",
      " Loss: 0.034411\n",
      " Loss: 0.000000\n",
      " Loss: 0.019900\n",
      " Loss: 0.000000\n",
      " Loss: 0.013980\n",
      " Loss: 0.000000\n",
      " Loss: 0.068400\n",
      "Epoch 2758 Chain 0 loss std 9.77e-04 variance 4.77e-07 smooth variance 4.31e-07 adaptive c -1.00\n",
      "Epoch 2758 Chain 1 loss std 1.86e+02 variance 1.73e+04 smooth variance 1.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.058734\n",
      " Loss: 0.000000\n",
      " Loss: 0.016949\n",
      " Loss: 0.000000\n",
      " Loss: 0.026283\n",
      " Loss: 0.000000\n",
      " Loss: 0.039073\n",
      " Loss: 0.000000\n",
      " Loss: 0.019799\n",
      " Loss: 0.000000\n",
      " Loss: 0.075792\n",
      " Loss: 0.000000\n",
      " Loss: 0.023157\n",
      " Loss: 0.000000\n",
      " Loss: 0.016588\n",
      " Loss: 0.000000\n",
      " Loss: 0.023257\n",
      " Loss: 0.000000\n",
      " Loss: 0.022044\n",
      "Epoch 2760 Chain 0 loss std 1.09e-03 variance 5.96e-07 smooth variance 4.81e-07 adaptive c -1.00\n",
      "Epoch 2760 Chain 1 loss std 1.51e+02 variance 1.13e+04 smooth variance 1.71e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024376\n",
      " Loss: 0.000000\n",
      " Loss: 0.012201\n",
      " Loss: 0.000000\n",
      " Loss: 0.056642\n",
      " Loss: 0.000000\n",
      " Loss: 0.030167\n",
      " Loss: 0.000000\n",
      " Loss: 0.037451\n",
      " Loss: 0.000000\n",
      " Loss: 0.018153\n",
      " Loss: 0.000000\n",
      " Loss: 0.015182\n",
      " Loss: 0.000000\n",
      " Loss: 0.044752\n",
      " Loss: 0.000000\n",
      " Loss: 0.022446\n",
      " Loss: 0.000000\n",
      " Loss: 0.060304\n",
      "Epoch 2762 Chain 0 loss std 1.14e-03 variance 6.55e-07 smooth variance 5.33e-07 adaptive c -1.00\n",
      "Epoch 2762 Chain 1 loss std 2.58e+02 variance 3.32e+04 smooth variance 2.20e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.064080\n",
      " Loss: 0.000000\n",
      " Loss: 0.031684\n",
      " Loss: 0.000000\n",
      " Loss: 0.025839\n",
      " Loss: 0.000000\n",
      " Loss: 0.018658\n",
      " Loss: 0.000000\n",
      " Loss: 0.020575\n",
      " Loss: 0.000000\n",
      " Loss: 0.052223\n",
      " Loss: 0.000000\n",
      " Loss: 0.024648\n",
      " Loss: 0.000000\n",
      " Loss: 0.024521\n",
      " Loss: 0.000000\n",
      " Loss: 0.022760\n",
      " Loss: 0.000000\n",
      " Loss: 0.036686\n",
      "Epoch 2764 Chain 0 loss std 6.77e-04 variance 2.29e-07 smooth variance 4.42e-07 adaptive c -1.00\n",
      "Epoch 2764 Chain 1 loss std 1.99e+02 variance 1.98e+04 smooth variance 2.13e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033832\n",
      " Loss: 0.000000\n",
      " Loss: 0.061511\n",
      " Loss: 0.000000\n",
      " Loss: 0.015600\n",
      " Loss: 0.000000\n",
      " Loss: 0.028131\n",
      " Loss: 0.000000\n",
      " Loss: 0.021764\n",
      " Loss: 0.000000\n",
      " Loss: 0.029257\n",
      " Loss: 0.000000\n",
      " Loss: 0.063203\n",
      " Loss: 0.000000\n",
      " Loss: 0.043934\n",
      " Loss: 0.000000\n",
      " Loss: 0.014530\n",
      " Loss: 0.000000\n",
      " Loss: 0.009913\n",
      "Epoch 2766 Chain 0 loss std 8.17e-04 variance 3.33e-07 smooth variance 4.09e-07 adaptive c -1.00\n",
      "Epoch 2766 Chain 1 loss std 1.74e+02 variance 1.51e+04 smooth variance 1.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026476\n",
      " Loss: 0.000000\n",
      " Loss: 0.021525\n",
      " Loss: 0.000000\n",
      " Loss: 0.066895\n",
      " Loss: 0.000000\n",
      " Loss: 0.030505\n",
      " Loss: 0.000000\n",
      " Loss: 0.015436\n",
      " Loss: 0.000000\n",
      " Loss: 0.044921\n",
      " Loss: 0.000000\n",
      " Loss: 0.020461\n",
      " Loss: 0.000000\n",
      " Loss: 0.014476\n",
      " Loss: 0.000000\n",
      " Loss: 0.018199\n",
      " Loss: 0.000000\n",
      " Loss: 0.062782\n",
      "Epoch 2768 Chain 0 loss std 7.08e-04 variance 2.51e-07 smooth variance 3.62e-07 adaptive c -1.00\n",
      "Epoch 2768 Chain 1 loss std 2.18e+02 variance 2.37e+04 smooth variance 2.07e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036805\n",
      " Loss: 0.000000\n",
      " Loss: 0.072330\n",
      " Loss: 0.000000\n",
      " Loss: 0.018758\n",
      " Loss: 0.000000\n",
      " Loss: 0.013271\n",
      " Loss: 0.000000\n",
      " Loss: 0.019673\n",
      " Loss: 0.000000\n",
      " Loss: 0.022178\n",
      " Loss: 0.000000\n",
      " Loss: 0.018141\n",
      " Loss: 0.000000\n",
      " Loss: 0.064997\n",
      " Loss: 0.000000\n",
      " Loss: 0.020743\n",
      " Loss: 0.000000\n",
      " Loss: 0.034779\n",
      "Epoch 2770 Chain 0 loss std 9.49e-04 variance 4.50e-07 smooth variance 3.88e-07 adaptive c -1.00\n",
      "Epoch 2770 Chain 1 loss std 2.12e+02 variance 2.25e+04 smooth variance 2.12e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016001\n",
      " Loss: 0.000000\n",
      " Loss: 0.063108\n",
      " Loss: 0.000000\n",
      " Loss: 0.028560\n",
      " Loss: 0.000000\n",
      " Loss: 0.032848\n",
      " Loss: 0.000000\n",
      " Loss: 0.020321\n",
      " Loss: 0.000000\n",
      " Loss: 0.027824\n",
      " Loss: 0.000000\n",
      " Loss: 0.055672\n",
      " Loss: 0.000000\n",
      " Loss: 0.021679\n",
      " Loss: 0.000000\n",
      " Loss: 0.014160\n",
      " Loss: 0.000000\n",
      " Loss: 0.041503\n",
      "Epoch 2772 Chain 0 loss std 7.82e-04 variance 3.06e-07 smooth variance 3.64e-07 adaptive c -1.00\n",
      "Epoch 2772 Chain 1 loss std 2.30e+02 variance 2.65e+04 smooth variance 2.28e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.029007\n",
      " Loss: 0.000000\n",
      " Loss: 0.042061\n",
      " Loss: 0.000000\n",
      " Loss: 0.063727\n",
      " Loss: 0.000000\n",
      " Loss: 0.010149\n",
      " Loss: 0.000000\n",
      " Loss: 0.015893\n",
      " Loss: 0.000000\n",
      " Loss: 0.018754\n",
      " Loss: 0.000000\n",
      " Loss: 0.076935\n",
      " Loss: 0.000000\n",
      " Loss: 0.028259\n",
      " Loss: 0.000000\n",
      " Loss: 0.019991\n",
      " Loss: 0.000000\n",
      " Loss: 0.016899\n",
      "Epoch 2774 Chain 0 loss std 8.30e-04 variance 3.44e-07 smooth variance 3.58e-07 adaptive c -1.00\n",
      "Epoch 2774 Chain 1 loss std 1.60e+02 variance 1.28e+04 smooth variance 1.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033595\n",
      " Loss: 0.000000\n",
      " Loss: 0.028350\n",
      " Loss: 0.000000\n",
      " Loss: 0.059941\n",
      " Loss: 0.000000\n",
      " Loss: 0.025466\n",
      " Loss: 0.000000\n",
      " Loss: 0.013485\n",
      " Loss: 0.000000\n",
      " Loss: 0.059998\n",
      " Loss: 0.000000\n",
      " Loss: 0.021407\n",
      " Loss: 0.000000\n",
      " Loss: 0.035344\n",
      " Loss: 0.000000\n",
      " Loss: 0.013371\n",
      " Loss: 0.000000\n",
      " Loss: 0.030717\n",
      "Epoch 2776 Chain 0 loss std 9.12e-04 variance 4.16e-07 smooth variance 3.75e-07 adaptive c -1.00\n",
      "Epoch 2776 Chain 1 loss std 2.15e+02 variance 2.32e+04 smooth variance 2.08e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014603\n",
      " Loss: 0.000000\n",
      " Loss: 0.020141\n",
      " Loss: 0.000000\n",
      " Loss: 0.025546\n",
      " Loss: 0.000000\n",
      " Loss: 0.020365\n",
      " Loss: 0.000000\n",
      " Loss: 0.080182\n",
      " Loss: 0.000000\n",
      " Loss: 0.019607\n",
      " Loss: 0.000000\n",
      " Loss: 0.033814\n",
      " Loss: 0.000000\n",
      " Loss: 0.014281\n",
      " Loss: 0.000000\n",
      " Loss: 0.067250\n",
      " Loss: 0.000000\n",
      " Loss: 0.025885\n",
      "Epoch 2778 Chain 0 loss std 7.75e-04 variance 3.00e-07 smooth variance 3.53e-07 adaptive c -1.00\n",
      "Epoch 2778 Chain 1 loss std 1.87e+02 variance 1.75e+04 smooth variance 1.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025383\n",
      " Loss: 0.000000\n",
      " Loss: 0.060169\n",
      " Loss: 0.000000\n",
      " Loss: 0.037602\n",
      " Loss: 0.000000\n",
      " Loss: 0.023829\n",
      " Loss: 0.000000\n",
      " Loss: 0.013855\n",
      " Loss: 0.000000\n",
      " Loss: 0.027771\n",
      " Loss: 0.000000\n",
      " Loss: 0.039502\n",
      " Loss: 0.000000\n",
      " Loss: 0.016532\n",
      " Loss: 0.000000\n",
      " Loss: 0.014421\n",
      " Loss: 0.000000\n",
      " Loss: 0.062611\n",
      "Epoch 2780 Chain 0 loss std 1.01e-03 variance 5.10e-07 smooth variance 4.00e-07 adaptive c -1.00\n",
      "Epoch 2780 Chain 1 loss std 2.69e+02 variance 3.61e+04 smooth variance 2.47e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018386\n",
      " Loss: 0.000000\n",
      " Loss: 0.067503\n",
      " Loss: 0.000000\n",
      " Loss: 0.041501\n",
      " Loss: 0.000000\n",
      " Loss: 0.019253\n",
      " Loss: 0.000000\n",
      " Loss: 0.014195\n",
      " Loss: 0.000000\n",
      " Loss: 0.038971\n",
      " Loss: 0.000000\n",
      " Loss: 0.014693\n",
      " Loss: 0.000000\n",
      " Loss: 0.017393\n",
      " Loss: 0.000000\n",
      " Loss: 0.061382\n",
      " Loss: 0.000000\n",
      " Loss: 0.028398\n",
      "Epoch 2782 Chain 0 loss std 1.12e-03 variance 6.33e-07 smooth variance 4.70e-07 adaptive c -1.00\n",
      "Epoch 2782 Chain 1 loss std 2.41e+02 variance 2.90e+04 smooth variance 2.60e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015657\n",
      " Loss: 0.000000\n",
      " Loss: 0.039898\n",
      " Loss: 0.000000\n",
      " Loss: 0.031307\n",
      " Loss: 0.000000\n",
      " Loss: 0.055259\n",
      " Loss: 0.000000\n",
      " Loss: 0.018717\n",
      " Loss: 0.000000\n",
      " Loss: 0.023148\n",
      " Loss: 0.000000\n",
      " Loss: 0.077524\n",
      " Loss: 0.000000\n",
      " Loss: 0.015980\n",
      " Loss: 0.000000\n",
      " Loss: 0.022519\n",
      " Loss: 0.000000\n",
      " Loss: 0.021667\n",
      "Epoch 2784 Chain 0 loss std 8.27e-04 variance 3.42e-07 smooth variance 4.31e-07 adaptive c -1.00\n",
      "Epoch 2784 Chain 1 loss std 1.46e+02 variance 1.06e+04 smooth variance 2.14e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023064\n",
      " Loss: 0.000000\n",
      " Loss: 0.022011\n",
      " Loss: 0.000000\n",
      " Loss: 0.043667\n",
      " Loss: 0.000000\n",
      " Loss: 0.057331\n",
      " Loss: 0.000000\n",
      " Loss: 0.014765\n",
      " Loss: 0.000000\n",
      " Loss: 0.033278\n",
      " Loss: 0.000000\n",
      " Loss: 0.026258\n",
      " Loss: 0.000000\n",
      " Loss: 0.016928\n",
      " Loss: 0.000000\n",
      " Loss: 0.055690\n",
      " Loss: 0.000000\n",
      " Loss: 0.028685\n",
      "Epoch 2786 Chain 0 loss std 1.27e-03 variance 8.11e-07 smooth variance 5.45e-07 adaptive c -1.00\n",
      "Epoch 2786 Chain 1 loss std 1.81e+02 variance 1.64e+04 smooth variance 1.99e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026307\n",
      " Loss: 0.000000\n",
      " Loss: 0.018630\n",
      " Loss: 0.000000\n",
      " Loss: 0.009458\n",
      " Loss: 0.000000\n",
      " Loss: 0.024168\n",
      " Loss: 0.000000\n",
      " Loss: 0.082276\n",
      " Loss: 0.000000\n",
      " Loss: 0.024758\n",
      " Loss: 0.000000\n",
      " Loss: 0.012766\n",
      " Loss: 0.000000\n",
      " Loss: 0.061219\n",
      " Loss: 0.000000\n",
      " Loss: 0.023508\n",
      " Loss: 0.000000\n",
      " Loss: 0.038586\n",
      "Epoch 2788 Chain 0 loss std 1.10e-03 variance 6.09e-07 smooth variance 5.64e-07 adaptive c -1.00\n",
      "Epoch 2788 Chain 1 loss std 2.01e+02 variance 2.02e+04 smooth variance 2.00e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023105\n",
      " Loss: 0.000000\n",
      " Loss: 0.033689\n",
      " Loss: 0.000000\n",
      " Loss: 0.016648\n",
      " Loss: 0.000000\n",
      " Loss: 0.025398\n",
      " Loss: 0.000000\n",
      " Loss: 0.061998\n",
      " Loss: 0.000000\n",
      " Loss: 0.018445\n",
      " Loss: 0.000000\n",
      " Loss: 0.020727\n",
      " Loss: 0.000000\n",
      " Loss: 0.062722\n",
      " Loss: 0.000000\n",
      " Loss: 0.034103\n",
      " Loss: 0.000000\n",
      " Loss: 0.024840\n",
      "Epoch 2790 Chain 0 loss std 1.54e-03 variance 1.18e-06 smooth variance 7.49e-07 adaptive c -1.00\n",
      "Epoch 2790 Chain 1 loss std 2.28e+02 variance 2.60e+04 smooth variance 2.18e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.068074\n",
      " Loss: 0.000000\n",
      " Loss: 0.017039\n",
      " Loss: 0.000000\n",
      " Loss: 0.032913\n",
      " Loss: 0.000000\n",
      " Loss: 0.016813\n",
      " Loss: 0.000000\n",
      " Loss: 0.026000\n",
      " Loss: 0.000000\n",
      " Loss: 0.012971\n",
      " Loss: 0.000000\n",
      " Loss: 0.037754\n",
      " Loss: 0.000000\n",
      " Loss: 0.060806\n",
      " Loss: 0.000000\n",
      " Loss: 0.022105\n",
      " Loss: 0.000000\n",
      " Loss: 0.027202\n",
      "Epoch 2792 Chain 0 loss std 5.07e-04 variance 1.29e-07 smooth variance 5.63e-07 adaptive c -1.00\n",
      "Epoch 2792 Chain 1 loss std 1.62e+02 variance 1.31e+04 smooth variance 1.92e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026189\n",
      " Loss: 0.000000\n",
      " Loss: 0.020924\n",
      " Loss: 0.000000\n",
      " Loss: 0.021959\n",
      " Loss: 0.000000\n",
      " Loss: 0.012042\n",
      " Loss: 0.000000\n",
      " Loss: 0.079723\n",
      " Loss: 0.000000\n",
      " Loss: 0.026266\n",
      " Loss: 0.000000\n",
      " Loss: 0.060291\n",
      " Loss: 0.000000\n",
      " Loss: 0.042406\n",
      " Loss: 0.000000\n",
      " Loss: 0.016941\n",
      " Loss: 0.000000\n",
      " Loss: 0.014933\n",
      "Epoch 2794 Chain 0 loss std 1.30e-03 variance 8.41e-07 smooth variance 6.46e-07 adaptive c -1.00\n",
      "Epoch 2794 Chain 1 loss std 1.48e+02 variance 1.10e+04 smooth variance 1.67e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018211\n",
      " Loss: 0.000000\n",
      " Loss: 0.017935\n",
      " Loss: 0.000000\n",
      " Loss: 0.057170\n",
      " Loss: 0.000000\n",
      " Loss: 0.028813\n",
      " Loss: 0.000000\n",
      " Loss: 0.038708\n",
      " Loss: 0.000000\n",
      " Loss: 0.063113\n",
      " Loss: 0.000000\n",
      " Loss: 0.016753\n",
      " Loss: 0.000000\n",
      " Loss: 0.011205\n",
      " Loss: 0.000000\n",
      " Loss: 0.039972\n",
      " Loss: 0.000000\n",
      " Loss: 0.029794\n",
      "Epoch 2796 Chain 0 loss std 1.10e-03 variance 6.07e-07 smooth variance 6.34e-07 adaptive c -1.00\n",
      "Epoch 2796 Chain 1 loss std 1.86e+02 variance 1.74e+04 smooth variance 1.69e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036106\n",
      " Loss: 0.000000\n",
      " Loss: 0.014112\n",
      " Loss: 0.000000\n",
      " Loss: 0.036480\n",
      " Loss: 0.000000\n",
      " Loss: 0.014547\n",
      " Loss: 0.000000\n",
      " Loss: 0.059593\n",
      " Loss: 0.000000\n",
      " Loss: 0.014131\n",
      " Loss: 0.000000\n",
      " Loss: 0.020053\n",
      " Loss: 0.000000\n",
      " Loss: 0.037670\n",
      " Loss: 0.000000\n",
      " Loss: 0.014442\n",
      " Loss: 0.000000\n",
      " Loss: 0.074542\n",
      "Epoch 2798 Chain 0 loss std 7.26e-04 variance 2.64e-07 smooth variance 5.23e-07 adaptive c -1.00\n",
      "Epoch 2798 Chain 1 loss std 1.73e+02 variance 1.50e+04 smooth variance 1.63e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017694\n",
      " Loss: 0.000000\n",
      " Loss: 0.057518\n",
      " Loss: 0.000000\n",
      " Loss: 0.026171\n",
      " Loss: 0.000000\n",
      " Loss: 0.028769\n",
      " Loss: 0.000000\n",
      " Loss: 0.030685\n",
      " Loss: 0.000000\n",
      " Loss: 0.043968\n",
      " Loss: 0.000000\n",
      " Loss: 0.014380\n",
      " Loss: 0.000000\n",
      " Loss: 0.061915\n",
      " Loss: 0.000000\n",
      " Loss: 0.022584\n",
      " Loss: 0.000000\n",
      " Loss: 0.017991\n",
      "Epoch 2800 Chain 0 loss std 1.02e-03 variance 5.16e-07 smooth variance 5.21e-07 adaptive c -1.00\n",
      "Epoch 2800 Chain 1 loss std 2.19e+02 variance 2.39e+04 smooth variance 1.86e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.030737\n",
      " Loss: 0.000000\n",
      " Loss: 0.020785\n",
      " Loss: 0.000000\n",
      " Loss: 0.063137\n",
      " Loss: 0.000000\n",
      " Loss: 0.020929\n",
      " Loss: 0.000000\n",
      " Loss: 0.025250\n",
      " Loss: 0.000000\n",
      " Loss: 0.016840\n",
      " Loss: 0.000000\n",
      " Loss: 0.071333\n",
      " Loss: 0.000000\n",
      " Loss: 0.017942\n",
      " Loss: 0.000000\n",
      " Loss: 0.037143\n",
      " Loss: 0.000000\n",
      " Loss: 0.017579\n",
      "Epoch 2802 Chain 0 loss std 1.18e-03 variance 7.01e-07 smooth variance 5.75e-07 adaptive c -1.00\n",
      "Epoch 2802 Chain 1 loss std 1.67e+02 variance 1.39e+04 smooth variance 1.72e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020856\n",
      " Loss: 0.000000\n",
      " Loss: 0.025609\n",
      " Loss: 0.000000\n",
      " Loss: 0.021277\n",
      " Loss: 0.000000\n",
      " Loss: 0.062601\n",
      " Loss: 0.000000\n",
      " Loss: 0.030494\n",
      " Loss: 0.000000\n",
      " Loss: 0.070600\n",
      " Loss: 0.000000\n",
      " Loss: 0.012899\n",
      " Loss: 0.000000\n",
      " Loss: 0.021562\n",
      " Loss: 0.000000\n",
      " Loss: 0.040162\n",
      " Loss: 0.000000\n",
      " Loss: 0.015615\n",
      "Epoch 2804 Chain 0 loss std 8.94e-04 variance 4.00e-07 smooth variance 5.23e-07 adaptive c -1.00\n",
      "Epoch 2804 Chain 1 loss std 1.63e+02 variance 1.33e+04 smooth variance 1.60e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.060734\n",
      " Loss: 0.000000\n",
      " Loss: 0.017118\n",
      " Loss: 0.000000\n",
      " Loss: 0.019074\n",
      " Loss: 0.000000\n",
      " Loss: 0.025870\n",
      " Loss: 0.000000\n",
      " Loss: 0.038042\n",
      " Loss: 0.000000\n",
      " Loss: 0.011615\n",
      " Loss: 0.000000\n",
      " Loss: 0.040564\n",
      " Loss: 0.000000\n",
      " Loss: 0.021518\n",
      " Loss: 0.000000\n",
      " Loss: 0.064058\n",
      " Loss: 0.000000\n",
      " Loss: 0.023083\n",
      "Epoch 2806 Chain 0 loss std 9.28e-04 variance 4.31e-07 smooth variance 4.95e-07 adaptive c -1.00\n",
      "Epoch 2806 Chain 1 loss std 2.10e+02 variance 2.20e+04 smooth variance 1.78e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026099\n",
      " Loss: 0.000000\n",
      " Loss: 0.017250\n",
      " Loss: 0.000000\n",
      " Loss: 0.032623\n",
      " Loss: 0.000000\n",
      " Loss: 0.021257\n",
      " Loss: 0.000000\n",
      " Loss: 0.063608\n",
      " Loss: 0.000000\n",
      " Loss: 0.026390\n",
      " Loss: 0.000000\n",
      " Loss: 0.012809\n",
      " Loss: 0.000000\n",
      " Loss: 0.031295\n",
      " Loss: 0.000000\n",
      " Loss: 0.068577\n",
      " Loss: 0.000000\n",
      " Loss: 0.021767\n",
      "Epoch 2808 Chain 0 loss std 8.44e-04 variance 3.56e-07 smooth variance 4.53e-07 adaptive c -1.00\n",
      "Epoch 2808 Chain 1 loss std 2.02e+02 variance 2.04e+04 smooth variance 1.86e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014631\n",
      " Loss: 0.000000\n",
      " Loss: 0.081260\n",
      " Loss: 0.000000\n",
      " Loss: 0.018163\n",
      " Loss: 0.000000\n",
      " Loss: 0.018194\n",
      " Loss: 0.000000\n",
      " Loss: 0.028590\n",
      " Loss: 0.000000\n",
      " Loss: 0.061011\n",
      " Loss: 0.000000\n",
      " Loss: 0.009580\n",
      " Loss: 0.000000\n",
      " Loss: 0.026066\n",
      " Loss: 0.000000\n",
      " Loss: 0.032135\n",
      " Loss: 0.000000\n",
      " Loss: 0.032046\n",
      "Epoch 2810 Chain 0 loss std 9.16e-04 variance 4.20e-07 smooth variance 4.43e-07 adaptive c -1.00\n",
      "Epoch 2810 Chain 1 loss std 2.12e+02 variance 2.25e+04 smooth variance 1.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020270\n",
      " Loss: 0.000000\n",
      " Loss: 0.026832\n",
      " Loss: 0.000000\n",
      " Loss: 0.020259\n",
      " Loss: 0.000000\n",
      " Loss: 0.062050\n",
      " Loss: 0.000000\n",
      " Loss: 0.031427\n",
      " Loss: 0.000000\n",
      " Loss: 0.011998\n",
      " Loss: 0.000000\n",
      " Loss: 0.029993\n",
      " Loss: 0.000000\n",
      " Loss: 0.018041\n",
      " Loss: 0.000000\n",
      " Loss: 0.038961\n",
      " Loss: 0.000000\n",
      " Loss: 0.061845\n",
      "Epoch 2812 Chain 0 loss std 7.38e-04 variance 2.72e-07 smooth variance 3.92e-07 adaptive c -1.00\n",
      "Epoch 2812 Chain 1 loss std 1.57e+02 variance 1.22e+04 smooth variance 1.75e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.044615\n",
      " Loss: 0.000000\n",
      " Loss: 0.021061\n",
      " Loss: 0.000000\n",
      " Loss: 0.016124\n",
      " Loss: 0.000000\n",
      " Loss: 0.026345\n",
      " Loss: 0.000000\n",
      " Loss: 0.052693\n",
      " Loss: 0.000000\n",
      " Loss: 0.063751\n",
      " Loss: 0.000000\n",
      " Loss: 0.022037\n",
      " Loss: 0.000000\n",
      " Loss: 0.033696\n",
      " Loss: 0.000000\n",
      " Loss: 0.014738\n",
      " Loss: 0.000000\n",
      " Loss: 0.026615\n",
      "Epoch 2814 Chain 0 loss std 1.42e-03 variance 1.00e-06 smooth variance 5.76e-07 adaptive c -1.00\n",
      "Epoch 2814 Chain 1 loss std 1.77e+02 variance 1.57e+04 smooth variance 1.70e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.087566\n",
      " Loss: 0.000000\n",
      " Loss: 0.015707\n",
      " Loss: 0.000000\n",
      " Loss: 0.026985\n",
      " Loss: 0.000000\n",
      " Loss: 0.014405\n",
      " Loss: 0.000000\n",
      " Loss: 0.016175\n",
      " Loss: 0.000000\n",
      " Loss: 0.034454\n",
      " Loss: 0.000000\n",
      " Loss: 0.062714\n",
      " Loss: 0.000000\n",
      " Loss: 0.017302\n",
      " Loss: 0.000000\n",
      " Loss: 0.025242\n",
      " Loss: 0.000000\n",
      " Loss: 0.021126\n",
      "Epoch 2816 Chain 0 loss std 1.30e-03 variance 8.39e-07 smooth variance 6.55e-07 adaptive c -1.00\n",
      "Epoch 2816 Chain 1 loss std 2.08e+02 variance 2.16e+04 smooth variance 1.83e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.060963\n",
      " Loss: 0.000000\n",
      " Loss: 0.019444\n",
      " Loss: 0.000000\n",
      " Loss: 0.021205\n",
      " Loss: 0.000000\n",
      " Loss: 0.042723\n",
      " Loss: 0.000000\n",
      " Loss: 0.016502\n",
      " Loss: 0.000000\n",
      " Loss: 0.021966\n",
      " Loss: 0.000000\n",
      " Loss: 0.016248\n",
      " Loss: 0.000000\n",
      " Loss: 0.056783\n",
      " Loss: 0.000000\n",
      " Loss: 0.039538\n",
      " Loss: 0.000000\n",
      " Loss: 0.026303\n",
      "Epoch 2818 Chain 0 loss std 6.94e-04 variance 2.41e-07 smooth variance 5.30e-07 adaptive c -1.00\n",
      "Epoch 2818 Chain 1 loss std 2.27e+02 variance 2.58e+04 smooth variance 2.06e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014484\n",
      " Loss: 0.000000\n",
      " Loss: 0.022693\n",
      " Loss: 0.000000\n",
      " Loss: 0.065416\n",
      " Loss: 0.000000\n",
      " Loss: 0.033896\n",
      " Loss: 0.000000\n",
      " Loss: 0.024348\n",
      " Loss: 0.000000\n",
      " Loss: 0.022371\n",
      " Loss: 0.000000\n",
      " Loss: 0.062930\n",
      " Loss: 0.000000\n",
      " Loss: 0.014178\n",
      " Loss: 0.000000\n",
      " Loss: 0.018652\n",
      " Loss: 0.000000\n",
      " Loss: 0.042707\n",
      "Epoch 2820 Chain 0 loss std 7.03e-04 variance 2.47e-07 smooth variance 4.46e-07 adaptive c -1.00\n",
      "Epoch 2820 Chain 1 loss std 2.16e+02 variance 2.33e+04 smooth variance 2.14e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.057549\n",
      " Loss: 0.000000\n",
      " Loss: 0.019307\n",
      " Loss: 0.000000\n",
      " Loss: 0.025959\n",
      " Loss: 0.000000\n",
      " Loss: 0.034667\n",
      " Loss: 0.000000\n",
      " Loss: 0.023357\n",
      " Loss: 0.000000\n",
      " Loss: 0.047194\n",
      " Loss: 0.000000\n",
      " Loss: 0.056748\n",
      " Loss: 0.000000\n",
      " Loss: 0.015217\n",
      " Loss: 0.000000\n",
      " Loss: 0.021217\n",
      " Loss: 0.000000\n",
      " Loss: 0.020462\n",
      "Epoch 2822 Chain 0 loss std 1.07e-03 variance 5.73e-07 smooth variance 4.84e-07 adaptive c -1.00\n",
      "Epoch 2822 Chain 1 loss std 1.89e+02 variance 1.79e+04 smooth variance 2.04e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024079\n",
      " Loss: 0.000000\n",
      " Loss: 0.012533\n",
      " Loss: 0.000000\n",
      " Loss: 0.026502\n",
      " Loss: 0.000000\n",
      " Loss: 0.077089\n",
      " Loss: 0.000000\n",
      " Loss: 0.020634\n",
      " Loss: 0.000000\n",
      " Loss: 0.032568\n",
      " Loss: 0.000000\n",
      " Loss: 0.058563\n",
      " Loss: 0.000000\n",
      " Loss: 0.029877\n",
      " Loss: 0.000000\n",
      " Loss: 0.018179\n",
      " Loss: 0.000000\n",
      " Loss: 0.021651\n",
      "Epoch 2824 Chain 0 loss std 1.05e-03 variance 5.50e-07 smooth variance 5.04e-07 adaptive c -1.00\n",
      "Epoch 2824 Chain 1 loss std 2.20e+02 variance 2.42e+04 smooth variance 2.15e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019952\n",
      " Loss: 0.000000\n",
      " Loss: 0.059525\n",
      " Loss: 0.000000\n",
      " Loss: 0.043161\n",
      " Loss: 0.000000\n",
      " Loss: 0.014936\n",
      " Loss: 0.000000\n",
      " Loss: 0.023262\n",
      " Loss: 0.000000\n",
      " Loss: 0.017339\n",
      " Loss: 0.000000\n",
      " Loss: 0.014742\n",
      " Loss: 0.000000\n",
      " Loss: 0.079049\n",
      " Loss: 0.000000\n",
      " Loss: 0.032639\n",
      " Loss: 0.000000\n",
      " Loss: 0.017069\n",
      "Epoch 2826 Chain 0 loss std 1.03e-03 variance 5.27e-07 smooth variance 5.11e-07 adaptive c -1.00\n",
      "Epoch 2826 Chain 1 loss std 1.48e+02 variance 1.10e+04 smooth variance 1.83e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.053665\n",
      " Loss: 0.000000\n",
      " Loss: 0.033490\n",
      " Loss: 0.000000\n",
      " Loss: 0.019259\n",
      " Loss: 0.000000\n",
      " Loss: 0.013469\n",
      " Loss: 0.000000\n",
      " Loss: 0.040954\n",
      " Loss: 0.000000\n",
      " Loss: 0.036488\n",
      " Loss: 0.000000\n",
      " Loss: 0.071019\n",
      " Loss: 0.000000\n",
      " Loss: 0.020646\n",
      " Loss: 0.000000\n",
      " Loss: 0.010338\n",
      " Loss: 0.000000\n",
      " Loss: 0.022346\n",
      "Epoch 2828 Chain 0 loss std 1.30e-03 variance 8.41e-07 smooth variance 6.10e-07 adaptive c -1.00\n",
      "Epoch 2828 Chain 1 loss std 2.52e+02 variance 3.19e+04 smooth variance 2.24e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.041822\n",
      " Loss: 0.000000\n",
      " Loss: 0.015659\n",
      " Loss: 0.000000\n",
      " Loss: 0.019509\n",
      " Loss: 0.000000\n",
      " Loss: 0.018396\n",
      " Loss: 0.000000\n",
      " Loss: 0.065451\n",
      " Loss: 0.000000\n",
      " Loss: 0.044263\n",
      " Loss: 0.000000\n",
      " Loss: 0.028523\n",
      " Loss: 0.000000\n",
      " Loss: 0.019109\n",
      " Loss: 0.000000\n",
      " Loss: 0.056653\n",
      " Loss: 0.000000\n",
      " Loss: 0.012291\n",
      "Epoch 2830 Chain 0 loss std 6.19e-04 variance 1.92e-07 smooth variance 4.85e-07 adaptive c -1.00\n",
      "Epoch 2830 Chain 1 loss std 1.89e+02 variance 1.79e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.033770\n",
      " Loss: 0.000000\n",
      " Loss: 0.017555\n",
      " Loss: 0.000000\n",
      " Loss: 0.056631\n",
      " Loss: 0.000000\n",
      " Loss: 0.015935\n",
      " Loss: 0.000000\n",
      " Loss: 0.036947\n",
      " Loss: 0.000000\n",
      " Loss: 0.039205\n",
      " Loss: 0.000000\n",
      " Loss: 0.010321\n",
      " Loss: 0.000000\n",
      " Loss: 0.026296\n",
      " Loss: 0.000000\n",
      " Loss: 0.062861\n",
      " Loss: 0.000000\n",
      " Loss: 0.022156\n",
      "Epoch 2832 Chain 0 loss std 1.08e-03 variance 5.79e-07 smooth variance 5.13e-07 adaptive c -1.00\n",
      "Epoch 2832 Chain 1 loss std 1.84e+02 variance 1.70e+04 smooth variance 1.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.034054\n",
      " Loss: 0.000000\n",
      " Loss: 0.073889\n",
      " Loss: 0.000000\n",
      " Loss: 0.016642\n",
      " Loss: 0.000000\n",
      " Loss: 0.024282\n",
      " Loss: 0.000000\n",
      " Loss: 0.011971\n",
      " Loss: 0.000000\n",
      " Loss: 0.058291\n",
      " Loss: 0.000000\n",
      " Loss: 0.032323\n",
      " Loss: 0.000000\n",
      " Loss: 0.034834\n",
      " Loss: 0.000000\n",
      " Loss: 0.015632\n",
      " Loss: 0.000000\n",
      " Loss: 0.019758\n",
      "Epoch 2834 Chain 0 loss std 1.09e-03 variance 5.89e-07 smooth variance 5.36e-07 adaptive c -1.00\n",
      "Epoch 2834 Chain 1 loss std 2.20e+02 variance 2.43e+04 smooth variance 2.12e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.011947\n",
      " Loss: 0.000000\n",
      " Loss: 0.011501\n",
      " Loss: 0.000000\n",
      " Loss: 0.053279\n",
      " Loss: 0.000000\n",
      " Loss: 0.067334\n",
      " Loss: 0.000000\n",
      " Loss: 0.016776\n",
      " Loss: 0.000000\n",
      " Loss: 0.024777\n",
      " Loss: 0.000000\n",
      " Loss: 0.067571\n",
      " Loss: 0.000000\n",
      " Loss: 0.024131\n",
      " Loss: 0.000000\n",
      " Loss: 0.013317\n",
      " Loss: 0.000000\n",
      " Loss: 0.031042\n",
      "Epoch 2836 Chain 0 loss std 6.62e-04 variance 2.19e-07 smooth variance 4.41e-07 adaptive c -1.00\n",
      "Epoch 2836 Chain 1 loss std 2.27e+02 variance 2.57e+04 smooth variance 2.25e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022190\n",
      " Loss: 0.000000\n",
      " Loss: 0.017712\n",
      " Loss: 0.000000\n",
      " Loss: 0.013282\n",
      " Loss: 0.000000\n",
      " Loss: 0.071142\n",
      " Loss: 0.000000\n",
      " Loss: 0.036512\n",
      " Loss: 0.000000\n",
      " Loss: 0.081923\n",
      " Loss: 0.000000\n",
      " Loss: 0.025729\n",
      " Loss: 0.000000\n",
      " Loss: 0.019294\n",
      " Loss: 0.000000\n",
      " Loss: 0.014559\n",
      " Loss: 0.000000\n",
      " Loss: 0.019334\n",
      "Epoch 2838 Chain 0 loss std 1.07e-03 variance 5.72e-07 smooth variance 4.80e-07 adaptive c -1.00\n",
      "Epoch 2838 Chain 1 loss std 2.82e+02 variance 3.97e+04 smooth variance 2.77e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.043569\n",
      " Loss: 0.000000\n",
      " Loss: 0.062203\n",
      " Loss: 0.000000\n",
      " Loss: 0.023202\n",
      " Loss: 0.000000\n",
      " Loss: 0.014863\n",
      " Loss: 0.000000\n",
      " Loss: 0.016999\n",
      " Loss: 0.000000\n",
      " Loss: 0.070517\n",
      " Loss: 0.000000\n",
      " Loss: 0.021310\n",
      " Loss: 0.000000\n",
      " Loss: 0.035060\n",
      " Loss: 0.000000\n",
      " Loss: 0.015538\n",
      " Loss: 0.000000\n",
      " Loss: 0.018412\n",
      "Epoch 2840 Chain 0 loss std 8.45e-04 variance 3.57e-07 smooth variance 4.43e-07 adaptive c -1.00\n",
      "Epoch 2840 Chain 1 loss std 2.55e+02 variance 3.26e+04 smooth variance 2.92e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.023349\n",
      " Loss: 0.000000\n",
      " Loss: 0.037042\n",
      " Loss: 0.000000\n",
      " Loss: 0.066093\n",
      " Loss: 0.000000\n",
      " Loss: 0.015070\n",
      " Loss: 0.000000\n",
      " Loss: 0.019284\n",
      " Loss: 0.000000\n",
      " Loss: 0.063437\n",
      " Loss: 0.000000\n",
      " Loss: 0.043657\n",
      " Loss: 0.000000\n",
      " Loss: 0.009599\n",
      " Loss: 0.000000\n",
      " Loss: 0.022282\n",
      " Loss: 0.000000\n",
      " Loss: 0.021863\n",
      "Epoch 2842 Chain 0 loss std 8.35e-04 variance 3.49e-07 smooth variance 4.15e-07 adaptive c -1.00\n",
      "Epoch 2842 Chain 1 loss std 1.87e+02 variance 1.75e+04 smooth variance 2.57e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016208\n",
      " Loss: 0.000000\n",
      " Loss: 0.015998\n",
      " Loss: 0.000000\n",
      " Loss: 0.019359\n",
      " Loss: 0.000000\n",
      " Loss: 0.081287\n",
      " Loss: 0.000000\n",
      " Loss: 0.027986\n",
      " Loss: 0.000000\n",
      " Loss: 0.020953\n",
      " Loss: 0.000001\n",
      " Loss: 0.067416\n",
      " Loss: 0.000000\n",
      " Loss: 0.009546\n",
      " Loss: 0.000000\n",
      " Loss: 0.036899\n",
      " Loss: 0.000000\n",
      " Loss: 0.026024\n",
      "Epoch 2844 Chain 0 loss std 7.44e-04 variance 2.77e-07 smooth variance 3.73e-07 adaptive c -1.00\n",
      "Epoch 2844 Chain 1 loss std 1.79e+02 variance 1.61e+04 smooth variance 2.28e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020728\n",
      " Loss: 0.000000\n",
      " Loss: 0.037882\n",
      " Loss: 0.000000\n",
      " Loss: 0.023068\n",
      " Loss: 0.000000\n",
      " Loss: 0.020000\n",
      " Loss: 0.000000\n",
      " Loss: 0.059160\n",
      " Loss: 0.000000\n",
      " Loss: 0.065959\n",
      " Loss: 0.000000\n",
      " Loss: 0.011635\n",
      " Loss: 0.000000\n",
      " Loss: 0.020357\n",
      " Loss: 0.000000\n",
      " Loss: 0.040307\n",
      " Loss: 0.000000\n",
      " Loss: 0.022580\n",
      "Epoch 2846 Chain 0 loss std 9.40e-04 variance 4.42e-07 smooth variance 3.94e-07 adaptive c -1.00\n",
      "Epoch 2846 Chain 1 loss std 1.78e+02 variance 1.59e+04 smooth variance 2.07e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022431\n",
      " Loss: 0.000000\n",
      " Loss: 0.022560\n",
      " Loss: 0.000000\n",
      " Loss: 0.015421\n",
      " Loss: 0.000000\n",
      " Loss: 0.042746\n",
      " Loss: 0.000000\n",
      " Loss: 0.057679\n",
      " Loss: 0.000000\n",
      " Loss: 0.019729\n",
      " Loss: 0.000000\n",
      " Loss: 0.062228\n",
      " Loss: 0.000000\n",
      " Loss: 0.014013\n",
      " Loss: 0.000000\n",
      " Loss: 0.044609\n",
      " Loss: 0.000000\n",
      " Loss: 0.020258\n",
      "Epoch 2848 Chain 0 loss std 8.45e-04 variance 3.57e-07 smooth variance 3.83e-07 adaptive c -1.00\n",
      "Epoch 2848 Chain 1 loss std 1.97e+02 variance 1.93e+04 smooth variance 2.03e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.067196\n",
      " Loss: 0.000000\n",
      " Loss: 0.012987\n",
      " Loss: 0.000000\n",
      " Loss: 0.030975\n",
      " Loss: 0.000000\n",
      " Loss: 0.033027\n",
      " Loss: 0.000000\n",
      " Loss: 0.016652\n",
      " Loss: 0.000000\n",
      " Loss: 0.016895\n",
      " Loss: 0.000000\n",
      " Loss: 0.071689\n",
      " Loss: 0.000000\n",
      " Loss: 0.033604\n",
      " Loss: 0.000000\n",
      " Loss: 0.023187\n",
      " Loss: 0.000000\n",
      " Loss: 0.015463\n",
      "Epoch 2850 Chain 0 loss std 8.75e-04 variance 3.82e-07 smooth variance 3.83e-07 adaptive c -1.00\n",
      "Epoch 2850 Chain 1 loss std 1.74e+02 variance 1.51e+04 smooth variance 1.87e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032040\n",
      " Loss: 0.000000\n",
      " Loss: 0.034729\n",
      " Loss: 0.000000\n",
      " Loss: 0.012305\n",
      " Loss: 0.000000\n",
      " Loss: 0.057565\n",
      " Loss: 0.000000\n",
      " Loss: 0.024198\n",
      " Loss: 0.000000\n",
      " Loss: 0.036429\n",
      " Loss: 0.000000\n",
      " Loss: 0.028413\n",
      " Loss: 0.000000\n",
      " Loss: 0.021276\n",
      " Loss: 0.000000\n",
      " Loss: 0.062064\n",
      " Loss: 0.000000\n",
      " Loss: 0.012656\n",
      "Epoch 2852 Chain 0 loss std 5.88e-04 variance 1.73e-07 smooth variance 3.20e-07 adaptive c -1.00\n",
      "Epoch 2852 Chain 1 loss std 1.65e+02 variance 1.37e+04 smooth variance 1.72e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035490\n",
      " Loss: 0.000000\n",
      " Loss: 0.009842\n",
      " Loss: 0.000000\n",
      " Loss: 0.029621\n",
      " Loss: 0.000000\n",
      " Loss: 0.013764\n",
      " Loss: 0.000000\n",
      " Loss: 0.072122\n",
      " Loss: 0.000000\n",
      " Loss: 0.016689\n",
      " Loss: 0.000000\n",
      " Loss: 0.019019\n",
      " Loss: 0.000000\n",
      " Loss: 0.024016\n",
      " Loss: 0.000000\n",
      " Loss: 0.027471\n",
      " Loss: 0.000000\n",
      " Loss: 0.073643\n",
      "Epoch 2854 Chain 0 loss std 1.13e-03 variance 6.35e-07 smooth variance 4.15e-07 adaptive c -1.00\n",
      "Epoch 2854 Chain 1 loss std 2.44e+02 variance 2.98e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015065\n",
      " Loss: 0.000000\n",
      " Loss: 0.060901\n",
      " Loss: 0.000000\n",
      " Loss: 0.025523\n",
      " Loss: 0.000000\n",
      " Loss: 0.040642\n",
      " Loss: 0.000000\n",
      " Loss: 0.018706\n",
      " Loss: 0.000000\n",
      " Loss: 0.027610\n",
      " Loss: 0.000000\n",
      " Loss: 0.013826\n",
      " Loss: 0.000000\n",
      " Loss: 0.057990\n",
      " Loss: 0.000000\n",
      " Loss: 0.037782\n",
      " Loss: 0.000000\n",
      " Loss: 0.023629\n",
      "Epoch 2856 Chain 0 loss std 8.29e-04 variance 3.43e-07 smooth variance 3.93e-07 adaptive c -1.00\n",
      "Epoch 2856 Chain 1 loss std 2.26e+02 variance 2.55e+04 smooth variance 2.23e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018197\n",
      " Loss: 0.000000\n",
      " Loss: 0.041133\n",
      " Loss: 0.000000\n",
      " Loss: 0.024850\n",
      " Loss: 0.000000\n",
      " Loss: 0.012720\n",
      " Loss: 0.000000\n",
      " Loss: 0.063938\n",
      " Loss: 0.000000\n",
      " Loss: 0.019063\n",
      " Loss: 0.000000\n",
      " Loss: 0.031749\n",
      " Loss: 0.000000\n",
      " Loss: 0.029806\n",
      " Loss: 0.000000\n",
      " Loss: 0.016826\n",
      " Loss: 0.000000\n",
      " Loss: 0.063394\n",
      "Epoch 2858 Chain 0 loss std 7.37e-04 variance 2.72e-07 smooth variance 3.57e-07 adaptive c -1.00\n",
      "Epoch 2858 Chain 1 loss std 2.21e+02 variance 2.44e+04 smooth variance 2.29e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.061369\n",
      " Loss: 0.000000\n",
      " Loss: 0.025600\n",
      " Loss: 0.000000\n",
      " Loss: 0.028939\n",
      " Loss: 0.000000\n",
      " Loss: 0.029999\n",
      " Loss: 0.000000\n",
      " Loss: 0.014930\n",
      " Loss: 0.000000\n",
      " Loss: 0.061293\n",
      " Loss: 0.000000\n",
      " Loss: 0.016680\n",
      " Loss: 0.000000\n",
      " Loss: 0.029663\n",
      " Loss: 0.000000\n",
      " Loss: 0.013253\n",
      " Loss: 0.000000\n",
      " Loss: 0.039948\n",
      "Epoch 2860 Chain 0 loss std 1.29e-03 variance 8.36e-07 smooth variance 5.00e-07 adaptive c -1.00\n",
      "Epoch 2860 Chain 1 loss std 2.68e+02 variance 3.59e+04 smooth variance 2.68e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.013904\n",
      " Loss: 0.000000\n",
      " Loss: 0.024837\n",
      " Loss: 0.000000\n",
      " Loss: 0.065795\n",
      " Loss: 0.000000\n",
      " Loss: 0.027728\n",
      " Loss: 0.000000\n",
      " Loss: 0.028574\n",
      " Loss: 0.000000\n",
      " Loss: 0.012463\n",
      " Loss: 0.000000\n",
      " Loss: 0.062416\n",
      " Loss: 0.000000\n",
      " Loss: 0.030832\n",
      " Loss: 0.000000\n",
      " Loss: 0.045843\n",
      " Loss: 0.000000\n",
      " Loss: 0.009283\n",
      "Epoch 2862 Chain 0 loss std 1.22e-03 variance 7.39e-07 smooth variance 5.72e-07 adaptive c -1.00\n",
      "Epoch 2862 Chain 1 loss std 2.73e+02 variance 3.73e+04 smooth variance 3.00e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032683\n",
      " Loss: 0.000000\n",
      " Loss: 0.012557\n",
      " Loss: 0.000000\n",
      " Loss: 0.033463\n",
      " Loss: 0.000000\n",
      " Loss: 0.017909\n",
      " Loss: 0.000000\n",
      " Loss: 0.064226\n",
      " Loss: 0.000000\n",
      " Loss: 0.012491\n",
      " Loss: 0.000000\n",
      " Loss: 0.013206\n",
      " Loss: 0.000000\n",
      " Loss: 0.079202\n",
      " Loss: 0.000000\n",
      " Loss: 0.018382\n",
      " Loss: 0.000000\n",
      " Loss: 0.037557\n",
      "Epoch 2864 Chain 0 loss std 5.39e-04 variance 1.45e-07 smooth variance 4.44e-07 adaptive c -1.00\n",
      "Epoch 2864 Chain 1 loss std 1.62e+02 variance 1.31e+04 smooth variance 2.49e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035912\n",
      " Loss: 0.000000\n",
      " Loss: 0.016071\n",
      " Loss: 0.000000\n",
      " Loss: 0.061356\n",
      " Loss: 0.000000\n",
      " Loss: 0.017575\n",
      " Loss: 0.000000\n",
      " Loss: 0.029923\n",
      " Loss: 0.000000\n",
      " Loss: 0.014449\n",
      " Loss: 0.000000\n",
      " Loss: 0.021151\n",
      " Loss: 0.000000\n",
      " Loss: 0.027365\n",
      " Loss: 0.000000\n",
      " Loss: 0.041563\n",
      " Loss: 0.000000\n",
      " Loss: 0.056310\n",
      "Epoch 2866 Chain 0 loss std 1.03e-03 variance 5.26e-07 smooth variance 4.69e-07 adaptive c -1.00\n",
      "Epoch 2866 Chain 1 loss std 1.61e+02 variance 1.29e+04 smooth variance 2.13e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.040462\n",
      " Loss: 0.000000\n",
      " Loss: 0.020863\n",
      " Loss: 0.000000\n",
      " Loss: 0.023884\n",
      " Loss: 0.000000\n",
      " Loss: 0.014615\n",
      " Loss: 0.000000\n",
      " Loss: 0.061014\n",
      " Loss: 0.000000\n",
      " Loss: 0.069703\n",
      " Loss: 0.000000\n",
      " Loss: 0.018370\n",
      " Loss: 0.000000\n",
      " Loss: 0.033504\n",
      " Loss: 0.000000\n",
      " Loss: 0.019444\n",
      " Loss: 0.000000\n",
      " Loss: 0.019816\n",
      "Epoch 2868 Chain 0 loss std 7.92e-04 variance 3.14e-07 smooth variance 4.22e-07 adaptive c -1.00\n",
      "Epoch 2868 Chain 1 loss std 1.93e+02 variance 1.85e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.011983\n",
      " Loss: 0.000000\n",
      " Loss: 0.039044\n",
      " Loss: 0.000000\n",
      " Loss: 0.031407\n",
      " Loss: 0.000000\n",
      " Loss: 0.056486\n",
      " Loss: 0.000000\n",
      " Loss: 0.021917\n",
      " Loss: 0.000000\n",
      " Loss: 0.067046\n",
      " Loss: 0.000000\n",
      " Loss: 0.044228\n",
      " Loss: 0.000000\n",
      " Loss: 0.013413\n",
      " Loss: 0.000000\n",
      " Loss: 0.018482\n",
      " Loss: 0.000000\n",
      " Loss: 0.017667\n",
      "Epoch 2870 Chain 0 loss std 9.68e-04 variance 4.68e-07 smooth variance 4.36e-07 adaptive c -1.00\n",
      "Epoch 2870 Chain 1 loss std 2.81e+02 variance 3.95e+04 smooth variance 2.62e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.030003\n",
      " Loss: 0.000000\n",
      " Loss: 0.027367\n",
      " Loss: 0.000000\n",
      " Loss: 0.071894\n",
      " Loss: 0.000000\n",
      " Loss: 0.021231\n",
      " Loss: 0.000000\n",
      " Loss: 0.010342\n",
      " Loss: 0.000000\n",
      " Loss: 0.034041\n",
      " Loss: 0.000000\n",
      " Loss: 0.062057\n",
      " Loss: 0.000000\n",
      " Loss: 0.026526\n",
      " Loss: 0.000000\n",
      " Loss: 0.018757\n",
      " Loss: 0.000000\n",
      " Loss: 0.019458\n",
      "Epoch 2872 Chain 0 loss std 9.23e-04 variance 4.26e-07 smooth variance 4.33e-07 adaptive c -1.00\n",
      "Epoch 2872 Chain 1 loss std 2.12e+02 variance 2.25e+04 smooth variance 2.51e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021761\n",
      " Loss: 0.000000\n",
      " Loss: 0.030347\n",
      " Loss: 0.000000\n",
      " Loss: 0.063922\n",
      " Loss: 0.000000\n",
      " Loss: 0.032506\n",
      " Loss: 0.000000\n",
      " Loss: 0.012301\n",
      " Loss: 0.000000\n",
      " Loss: 0.016413\n",
      " Loss: 0.000000\n",
      " Loss: 0.017705\n",
      " Loss: 0.000000\n",
      " Loss: 0.019177\n",
      " Loss: 0.000000\n",
      " Loss: 0.024751\n",
      " Loss: 0.000000\n",
      " Loss: 0.082791\n",
      "Epoch 2874 Chain 0 loss std 1.70e-03 variance 1.45e-06 smooth variance 7.38e-07 adaptive c -1.00\n",
      "Epoch 2874 Chain 1 loss std 1.95e+02 variance 1.91e+04 smooth variance 2.33e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020201\n",
      " Loss: 0.000000\n",
      " Loss: 0.033110\n",
      " Loss: 0.000000\n",
      " Loss: 0.078710\n",
      " Loss: 0.000000\n",
      " Loss: 0.013203\n",
      " Loss: 0.000000\n",
      " Loss: 0.015613\n",
      " Loss: 0.000000\n",
      " Loss: 0.012070\n",
      " Loss: 0.000000\n",
      " Loss: 0.078228\n",
      " Loss: 0.000000\n",
      " Loss: 0.023479\n",
      " Loss: 0.000000\n",
      " Loss: 0.021327\n",
      " Loss: 0.000000\n",
      " Loss: 0.025733\n",
      "Epoch 2876 Chain 0 loss std 9.25e-04 variance 4.28e-07 smooth variance 6.45e-07 adaptive c -1.00\n",
      "Epoch 2876 Chain 1 loss std 1.77e+02 variance 1.57e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.013178\n",
      " Loss: 0.000000\n",
      " Loss: 0.060917\n",
      " Loss: 0.000000\n",
      " Loss: 0.042587\n",
      " Loss: 0.000000\n",
      " Loss: 0.024631\n",
      " Loss: 0.000000\n",
      " Loss: 0.019525\n",
      " Loss: 0.000000\n",
      " Loss: 0.035226\n",
      " Loss: 0.000000\n",
      " Loss: 0.022196\n",
      " Loss: 0.000000\n",
      " Loss: 0.021648\n",
      " Loss: 0.000000\n",
      " Loss: 0.018504\n",
      " Loss: 0.000000\n",
      " Loss: 0.063264\n",
      "Epoch 2878 Chain 0 loss std 8.62e-04 variance 3.72e-07 smooth variance 5.63e-07 adaptive c -1.00\n",
      "Epoch 2878 Chain 1 loss std 2.70e+02 variance 3.65e+04 smooth variance 2.56e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.013874\n",
      " Loss: 0.000000\n",
      " Loss: 0.028601\n",
      " Loss: 0.000000\n",
      " Loss: 0.060696\n",
      " Loss: 0.000000\n",
      " Loss: 0.011683\n",
      " Loss: 0.000000\n",
      " Loss: 0.045985\n",
      " Loss: 0.000000\n",
      " Loss: 0.011938\n",
      " Loss: 0.000000\n",
      " Loss: 0.068924\n",
      " Loss: 0.000000\n",
      " Loss: 0.011479\n",
      " Loss: 0.000000\n",
      " Loss: 0.024216\n",
      " Loss: 0.000000\n",
      " Loss: 0.044281\n",
      "Epoch 2880 Chain 0 loss std 7.52e-04 variance 2.83e-07 smooth variance 4.79e-07 adaptive c -1.00\n",
      "Epoch 2880 Chain 1 loss std 1.96e+02 variance 1.92e+04 smooth variance 2.37e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.052449\n",
      " Loss: 0.000000\n",
      " Loss: 0.018861\n",
      " Loss: 0.000000\n",
      " Loss: 0.028478\n",
      " Loss: 0.000000\n",
      " Loss: 0.023175\n",
      " Loss: 0.000000\n",
      " Loss: 0.037874\n",
      " Loss: 0.000000\n",
      " Loss: 0.076800\n",
      " Loss: 0.000000\n",
      " Loss: 0.015832\n",
      " Loss: 0.000000\n",
      " Loss: 0.024206\n",
      " Loss: 0.000000\n",
      " Loss: 0.022959\n",
      " Loss: 0.000000\n",
      " Loss: 0.021040\n",
      "Epoch 2882 Chain 0 loss std 1.11e-03 variance 6.14e-07 smooth variance 5.19e-07 adaptive c -1.00\n",
      "Epoch 2882 Chain 1 loss std 1.44e+02 variance 1.03e+04 smooth variance 1.97e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.040270\n",
      " Loss: 0.000000\n",
      " Loss: 0.020592\n",
      " Loss: 0.000000\n",
      " Loss: 0.013022\n",
      " Loss: 0.000000\n",
      " Loss: 0.065377\n",
      " Loss: 0.000000\n",
      " Loss: 0.021576\n",
      " Loss: 0.000000\n",
      " Loss: 0.023921\n",
      " Loss: 0.000000\n",
      " Loss: 0.034615\n",
      " Loss: 0.000000\n",
      " Loss: 0.024891\n",
      " Loss: 0.000000\n",
      " Loss: 0.059725\n",
      " Loss: 0.000000\n",
      " Loss: 0.017686\n",
      "Epoch 2884 Chain 0 loss std 1.08e-03 variance 5.78e-07 smooth variance 5.37e-07 adaptive c -1.00\n",
      "Epoch 2884 Chain 1 loss std 1.84e+02 variance 1.69e+04 smooth variance 1.89e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.063282\n",
      " Loss: 0.000000\n",
      " Loss: 0.013967\n",
      " Loss: 0.000000\n",
      " Loss: 0.033790\n",
      " Loss: 0.000000\n",
      " Loss: 0.022520\n",
      " Loss: 0.000000\n",
      " Loss: 0.027278\n",
      " Loss: 0.000000\n",
      " Loss: 0.068189\n",
      " Loss: 0.000000\n",
      " Loss: 0.012790\n",
      " Loss: 0.000000\n",
      " Loss: 0.024329\n",
      " Loss: 0.000000\n",
      " Loss: 0.040341\n",
      " Loss: 0.000000\n",
      " Loss: 0.015189\n",
      "Epoch 2886 Chain 0 loss std 6.45e-04 variance 2.08e-07 smooth variance 4.38e-07 adaptive c -1.00\n",
      "Epoch 2886 Chain 1 loss std 1.56e+02 variance 1.22e+04 smooth variance 1.68e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025235\n",
      " Loss: 0.000000\n",
      " Loss: 0.010531\n",
      " Loss: 0.000000\n",
      " Loss: 0.079463\n",
      " Loss: 0.000000\n",
      " Loss: 0.011754\n",
      " Loss: 0.000000\n",
      " Loss: 0.033855\n",
      " Loss: 0.000000\n",
      " Loss: 0.040884\n",
      " Loss: 0.000000\n",
      " Loss: 0.061946\n",
      " Loss: 0.000000\n",
      " Loss: 0.017225\n",
      " Loss: 0.000000\n",
      " Loss: 0.014506\n",
      " Loss: 0.000000\n",
      " Loss: 0.026277\n",
      "Epoch 2888 Chain 0 loss std 1.14e-03 variance 6.47e-07 smooth variance 5.01e-07 adaptive c -1.00\n",
      "Epoch 2888 Chain 1 loss std 2.09e+02 variance 2.18e+04 smooth variance 1.83e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.035499\n",
      " Loss: 0.000000\n",
      " Loss: 0.066621\n",
      " Loss: 0.000000\n",
      " Loss: 0.013266\n",
      " Loss: 0.000000\n",
      " Loss: 0.028104\n",
      " Loss: 0.000000\n",
      " Loss: 0.017348\n",
      " Loss: 0.000000\n",
      " Loss: 0.022488\n",
      " Loss: 0.000000\n",
      " Loss: 0.016068\n",
      " Loss: 0.000000\n",
      " Loss: 0.021569\n",
      " Loss: 0.000000\n",
      " Loss: 0.021889\n",
      " Loss: 0.000000\n",
      " Loss: 0.078824\n",
      "Epoch 2890 Chain 0 loss std 1.13e-03 variance 6.35e-07 smooth variance 5.41e-07 adaptive c -1.00\n",
      "Epoch 2890 Chain 1 loss std 1.60e+02 variance 1.28e+04 smooth variance 1.67e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.019865\n",
      " Loss: 0.000000\n",
      " Loss: 0.019184\n",
      " Loss: 0.000000\n",
      " Loss: 0.023972\n",
      " Loss: 0.000000\n",
      " Loss: 0.063494\n",
      " Loss: 0.000000\n",
      " Loss: 0.034322\n",
      " Loss: 0.000000\n",
      " Loss: 0.061590\n",
      " Loss: 0.000000\n",
      " Loss: 0.020237\n",
      " Loss: 0.000000\n",
      " Loss: 0.019580\n",
      " Loss: 0.000000\n",
      " Loss: 0.029828\n",
      " Loss: 0.000000\n",
      " Loss: 0.029602\n",
      "Epoch 2892 Chain 0 loss std 1.07e-03 variance 5.77e-07 smooth variance 5.52e-07 adaptive c -1.00\n",
      "Epoch 2892 Chain 1 loss std 2.32e+02 variance 2.70e+04 smooth variance 1.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.021975\n",
      " Loss: 0.000000\n",
      " Loss: 0.056931\n",
      " Loss: 0.000000\n",
      " Loss: 0.041499\n",
      " Loss: 0.000000\n",
      " Loss: 0.026536\n",
      " Loss: 0.000000\n",
      " Loss: 0.013896\n",
      " Loss: 0.000000\n",
      " Loss: 0.035810\n",
      " Loss: 0.000000\n",
      " Loss: 0.012461\n",
      " Loss: 0.000000\n",
      " Loss: 0.032854\n",
      " Loss: 0.000000\n",
      " Loss: 0.065615\n",
      " Loss: 0.000000\n",
      " Loss: 0.014099\n",
      "Epoch 2894 Chain 0 loss std 1.79e-03 variance 1.60e-06 smooth variance 8.65e-07 adaptive c -1.00\n",
      "Epoch 2894 Chain 1 loss std 2.84e+02 variance 4.04e+04 smooth variance 2.60e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014144\n",
      " Loss: 0.000000\n",
      " Loss: 0.027108\n",
      " Loss: 0.000000\n",
      " Loss: 0.021377\n",
      " Loss: 0.000000\n",
      " Loss: 0.067200\n",
      " Loss: 0.000000\n",
      " Loss: 0.031010\n",
      " Loss: 0.000000\n",
      " Loss: 0.030956\n",
      " Loss: 0.000000\n",
      " Loss: 0.010222\n",
      " Loss: 0.000000\n",
      " Loss: 0.017774\n",
      " Loss: 0.000000\n",
      " Loss: 0.038987\n",
      " Loss: 0.000000\n",
      " Loss: 0.062899\n",
      "Epoch 2896 Chain 0 loss std 1.28e-03 variance 8.18e-07 smooth variance 8.51e-07 adaptive c -1.00\n",
      "Epoch 2896 Chain 1 loss std 3.04e+02 variance 4.61e+04 smooth variance 3.20e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024582\n",
      " Loss: 0.000000\n",
      " Loss: 0.012353\n",
      " Loss: 0.000000\n",
      " Loss: 0.078391\n",
      " Loss: 0.000000\n",
      " Loss: 0.018712\n",
      " Loss: 0.000000\n",
      " Loss: 0.026800\n",
      " Loss: 0.000000\n",
      " Loss: 0.027479\n",
      " Loss: 0.000000\n",
      " Loss: 0.023876\n",
      " Loss: 0.000000\n",
      " Loss: 0.080279\n",
      " Loss: 0.000000\n",
      " Loss: 0.013991\n",
      " Loss: 0.000000\n",
      " Loss: 0.015213\n",
      "Epoch 2898 Chain 0 loss std 8.28e-04 variance 3.43e-07 smooth variance 6.99e-07 adaptive c -1.00\n",
      "Epoch 2898 Chain 1 loss std 2.24e+02 variance 2.51e+04 smooth variance 2.99e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.060951\n",
      " Loss: 0.000000\n",
      " Loss: 0.018961\n",
      " Loss: 0.000000\n",
      " Loss: 0.008578\n",
      " Loss: 0.000000\n",
      " Loss: 0.030766\n",
      " Loss: 0.000000\n",
      " Loss: 0.041581\n",
      " Loss: 0.000000\n",
      " Loss: 0.063152\n",
      " Loss: 0.000000\n",
      " Loss: 0.015375\n",
      " Loss: 0.000000\n",
      " Loss: 0.025431\n",
      " Loss: 0.000000\n",
      " Loss: 0.037247\n",
      " Loss: 0.000000\n",
      " Loss: 0.019633\n",
      "Epoch 2900 Chain 0 loss std 7.97e-04 variance 3.18e-07 smooth variance 5.84e-07 adaptive c -1.00\n",
      "Epoch 2900 Chain 1 loss std 1.88e+02 variance 1.77e+04 smooth variance 2.63e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.050964\n",
      " Loss: 0.000000\n",
      " Loss: 0.060372\n",
      " Loss: 0.000000\n",
      " Loss: 0.013340\n",
      " Loss: 0.000000\n",
      " Loss: 0.022156\n",
      " Loss: 0.000000\n",
      " Loss: 0.014006\n",
      " Loss: 0.000000\n",
      " Loss: 0.012573\n",
      " Loss: 0.000000\n",
      " Loss: 0.023168\n",
      " Loss: 0.000000\n",
      " Loss: 0.039326\n",
      " Loss: 0.000000\n",
      " Loss: 0.060993\n",
      " Loss: 0.000000\n",
      " Loss: 0.024778\n",
      "Epoch 2902 Chain 0 loss std 1.67e-03 variance 1.40e-06 smooth variance 8.29e-07 adaptive c -1.00\n",
      "Epoch 2902 Chain 1 loss std 1.79e+02 variance 1.60e+04 smooth variance 2.32e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015085\n",
      " Loss: 0.000000\n",
      " Loss: 0.066557\n",
      " Loss: 0.000000\n",
      " Loss: 0.015434\n",
      " Loss: 0.000000\n",
      " Loss: 0.034497\n",
      " Loss: 0.000000\n",
      " Loss: 0.029265\n",
      " Loss: 0.000000\n",
      " Loss: 0.016609\n",
      " Loss: 0.000000\n",
      " Loss: 0.025362\n",
      " Loss: 0.000000\n",
      " Loss: 0.061344\n",
      " Loss: 0.000000\n",
      " Loss: 0.022609\n",
      " Loss: 0.000000\n",
      " Loss: 0.034913\n",
      "Epoch 2904 Chain 0 loss std 1.02e-03 variance 5.19e-07 smooth variance 7.36e-07 adaptive c -1.00\n",
      "Epoch 2904 Chain 1 loss std 2.39e+02 variance 2.86e+04 smooth variance 2.48e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.039934\n",
      " Loss: 0.000000\n",
      " Loss: 0.021270\n",
      " Loss: 0.000000\n",
      " Loss: 0.024547\n",
      " Loss: 0.000000\n",
      " Loss: 0.016628\n",
      " Loss: 0.000000\n",
      " Loss: 0.058458\n",
      " Loss: 0.000000\n",
      " Loss: 0.021025\n",
      " Loss: 0.000000\n",
      " Loss: 0.081795\n",
      " Loss: 0.000000\n",
      " Loss: 0.022601\n",
      " Loss: 0.000000\n",
      " Loss: 0.015217\n",
      " Loss: 0.000000\n",
      " Loss: 0.020200\n",
      "Epoch 2906 Chain 0 loss std 9.26e-04 variance 4.28e-07 smooth variance 6.44e-07 adaptive c -1.00\n",
      "Epoch 2906 Chain 1 loss std 2.03e+02 variance 2.06e+04 smooth variance 2.36e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.013860\n",
      " Loss: 0.000000\n",
      " Loss: 0.017422\n",
      " Loss: 0.000000\n",
      " Loss: 0.061460\n",
      " Loss: 0.000000\n",
      " Loss: 0.019519\n",
      " Loss: 0.000000\n",
      " Loss: 0.048576\n",
      " Loss: 0.000000\n",
      " Loss: 0.073264\n",
      " Loss: 0.000000\n",
      " Loss: 0.019523\n",
      " Loss: 0.000000\n",
      " Loss: 0.014831\n",
      " Loss: 0.000000\n",
      " Loss: 0.035775\n",
      " Loss: 0.000000\n",
      " Loss: 0.017444\n",
      "Epoch 2908 Chain 0 loss std 1.09e-03 variance 5.95e-07 smooth variance 6.29e-07 adaptive c -1.00\n",
      "Epoch 2908 Chain 1 loss std 1.90e+02 variance 1.81e+04 smooth variance 2.19e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.059575\n",
      " Loss: 0.000000\n",
      " Loss: 0.013638\n",
      " Loss: 0.000000\n",
      " Loss: 0.033442\n",
      " Loss: 0.000000\n",
      " Loss: 0.025975\n",
      " Loss: 0.000000\n",
      " Loss: 0.028207\n",
      " Loss: 0.000000\n",
      " Loss: 0.028402\n",
      " Loss: 0.000000\n",
      " Loss: 0.083578\n",
      " Loss: 0.000000\n",
      " Loss: 0.013049\n",
      " Loss: 0.000000\n",
      " Loss: 0.019325\n",
      " Loss: 0.000000\n",
      " Loss: 0.016483\n",
      "Epoch 2910 Chain 0 loss std 6.67e-04 variance 2.23e-07 smooth variance 5.07e-07 adaptive c -1.00\n",
      "Epoch 2910 Chain 1 loss std 2.83e+02 variance 3.99e+04 smooth variance 2.73e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.039689\n",
      " Loss: 0.000000\n",
      " Loss: 0.055512\n",
      " Loss: 0.000000\n",
      " Loss: 0.022427\n",
      " Loss: 0.000000\n",
      " Loss: 0.019447\n",
      " Loss: 0.000000\n",
      " Loss: 0.023763\n",
      " Loss: 0.000000\n",
      " Loss: 0.069556\n",
      " Loss: 0.000000\n",
      " Loss: 0.025182\n",
      " Loss: 0.000000\n",
      " Loss: 0.021209\n",
      " Loss: 0.000000\n",
      " Loss: 0.016505\n",
      " Loss: 0.000000\n",
      " Loss: 0.028386\n",
      "Epoch 2912 Chain 0 loss std 1.42e-03 variance 1.01e-06 smooth variance 6.57e-07 adaptive c -1.00\n",
      "Epoch 2912 Chain 1 loss std 1.63e+02 variance 1.33e+04 smooth variance 2.31e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.041278\n",
      " Loss: 0.000000\n",
      " Loss: 0.013047\n",
      " Loss: 0.000000\n",
      " Loss: 0.060593\n",
      " Loss: 0.000000\n",
      " Loss: 0.024941\n",
      " Loss: 0.000000\n",
      " Loss: 0.020979\n",
      " Loss: 0.000000\n",
      " Loss: 0.035054\n",
      " Loss: 0.000000\n",
      " Loss: 0.015889\n",
      " Loss: 0.000000\n",
      " Loss: 0.020046\n",
      " Loss: 0.000000\n",
      " Loss: 0.026218\n",
      " Loss: 0.000000\n",
      " Loss: 0.063631\n",
      "Epoch 2914 Chain 0 loss std 9.73e-04 variance 4.73e-07 smooth variance 6.02e-07 adaptive c -1.00\n",
      "Epoch 2914 Chain 1 loss std 1.72e+02 variance 1.48e+04 smooth variance 2.06e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024331\n",
      " Loss: 0.000000\n",
      " Loss: 0.037716\n",
      " Loss: 0.000000\n",
      " Loss: 0.020870\n",
      " Loss: 0.000000\n",
      " Loss: 0.062217\n",
      " Loss: 0.000000\n",
      " Loss: 0.015704\n",
      " Loss: 0.000000\n",
      " Loss: 0.020330\n",
      " Loss: 0.000000\n",
      " Loss: 0.032117\n",
      " Loss: 0.000000\n",
      " Loss: 0.065086\n",
      " Loss: 0.000000\n",
      " Loss: 0.028634\n",
      " Loss: 0.000000\n",
      " Loss: 0.014671\n",
      "Epoch 2916 Chain 0 loss std 1.05e-03 variance 5.55e-07 smooth variance 5.87e-07 adaptive c -1.00\n",
      "Epoch 2916 Chain 1 loss std 2.67e+02 variance 3.56e+04 smooth variance 2.51e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.062425\n",
      " Loss: 0.000000\n",
      " Loss: 0.025920\n",
      " Loss: 0.000000\n",
      " Loss: 0.015860\n",
      " Loss: 0.000000\n",
      " Loss: 0.041769\n",
      " Loss: 0.000000\n",
      " Loss: 0.014864\n",
      " Loss: 0.000000\n",
      " Loss: 0.015824\n",
      " Loss: 0.000000\n",
      " Loss: 0.036325\n",
      " Loss: 0.000000\n",
      " Loss: 0.014299\n",
      " Loss: 0.000000\n",
      " Loss: 0.072527\n",
      " Loss: 0.000000\n",
      " Loss: 0.021862\n",
      "Epoch 2918 Chain 0 loss std 1.06e-03 variance 5.58e-07 smooth variance 5.79e-07 adaptive c -1.00\n",
      "Epoch 2918 Chain 1 loss std 2.14e+02 variance 2.29e+04 smooth variance 2.44e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.017157\n",
      " Loss: 0.000000\n",
      " Loss: 0.042339\n",
      " Loss: 0.000000\n",
      " Loss: 0.016973\n",
      " Loss: 0.000000\n",
      " Loss: 0.024884\n",
      " Loss: 0.000000\n",
      " Loss: 0.059485\n",
      " Loss: 0.000000\n",
      " Loss: 0.015020\n",
      " Loss: 0.000000\n",
      " Loss: 0.023066\n",
      " Loss: 0.000000\n",
      " Loss: 0.082081\n",
      " Loss: 0.000000\n",
      " Loss: 0.017276\n",
      " Loss: 0.000000\n",
      " Loss: 0.023395\n",
      "Epoch 2920 Chain 0 loss std 9.12e-04 variance 4.16e-07 smooth variance 5.30e-07 adaptive c -1.00\n",
      "Epoch 2920 Chain 1 loss std 1.83e+02 variance 1.67e+04 smooth variance 2.21e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.012529\n",
      " Loss: 0.000000\n",
      " Loss: 0.018649\n",
      " Loss: 0.000000\n",
      " Loss: 0.070077\n",
      " Loss: 0.000000\n",
      " Loss: 0.033579\n",
      " Loss: 0.000000\n",
      " Loss: 0.026003\n",
      " Loss: 0.000000\n",
      " Loss: 0.021519\n",
      " Loss: 0.000000\n",
      " Loss: 0.058873\n",
      " Loss: 0.000000\n",
      " Loss: 0.023741\n",
      " Loss: 0.000000\n",
      " Loss: 0.034510\n",
      " Loss: 0.000000\n",
      " Loss: 0.022195\n",
      "Epoch 2922 Chain 0 loss std 6.63e-04 variance 2.20e-07 smooth variance 4.37e-07 adaptive c -1.00\n",
      "Epoch 2922 Chain 1 loss std 1.58e+02 variance 1.24e+04 smooth variance 1.92e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022199\n",
      " Loss: 0.000000\n",
      " Loss: 0.067489\n",
      " Loss: 0.000000\n",
      " Loss: 0.021090\n",
      " Loss: 0.000000\n",
      " Loss: 0.033344\n",
      " Loss: 0.000000\n",
      " Loss: 0.016715\n",
      " Loss: 0.000000\n",
      " Loss: 0.033070\n",
      " Loss: 0.000000\n",
      " Loss: 0.060044\n",
      " Loss: 0.000000\n",
      " Loss: 0.015859\n",
      " Loss: 0.000000\n",
      " Loss: 0.014715\n",
      " Loss: 0.000000\n",
      " Loss: 0.037150\n",
      "Epoch 2924 Chain 0 loss std 1.11e-03 variance 6.21e-07 smooth variance 4.92e-07 adaptive c -1.00\n",
      "Epoch 2924 Chain 1 loss std 2.07e+02 variance 2.15e+04 smooth variance 1.99e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.064351\n",
      " Loss: 0.000000\n",
      " Loss: 0.036476\n",
      " Loss: 0.000000\n",
      " Loss: 0.015788\n",
      " Loss: 0.000000\n",
      " Loss: 0.029124\n",
      " Loss: 0.000000\n",
      " Loss: 0.015098\n",
      " Loss: 0.000000\n",
      " Loss: 0.020980\n",
      " Loss: 0.000001\n",
      " Loss: 0.060101\n",
      " Loss: 0.000000\n",
      " Loss: 0.020017\n",
      " Loss: 0.000000\n",
      " Loss: 0.036819\n",
      " Loss: 0.000000\n",
      " Loss: 0.022921\n",
      "Epoch 2926 Chain 0 loss std 1.52e-03 variance 1.15e-06 smooth variance 6.91e-07 adaptive c -1.00\n",
      "Epoch 2926 Chain 1 loss std 1.95e+02 variance 1.90e+04 smooth variance 1.96e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.013432\n",
      " Loss: 0.000000\n",
      " Loss: 0.018422\n",
      " Loss: 0.000000\n",
      " Loss: 0.076945\n",
      " Loss: 0.000000\n",
      " Loss: 0.033804\n",
      " Loss: 0.000000\n",
      " Loss: 0.018235\n",
      " Loss: 0.000000\n",
      " Loss: 0.016422\n",
      " Loss: 0.000000\n",
      " Loss: 0.020182\n",
      " Loss: 0.000000\n",
      " Loss: 0.059440\n",
      " Loss: 0.000000\n",
      " Loss: 0.013445\n",
      " Loss: 0.000000\n",
      " Loss: 0.051349\n",
      "Epoch 2928 Chain 0 loss std 7.46e-04 variance 2.78e-07 smooth variance 5.67e-07 adaptive c -1.00\n",
      "Epoch 2928 Chain 1 loss std 1.95e+02 variance 1.90e+04 smooth variance 1.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014986\n",
      " Loss: 0.000000\n",
      " Loss: 0.044639\n",
      " Loss: 0.000000\n",
      " Loss: 0.058861\n",
      " Loss: 0.000000\n",
      " Loss: 0.019933\n",
      " Loss: 0.000000\n",
      " Loss: 0.022419\n",
      " Loss: 0.000000\n",
      " Loss: 0.043082\n",
      " Loss: 0.000000\n",
      " Loss: 0.062235\n",
      " Loss: 0.000000\n",
      " Loss: 0.023032\n",
      " Loss: 0.000000\n",
      " Loss: 0.015267\n",
      " Loss: 0.000000\n",
      " Loss: 0.017222\n",
      "Epoch 2930 Chain 0 loss std 9.13e-04 variance 4.17e-07 smooth variance 5.22e-07 adaptive c -1.00\n",
      "Epoch 2930 Chain 1 loss std 3.12e+02 variance 4.85e+04 smooth variance 2.82e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.059661\n",
      " Loss: 0.000000\n",
      " Loss: 0.012089\n",
      " Loss: 0.000000\n",
      " Loss: 0.043433\n",
      " Loss: 0.000000\n",
      " Loss: 0.015560\n",
      " Loss: 0.000000\n",
      " Loss: 0.030095\n",
      " Loss: 0.000000\n",
      " Loss: 0.031436\n",
      " Loss: 0.000000\n",
      " Loss: 0.018062\n",
      " Loss: 0.000000\n",
      " Loss: 0.017333\n",
      " Loss: 0.000000\n",
      " Loss: 0.060384\n",
      " Loss: 0.000000\n",
      " Loss: 0.033623\n",
      "Epoch 2932 Chain 0 loss std 9.29e-04 variance 4.32e-07 smooth variance 4.95e-07 adaptive c -1.00\n",
      "Epoch 2932 Chain 1 loss std 2.08e+02 variance 2.17e+04 smooth variance 2.62e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026235\n",
      " Loss: 0.000000\n",
      " Loss: 0.062727\n",
      " Loss: 0.000000\n",
      " Loss: 0.032462\n",
      " Loss: 0.000000\n",
      " Loss: 0.017205\n",
      " Loss: 0.000000\n",
      " Loss: 0.022209\n",
      " Loss: 0.000000\n",
      " Loss: 0.069484\n",
      " Loss: 0.000000\n",
      " Loss: 0.040830\n",
      " Loss: 0.000000\n",
      " Loss: 0.021270\n",
      " Loss: 0.000000\n",
      " Loss: 0.017577\n",
      " Loss: 0.000000\n",
      " Loss: 0.011677\n",
      "Epoch 2934 Chain 0 loss std 1.49e-03 variance 1.11e-06 smooth variance 6.79e-07 adaptive c -1.00\n",
      "Epoch 2934 Chain 1 loss std 1.88e+02 variance 1.77e+04 smooth variance 2.37e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022623\n",
      " Loss: 0.000000\n",
      " Loss: 0.037732\n",
      " Loss: 0.000000\n",
      " Loss: 0.014152\n",
      " Loss: 0.000000\n",
      " Loss: 0.027107\n",
      " Loss: 0.000000\n",
      " Loss: 0.059224\n",
      " Loss: 0.000000\n",
      " Loss: 0.015964\n",
      " Loss: 0.000000\n",
      " Loss: 0.008515\n",
      " Loss: 0.000000\n",
      " Loss: 0.044503\n",
      " Loss: 0.000000\n",
      " Loss: 0.025639\n",
      " Loss: 0.000000\n",
      " Loss: 0.066217\n",
      "Epoch 2936 Chain 0 loss std 1.24e-03 variance 7.75e-07 smooth variance 7.07e-07 adaptive c -1.00\n",
      "Epoch 2936 Chain 1 loss std 3.02e+02 variance 4.55e+04 smooth variance 3.02e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.036912\n",
      " Loss: 0.000000\n",
      " Loss: 0.023627\n",
      " Loss: 0.000000\n",
      " Loss: 0.021483\n",
      " Loss: 0.000000\n",
      " Loss: 0.063008\n",
      " Loss: 0.000000\n",
      " Loss: 0.015809\n",
      " Loss: 0.000000\n",
      " Loss: 0.015279\n",
      " Loss: 0.000000\n",
      " Loss: 0.026282\n",
      " Loss: 0.000000\n",
      " Loss: 0.072116\n",
      " Loss: 0.000000\n",
      " Loss: 0.030905\n",
      " Loss: 0.000000\n",
      " Loss: 0.016256\n",
      "Epoch 2938 Chain 0 loss std 1.37e-03 variance 9.35e-07 smooth variance 7.76e-07 adaptive c -1.00\n",
      "Epoch 2938 Chain 1 loss std 1.90e+02 variance 1.81e+04 smooth variance 2.66e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.026696\n",
      " Loss: 0.000000\n",
      " Loss: 0.020761\n",
      " Loss: 0.000000\n",
      " Loss: 0.021185\n",
      " Loss: 0.000000\n",
      " Loss: 0.078554\n",
      " Loss: 0.000000\n",
      " Loss: 0.013642\n",
      " Loss: 0.000000\n",
      " Loss: 0.080758\n",
      " Loss: 0.000000\n",
      " Loss: 0.026887\n",
      " Loss: 0.000000\n",
      " Loss: 0.019459\n",
      " Loss: 0.000000\n",
      " Loss: 0.011551\n",
      " Loss: 0.000000\n",
      " Loss: 0.022182\n",
      "Epoch 2940 Chain 0 loss std 7.15e-04 variance 2.56e-07 smooth variance 6.20e-07 adaptive c -1.00\n",
      "Epoch 2940 Chain 1 loss std 1.94e+02 variance 1.87e+04 smooth variance 2.42e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.025692\n",
      " Loss: 0.000000\n",
      " Loss: 0.017874\n",
      " Loss: 0.000000\n",
      " Loss: 0.065582\n",
      " Loss: 0.000000\n",
      " Loss: 0.030963\n",
      " Loss: 0.000000\n",
      " Loss: 0.020725\n",
      " Loss: 0.000000\n",
      " Loss: 0.012724\n",
      " Loss: 0.000000\n",
      " Loss: 0.074868\n",
      " Loss: 0.000000\n",
      " Loss: 0.021305\n",
      " Loss: 0.000000\n",
      " Loss: 0.011276\n",
      " Loss: 0.000000\n",
      " Loss: 0.040665\n",
      "Epoch 2942 Chain 0 loss std 6.57e-04 variance 2.16e-07 smooth variance 4.98e-07 adaptive c -1.00\n",
      "Epoch 2942 Chain 1 loss std 1.94e+02 variance 1.89e+04 smooth variance 2.26e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.071950\n",
      " Loss: 0.000000\n",
      " Loss: 0.028826\n",
      " Loss: 0.000000\n",
      " Loss: 0.024244\n",
      " Loss: 0.000000\n",
      " Loss: 0.016713\n",
      " Loss: 0.000000\n",
      " Loss: 0.019105\n",
      " Loss: 0.000000\n",
      " Loss: 0.064663\n",
      " Loss: 0.000000\n",
      " Loss: 0.014259\n",
      " Loss: 0.000000\n",
      " Loss: 0.026671\n",
      " Loss: 0.000000\n",
      " Loss: 0.013742\n",
      " Loss: 0.000000\n",
      " Loss: 0.041502\n",
      "Epoch 2944 Chain 0 loss std 1.26e-03 variance 7.97e-07 smooth variance 5.88e-07 adaptive c -1.00\n",
      "Epoch 2944 Chain 1 loss std 1.71e+02 variance 1.45e+04 smooth variance 2.02e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.060800\n",
      " Loss: 0.000000\n",
      " Loss: 0.032181\n",
      " Loss: 0.000000\n",
      " Loss: 0.018691\n",
      " Loss: 0.000000\n",
      " Loss: 0.027960\n",
      " Loss: 0.000000\n",
      " Loss: 0.021204\n",
      " Loss: 0.000000\n",
      " Loss: 0.041058\n",
      " Loss: 0.000000\n",
      " Loss: 0.014128\n",
      " Loss: 0.000000\n",
      " Loss: 0.022109\n",
      " Loss: 0.000000\n",
      " Loss: 0.022990\n",
      " Loss: 0.000000\n",
      " Loss: 0.060553\n",
      "Epoch 2946 Chain 0 loss std 5.59e-04 variance 1.56e-07 smooth variance 4.59e-07 adaptive c -1.00\n",
      "Epoch 2946 Chain 1 loss std 2.82e+02 variance 3.97e+04 smooth variance 2.61e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018473\n",
      " Loss: 0.000000\n",
      " Loss: 0.022310\n",
      " Loss: 0.000000\n",
      " Loss: 0.017860\n",
      " Loss: 0.000000\n",
      " Loss: 0.057928\n",
      " Loss: 0.000000\n",
      " Loss: 0.044267\n",
      " Loss: 0.000000\n",
      " Loss: 0.014475\n",
      " Loss: 0.000000\n",
      " Loss: 0.060133\n",
      " Loss: 0.000000\n",
      " Loss: 0.029966\n",
      " Loss: 0.000000\n",
      " Loss: 0.037859\n",
      " Loss: 0.000000\n",
      " Loss: 0.018404\n",
      "Epoch 2948 Chain 0 loss std 1.20e-03 variance 7.23e-07 smooth variance 5.38e-07 adaptive c -1.00\n",
      "Epoch 2948 Chain 1 loss std 2.21e+02 variance 2.44e+04 smooth variance 2.56e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.012340\n",
      " Loss: 0.000000\n",
      " Loss: 0.042105\n",
      " Loss: 0.000000\n",
      " Loss: 0.018299\n",
      " Loss: 0.000000\n",
      " Loss: 0.028477\n",
      " Loss: 0.000000\n",
      " Loss: 0.059616\n",
      " Loss: 0.000000\n",
      " Loss: 0.034609\n",
      " Loss: 0.000000\n",
      " Loss: 0.020937\n",
      " Loss: 0.000000\n",
      " Loss: 0.024109\n",
      " Loss: 0.000000\n",
      " Loss: 0.055140\n",
      " Loss: 0.000000\n",
      " Loss: 0.026043\n",
      "Epoch 2950 Chain 0 loss std 1.07e-03 variance 5.74e-07 smooth variance 5.49e-07 adaptive c -1.00\n",
      "Epoch 2950 Chain 1 loss std 1.99e+02 variance 1.98e+04 smooth variance 2.39e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.060961\n",
      " Loss: 0.000000\n",
      " Loss: 0.014705\n",
      " Loss: 0.000000\n",
      " Loss: 0.031877\n",
      " Loss: 0.000000\n",
      " Loss: 0.037576\n",
      " Loss: 0.000000\n",
      " Loss: 0.015720\n",
      " Loss: 0.000000\n",
      " Loss: 0.037408\n",
      " Loss: 0.000000\n",
      " Loss: 0.016163\n",
      " Loss: 0.000000\n",
      " Loss: 0.019167\n",
      " Loss: 0.000000\n",
      " Loss: 0.062748\n",
      " Loss: 0.000000\n",
      " Loss: 0.025352\n",
      "Epoch 2952 Chain 0 loss std 7.83e-04 variance 3.07e-07 smooth variance 4.76e-07 adaptive c -1.00\n",
      "Epoch 2952 Chain 1 loss std 2.32e+02 variance 2.70e+04 smooth variance 2.48e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.022625\n",
      " Loss: 0.000000\n",
      " Loss: 0.013746\n",
      " Loss: 0.000000\n",
      " Loss: 0.016817\n",
      " Loss: 0.000000\n",
      " Loss: 0.045567\n",
      " Loss: 0.000000\n",
      " Loss: 0.062083\n",
      " Loss: 0.000000\n",
      " Loss: 0.059817\n",
      " Loss: 0.000000\n",
      " Loss: 0.021810\n",
      " Loss: 0.000000\n",
      " Loss: 0.029574\n",
      " Loss: 0.000000\n",
      " Loss: 0.037633\n",
      " Loss: 0.000000\n",
      " Loss: 0.012004\n",
      "Epoch 2954 Chain 0 loss std 9.41e-04 variance 4.43e-07 smooth variance 4.66e-07 adaptive c -1.00\n",
      "Epoch 2954 Chain 1 loss std 1.94e+02 variance 1.88e+04 smooth variance 2.30e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.079031\n",
      " Loss: 0.000000\n",
      " Loss: 0.015227\n",
      " Loss: 0.000000\n",
      " Loss: 0.026359\n",
      " Loss: 0.000000\n",
      " Loss: 0.018350\n",
      " Loss: 0.000000\n",
      " Loss: 0.021871\n",
      " Loss: 0.000000\n",
      " Loss: 0.019979\n",
      " Loss: 0.000000\n",
      " Loss: 0.014983\n",
      " Loss: 0.000000\n",
      " Loss: 0.075370\n",
      " Loss: 0.000000\n",
      " Loss: 0.035702\n",
      " Loss: 0.000000\n",
      " Loss: 0.014803\n",
      "Epoch 2956 Chain 0 loss std 6.23e-04 variance 1.94e-07 smooth variance 3.85e-07 adaptive c -1.00\n",
      "Epoch 2956 Chain 1 loss std 1.97e+02 variance 1.94e+04 smooth variance 2.19e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016132\n",
      " Loss: 0.000000\n",
      " Loss: 0.064086\n",
      " Loss: 0.000000\n",
      " Loss: 0.027026\n",
      " Loss: 0.000000\n",
      " Loss: 0.021335\n",
      " Loss: 0.000000\n",
      " Loss: 0.032258\n",
      " Loss: 0.000000\n",
      " Loss: 0.014908\n",
      " Loss: 0.000000\n",
      " Loss: 0.022249\n",
      " Loss: 0.000000\n",
      " Loss: 0.078574\n",
      " Loss: 0.000000\n",
      " Loss: 0.011476\n",
      " Loss: 0.000000\n",
      " Loss: 0.033630\n",
      "Epoch 2958 Chain 0 loss std 8.63e-04 variance 3.72e-07 smooth variance 3.81e-07 adaptive c -1.00\n",
      "Epoch 2958 Chain 1 loss std 2.14e+02 variance 2.28e+04 smooth variance 2.22e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.068416\n",
      " Loss: 0.000000\n",
      " Loss: 0.010861\n",
      " Loss: 0.000000\n",
      " Loss: 0.035814\n",
      " Loss: 0.000000\n",
      " Loss: 0.018051\n",
      " Loss: 0.000000\n",
      " Loss: 0.027694\n",
      " Loss: 0.000000\n",
      " Loss: 0.031916\n",
      " Loss: 0.000000\n",
      " Loss: 0.025234\n",
      " Loss: 0.000000\n",
      " Loss: 0.026896\n",
      " Loss: 0.000000\n",
      " Loss: 0.055501\n",
      " Loss: 0.000000\n",
      " Loss: 0.021291\n",
      "Epoch 2960 Chain 0 loss std 1.05e-03 variance 5.56e-07 smooth variance 4.33e-07 adaptive c -1.00\n",
      "Epoch 2960 Chain 1 loss std 1.69e+02 variance 1.43e+04 smooth variance 1.98e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.024704\n",
      " Loss: 0.000000\n",
      " Loss: 0.058190\n",
      " Loss: 0.000000\n",
      " Loss: 0.018347\n",
      " Loss: 0.000000\n",
      " Loss: 0.035493\n",
      " Loss: 0.000000\n",
      " Loss: 0.024104\n",
      " Loss: 0.000000\n",
      " Loss: 0.034709\n",
      " Loss: 0.000000\n",
      " Loss: 0.019643\n",
      " Loss: 0.000000\n",
      " Loss: 0.014440\n",
      " Loss: 0.000000\n",
      " Loss: 0.072550\n",
      " Loss: 0.000000\n",
      " Loss: 0.019494\n",
      "Epoch 2962 Chain 0 loss std 1.00e-03 variance 5.04e-07 smooth variance 4.54e-07 adaptive c -1.00\n",
      "Epoch 2962 Chain 1 loss std 1.97e+02 variance 1.95e+04 smooth variance 1.97e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032865\n",
      " Loss: 0.000000\n",
      " Loss: 0.013115\n",
      " Loss: 0.000000\n",
      " Loss: 0.077411\n",
      " Loss: 0.000000\n",
      " Loss: 0.019085\n",
      " Loss: 0.000000\n",
      " Loss: 0.018362\n",
      " Loss: 0.000000\n",
      " Loss: 0.013465\n",
      " Loss: 0.000000\n",
      " Loss: 0.061026\n",
      " Loss: 0.000000\n",
      " Loss: 0.015665\n",
      " Loss: 0.000000\n",
      " Loss: 0.034381\n",
      " Loss: 0.000000\n",
      " Loss: 0.036300\n",
      "Epoch 2964 Chain 0 loss std 1.24e-03 variance 7.73e-07 smooth variance 5.50e-07 adaptive c -1.00\n",
      "Epoch 2964 Chain 1 loss std 2.54e+02 variance 3.23e+04 smooth variance 2.35e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.034152\n",
      " Loss: 0.000000\n",
      " Loss: 0.076527\n",
      " Loss: 0.000000\n",
      " Loss: 0.020459\n",
      " Loss: 0.000000\n",
      " Loss: 0.014002\n",
      " Loss: 0.000000\n",
      " Loss: 0.015698\n",
      " Loss: 0.000000\n",
      " Loss: 0.038609\n",
      " Loss: 0.000000\n",
      " Loss: 0.060981\n",
      " Loss: 0.000000\n",
      " Loss: 0.016880\n",
      " Loss: 0.000000\n",
      " Loss: 0.025406\n",
      " Loss: 0.000000\n",
      " Loss: 0.018960\n",
      "Epoch 2966 Chain 0 loss std 9.95e-04 variance 4.95e-07 smooth variance 5.34e-07 adaptive c -1.00\n",
      "Epoch 2966 Chain 1 loss std 1.83e+02 variance 1.67e+04 smooth variance 2.15e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.044878\n",
      " Loss: 0.000000\n",
      " Loss: 0.017530\n",
      " Loss: 0.000000\n",
      " Loss: 0.022083\n",
      " Loss: 0.000000\n",
      " Loss: 0.062182\n",
      " Loss: 0.000000\n",
      " Loss: 0.014165\n",
      " Loss: 0.000000\n",
      " Loss: 0.033114\n",
      " Loss: 0.000000\n",
      " Loss: 0.016608\n",
      " Loss: 0.000000\n",
      " Loss: 0.016466\n",
      " Loss: 0.000000\n",
      " Loss: 0.069053\n",
      " Loss: 0.000000\n",
      " Loss: 0.025597\n",
      "Epoch 2968 Chain 0 loss std 1.27e-03 variance 8.06e-07 smooth variance 6.15e-07 adaptive c -1.00\n",
      "Epoch 2968 Chain 1 loss std 2.01e+02 variance 2.03e+04 smooth variance 2.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015704\n",
      " Loss: 0.000000\n",
      " Loss: 0.037654\n",
      " Loss: 0.000000\n",
      " Loss: 0.024577\n",
      " Loss: 0.000000\n",
      " Loss: 0.024538\n",
      " Loss: 0.000000\n",
      " Loss: 0.058364\n",
      " Loss: 0.000000\n",
      " Loss: 0.057084\n",
      " Loss: 0.000000\n",
      " Loss: 0.021290\n",
      " Loss: 0.000000\n",
      " Loss: 0.031448\n",
      " Loss: 0.000000\n",
      " Loss: 0.020219\n",
      " Loss: 0.000000\n",
      " Loss: 0.030797\n",
      "Epoch 2970 Chain 0 loss std 8.29e-04 variance 3.43e-07 smooth variance 5.34e-07 adaptive c -1.00\n",
      "Epoch 2970 Chain 1 loss std 2.06e+02 variance 2.12e+04 smooth variance 2.11e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.059126\n",
      " Loss: 0.000000\n",
      " Loss: 0.030709\n",
      " Loss: 0.000000\n",
      " Loss: 0.022381\n",
      " Loss: 0.000000\n",
      " Loss: 0.031611\n",
      " Loss: 0.000000\n",
      " Loss: 0.017011\n",
      " Loss: 0.000000\n",
      " Loss: 0.011698\n",
      " Loss: 0.000000\n",
      " Loss: 0.032062\n",
      " Loss: 0.000000\n",
      " Loss: 0.030681\n",
      " Loss: 0.000000\n",
      " Loss: 0.020870\n",
      " Loss: 0.000000\n",
      " Loss: 0.065527\n",
      "Epoch 2972 Chain 0 loss std 6.83e-04 variance 2.33e-07 smooth variance 4.44e-07 adaptive c -1.00\n",
      "Epoch 2972 Chain 1 loss std 1.98e+02 variance 1.95e+04 smooth variance 2.07e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.013821\n",
      " Loss: 0.000000\n",
      " Loss: 0.034379\n",
      " Loss: 0.000000\n",
      " Loss: 0.024339\n",
      " Loss: 0.000000\n",
      " Loss: 0.024792\n",
      " Loss: 0.000000\n",
      " Loss: 0.063506\n",
      " Loss: 0.000000\n",
      " Loss: 0.037529\n",
      " Loss: 0.000000\n",
      " Loss: 0.017940\n",
      " Loss: 0.000000\n",
      " Loss: 0.022415\n",
      " Loss: 0.000000\n",
      " Loss: 0.014935\n",
      " Loss: 0.000000\n",
      " Loss: 0.068019\n",
      "Epoch 2974 Chain 0 loss std 1.31e-03 variance 8.64e-07 smooth variance 5.70e-07 adaptive c -1.00\n",
      "Epoch 2974 Chain 1 loss std 2.10e+02 variance 2.20e+04 smooth variance 2.10e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.055614\n",
      " Loss: 0.000000\n",
      " Loss: 0.017647\n",
      " Loss: 0.000000\n",
      " Loss: 0.020435\n",
      " Loss: 0.000000\n",
      " Loss: 0.028607\n",
      " Loss: 0.000000\n",
      " Loss: 0.038535\n",
      " Loss: 0.000000\n",
      " Loss: 0.015188\n",
      " Loss: 0.000000\n",
      " Loss: 0.072451\n",
      " Loss: 0.000000\n",
      " Loss: 0.020397\n",
      " Loss: 0.000000\n",
      " Loss: 0.025133\n",
      " Loss: 0.000000\n",
      " Loss: 0.027669\n",
      "Epoch 2976 Chain 0 loss std 1.54e-03 variance 1.19e-06 smooth variance 7.55e-07 adaptive c -1.00\n",
      "Epoch 2976 Chain 1 loss std 1.77e+02 variance 1.57e+04 smooth variance 1.94e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.034629\n",
      " Loss: 0.000000\n",
      " Loss: 0.010905\n",
      " Loss: 0.000000\n",
      " Loss: 0.070157\n",
      " Loss: 0.000000\n",
      " Loss: 0.022019\n",
      " Loss: 0.000000\n",
      " Loss: 0.023128\n",
      " Loss: 0.000000\n",
      " Loss: 0.021288\n",
      " Loss: 0.000000\n",
      " Loss: 0.033963\n",
      " Loss: 0.000000\n",
      " Loss: 0.022975\n",
      " Loss: 0.000000\n",
      " Loss: 0.061380\n",
      " Loss: 0.000000\n",
      " Loss: 0.021233\n",
      "Epoch 2978 Chain 0 loss std 7.65e-04 variance 2.93e-07 smooth variance 6.16e-07 adaptive c -1.00\n",
      "Epoch 2978 Chain 1 loss std 2.88e+02 variance 4.16e+04 smooth variance 2.61e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.030247\n",
      " Loss: 0.000000\n",
      " Loss: 0.032879\n",
      " Loss: 0.000000\n",
      " Loss: 0.019673\n",
      " Loss: 0.000000\n",
      " Loss: 0.015178\n",
      " Loss: 0.000000\n",
      " Loss: 0.062861\n",
      " Loss: 0.000000\n",
      " Loss: 0.083971\n",
      " Loss: 0.000000\n",
      " Loss: 0.027239\n",
      " Loss: 0.000000\n",
      " Loss: 0.015307\n",
      " Loss: 0.000000\n",
      " Loss: 0.017971\n",
      " Loss: 0.000000\n",
      " Loss: 0.016350\n",
      "Epoch 2980 Chain 0 loss std 9.11e-04 variance 4.15e-07 smooth variance 5.56e-07 adaptive c -1.00\n",
      "Epoch 2980 Chain 1 loss std 2.07e+02 variance 2.14e+04 smooth variance 2.47e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.074973\n",
      " Loss: 0.000000\n",
      " Loss: 0.011421\n",
      " Loss: 0.000000\n",
      " Loss: 0.021200\n",
      " Loss: 0.000000\n",
      " Loss: 0.028776\n",
      " Loss: 0.000000\n",
      " Loss: 0.024468\n",
      " Loss: 0.000000\n",
      " Loss: 0.018317\n",
      " Loss: 0.000000\n",
      " Loss: 0.066267\n",
      " Loss: 0.000000\n",
      " Loss: 0.042703\n",
      " Loss: 0.000000\n",
      " Loss: 0.017843\n",
      " Loss: 0.000000\n",
      " Loss: 0.015708\n",
      "Epoch 2982 Chain 0 loss std 1.66e-03 variance 1.37e-06 smooth variance 8.01e-07 adaptive c -1.00\n",
      "Epoch 2982 Chain 1 loss std 1.38e+02 variance 9.53e+03 smooth variance 2.01e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016996\n",
      " Loss: 0.000000\n",
      " Loss: 0.029420\n",
      " Loss: 0.000000\n",
      " Loss: 0.064378\n",
      " Loss: 0.000000\n",
      " Loss: 0.019672\n",
      " Loss: 0.000000\n",
      " Loss: 0.030372\n",
      " Loss: 0.000000\n",
      " Loss: 0.020637\n",
      " Loss: 0.000000\n",
      " Loss: 0.023981\n",
      " Loss: 0.000000\n",
      " Loss: 0.012747\n",
      " Loss: 0.000000\n",
      " Loss: 0.036189\n",
      " Loss: 0.000000\n",
      " Loss: 0.067284\n",
      "Epoch 2984 Chain 0 loss std 8.74e-04 variance 3.82e-07 smooth variance 6.75e-07 adaptive c -1.00\n",
      "Epoch 2984 Chain 1 loss std 2.62e+02 variance 3.42e+04 smooth variance 2.44e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.040276\n",
      " Loss: 0.000000\n",
      " Loss: 0.025277\n",
      " Loss: 0.000000\n",
      " Loss: 0.018095\n",
      " Loss: 0.000000\n",
      " Loss: 0.018734\n",
      " Loss: 0.000000\n",
      " Loss: 0.058456\n",
      " Loss: 0.000000\n",
      " Loss: 0.015440\n",
      " Loss: 0.000000\n",
      " Loss: 0.019157\n",
      " Loss: 0.000000\n",
      " Loss: 0.077053\n",
      " Loss: 0.000000\n",
      " Loss: 0.026133\n",
      " Loss: 0.000000\n",
      " Loss: 0.023055\n",
      "Epoch 2986 Chain 0 loss std 1.17e-03 variance 6.90e-07 smooth variance 6.80e-07 adaptive c -1.00\n",
      "Epoch 2986 Chain 1 loss std 2.46e+02 variance 3.03e+04 smooth variance 2.61e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.018461\n",
      " Loss: 0.000000\n",
      " Loss: 0.016318\n",
      " Loss: 0.000000\n",
      " Loss: 0.030277\n",
      " Loss: 0.000000\n",
      " Loss: 0.017553\n",
      " Loss: 0.000000\n",
      " Loss: 0.078228\n",
      " Loss: 0.000000\n",
      " Loss: 0.041220\n",
      " Loss: 0.000000\n",
      " Loss: 0.021952\n",
      " Loss: 0.000000\n",
      " Loss: 0.024731\n",
      " Loss: 0.000000\n",
      " Loss: 0.056246\n",
      " Loss: 0.000000\n",
      " Loss: 0.016689\n",
      "Epoch 2988 Chain 0 loss std 1.46e-03 variance 1.06e-06 smooth variance 7.94e-07 adaptive c -1.00\n",
      "Epoch 2988 Chain 1 loss std 1.98e+02 variance 1.96e+04 smooth variance 2.42e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.032195\n",
      " Loss: 0.000000\n",
      " Loss: 0.010815\n",
      " Loss: 0.000000\n",
      " Loss: 0.031765\n",
      " Loss: 0.000000\n",
      " Loss: 0.016604\n",
      " Loss: 0.000000\n",
      " Loss: 0.069458\n",
      " Loss: 0.000000\n",
      " Loss: 0.032350\n",
      " Loss: 0.000000\n",
      " Loss: 0.059616\n",
      " Loss: 0.000000\n",
      " Loss: 0.015902\n",
      " Loss: 0.000000\n",
      " Loss: 0.016455\n",
      " Loss: 0.000000\n",
      " Loss: 0.036515\n",
      "Epoch 2990 Chain 0 loss std 9.45e-04 variance 4.46e-07 smooth variance 6.90e-07 adaptive c -1.00\n",
      "Epoch 2990 Chain 1 loss std 1.76e+02 variance 1.55e+04 smooth variance 2.16e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.015712\n",
      " Loss: 0.000000\n",
      " Loss: 0.065826\n",
      " Loss: 0.000000\n",
      " Loss: 0.018135\n",
      " Loss: 0.000000\n",
      " Loss: 0.018507\n",
      " Loss: 0.000000\n",
      " Loss: 0.042657\n",
      " Loss: 0.000000\n",
      " Loss: 0.027570\n",
      " Loss: 0.000000\n",
      " Loss: 0.018745\n",
      " Loss: 0.000000\n",
      " Loss: 0.021608\n",
      " Loss: 0.000000\n",
      " Loss: 0.017175\n",
      " Loss: 0.000000\n",
      " Loss: 0.075739\n",
      "Epoch 2992 Chain 0 loss std 1.10e-03 variance 6.09e-07 smooth variance 6.65e-07 adaptive c -1.00\n",
      "Epoch 2992 Chain 1 loss std 1.90e+02 variance 1.81e+04 smooth variance 2.05e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.020663\n",
      " Loss: 0.000000\n",
      " Loss: 0.022138\n",
      " Loss: 0.000000\n",
      " Loss: 0.014246\n",
      " Loss: 0.000000\n",
      " Loss: 0.088225\n",
      " Loss: 0.000000\n",
      " Loss: 0.015566\n",
      " Loss: 0.000000\n",
      " Loss: 0.011858\n",
      " Loss: 0.000000\n",
      " Loss: 0.019016\n",
      " Loss: 0.000000\n",
      " Loss: 0.062634\n",
      " Loss: 0.000000\n",
      " Loss: 0.036038\n",
      " Loss: 0.000000\n",
      " Loss: 0.031291\n",
      "Epoch 2994 Chain 0 loss std 6.41e-04 variance 2.06e-07 smooth variance 5.27e-07 adaptive c -1.00\n",
      "Epoch 2994 Chain 1 loss std 2.80e+02 variance 3.91e+04 smooth variance 2.61e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.014676\n",
      " Loss: 0.000000\n",
      " Loss: 0.014204\n",
      " Loss: 0.000000\n",
      " Loss: 0.036198\n",
      " Loss: 0.000000\n",
      " Loss: 0.059891\n",
      " Loss: 0.000000\n",
      " Loss: 0.035868\n",
      " Loss: 0.000000\n",
      " Loss: 0.066880\n",
      " Loss: 0.000000\n",
      " Loss: 0.029995\n",
      " Loss: 0.000000\n",
      " Loss: 0.017964\n",
      " Loss: 0.000000\n",
      " Loss: 0.015347\n",
      " Loss: 0.000000\n",
      " Loss: 0.030652\n",
      "Epoch 2996 Chain 0 loss std 1.05e-03 variance 5.50e-07 smooth variance 5.34e-07 adaptive c -1.00\n",
      "Epoch 2996 Chain 1 loss std 1.86e+02 variance 1.74e+04 smooth variance 2.35e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.016924\n",
      " Loss: 0.000000\n",
      " Loss: 0.026865\n",
      " Loss: 0.000000\n",
      " Loss: 0.020284\n",
      " Loss: 0.000000\n",
      " Loss: 0.037763\n",
      " Loss: 0.000000\n",
      " Loss: 0.059002\n",
      " Loss: 0.000000\n",
      " Loss: 0.026506\n",
      " Loss: 0.000000\n",
      " Loss: 0.065734\n",
      " Loss: 0.000000\n",
      " Loss: 0.011632\n",
      " Loss: 0.000000\n",
      " Loss: 0.018534\n",
      " Loss: 0.000000\n",
      " Loss: 0.038432\n",
      "Epoch 2998 Chain 0 loss std 1.25e-03 variance 7.79e-07 smooth variance 6.08e-07 adaptive c -1.00\n",
      "Epoch 2998 Chain 1 loss std 1.72e+02 variance 1.48e+04 smooth variance 2.09e+04 adaptive c -1.00\n",
      " Loss: 0.000000\n",
      " Loss: 0.070041\n",
      " Loss: 0.000000\n",
      " Loss: 0.015572\n",
      " Loss: 0.000000\n",
      " Loss: 0.032748\n",
      " Loss: 0.000000\n",
      " Loss: 0.018839\n",
      " Loss: 0.000000\n",
      " Loss: 0.023638\n",
      " Loss: 0.000000\n",
      " Loss: 0.025807\n",
      " Loss: 0.000000\n",
      " Loss: 0.064654\n",
      " Loss: 0.000000\n",
      " Loss: 0.014576\n",
      " Loss: 0.000000\n",
      " Loss: 0.019868\n",
      " Loss: 0.000000\n",
      " Loss: 0.035933\n",
      "Time used 30.42s\n"
     ]
    }
   ],
   "source": [
    "class Parameters:\n",
    "    T = 0.01\n",
    "    lr = 2e-4\n",
    "    num_of_chains = 2\n",
    "    wdecay = 5e-4\n",
    "    total = 10000  # Adjust based on dataset size\n",
    "    Tgap = 0.2\n",
    "    LRgap = 0.66\n",
    "    num_epoch = 3000\n",
    "    period = 2\n",
    "    batch = 256\n",
    "    var_reduce = 0\n",
    "    adapt_c = 0\n",
    "    alpha = 0.3\n",
    "    bias_F = 1.5e5\n",
    "    cool = 1\n",
    "    burn = 0.6\n",
    "    Tanneal = 1.02\n",
    "    LRanneal = 0.984\n",
    "\n",
    "params = Parameters()\n",
    "\n",
    "# Create multiple chains (models)\n",
    "nets = [DNNRegressor() for _ in range(params.num_of_chains)]\n",
    "\n",
    "# Train using Replica Exchange\n",
    "trainer(nets, train_loader, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4991\n",
      "Predictions for test set:\n",
      "[[ 17.593515 275.22482   49.40867 ]\n",
      " [ 10.09407  256.58386   87.29531 ]\n",
      " [ 25.355549 196.27771  200.56403 ]\n",
      " [ 31.563593 448.61096  184.61217 ]\n",
      " [ 19.785938   9.798447 174.51738 ]\n",
      " [ 32.926853 217.86102  231.10056 ]\n",
      " [ 15.444226 229.64482  113.46571 ]\n",
      " [ 22.61806  -17.832626 231.54088 ]\n",
      " [ 19.389854 189.3818   151.5189  ]\n",
      " [ 26.36528  209.93726  228.96655 ]]\n",
      "True values for test set:\n",
      "[[  9.        200.         80.       ]\n",
      " [  4.0000005 163.         70.       ]\n",
      " [ 27.        168.        240.       ]\n",
      " [ 28.        321.        270.       ]\n",
      " [ 26.         88.        160.       ]\n",
      " [ 29.        244.        320.       ]\n",
      " [ 12.        176.        120.       ]\n",
      " [ 11.        180.        160.       ]\n",
      " [ 18.        225.        140.       ]\n",
      " [ 29.         74.        200.       ]]\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "nets[0].eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        y_pred = nets[0](x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "# Print test loss\n",
    "print(f'Test Loss: {test_loss/len(test_loader):.4f}')\n",
    "\n",
    "# Make predictions for the test set\n",
    "with torch.no_grad():\n",
    "    y_test_pred = nets[0](x_test_tensor)\n",
    "\n",
    "# Inverse transform the predictions and true values back to original scale\n",
    "y_test_pred = scaler_y.inverse_transform(y_test_pred.numpy())  # Convert to numpy\n",
    "y_test = scaler_y.inverse_transform(y_test_tensor.numpy())  # Convert to numpy\n",
    "\n",
    "# Print first few predictions and true values\n",
    "print(\"Predictions for test set:\")\n",
    "print(y_test_pred[:10])\n",
    "print(\"True values for test set:\")\n",
    "print(y_test[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3959\n",
      "Predictions for test set:\n",
      "[[ 11.945619 128.15623  102.99774 ]\n",
      " [ 17.460901 133.03955  204.22476 ]\n",
      " [ 29.041254 141.10402  227.03519 ]\n",
      " [ 32.624077 279.21582  314.49896 ]\n",
      " [ 19.082756  88.85163  148.95969 ]\n",
      " [ 26.150257 221.139    235.27725 ]\n",
      " [ 27.372606 134.62715  218.7594  ]\n",
      " [ 21.61272  125.250145 170.83461 ]\n",
      " [ 22.736105 241.2504   161.32562 ]\n",
      " [ 23.296679  62.78354  187.37979 ]]\n",
      "True values for test set:\n",
      "[[  9.        200.         80.       ]\n",
      " [  4.0000005 163.         70.       ]\n",
      " [ 27.        168.        240.       ]\n",
      " [ 28.        321.        270.       ]\n",
      " [ 26.         88.        160.       ]\n",
      " [ 29.        244.        320.       ]\n",
      " [ 12.        176.        120.       ]\n",
      " [ 11.        180.        160.       ]\n",
      " [ 18.        225.        140.       ]\n",
      " [ 29.         74.        200.       ]]\n"
     ]
    }
   ],
   "source": [
    "# Testing loop\n",
    "nets[1].eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        y_pred = nets[1](x_batch)\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "# Print test loss\n",
    "print(f'Test Loss: {test_loss/len(test_loader):.4f}')\n",
    "\n",
    "# Make predictions for the test set\n",
    "with torch.no_grad():\n",
    "    y_test_pred = nets[1](x_test_tensor)\n",
    "\n",
    "# Inverse transform the predictions and true values back to original scale\n",
    "y_test_pred = scaler_y.inverse_transform(y_test_pred.numpy())  # Convert to numpy\n",
    "y_test = scaler_y.inverse_transform(y_test_tensor.numpy())  # Convert to numpy\n",
    "\n",
    "# Print first few predictions and true values\n",
    "print(\"Predictions for test set:\")\n",
    "print(y_test_pred[:10])\n",
    "print(\"True values for test set:\")\n",
    "print(y_test[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NSGA_replica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
