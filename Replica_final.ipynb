{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRDvxzlS5E1D"
      },
      "outputs": [],
      "source": [
        "import sys, copy\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class One_Chain_Optimizer:\n",
        "    def __init__(self, net, criterion, momentum=0.5, lr=1e-4, wdecay=5e-4, T=0.5, total=1000):\n",
        "        self.net = net\n",
        "        self.eta = lr\n",
        "        self.momentum = momentum\n",
        "        self.T = T\n",
        "        self.wdecay = wdecay\n",
        "        self.V = 0.1\n",
        "        self.velocity = []\n",
        "        self.criterion = criterion\n",
        "        self.total = total\n",
        "\n",
        "        self.beta = 0.5 * self.V * self.eta\n",
        "        self.alpha = 1 - self.momentum\n",
        "\n",
        "        if self.beta > self.alpha:\n",
        "            sys.exit('Momentum is too large')\n",
        "\n",
        "        self.sigma = np.sqrt(2.0 * self.eta * (self.alpha - self.beta))\n",
        "        self.scale = self.sigma * np.sqrt(self.T)\n",
        "\n",
        "        for param in net.parameters():\n",
        "            p = torch.zeros_like(param.data)\n",
        "            self.velocity.append(p)\n",
        "\n",
        "    def set_T(self, factor=1):\n",
        "        self.T /= factor\n",
        "        self.scale = self.sigma * np.sqrt(self.T)\n",
        "\n",
        "    def set_eta(self, eta):\n",
        "        self.eta = eta\n",
        "        self.beta = 0.5 * self.V * self.eta\n",
        "        self.sigma = np.sqrt(2.0 * self.eta * (self.alpha - self.beta))\n",
        "        self.scale = self.sigma * np.sqrt(self.T)\n",
        "\n",
        "    def backprop(self, x, y):\n",
        "        self.net.zero_grad()\n",
        "        \"\"\" convert mean loss to sum losses \"\"\"\n",
        "        loss = self.criterion(self.net(x), y)  # * self.total\n",
        "        loss.backward()\n",
        "        return loss\n",
        "\n",
        "    def step(self, x, y):\n",
        "        loss = self.backprop(x, y)\n",
        "        print(\"Check loss:\", loss)\n",
        "        for i, param in enumerate(self.net.parameters()):\n",
        "            proposal = torch.FloatTensor(param.data.size()).normal_().mul(self.scale)\n",
        "            grads = param.grad.data\n",
        "            if self.wdecay != 0:\n",
        "                grads.add_(self.wdecay, param.data)\n",
        "            self.velocity[i].mul_(self.momentum).add_(-self.eta, grads).add_(proposal)\n",
        "            param.data.add_(self.velocity[i])\n",
        "        return loss.data.item()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import copy\n",
        "import sys\n",
        "import os\n",
        "import time\n",
        "import csv\n",
        "import argparse\n",
        "import random\n",
        "import collections\n",
        "from random import shuffle\n",
        "import pickle\n",
        "\n",
        "from tqdm import tqdm ## better progressbar\n",
        "from math import exp\n",
        "from sys import getsizeof\n",
        "import numpy as np\n",
        "\n",
        "## import pytorch modules\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "CUDA_EXISTS = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define Your own Parameters in parameters : parameters = [T, lr, num_of_chains, wdecay, total, Tgap, LRgap, num_epoch, period, batch, var_reduce, adapt_c, alpha, bias_F, cool, burn, Tanneal, LRanneal]\n",
        "# T:Temperature for high temperature chain, default=0.05\n",
        "# lr: Sampling learning rate, default=0.1\n",
        "# num_of_chains: Total number of chains, default=1\n",
        "# wdecay: Samling weight decay, default=5e-4\n",
        "# total: Total data points, default=50000\n",
        "# Tgap: Temperature gap between chains, default=0.2\n",
        "# LRgap: Learning rate gap between chains, default=0.66\n",
        "# num_epoch: Sampling Epochs, default=1000\n",
        "# period: estimate adaptive variance every [period] epochs, default=2\n",
        "# batch: Batch size, default=256\n",
        "# var_reduce: n>0 means update variance reduction every n epochs; n divides 10, default=0\n",
        "# adapt_c: adapt_c=1 is equivalent to running Alg. 2 in the appendix, default=0\n",
        "# alpha: forgetting rate, default=0.3\n",
        "# bias_F: correction factor F, default=1.5e5\n",
        "# cool: No swaps happen during the cooling time after a swap, default=1\n",
        "# burn: burn in iterations for sampling (sn * burn), default=0.6\n",
        "# Tanneal: temperature annealing factor, default=1.02\n",
        "# LRanneal: lr annealing factor, default=0.984\n",
        "\n",
        "def trainer(nets, training_data, parameters):\n",
        "  # Loss function\n",
        "  criterion = nn.MSELoss()\n",
        "  # Initial temperature and learning rate\n",
        "  init_T, init_lr = parameters.T, parameters.lr\n",
        "\n",
        "  chains, lr_set, myVars, cooling_time, BMAS = {}, [], [], [], []\n",
        "  for idx in range(parameters.num_of_chains-1, -1, -1):\n",
        "    print('Chain {} Initial learning rate {:.2e} temperature {:.2e}'.format(idx, init_lr, init_T))\n",
        "    chain = One_Chain_Optimizer(nets[idx], criterion)\n",
        "    lr_set.insert(0, init_lr)\n",
        "    init_T /= parameters.Tgap\n",
        "    init_lr /= parameters.LRgap\n",
        "    chains[idx] = chain\n",
        "    myVars.append(sys.float_info.max)\n",
        "\n",
        "  start = time.time()\n",
        "  counter, warm_up, adjusted_corrections = 1., 10, 0\n",
        "  # Initialization for variance reduction\n",
        "  last_full_losses, last_VRnets, corr = [0] * parameters.num_of_chains, [], [-1] * parameters.num_of_chains\n",
        "  for idx in range(parameters.num_of_chains):\n",
        "    last_VRnets.append(pickle.loads(pickle.dumps(nets[idx])))\n",
        "\n",
        "  for epoch in range(parameters.num_epoch):\n",
        "    # Update adaptive variance and variance reduction every [period] epochs\n",
        "    if parameters.period > 0 and epoch % parameters.period ==0:\n",
        "      cur_full_losses = [0] * parameters.num_of_chains\n",
        "      for idx in range(parameters.num_of_chains):\n",
        "        stage_losses, cv_losses = [], []\n",
        "        nets[idx].eval()\n",
        "        for i, (x, y) in enumerate(training_data):\n",
        "          x = x.to(device)\n",
        "          y = y.to(device)\n",
        "          nets[idx].zero_grad()\n",
        "          avg_loss = criterion(nets[idx](x), y).item()\n",
        "          cur_full_losses[idx] += avg_loss * parameters.batch\n",
        "          stage_losses.append(avg_loss * parameters.total)\n",
        "\n",
        "\n",
        "          if parameters.var_reduce:\n",
        "            cv_losses.append(criterion(last_VRnets[idx](x), y).item() * parameters.total)\n",
        "\n",
        "          if parameters.adapt_c:\n",
        "            adaptive_corr = -np.cov(stage_losses, cv_losses, ddof=1)[0][1] / np.var(cv_losses, ddof=1)\n",
        "            corr[idx] = (1 - parameters.alpha) * corr[idx] + parameters.alpha * adaptive_corr\n",
        "\n",
        "          if parameters.var_reduce:\n",
        "            for i in range(len(stage_losses)):\n",
        "              stage_losses[i] = stage_losses[i] + corr[idx] * (cv_losses[i] - np.mean(cv_losses))\n",
        "\n",
        "        std_epoch = np.std(stage_losses, ddof=1)\n",
        "\n",
        "        myVars[idx] = 0.5 * std_epoch**2 if myVars[idx] == sys.float_info.max else ((1 - parameters.alpha) * myVars[idx] + parameters.alpha * 0.5 * std_epoch ** 2)\n",
        "\n",
        "        print('Epoch {} Chain {} loss std {:.2e} variance {:.2e} smooth variance {:.2e} adaptive c {:.2f}'.format(epoch, idx, std_epoch, 0.5 * std_epoch**2, myVars[idx], corr[idx]))\n",
        "        last_VRnets[idx] = pickle.loads(pickle.dumps(nets[idx]))\n",
        "        last_full_losses[idx] = cur_full_losses[idx]\n",
        "\n",
        "    for idx in range(parameters.num_of_chains):\n",
        "      nets[idx].train()\n",
        "\n",
        "    for i, (x, y) in enumerate(training_data):\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      counter += 1\n",
        "      loss_chains = []\n",
        "      for idx in range(parameters.num_of_chains):\n",
        "        loss = chains[idx].step(x, y)\n",
        "        # variance-reduced negative log posterior\n",
        "        if parameters.var_reduce and epoch > warm_up:\n",
        "          control_variate_loss = criterion(last_VRnets[idx](x), y).item() * parameters.total\n",
        "          loss = loss + corr[idx] * (control_variate_loss - last_full_losses[idx])\n",
        "        loss_chains.append(loss)\n",
        "\n",
        "      # Swap\n",
        "\n",
        "      for idx in range(parameters.num_of_chains - 1):\n",
        "\n",
        "        # exponential average smoothing\n",
        "        delta_invT = 1. / chains[idx].T - 1. / chains[idx+1].T\n",
        "        adjusted_corrections = delta_invT * (myVars[idx] + myVars[idx+1]) / parameters.bias_F\n",
        "        print(\"Check first term:\",  np.log(np.random.uniform(0, 1)))\n",
        "        print(\"Check second term:\", delta_invT * (loss_chains[idx] - loss_chains[idx+1] - adjusted_corrections))\n",
        "        if np.log(np.random.uniform(0, 1)) < delta_invT * (loss_chains[idx] - loss_chains[idx+1] - adjusted_corrections):\n",
        "          print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "\n",
        "          if epoch not in cooling_time:\n",
        "            temporary = pickle.loads(pickle.dumps(chains[idx+1].net))\n",
        "            chains[idx+1].net.load_state_dict(chains[idx].net.state_dict())\n",
        "            chains[idx].net.load_state_dict(temporary.state_dict())\n",
        "            print('Epoch {} Swap chain {} with chain {} and increased F {:0.2e}'.format(epoch, idx, idx+1, parameters.bias_F))\n",
        "            cooling_time = range(epoch, epoch+parameters.cool)\n",
        "          else:\n",
        "            print('Epoch {} Cooling period'.format(epoch))\n",
        "\n",
        "    # Anneaing]\n",
        "    if epoch < parameters.burn * parameters.num_epoch:\n",
        "      parameters.bias_F *= parameters.Tanneal\n",
        "    for idx in range(parameters.num_of_chains):\n",
        "      if epoch > 0.4 * parameters.num_epoch and parameters.LRanneal <=1:\n",
        "        chains[idx].eta *= parameters.LRanneal\n",
        "      if epoch < parameters.burn * parameters.num_epoch:\n",
        "        chains[idx].set_T(parameters.Tanneal)\n",
        "\n",
        "      # add test set here\n",
        "      ##########################################\n",
        "\n",
        "  end = time.time()\n",
        "  print('Time used {:.2f}s'.format(end - start))"
      ],
      "metadata": {
        "id": "rxiDzcbM5G_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = argparse.Namespace(\n",
        "    T=0.05,              # Lower initial temperature\n",
        "    lr=1e-4,            # Lower learning rate\n",
        "    num_of_chains=2,      # Only 1 chain for now\n",
        "    wdecay=1e-4,          # Smaller weight decay to prevent over-penalizing weights\n",
        "    total=50000,   # Total number of data points\n",
        "    Tgap=0.2,             # Default Tgap\n",
        "    LRgap=0.66,           # Default LRgap\n",
        "    num_epoch=1000,        # Training epochs\n",
        "    period=2,             # Period for variance reduction\n",
        "    batch=256,             # Batch size\n",
        "    var_reduce=0,         # No variance reduction\n",
        "    adapt_c=0,            # No adaptive correction\n",
        "    alpha=0.3,            # Forgetting rate\n",
        "    bias_F=1.5e5,         # Correction factor\n",
        "    cool=1,              # Cooling time for swaps\n",
        "    burn=0.6,             # Burn-in period for annealing\n",
        "    Tanneal=1.02,         # Temperature annealing factor\n",
        "    LRanneal=0.984,         # Learning rate annealing factor\n",
        "    momentum = 0.9\n",
        ")"
      ],
      "metadata": {
        "id": "fdU6Xoky5O5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use GPU if available, otherwise fall back to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Create a simple linear dataset\n",
        "np.random.seed(42)\n",
        "x = np.random.rand(100, 1).astype(np.float32)\n",
        "y = 3 * x + 1 + np.random.randn(100, 1).astype(np.float32) * 0.1  # Linear relationship y = 3x + 1 + noise\n",
        "\n",
        "# Convert the numpy arrays to torch tensors\n",
        "x_train = torch.tensor(x, dtype=torch.float32).to(device)\n",
        "y_train = torch.tensor(y, dtype=torch.float32).to(device)\n",
        "\n",
        "# Define a simple neural network model for regression\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, 50)  # 1 input feature to 10 hidden units\n",
        "        self.fc2 = nn.Linear(50, 1)  # 10 hidden units to 1 output feature\n",
        "        self.relu = nn.ReLU()  # ReLU activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))  # First layer + ReLU activation\n",
        "        x = self.fc2(x)  # Second layer (output)\n",
        "        return x\n",
        "\n",
        "# Initialize the neural network\n",
        "model = SimpleNN().to(device)\n",
        "\n",
        "# Duplicate the model structure\n",
        "model_duplicate = SimpleNN().to(device)\n",
        "\n",
        "# Copy the weights from the original model to the duplicate\n",
        "model_duplicate.load_state_dict(model.state_dict())\n",
        "\n",
        "# Create a DataLoader to handle batching\n",
        "train_dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
        "training_data = DataLoader(train_dataset, batch_size=parameters.batch, shuffle=True)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu88ToPE5RPV",
        "outputId": "8fb1b29a-fefd-4178-ebc6-f50a4ad8ab0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nets = []\n",
        "nets.append(model)\n",
        "nets.append(model_duplicate)"
      ],
      "metadata": {
        "id": "rixuxCvZ5UHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer(nets, training_data, parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HWjMFwPA5lSP",
        "outputId": "c0c8a40c-6ca3-4846-f586-47d2f2938062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chain 1 Initial learning rate 1.00e-04 temperature 5.00e-02\n",
            "Chain 0 Initial learning rate 1.52e-04 temperature 2.50e-01\n",
            "Epoch 0 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 0 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(7.8027, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(7.8027, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.2296505465363947\n",
            "Check second term: nan\n",
            "Check loss: tensor(7.7017, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(7.5141, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5500796041202634\n",
            "Check second term: nan\n",
            "Epoch 2 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 2 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(7.7592, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(7.2620, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.633510404873745\n",
            "Check second term: nan\n",
            "Check loss: tensor(7.6299, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(7.3981, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.2702110360304024\n",
            "Check second term: nan\n",
            "Epoch 4 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 4 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(7.4385, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(7.3363, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.4377729884279922\n",
            "Check second term: nan\n",
            "Check loss: tensor(7.2204, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(7.0659, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.06138766698639759\n",
            "Check second term: nan\n",
            "Epoch 6 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 6 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(7.2381, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(6.7546, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.08897943209976497\n",
            "Check second term: nan\n",
            "Check loss: tensor(7.2144, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(6.6915, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -4.1697181130174545\n",
            "Check second term: nan\n",
            "Epoch 8 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 8 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(7.3000, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(6.5667, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.848201922854818\n",
            "Check second term: nan\n",
            "Check loss: tensor(7.3712, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(6.5131, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.03705827673231329\n",
            "Check second term: nan\n",
            "Epoch 10 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 10 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(7.2090, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(6.3107, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.2226498323101809\n",
            "Check second term: nan\n",
            "Check loss: tensor(7.0205, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(6.1251, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.16118256222634766\n",
            "Check second term: nan\n",
            "Epoch 12 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 12 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(6.9768, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(5.8595, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.7749451454896872\n",
            "Check second term: nan\n",
            "Check loss: tensor(7.0048, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(5.5497, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.06597445916512698\n",
            "Check second term: nan\n",
            "Epoch 14 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 14 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(6.9688, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(5.3386, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5620116079652311\n",
            "Check second term: nan\n",
            "Check loss: tensor(6.8523, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(5.3799, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.48612126051430116\n",
            "Check second term: nan\n",
            "Epoch 16 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 16 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(6.8377, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(5.2655, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.9655129275338168\n",
            "Check second term: nan\n",
            "Check loss: tensor(6.5998, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(5.1592, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.13082298148010607\n",
            "Check second term: nan\n",
            "Epoch 18 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 18 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(6.3650, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(5.0552, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.36094728455228187\n",
            "Check second term: nan\n",
            "Check loss: tensor(6.2114, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.8685, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.0230657162553864\n",
            "Check second term: nan\n",
            "Epoch 20 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 20 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(6.0039, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.8598, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.21151003944082214\n",
            "Check second term: nan\n",
            "Check loss: tensor(5.6953, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.8519, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.14263289324641987\n",
            "Check second term: nan\n",
            "Epoch 22 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 22 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(5.4679, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.8322, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6707158566867157\n",
            "Check second term: nan\n",
            "Check loss: tensor(5.2870, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.7637, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.22527685147329043\n",
            "Check second term: nan\n",
            "Epoch 24 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 24 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(5.2720, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.8922, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.3538690594630822\n",
            "Check second term: nan\n",
            "Check loss: tensor(5.0462, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.9160, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.11652781423175439\n",
            "Check second term: nan\n",
            "Epoch 26 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 26 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(4.9854, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.8982, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.9792759196856544\n",
            "Check second term: nan\n",
            "Check loss: tensor(5.0481, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.9042, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5476968547220212\n",
            "Check second term: nan\n",
            "Epoch 28 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 28 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(4.9694, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.7184, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.7644326391623271\n",
            "Check second term: nan\n",
            "Check loss: tensor(4.9756, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.8043, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.2498727667062435\n",
            "Check second term: nan\n",
            "Epoch 30 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 30 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(5.0377, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.8548, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.4900204006794158\n",
            "Check second term: nan\n",
            "Check loss: tensor(5.0063, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.8631, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.19528454161583134\n",
            "Check second term: nan\n",
            "Epoch 32 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 32 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(4.9511, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.9136, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.0630918284290436\n",
            "Check second term: nan\n",
            "Check loss: tensor(4.9367, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.9606, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.26137313676866464\n",
            "Check second term: nan\n",
            "Epoch 34 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 34 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(4.8786, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(5.0498, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.4733845769031468\n",
            "Check second term: nan\n",
            "Check loss: tensor(4.7134, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(5.0074, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.962651115716244\n",
            "Check second term: nan\n",
            "Epoch 36 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 36 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(4.6742, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(5.0199, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6150106794178726\n",
            "Check second term: nan\n",
            "Check loss: tensor(4.4895, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(5.1148, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.32007946804429915\n",
            "Check second term: nan\n",
            "Epoch 38 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 38 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(4.5925, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(5.2317, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6610666124866599\n",
            "Check second term: nan\n",
            "Check loss: tensor(4.6837, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(5.1999, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.229178984493812\n",
            "Check second term: nan\n",
            "Epoch 40 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 40 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(4.5869, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(5.0704, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.8233209689244444\n",
            "Check second term: nan\n",
            "Check loss: tensor(4.5276, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.8904, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.6749472233213947\n",
            "Check second term: nan\n",
            "Epoch 42 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 42 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(4.3902, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.8554, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.1791504454717871\n",
            "Check second term: nan\n",
            "Check loss: tensor(4.2572, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.7295, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.8941551798899909\n",
            "Check second term: nan\n",
            "Epoch 44 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 44 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(4.1387, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.6234, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.85510163319139\n",
            "Check second term: nan\n",
            "Check loss: tensor(3.9949, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.6040, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5992440543621188\n",
            "Check second term: nan\n",
            "Epoch 46 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 46 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(3.8480, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.6265, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.4152164330369622\n",
            "Check second term: nan\n",
            "Check loss: tensor(3.6402, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.6321, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.04618501582072701\n",
            "Check second term: nan\n",
            "Epoch 48 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 48 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(3.5953, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.7250, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5899517124064425\n",
            "Check second term: nan\n",
            "Check loss: tensor(3.4978, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.6442, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.8684532536807165\n",
            "Check second term: nan\n",
            "Epoch 50 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 50 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(3.5053, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.5144, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.0329012964368074\n",
            "Check second term: nan\n",
            "Check loss: tensor(3.5951, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.5486, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -4.24097935315288\n",
            "Check second term: nan\n",
            "Epoch 52 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 52 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(3.5933, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.4400, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.0790564488868886\n",
            "Check second term: nan\n",
            "Check loss: tensor(3.5807, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.3675, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.15611526033959022\n",
            "Check second term: nan\n",
            "Epoch 54 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 54 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(3.5036, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.2558, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.7461812964830179\n",
            "Check second term: nan\n",
            "Check loss: tensor(3.3531, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.2043, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.7100576090597605\n",
            "Check second term: nan\n",
            "Epoch 56 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 56 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(3.2656, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.1793, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.7532974866648805\n",
            "Check second term: nan\n",
            "Check loss: tensor(3.1890, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.1696, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.9200359002769612\n",
            "Check second term: nan\n",
            "Epoch 58 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 58 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(3.1830, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.0901, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.4539828092824706\n",
            "Check second term: nan\n",
            "Check loss: tensor(3.1041, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.0339, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.9818628146152945\n",
            "Check second term: nan\n",
            "Epoch 60 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 60 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(3.1000, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.0462, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6868942537576397\n",
            "Check second term: nan\n",
            "Check loss: tensor(3.0668, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(4.0487, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.41749675148766874\n",
            "Check second term: nan\n",
            "Epoch 62 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 62 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(2.9978, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.9522, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.651167903872855\n",
            "Check second term: nan\n",
            "Check loss: tensor(3.0176, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.9404, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.6301838241572844\n",
            "Check second term: nan\n",
            "Epoch 64 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 64 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(3.0009, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.8847, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.06163049602430001\n",
            "Check second term: nan\n",
            "Check loss: tensor(2.9866, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.7967, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.9463120810922666\n",
            "Check second term: nan\n",
            "Epoch 66 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 66 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(2.9332, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.7359, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.7803340846084208\n",
            "Check second term: nan\n",
            "Check loss: tensor(2.8385, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.7148, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.060318309409812525\n",
            "Check second term: nan\n",
            "Epoch 68 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 68 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(2.7278, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.7464, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.03958259224675197\n",
            "Check second term: nan\n",
            "Check loss: tensor(2.6474, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.7153, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.6307068267784957\n",
            "Check second term: nan\n",
            "Epoch 70 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 70 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(2.6454, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.6478, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.2948351874660564\n",
            "Check second term: nan\n",
            "Check loss: tensor(2.5861, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.7063, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.3597592166005033\n",
            "Check second term: nan\n",
            "Epoch 72 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 72 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(2.5309, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.7199, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.6424219050131543\n",
            "Check second term: nan\n",
            "Check loss: tensor(2.4643, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.6696, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.1685662234960502\n",
            "Check second term: nan\n",
            "Epoch 74 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 74 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(2.4410, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.6676, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.2052195470982564\n",
            "Check second term: nan\n",
            "Check loss: tensor(2.4790, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.5238, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.1356747849445346\n",
            "Check second term: nan\n",
            "Epoch 76 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 76 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(2.5180, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.4162, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.46371489003503147\n",
            "Check second term: nan\n",
            "Check loss: tensor(2.4845, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.3593, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.30778812620382745\n",
            "Check second term: nan\n",
            "Epoch 78 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 78 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(2.4873, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.2972, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.2657256177879257\n",
            "Check second term: nan\n",
            "Check loss: tensor(2.4847, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.2414, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.28686273934236467\n",
            "Check second term: nan\n",
            "Epoch 80 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 80 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(2.4533, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.2215, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.009540221538810114\n",
            "Check second term: nan\n",
            "Check loss: tensor(2.4002, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.2727, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.9888128081682582\n",
            "Check second term: nan\n",
            "Epoch 82 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 82 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(2.4290, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.3018, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.076449096014565\n",
            "Check second term: nan\n",
            "Check loss: tensor(2.4133, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.3108, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.15267023241367245\n",
            "Check second term: nan\n",
            "Epoch 84 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 84 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(2.3871, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.2170, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.28652132266055313\n",
            "Check second term: nan\n",
            "Check loss: tensor(2.3278, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.1127, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.2718244032511343\n",
            "Check second term: nan\n",
            "Epoch 86 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 86 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(2.2483, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.0451, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6826972271174326\n",
            "Check second term: nan\n",
            "Check loss: tensor(2.1777, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.0237, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.139279291979461\n",
            "Check second term: nan\n",
            "Epoch 88 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 88 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(2.1225, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.0114, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.9436576153852338\n",
            "Check second term: nan\n",
            "Check loss: tensor(2.0993, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.0181, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.09939835093867763\n",
            "Check second term: nan\n",
            "Epoch 90 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 90 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(2.0640, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.0156, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.1415814692733448\n",
            "Check second term: nan\n",
            "Check loss: tensor(2.0544, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.0217, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.050654396486753905\n",
            "Check second term: nan\n",
            "Epoch 92 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 92 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.9847, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.0305, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.45912349369429006\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.8988, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(3.0214, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.2268635712472602\n",
            "Check second term: nan\n",
            "Epoch 94 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 94 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.8161, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.9384, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.39672572390199573\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.7874, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.8921, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.23372553891662098\n",
            "Check second term: nan\n",
            "Epoch 96 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 96 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.7821, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.8900, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.3946334647473195\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.7676, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.8714, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.8549489396438603\n",
            "Check second term: nan\n",
            "Epoch 98 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 98 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.7695, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.8364, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.8175081755410217\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.7702, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.7916, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.047211214315604\n",
            "Check second term: nan\n",
            "Epoch 100 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 100 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.7521, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.7936, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.9449688178767086\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.7389, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.7415, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.48091403049996023\n",
            "Check second term: nan\n",
            "Epoch 102 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 102 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.7482, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.6852, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.4756677864431063\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.7310, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.6355, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.6205476072716687\n",
            "Check second term: nan\n",
            "Epoch 104 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 104 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.7347, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.6216, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.34779700237816213\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.7161, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.6323, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.46701509348184\n",
            "Check second term: nan\n",
            "Epoch 106 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 106 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.6899, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.5822, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.9827756907435397\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.6662, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.5244, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.20727073456763\n",
            "Check second term: nan\n",
            "Epoch 108 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 108 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.6048, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.4818, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.014097845452222731\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.5513, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.4576, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.9774759867494437\n",
            "Check second term: nan\n",
            "Epoch 110 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 110 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.5306, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.3980, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.25212586550035443\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.5180, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.3394, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.8574983540697758\n",
            "Check second term: nan\n",
            "Epoch 112 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 112 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.4769, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.3070, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.1964475385537017\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.4670, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.2822, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -4.478216461721548\n",
            "Check second term: nan\n",
            "Epoch 114 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 114 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.4798, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.2549, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.8770025629031504\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.4845, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.1868, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.1410935935163873\n",
            "Check second term: nan\n",
            "Epoch 116 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 116 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.4498, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.1504, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.29296952071468724\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.4161, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.1198, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.0385614800816361\n",
            "Check second term: nan\n",
            "Epoch 118 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 118 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.3808, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.1461, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.2527706665384852\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.3678, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.1828, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.497915149146958\n",
            "Check second term: nan\n",
            "Epoch 120 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 120 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.3650, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.2374, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -4.410057889768992\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.3765, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.2626, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.1428431786643465\n",
            "Check second term: nan\n",
            "Epoch 122 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 122 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.3689, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.2381, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6392252368363205\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.3452, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.2445, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.6064430967599446\n",
            "Check second term: nan\n",
            "Epoch 124 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 124 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.3357, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.2066, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.031178501558904958\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.3295, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.1928, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.462990458104946\n",
            "Check second term: nan\n",
            "Epoch 126 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 126 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.3155, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.1660, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.7884670179218031\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.3100, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.1436, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5373162355866884\n",
            "Check second term: nan\n",
            "Epoch 128 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 128 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.3242, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.0987, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.0912221019820905\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.3231, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.0741, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.050860247032872875\n",
            "Check second term: nan\n",
            "Epoch 130 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 130 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.3220, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(2.0384, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.7860154880341307\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.3078, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.9967, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.2823626069237148\n",
            "Check second term: nan\n",
            "Epoch 132 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 132 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.2972, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.9370, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.7685209274440301\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.2848, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.8821, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5384433191643329\n",
            "Check second term: nan\n",
            "Epoch 134 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 134 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.2925, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.8389, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.025938710790531453\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.2745, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.7817, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.3593045210771769\n",
            "Check second term: nan\n",
            "Epoch 136 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 136 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.2350, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.7643, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.1727079621262482\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.2012, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.7252, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.3787289665745598\n",
            "Check second term: nan\n",
            "Epoch 138 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 138 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.1741, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.7077, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.09329231412212975\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.1586, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.7010, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.0515039341579978\n",
            "Check second term: nan\n",
            "Epoch 140 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 140 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.1565, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.6892, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.48871325431932156\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.1706, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.6933, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.06964113511369019\n",
            "Check second term: nan\n",
            "Epoch 142 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 142 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.1708, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.6726, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.0962452219812002\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.1671, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.6586, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.9769345356047424\n",
            "Check second term: nan\n",
            "Epoch 144 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 144 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.1508, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.6197, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.012805512399403245\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.1412, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.5870, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5206559243136566\n",
            "Check second term: nan\n",
            "Epoch 146 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 146 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.1150, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.5581, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.030547461054607088\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.1058, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.5584, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.1763450063509678\n",
            "Check second term: nan\n",
            "Epoch 148 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 148 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.0961, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.5313, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.8799117874888279\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.1002, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.4864, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.875720671425557\n",
            "Check second term: nan\n",
            "Epoch 150 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 150 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.0910, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.4491, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.20714593683528\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.0848, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.4177, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.0033688310706923557\n",
            "Check second term: nan\n",
            "Epoch 152 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 152 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.0679, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.3955, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.26268067478529283\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.0416, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.3630, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.1629338500625713\n",
            "Check second term: nan\n",
            "Epoch 154 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 154 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.0261, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.3260, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.7972992371207032\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.0105, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.2967, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.047038121271685045\n",
            "Check second term: nan\n",
            "Epoch 156 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 156 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(1.0068, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.2988, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.47559429447933\n",
            "Check second term: nan\n",
            "Check loss: tensor(1.0090, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.3229, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.48105933421987923\n",
            "Check second term: nan\n",
            "Epoch 158 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 158 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.9985, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.3291, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.175445150493759\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.9983, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.3313, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6533349099040154\n",
            "Check second term: nan\n",
            "Epoch 160 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 160 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.9834, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.3356, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6536120916125409\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.9659, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.3387, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5943760172844345\n",
            "Check second term: nan\n",
            "Epoch 162 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 162 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.9436, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.3492, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.13164334450010415\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.9383, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.3359, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.009801840334312\n",
            "Check second term: nan\n",
            "Epoch 164 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 164 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.9261, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.3318, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.2808557506617315\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.9164, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.3157, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.3508636222837189\n",
            "Check second term: nan\n",
            "Epoch 166 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 166 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.9179, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.3008, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.9923726787062455\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.9010, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.3125, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.048144792559318\n",
            "Check second term: nan\n",
            "Epoch 168 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 168 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.8857, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.3132, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.935871068874336\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.8745, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.3076, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.10075038699017438\n",
            "Check second term: nan\n",
            "Epoch 170 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 170 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.8725, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.2927, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6655524628414842\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.8685, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.2667, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.9249713438004714\n",
            "Check second term: nan\n",
            "Epoch 172 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 172 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.8653, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.2545, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.14807816140726865\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.8555, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.2365, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.9168229468313591\n",
            "Check second term: nan\n",
            "Epoch 174 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 174 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.8610, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.2233, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.709040222372513\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.8628, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.1907, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.7784093474265336\n",
            "Check second term: nan\n",
            "Epoch 176 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 176 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.8627, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.1742, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.708021062356668\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.8563, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.1737, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.45665179609933804\n",
            "Check second term: nan\n",
            "Epoch 178 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 178 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.8520, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.1710, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.5788218719639215\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.8355, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.1544, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.0553669623134594\n",
            "Check second term: nan\n",
            "Epoch 180 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 180 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.8220, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.1512, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.974525481702051\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.8075, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.1461, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.7044076859879111\n",
            "Check second term: nan\n",
            "Epoch 182 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 182 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.8033, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.1522, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.10893533114131786\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.8008, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.1401, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.4041293927916425\n",
            "Check second term: nan\n",
            "Epoch 184 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 184 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7995, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.1459, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.648755732497017\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.7976, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.1499, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.7782408800755454\n",
            "Check second term: nan\n",
            "Epoch 186 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 186 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7892, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.1353, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.7315463149605654\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.7844, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.1087, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.114978600270042\n",
            "Check second term: nan\n",
            "Epoch 188 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 188 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7811, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.0809, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.5782604287034543\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.7764, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.0608, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6863358884569329\n",
            "Check second term: nan\n",
            "Epoch 190 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 190 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7673, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.0398, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.2362219059981294\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.7640, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.0340, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.46537374055503883\n",
            "Check second term: nan\n",
            "Epoch 192 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 192 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7610, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.0259, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.1351571430331032\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.7642, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.0200, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.795604200386922\n",
            "Check second term: nan\n",
            "Epoch 194 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 194 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7646, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(1.0086, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.2154218408616547\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.7716, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.9951, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.6899918959398093\n",
            "Check second term: nan\n",
            "Epoch 196 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 196 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7787, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.9747, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.9929771331905201\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.7908, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.9711, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.4808546548096722\n",
            "Check second term: nan\n",
            "Epoch 198 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 198 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7959, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.9602, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.7710336629371524\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.7996, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.9474, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.3054363155969226\n",
            "Check second term: nan\n",
            "Epoch 200 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 200 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7971, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.9363, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.33778367594359265\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.7939, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.9362, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6700608483412523\n",
            "Check second term: nan\n",
            "Epoch 202 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 202 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7884, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.9354, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.233320152683264\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.7766, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.9333, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6299521869482552\n",
            "Check second term: nan\n",
            "Epoch 204 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 204 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7653, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.9195, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.3121401036539353\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.7597, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.9057, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.9084694379483746\n",
            "Check second term: nan\n",
            "Epoch 206 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 206 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7532, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.9007, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.5537761405204749\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.7477, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.8897, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.1222477382672453\n",
            "Check second term: nan\n",
            "Epoch 208 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 208 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7461, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.8910, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5215623002251941\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.7491, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.8812, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.236771949228964\n",
            "Check second term: nan\n",
            "Epoch 210 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 210 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7496, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.8726, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.442763809201981\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.7439, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.8583, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5330011635579875\n",
            "Check second term: nan\n",
            "Epoch 212 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 212 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7344, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.8441, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.8401180888734762\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.7229, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.8349, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.2595704163848576\n",
            "Check second term: nan\n",
            "Epoch 214 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 214 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7117, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.8238, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.43708389280005067\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.7054, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.8123, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.0325528830741575\n",
            "Check second term: nan\n",
            "Epoch 216 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 216 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.7000, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.7969, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5012469471873755\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.6950, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.7966, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.2849173643416942\n",
            "Check second term: nan\n",
            "Epoch 218 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 218 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.6902, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.7855, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.4025955936505756\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.6885, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.7756, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.6789647261679939\n",
            "Check second term: nan\n",
            "Epoch 220 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 220 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.6875, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.7695, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.7523065025010607\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.6795, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.7582, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.5228110837596494\n",
            "Check second term: nan\n",
            "Epoch 222 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 222 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.6675, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.7465, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.8906307166621382\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.6585, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.7455, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.188909127209707\n",
            "Check second term: nan\n",
            "Epoch 224 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 224 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.6519, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.7396, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.031005301643924343\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.6463, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.7396, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.20202797387656676\n",
            "Check second term: nan\n",
            "Epoch 226 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 226 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.6410, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.7383, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.7667493223347002\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.6372, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.7382, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.07324189747498379\n",
            "Check second term: nan\n",
            "Epoch 228 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 228 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.6367, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.7378, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5592936332604881\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.6341, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.7326, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.2620235093815823\n",
            "Check second term: nan\n",
            "Epoch 230 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 230 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.6339, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.7228, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.1280022646724923\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.6357, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.7057, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6780410967700523\n",
            "Check second term: nan\n",
            "Epoch 232 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 232 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.6372, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6886, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.1642430735437492\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.6345, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6775, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.2426077711625374\n",
            "Check second term: nan\n",
            "Epoch 234 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 234 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.6316, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6707, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.8684501519374856\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.6339, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6663, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6300044470466372\n",
            "Check second term: nan\n",
            "Epoch 236 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 236 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.6304, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6662, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.088847287282672\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.6268, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6591, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.7586862829838332\n",
            "Check second term: nan\n",
            "Epoch 238 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 238 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.6267, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6567, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.1321054393465197\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.6243, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6551, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.3679019246804562\n",
            "Check second term: nan\n",
            "Epoch 240 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 240 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.6206, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6553, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.27413707499316475\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.6197, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6538, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.7516746023693689\n",
            "Check second term: nan\n",
            "Epoch 242 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 242 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.6186, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6481, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.0530608877977685\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.6192, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6408, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.1855835820727562\n",
            "Check second term: nan\n",
            "Epoch 244 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 244 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.6153, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6308, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.085079617918935\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.6108, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6222, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.06364243546651087\n",
            "Check second term: nan\n",
            "Epoch 246 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 246 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.6069, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6156, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.710609462718561\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.6023, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6110, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5543019831715938\n",
            "Check second term: nan\n",
            "Epoch 248 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 248 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5986, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6058, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.9677400607929427\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5979, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.6031, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.601334235856558\n",
            "Check second term: nan\n",
            "Epoch 250 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 250 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5929, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5997, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.8062694440143636\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5880, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5954, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.4076717098197175\n",
            "Check second term: nan\n",
            "Epoch 252 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 252 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5831, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5916, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.0249051910812472\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5808, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5920, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.9353586052404066\n",
            "Check second term: nan\n",
            "Epoch 254 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 254 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5771, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5930, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.8229486043006609\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5767, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5952, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.770720071791824\n",
            "Check second term: nan\n",
            "Epoch 256 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 256 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5757, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5936, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.29087465642720756\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5743, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5872, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.460101537884638\n",
            "Check second term: nan\n",
            "Epoch 258 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 258 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5743, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5792, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.957396044199038\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5749, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5702, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.098195014881521\n",
            "Check second term: nan\n",
            "Epoch 260 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 260 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5728, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5642, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.1464531710520647\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5699, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5560, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.4656801042500802\n",
            "Check second term: nan\n",
            "Epoch 262 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 262 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5707, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5491, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.971325901688628\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5720, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5404, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.4779184595559737\n",
            "Check second term: nan\n",
            "Epoch 264 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 264 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5713, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5308, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.1121696642144436\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5679, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5258, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.8860159980813938\n",
            "Check second term: nan\n",
            "Epoch 266 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 266 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5643, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5185, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.3923561373603521\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5617, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5113, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.3952421074874137\n",
            "Check second term: nan\n",
            "Epoch 268 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 268 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5596, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.5033, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.27120695460366234\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5551, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4970, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.0727055391499065\n",
            "Check second term: nan\n",
            "Epoch 270 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 270 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5520, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4889, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.2015482784781923\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5482, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4853, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.059727841223943\n",
            "Check second term: nan\n",
            "Epoch 272 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 272 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5478, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4824, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.22653007188296156\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5463, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4802, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.472936081789311\n",
            "Check second term: nan\n",
            "Epoch 274 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 274 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5435, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4800, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.32845332305664926\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5410, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4789, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.3653576087461696\n",
            "Check second term: nan\n",
            "Epoch 276 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 276 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5376, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4748, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.3791238948413338\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5355, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4725, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.705961385573355\n",
            "Check second term: nan\n",
            "Epoch 278 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 278 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5325, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4709, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5388962861552719\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5296, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4681, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.7721778259790123\n",
            "Check second term: nan\n",
            "Epoch 280 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 280 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5274, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4658, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.87502323870123\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5263, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4607, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6814386361033192\n",
            "Check second term: nan\n",
            "Epoch 282 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 282 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5258, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4571, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -4.0112808568986535\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5253, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4514, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.07029555981319566\n",
            "Check second term: nan\n",
            "Epoch 284 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 284 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5251, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4505, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.36147096379653315\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5241, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4479, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.3463871391828247\n",
            "Check second term: nan\n",
            "Epoch 286 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 286 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5231, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4434, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5511471182676724\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5208, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4401, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.857713684196119\n",
            "Check second term: nan\n",
            "Epoch 288 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 288 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5187, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4373, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.06788596850620983\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5174, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4362, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.7966441638862871\n",
            "Check second term: nan\n",
            "Epoch 290 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 290 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5155, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4316, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.01527487013486003\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5125, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4257, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.0821437397044855\n",
            "Check second term: nan\n",
            "Epoch 292 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 292 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5090, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4223, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.139381198495862\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5066, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4184, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5254733198139336\n",
            "Check second term: nan\n",
            "Epoch 294 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 294 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5036, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4137, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.904765351653397\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5024, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4106, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.21958308655067724\n",
            "Check second term: nan\n",
            "Epoch 296 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 296 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.5007, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4066, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.098114897314268\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.5000, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.4024, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.62102076493708\n",
            "Check second term: nan\n",
            "Epoch 298 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 298 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4990, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3977, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.0603170198584113\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4991, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3929, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.304487498417393\n",
            "Check second term: nan\n",
            "Epoch 300 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 300 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4997, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3884, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.4934127634444903\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4982, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3867, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.9600099429497984\n",
            "Check second term: nan\n",
            "Epoch 302 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 302 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4958, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3837, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6964169750371755\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4930, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3791, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.08899964202309234\n",
            "Check second term: nan\n",
            "Epoch 304 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 304 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4910, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3779, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5437132925635568\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4890, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3763, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -4.335566299528901\n",
            "Check second term: nan\n",
            "Epoch 306 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 306 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4877, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3739, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.7257696880356204\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4869, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3710, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.9060751109153975\n",
            "Check second term: nan\n",
            "Epoch 308 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 308 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4857, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3704, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.4609987186930824\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4843, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3670, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6887667679287944\n",
            "Check second term: nan\n",
            "Epoch 310 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 310 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4835, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3645, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.70192185699535\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4836, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3629, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.5610974060332585\n",
            "Check second term: nan\n",
            "Epoch 312 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 312 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4829, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3615, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.5840643586538512\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4823, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3615, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.3090831804310654\n",
            "Check second term: nan\n",
            "Epoch 314 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 314 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4820, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3617, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5712107674403883\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4817, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3597, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.2542116855295839\n",
            "Check second term: nan\n",
            "Epoch 316 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 316 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4811, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3577, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6455190830855392\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4802, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3560, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.9143848969435125\n",
            "Check second term: nan\n",
            "Epoch 318 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 318 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4797, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3544, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.8627813882858781\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4796, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3523, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.14874873876957964\n",
            "Check second term: nan\n",
            "Epoch 320 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 320 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4788, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3491, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.9853479368239783\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4769, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3467, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.4400572621342217\n",
            "Check second term: nan\n",
            "Epoch 322 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 322 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4762, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3455, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.673543428016409\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4762, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3438, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.33411389929968927\n",
            "Check second term: nan\n",
            "Epoch 324 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 324 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4757, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3409, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.6083694401317663\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4757, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3372, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.4650138261169958\n",
            "Check second term: nan\n",
            "Epoch 326 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 326 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4743, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3349, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.92660187486325\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4731, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3344, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.22324845009940825\n",
            "Check second term: nan\n",
            "Epoch 328 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 328 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4726, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3330, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.4265670341140887\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4714, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3317, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.308186825850561\n",
            "Check second term: nan\n",
            "Epoch 330 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 330 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4708, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3307, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.3253604967044061\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4696, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3284, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.1860647162018626\n",
            "Check second term: nan\n",
            "Epoch 332 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 332 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4685, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3266, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.40333966361048984\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4670, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3242, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.2270785981875487\n",
            "Check second term: nan\n",
            "Epoch 334 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 334 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4666, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3235, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -4.342657970101641\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4665, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3228, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.5707641991174397\n",
            "Check second term: nan\n",
            "Epoch 336 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 336 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4656, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3226, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.706855418096788\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4646, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3210, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.8641145197160541\n",
            "Check second term: nan\n",
            "Epoch 338 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 338 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4637, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3192, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.20157341622275385\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4625, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3165, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.3492936741279251\n",
            "Check second term: nan\n",
            "Epoch 340 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 340 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4614, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3152, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5271329644245629\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4608, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3119, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.4713663047077503\n",
            "Check second term: nan\n",
            "Epoch 342 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 342 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4607, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3100, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5941217637996775\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4602, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3095, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.2225925490611043\n",
            "Check second term: nan\n",
            "Epoch 344 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 344 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4594, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3079, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.2697035992078389\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4584, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3068, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.1410245668674855\n",
            "Check second term: nan\n",
            "Epoch 346 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 346 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4568, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3053, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.11143199104792662\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4560, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3038, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.8551638727429774\n",
            "Check second term: nan\n",
            "Epoch 348 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 348 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4549, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3024, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.3142440267360345\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4541, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3018, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.45652966051260885\n",
            "Check second term: nan\n",
            "Epoch 350 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 350 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4539, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.3006, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.9707229373939876\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4537, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2989, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.015720745206056336\n",
            "Check second term: nan\n",
            "Epoch 352 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 352 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4534, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2975, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.7621271598922805\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4535, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2964, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.9959114521645844\n",
            "Check second term: nan\n",
            "Epoch 354 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 354 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4531, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2955, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.139182349608652\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4530, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2943, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.2944256575448219\n",
            "Check second term: nan\n",
            "Epoch 356 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 356 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4517, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2929, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.4286000873484772\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4507, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2911, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.5778361898294988\n",
            "Check second term: nan\n",
            "Epoch 358 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 358 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4499, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2900, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.9886095188237976\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4495, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2877, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.13480068061550635\n",
            "Check second term: nan\n",
            "Epoch 360 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 360 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4491, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2859, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5099645605312747\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4486, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2844, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.7408499603230696\n",
            "Check second term: nan\n",
            "Epoch 362 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 362 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4480, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2824, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.8704321823764032\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4479, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2808, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6560099723910887\n",
            "Check second term: nan\n",
            "Epoch 364 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 364 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4480, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2794, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.794061905264316\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4474, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2785, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.4913433055811254\n",
            "Check second term: nan\n",
            "Epoch 366 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 366 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4474, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2779, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.4050731452226437\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4464, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2770, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.2423888871426214\n",
            "Check second term: nan\n",
            "Epoch 368 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 368 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4460, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2758, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.3298300774239839\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4452, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2752, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.568446544021608\n",
            "Check second term: nan\n",
            "Epoch 370 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 370 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4445, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2740, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.409968485061589\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4437, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2729, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.31119351670886014\n",
            "Check second term: nan\n",
            "Epoch 372 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 372 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4430, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2720, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.4678778732202282\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4425, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2710, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.5190629060462955\n",
            "Check second term: nan\n",
            "Epoch 374 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 374 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4418, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2703, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.7004412231261595\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4412, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2695, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.0958843404536955\n",
            "Check second term: nan\n",
            "Epoch 376 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 376 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4404, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2685, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.238688154497498\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4396, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2668, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.3171949838933756\n",
            "Check second term: nan\n",
            "Epoch 378 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 378 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4389, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2656, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.3733817334948909\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4385, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2649, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.4007907955747287\n",
            "Check second term: nan\n",
            "Epoch 380 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 380 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4382, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2644, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.223873969293262\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4377, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2627, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.3014197622389176\n",
            "Check second term: nan\n",
            "Epoch 382 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 382 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4375, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2611, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.018949630908935\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4374, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2599, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.0863059072058822\n",
            "Check second term: nan\n",
            "Epoch 384 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 384 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4372, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2587, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.05104347946673596\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4373, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2570, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.6866811776631556\n",
            "Check second term: nan\n",
            "Epoch 386 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 386 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4369, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2551, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.13588176873695834\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4364, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2541, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.21497556549190366\n",
            "Check second term: nan\n",
            "Epoch 388 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 388 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4359, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2528, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.3677697434992567\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4354, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2520, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.387623208209483\n",
            "Check second term: nan\n",
            "Epoch 390 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 390 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4351, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2511, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.5086453257078356\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4349, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2499, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.05756625497471911\n",
            "Check second term: nan\n",
            "Epoch 392 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 392 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4345, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2491, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.3487419612525884\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4339, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2478, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.7116071637784194\n",
            "Check second term: nan\n",
            "Epoch 394 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 394 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4334, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2466, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.08829769748554221\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4327, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2454, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.36036708401166334\n",
            "Check second term: nan\n",
            "Epoch 396 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 396 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4323, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2446, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.07861451636652748\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4319, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2438, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.05734685488550544\n",
            "Check second term: nan\n",
            "Epoch 398 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 398 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4315, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2431, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.14845053043656248\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4310, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2424, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.1422492626427694\n",
            "Check second term: nan\n",
            "Epoch 400 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 400 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4306, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2416, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -3.296631043961875\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4301, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2410, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.4696375478070727\n",
            "Check second term: nan\n",
            "Epoch 402 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 402 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4298, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2403, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.564557812945377\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4293, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2395, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.079177482633212\n",
            "Check second term: nan\n",
            "Epoch 404 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 404 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4287, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2389, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -2.727900815325926\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4284, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2381, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.6171286345896656\n",
            "Check second term: nan\n",
            "Epoch 406 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 406 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4281, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2370, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.143340330204425\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4278, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2364, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.12106344355001601\n",
            "Check second term: nan\n",
            "Epoch 408 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 408 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4275, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2355, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -1.4568907686396741\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4272, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2345, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.1391484256289824\n",
            "Check second term: nan\n",
            "Epoch 410 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 410 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4268, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2338, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.1338723962634273\n",
            "Check second term: nan\n",
            "Check loss: tensor(0.4263, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2331, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.06286770597983349\n",
            "Check second term: nan\n",
            "Epoch 412 Chain 0 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Epoch 412 Chain 1 loss std nan variance nan smooth variance nan adaptive c -1.00\n",
            "Check loss: tensor(0.4257, grad_fn=<MseLossBackward0>)\n",
            "Check loss: tensor(0.2323, grad_fn=<MseLossBackward0>)\n",
            "Check first term: -0.0020680263598707714\n",
            "Check second term: nan\n",
            "Check loss: "
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-f8e1377ef02d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-52-4ceed9d84dd7>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(nets, training_data, parameters)\u001b[0m\n\u001b[1;32m    117\u001b[0m       \u001b[0mloss_chains\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_of_chains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchains\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# variance-reduced negative log posterior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_reduce\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-21dd0bec1578>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Check loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mproposal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    618\u001b[0m                 )\n\u001b[1;32m    619\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def send_multipart(\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "delta_invT = 1 / 0.05 - 1 / 0.05"
      ],
      "metadata": {
        "id": "_qemBUFtwr3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stage_losses = [390.68483747541904]\n",
        "std_epoch = np.std(stage_losses, ddof=1)\n",
        "print(\"std_epoch\",std_epoch)"
      ],
      "metadata": {
        "id": "JfbF2rB-zgvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MRmq1XYD24nE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}